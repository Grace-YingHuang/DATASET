paper introduces dual decomposition framework deriving inference algorithms nlp problems approach relies standard algorithms oracle solvers together simple method forcing agreement different oracles approach provably solves linear programming lp relaxation global inference problem leads algorithms simple use existing decoding algorithms efficient avoid exact algorithms full model often exact empirically often recover correct solution spite using lp relaxation give experimental results two problems combination two lexicalized parsing models combination lexicalized parsing model trigram tagger dual decomposition linear programming relaxations natural language processing dual decomposition linear programming relaxations natural language processing dual decomposition linear programming relaxations natural language processing 
study products latent variable grammars paper show increasing quality automatically parsed data used gives higher accuracy grammars generative grammars reach scores wsj test set surpass even discriminative reranking systems without selftraining additionally show multiple grammars combined product model achieve even higher accuracy product model effective individual underlying grammars diverse combining multiple grammars disjoint sets unlabeled data results final test accuracy wsj test set broadcast news test set self-training products latent variable grammars self-training products latent variable grammars self-training products latent variable grammars 
present unified view two dependency parsers approximate loopy belief propagation parser smith eisner relaxed linear program martins et al representing model assumptions factor graph shed light optimization problems tackled method also propose new aggressive online algorithm learn model parameters makes use underlying variational representation algorithm require learning rate parameter provides single framework wide family convex loss functions including crfs structured svms experiments show performance languages turbo parsers: dependency parsing approximate variational inference turbo parsers: dependency parsing approximate variational inference turbo parsers: dependency parsing approximate variational inference 
paper present novel approach web search result clustering based automatic discovery word senses raw text task referred word sense induction wsi first acquire senses meanings query means graphbased clustering algorithm exploits cycles triangles squares graph query cluster search results based semantic similarity induced word senses experiments conducted datasets ambiguous queries show approach improves search result clustering terms clustering quality degree diversification inducing word senses improve web search result clustering inducing word senses improve web search result clustering inducing word senses improve web search result clustering 
computation meaning similarity operationalized models found widespread use many tasks ranging acquisition synonyms paraphrases word sense disambiguation textual entailment models typically directed representing words isolation thus best suited measuring similarity context paper propose probabilistic framework measuring similarity context central approach intuition word meaning represented probability distribution set latent senses modulated context experimental results lexical substitution word similarity show algorithm outperforms previously proposed models measuring distributional similarity context measuring distributional similarity context measuring distributional similarity context 
paper present novel approach enhance hierarchical machine translation systems linguistically motivated syntactic features rather directly using treebank categories previous studies learn set latent syntactic categories automatically parsed parallel corpus based hierarchical structure among phrase pairs well syntactic structure source side model nonterminal scfg rule decorated feature vector computed based distribution latent syntactic categories feature vectors utilized decoding time measure similarity syntactic analysis source side syntax scfg rules applied derive translations approach maintains advantages hierarchical translation systems time naturally incorporates soft syntactic constraints soft syntactic constraints hierarchical phrase-based translation using latent syntactic distributions soft syntactic constraints hierarchical phrase-based translation using latent syntactic distributions soft syntactic constraints hierarchical phrase-based translation using latent syntactic distributions 
prerequisite translation poetry implement ability produce translations meter rhyme mt examine whether hypothesis space system flexible enough accomodate constraints investigate impact constraints translation quality "poetic" statistical machine translation: rhyme meter "poetic" statistical machine translation: rhyme meter "poetic" statistical machine translation: rhyme meter 
electronic health records growing along large quantities clinical information could used research purposes protecting patient privacy becomes challenge needs met paper present novel hybrid system designed improve current used person names overcome task system comprises several components designed accomplish two separate goals achieve highest patient data exposed create methods filter false positives result system reached person names veteran health administration clinical notes considerably outperformed existing named entity recognition systems hybrid stepwise approach de-identifying person names clinical documents hybrid stepwise approach de-identifying person names clinical documents hybrid stepwise approach de-identifying person names clinical documents 
present three novel methods compactly storing large language models methods use substantially less space known approaches allow probabilities counts retrieved constant time speeds comparable modern language modeling toolkits basic approach generates explicit minimal perfect hash function maps model distinct integers enable storage associated values extensions approach exploit distributional characteristics data reduce storage costs including variable length coding values use tiered structures partition data efficient storage apply approach storing full google web set grams gigaword newswire corpus billion gigaword example store full count information cost bytes per around cost using current approach quantized counts bytes per applications tolerant certain class relatively innocuous errors unseen may accepted rare reduce latter cost byte per storing web memory: space efficient language models constant time retrieval storing web memory: space efficient language models constant time retrieval storing web memory: space efficient language models constant time retrieval 
show jointly performing semantic role labeling srl bitext improve srl results sides approach use monolingual srl systems produce argument candidates predicates bitext first simultaneously generate srl results two sides bitext using joint inference model model prefers bilingual srl result reasonable side bitext also consistent argument structures two sides evaluate consistency two argument structures also formulate model compute probability aligning two arguments experimented model parallel propbank data using joint inference model scores srl results chinese english text achieve respectively points higher results baseline monolingual srl combination systems respectively joint inference bilingual semantic role labeling joint inference bilingual semantic role labeling joint inference bilingual semantic role labeling 
polysemy major characteristic natural languages like words syntactic forms several meanings understanding correct meaning syntactic form great importance many nlp applications paper address important type syntactic polysemy multiple possible senses tense syntactic forms make discussion concrete introducing task tense sense disambiguation tsd given concrete tense syntactic form present sentence select appropriate sense among set possible senses using english grammar textbooks compiled syntactic sense dictionary comprising common tense syntactic forms semantic senses annotated thousands bnc sentences using defined senses describe supervised tsd algorithm trained annotations outperforms strong baseline task tense sense disambiguation: new syntactic polysemy task tense sense disambiguation: new syntactic polysemy task tense sense disambiguation: new syntactic polysemy task 
preliminary work symptom name recognition clinical records fcrs traditional chinese medicine tcm depicted paper problem viewed labeling character fcrs tcm tag osyc indicate character role beginning inside outside part symptom name task handled conditional random fields crfs based two types features symptom name recognition fmeasure reach recognition rate recognition error rate experiment settings feasibility effectiveness methods reasonable features verified several interesting helpful results shown detailed analysis recognizing symptom names fcrs tcm presented analyzing labeling results crfs preliminary work symptom name recognition free-text clinical records traditional chinese medicine using conditional random fields reasonable features preliminary work symptom name recognition free-text clinical records traditional chinese medicine using conditional random fields reasonable features preliminary work symptom name recognition free-text clinical records traditional chinese medicine using conditional random fields reasonable features 
several recent discourse parsers employed machine learning approaches methods require human annotators beforehand create extensive training corpus costly process hand unlabeled data abundant cheap collect paper propose novel method discourse relation classification based analysis cooccurring features unlabeled data taken account extending feature vectors given classifier experimental results rst discourse treebank corpus penn discourse treebank indicate proposed method brings significant improvement classification accuracy small training datasets used instance training sets labeled instances proposed method brings improvements accuracy compared baseline classifier believe proposed method first step towards detecting relations useful domains lack annotated data semi-supervised approach improve classification infrequent discourse relations using feature vector extension semi-supervised approach improve classification infrequent discourse relations using feature vector extension semi-supervised approach improve classification infrequent discourse relations using feature vector extension 
language pairs coverage test set parallel corpus important factor affects translation quality two respects vocabulary words information input sentence expressed different ways current smt systems cannot automatically select alternative way transfer information therefore given limited data order facilitate translation input side paper proposes novel method reduce translation difficulty using paraphrases utilise original phrases input sentence corresponding paraphrases build lattice estimated weights edge improve translation quality compared baseline system method achieves relative improvements terms bleu score small medium largescale translation tasks respectively results show proposed method effective resourcelimited language pairs also resourcesufficient pairs extent facilitating translation using source language paraphrase lattices facilitating translation using source language paraphrase lattices facilitating translation using source language paraphrase lattices 
today automatic evaluation metrics rouge become mode evaluating automatic summarization system however based duc tac evaluation results conroy schlesinger dang owczarzak showed performance gap humangenerated summaries summaries clearly visible manual evaluations often reflected automated evaluations using rouge scores paper present experiments comparing results manual evaluations versus automatic evaluations using text summarizer blogsum evaluated summary content using rouge compared results original candidate list olist results showed significant difference summaries olist summaries however two manual evaluations content using two different datasets show blogsum performed significantly better olist manual evaluation summary coherence also shows blogsum performs significantly better olist results agree previous work show need better automated summary evaluation metric rather standard rouge metric discrepancy automatic manual evaluation summaries discrepancy automatic manual evaluation summaries discrepancy automatic manual evaluation summaries 
present first evaluation utility automatic evaluation metrics surface realizations penn treebank data using outputs openccg xle realizers along ranked wordnet synonym substitutions collected corpus generated surface realizations outputs rated human annotators evaluated realizations using seven automatic metrics analyzed correlations obtained human judgments automatic scores contrast previous nlg find several metrics correlate moderately well human judgments adequacy fluency ter family performing best overall also find metrics correctly predict half significant systemlevel differences though none correct cases conclude discussion implications utility metrics evaluating generation presence variation result research corpus realizations made available research community meta-evaluation broad-coverage surface realization meta-evaluation broad-coverage surface realization meta-evaluation broad-coverage surface realization 
pos induction one popular tasks research unsupervised nlp many different methods proposed yet comparisons difficult make since little consensus evaluation framework many papers evaluate one two competitor systems evaluate seven different pos induction systems spanning nearly years work using variety measures show oldest simplest systems stand surprisingly well recent approaches since systems developed tested using data wsj corpus compare generalization abilities testing wsj multilingual corpus finally introduce idea evaluating systems based ability produce cluster prototypes useful input learner cases learner outperforms unsupervised system used initialize yielding results wsj improvements nonenglish corpora two decades unsupervised pos induction: far come? two decades unsupervised pos induction: far come? two decades unsupervised pos induction: far come? 
minimum error rate training algorithm model parameter training used statistical machine translation systems original formulation algorithm uses lists output decoder grow translation pool shapes surface actual optimization performed recent work done extend algorithm use entire translation lattice built decoder instead lists propose third intermediate way consisting growing translation pool using samples randomly drawn translation lattice empirically measure systematic improvement bleu scores compared training using lists without suffering increase computational complexity associated operating whole lattice minimum error rate training sampling translation lattice minimum error rate training sampling translation lattice minimum error rate training sampling translation lattice 
statistical language models used deployed systems speech recognition machine translation human language technologies almost exclusively models regarded linguistically na ve estimating amount text large small straightforward furthermore doggedly matched outperformed numerous competing proposals syntactically models unusual resilience well weaknesses examined demonstrated good even linguistically speaking large majority suggested improve one must explore language models focus positions weak revisiting case explicit syntactic information language models revisiting case explicit syntactic information language models revisiting case explicit syntactic information language models 
production parallel training corpora development statistical machine translation smt systems languages usually requires extensive manual effort active sample selection aims reduce labor time expense incurred producing resources attaining given performance benchmark smallest possible training corpus choosing informative nonredundant source sentences available candidate pool manual translation present novel discriminative sample selection strategy preferentially selects batches candidate sentences constructs lead erroneous translations development set proposed strategy supports diversity mechanism reduces redundancy selected batches simulation experiments translation tasks demonstrate superiority proposed approach number competing techniques random selection selection well recently proposed semisupervised active learning strategy discriminative sample selection statistical machine translation discriminative sample selection statistical machine translation discriminative sample selection statistical machine translation 
present new syntactic parser works top thus maintaining parse tree alternative parse hypotheses commonly used statistical parsers use dynamic programming algorithms work bottom entire sentence thus find complete fully connected parse end contrast subjective experimental evidence show people understand sentence go along close constraint parser keeps one fully connected syntactic trees intended operationalize cognitive fact parser achieves new best result topdown parsers error reduction previous best result parsers type roark improved performance due embracing large feature set available exchange giving dynamic programming top-down nearly-context-sensitive parsing top-down nearly-context-sensitive parsing top-down nearly-context-sensitive parsing 
introduce novel training algorithm unsupervised grammar induction called zoomed learning given training set test set goal algorithm identify subset pairs ti si unsupervised parser trained training subset ti results paired test subset si better trained entire training set successful application zoomed learning improves overall performance full test set study algorithm effect leading algorithm task fully unsupervised parsing seginer three different english domains wsj brown genia show improves parser improved fully unsupervised parsing zoomed learning improved fully unsupervised parsing zoomed learning improved fully unsupervised parsing zoomed learning 
well known parsing accuracies drop significantly data less known parsers suffer domain shifts others show dependency parsers difficulty parsing questions constituency parsers particular deterministic dependency parsers highest interest practical applications linear running time drop labeled accuracy question test set propose uptraining procedure deterministic parser trained output accurate slower latent variable constituency parser converted dependencies uptraining unlabeled questions achieves results comparable labeled questions training unlabeled labeled questions uptraining able improve parsing accuracy closing gap performance uptraining accurate deterministic question parsing uptraining accurate deterministic question parsing uptraining accurate deterministic question parsing 
many nlp systems unidirectional flow information parser supplies input semantic role labeler paper build system allows information flow directions make use semantic role predictions choosing parse process relies averaged perceptron model distinguish likely semantic roles erroneous ones system penalizes parses give rise semantic roles explore consequences perform two experiments first use baseline generative model produce parses semantic model second use modified version semantic role labeler predict semantic roles parse time performance modified labeler weaker best full srl restricted features computed directly parser packed chart experiments resulting semantic predictions used select parses finally feed selected parses produced experiment full version semantic role labeler find srl performance improved baseline selecting parses likely semantic roles parser learn semantic role labeler vice versa parser learn semantic role labeler vice versa parser learn semantic role labeler vice versa 
recent paper described new machine translation evaluation metric amber paper describes two changes amber first one incorporation new ordering penalty second one use downhill simplex algorithm tune weights components amber tested impact two changes using data wmt metrics task changes improved performance amber two together yielded even greater improvement cases additive new version amber clearly outperforms bleu terms correlation human judgment improving amber, mt evaluation metric improving amber, mt evaluation metric improving amber, mt evaluation metric 
paper describes study contribution features task quality estimation machine translation sentence level standard regression algorithm used build models using combination linguistic features extracted input text machine translation experiments englishspanish translations show linguistic features although informative yet able outperform shallower features based statistics input text translation additional corpora however analysis suggests linguistic information actually useful needs carefully combined features order produce better results linguistic features quality estimation linguistic features quality estimation linguistic features quality estimation 
paper describe upc system participated wmt shared task quality estimation machine translation based empirical evidence fluencyrelated features high correlation effort present set features assessment quality estimation machine translation designed around different kinds language models plus another set features model quality dependency parses automatically projected source sentences translations document results obtained shared task dataset obtained combining features designed baseline features provided task organizers upc submission wmt 2012 shared task quality estimation upc submission wmt 2012 shared task quality estimation upc submission wmt 2012 shared task quality estimation 
present paper system submissions sdl language weaver team wmt quality estimation mt systems use machine learning techniques models algorithm designed directly optimize towards official metrics used resulting submissions placed st model nd svm model respectively ranking task scoring task participating teams sdl language weaver systems wmt12 quality estimation shared task sdl language weaver systems wmt12 quality estimation shared task sdl language weaver systems wmt12 quality estimation shared task 
present pem first fully automatic metric evaluate quality paraphrases consequently paraphrase generation systems metric based three criteria adequacy fluency lexical dissimilarity key component metric robust shallow semantic similarity measure based pivot language allows us approximate adequacy independently lexical similarity human evaluation shows pem achieves high correlation human judgments pem: paraphrase evaluation metric exploiting parallel texts pem: paraphrase evaluation metric exploiting parallel texts pem: paraphrase evaluation metric exploiting parallel texts 
paper presents techniques referencefree automatic prediction machine translation output quality addition helping quality estimation sentencelevel predictions used system selection improving quality output translations present three system selection techniques perform evaluations quantify gains across multiple domains language pairs combining quality prediction system selection improved automatic translation output combining quality prediction system selection improved automatic translation output combining quality prediction system selection improved automatic translation output 
address two challenges automatic machine translation evaluation avoiding use reference translations focusing adequacy estimation economic perspective getting rid costly reference translations permits alleviate main bottleneck mt evaluation system evaluation perspective pushing semantics mt necessity order complement shallow methods currently used overcoming limitations casting problem textual entailment application experiment different benchmarks evaluation settings method shows high correlation human judgements good results datasets without relying reference translations match without referee: evaluating mt adequacy without reference translations match without referee: evaluating mt adequacy without reference translations match without referee: evaluating mt adequacy without reference translations 
confusion network decoding proven one successful approaches machine translation system combination hypothesis alignment algorithm crucial part building confusion networks many alternatives proposed literature paper describes systematic comparison five well known hypothesis alignment algorithms mt system combination via confusion network decoding controlled experiments using identical decoding weight tuning methods standard system combination evaluation sets presented translation quality assessed using case insensitive bleu scores bootstrapping used establish statistical significance score differences aligners yield significant bleu score gains best individual system included combination incremental indirect hidden markov model novel incremental inversion transduction grammar flexible matching consistently yield best translation quality though keeping things equal differences aligners relatively small work reported paper carried authors raytheon bbn technologies rwth aachen university review hypothesis alignment algorithms mt system combination via confusion network decoding review hypothesis alignment algorithms mt system combination via confusion network decoding review hypothesis alignment algorithms mt system combination via confusion network decoding 
addition deterministic permutation parser provide valuable hierarchical information statistical machine translation pbsmt system permutation parsers used implement hierarchical models galley manning enforce inversion transduction grammar itg constraints feng et al present number theoretical results regarding use permutation parsers pbsmt particular show existing itg constraint zens et al prevent permutations demonstrate hierarchical reordering model produce analyses decoding inconsistent analyses made training experimentally verify utility hierarchical compare several variants terms translation quality syntactic complexity output hierarchical re-ordering permutation parsing phrase-based decoding hierarchical re-ordering permutation parsing phrase-based decoding hierarchical re-ordering permutation parsing phrase-based decoding 
chiang hierarchical hpb translation model advances statistical machine translation expanding conventional phrases hierarchical phrases phrases contain however original hpb model prone overgeneration due lack linguistic knowledge grammar may suggest derivations appropriate many may lead ungrammatical translations hand limitations glue grammar rules original hpb model may actually prevent systems considering reasonable derivations paper presents simple effective translation model called hpb model incorporates head information translation rules better capture information derivation addition unlike original glue rules model allows improved reordering two neighboring explore larger reordering search space extensive set experiments translation four nist mt test sets using small large training set show hdhpb model consistently statistically significantly outperforms chiang model well source side model using syntactic head information hierarchical phrase-based translation using syntactic head information hierarchical phrase-based translation using syntactic head information hierarchical phrase-based translation 
introduce first fully automatic fully semantic frame based mt evaluation metric meant outperforms commonly used automatic metrics correlating human judgment translation adequacy recent work hmeant human metric indicates machine translation better evaluated via semantic frames evaluation paradigms requiring minimal effort monolingual humans annotate align semantic frames reference machine translations propose surprisingly effective occam razor automation hmeant combines standard shallow semantic parsing simple maximum weighted bipartite matching algorithm aligning semantic frames matching criterion based lexical similarity scoring semantic role fillers simple context vector model readily trained using publicly available large monolingual corpus sentence level correlation analysis following standard nist metricsmatr protocol shows fully automated version hmeant achieves significantly higher kendall correlation human adequacy judgments bleu nist meteor per cder wer ter furthermore demonstrate performing semantic frame alignment automatically actually tends good performing manually despite high performance fully automated meant still able preserve hmeant virtues simplicity representational transparency inexpensiveness fully automatic semantic mt evaluation fully automatic semantic mt evaluation fully automatic semantic mt evaluation 
introduce taxonomy factored phrasebased translation scenarios conduct range experiments taxonomy point several common pitfalls designing factored setups paper also describes wmt submissions probes taxonomy factored phrase-based models probes taxonomy factored phrase-based models probes taxonomy factored phrase-based models 
paper describes translation system developed avenue research group carnegie mellon university seventh workshop statistical machine translation naacl wmt present method training data selection description hierarchical translation system discussion impact data size best practice system building cmu-avenue french-english translation system cmu-avenue french-english translation system cmu-avenue french-english translation system 
proceedings th workshop statistical machine translation pages montre al canada june association computational linguistics translation systems wmt morphologysimplification domain adaptationllu formiga carlos henr quez adolfo herna ndez jose marin enric monte jose fonollosa talp research centre universitat polite cnica de catalunya barcelona spain lluis formiga carlos henriquez adolfo hernandezjose marino enric monte jose fonollosa upc eduabstract paper describes upc participation wmt evaluation campaign systems presented based standard phrasebased moses systems variations adopted several improvement techniques morphology simplification generation domain adaptation morphology simplification overcomes data sparsity problem translating morphologicallyrich languages spanish translating first language secondly leave morphology generation independent classification task domain adaptation approach improves smt system adding new translation units learned reference alignment results depict improvement ter meteor nist bleu scores compared baseline system obtaining official test set benefits domain adaptation approach morphological generalization method talp-upc phrase-based translation systems wmt12: morphology simplification domain adaptation talp-upc phrase-based translation systems wmt12: morphology simplification domain adaptation talp-upc phrase-based translation systems wmt12: morphology simplification domain adaptation 
describe systems developed team qatar computing research institute wmt shared translation task used statistical machine translation model several settings notably tuning data selection phrase table combination evaluation results show rank second bleu ter top tier qcri wmt12: experiments spanish-english german-english machine translation news text qcri wmt12: experiments spanish-english german-english machine translation news text qcri wmt12: experiments spanish-english german-english machine translation news text 
paper describes statistical machine translation smt systems developed rwth aachen university translation task naacl seventh workshop statistical machine translation wmt participated evaluation campaign language pairs translation directions hierarchical smt systems applied number different techniques evaluated including insertion model different lexical smoothing methods discriminative reordering extension hierarchical system reverse translation system combination application methods achieve considerable improvements respective baseline systems rwth aachen machine translation system wmt 2012 rwth aachen machine translation system wmt 2012 rwth aachen machine translation system wmt 2012 
describe system hybrid machine translation mt extended machine learning components controlling phrase selection approach based mt rbmt system creates template translations based generation parse tree algnments identify set interesting translation candidates one translation engines could substituted translation templates substitution process either controlled output binary classifier trained feature vectors different mt engines depending weights decision factors tuned using mert able observe improvements terms bleu scores baseline version hybrid system machine learning hybrid machine translation machine learning hybrid machine translation machine learning hybrid machine translation 
report findings exploiting large data sets translation modeling language modeling tuning development competitive machine translation systems eight language pairs towards effective use training data statistical machine translation towards effective use training data statistical machine translation towards effective use training data statistical machine translation 
paper describes joint quaero submission wmt machine translation evaluation four groups rwth aachen university karlsruhe institute technology systran quaero project submitted joint translation wmt german english task group translated data sets systems finally rwth system combination combined translations final submission experimental results show improvements points bleu points ter compared best single system joint wmt 2012 submission quaero project joint wmt 2012 submission quaero project joint wmt 2012 submission quaero project 
paper describes limsi submissions shared translation task report results directions submissions use open source system based bilingual approach translation target language models estimated conventional smoothed models approach extend estimating translation probabilities continuous space using neural networks experimental results show significant consistent bleu improvement approximately point conditions also report preliminary experiments using translation model limsi @ wmt12 limsi @ wmt12 limsi @ wmt12 
paper describes upm system translation task naacl workshop statistical machine translation system based moses used available free corpora cleaning deleting repetitions paper also propose technique selecting sentences tuning system technique based similarity sentences translate approach improve bleu score result wmt challenge obtained bleu test set finally explain different experiments carried competition upm system wmt 2012 upm system wmt 2012 upm system wmt 2012 
paper describes smt systems developed participation wmt shared translation task translations english german english french generated using translation system extended additional models bilingual pos automatic cluster language models discriminative word lexica addition explicitly handle oov words german translations morphological forms stem furthermore extended reordering approach also use information syntactic trees karlsruhe institute technology translation systems wmt 2012 karlsruhe institute technology translation systems wmt 2012 karlsruhe institute technology translation systems wmt 2012 
paper describes submissions translation task using kriya hierarchical system submitted systems language pairs addition baseline system following standard mt pipeline tried ensemble decoding ensemble decoding method improved bleu score points baseline segmented czech side corpora trained two different segmented models addition baseline system baseline systems shared task submissions trained hierarchical model chiang framework specifically use kriya sankaran et al system training decoding briefly explain baseline systems language pairs use giza word alignments moses koehn et al extracting initial phrases translation models trained using rule extraction module kriya cases training data running usual pipeline tokenization lowercasing baseline system trained simplified hierarchical model side one nonterminal denoted nt instead usual two nt model earlier experiments found nt model perform comparably nt model close language pairs sankaran et al time resulting smaller model used training data consisting europarl news commentary un documents training translation models total sentence pairs use giga parallel corpus training trained language model english using english gigaword trained standard hiero model two righthand side used europarl news commentary czeng corpora sentence pairs training translation models trained language model using czech side parallel corpora use czech monolingual corpus baseline systems use following standard hiero features rule probabilities lexical weights pl pl word penalty phrase penalty kriya - sfu system translation task wmt-12 kriya - sfu system translation task wmt-12 kriya - sfu system translation task wmt-12 
present improved version depfix marec ek et al system automatic mt outputs designed increase fluency enhanced rule set used original depfix system measured performance individual rules also modified dependency parser mcdonald et al two ways adjust parsing mt outputs show system able improve quality mt systems depfix: system automatic correction czech mt outputs depfix: system automatic correction czech mt outputs depfix: system automatic correction czech mt outputs 
paper describes development french english english french statistical machine translation systems wmt shared task evaluation developed systems based moses decoder trained provided data additionally new features year included improved language translation model adaptation using score corpus selection lium’s smt machine translation systems wmt 2012 lium’s smt machine translation systems wmt 2012 lium’s smt machine translation systems wmt 2012 
describe dfki statistical based submission wmt evaluation submission based freely available machine translation toolkit jane supports hierarchical translation models different setups tested combined using sentence selection method dfki's smt system wmt 2012 dfki's smt system wmt 2012 dfki's smt system wmt 2012 
recognition errors hinder proliferation speech recognition sr systems based observation recognition errors may result ungrammatical sentences especially dictation application acceptable level accuracy generated documents indispensable propose incorporate two kinds linguistic features error detection lexical features words syntactic features robust lexicalized parser learning chosen predict recognition errors integrating word confidence scores linguistic features experimental results dictation data corpus show linguistic features alone useful word confidence scores detecting errors however linguistic features provide complementary information combined word confidence scores collectively reduce classification error rate improve measure error detection using linguistic features error detection using linguistic features error detection using linguistic features 
paper presents novel approach combining different word alignments view word alignment pattern classification problem alignment combination treated classifier ensemble alignment links adorned linguistic features neural network model used learn word alignments individual alignment systems show alignment combination approach yields significant relative error reduction alignment combination technique englishspanish data neuralign: combining word alignments using neural networks neuralign: combining word alignments using neural networks neuralign: combining word alignments using neural networks 
present discriminative largemargin approach matching word alignment framework pairs word tokens receive matching score based features pair including measures association words distortion positions similarity orthographic form even labeled training examples simple features incorporate counts large unlabeled corpus achieve aer performance close ibm model much less time including model predictions features achieve relative aer reduction intersected model alignments discriminative matching approach word alignment discriminative matching approach word alignment discriminative matching approach word alignment 
smt typically models translation sentence level ignoring wider document context hurt consistency translated documents using smt system various data conditions show smt translates documents remarkably consistently even without document knowledge nevertheless translation inconsistencies often indicate translation errors however unlike human translation errors rarely due terminology inconsistency often symptoms deeper issues smt models instead trouble smt consistency trouble smt consistency trouble smt consistency 
minimum error rate training crucial component many nlp applications machine translation speech recognition however common evaluation functions bleu word error rate generally highly thus prone search errors paper present exact search algorithm minimum error rate training reaches global optimum using series reductions linear programming given set lists produced input sentences algorithm finds linear model globally optimal respect set find algorithm polynomial size model exponential present extensions work let us scale reasonably large tuning sets one thousand sentences either searching promising regions parameter space using variant relies approximation experimental results show improvements standard och algorithm optimal search minimum error rate training optimal search minimum error rate training optimal search minimum error rate training 
training phrase table fa training data reference translation shown improve phrasal translation quality significantly reducing phrase table size medium sized tasks apply procedure several tasks primary goal reducing model sizes without sacrificing translation quality deal noise automatically crawled parallel training data introduce word deletions insertions backoffs achieve successful alignment rate also add heuristics avoid increase oov rates able reduce already heavily pruned baseline phrase tables little degradation quality occasionally slight improvement without increase oovs introduce two global scaling factors phrase table via posterior phrase alignment probabilities modified absolute discounting method applied fractional counts index terms phrasal machine translation phrase training phrase table pruning leave-one-out phrase model training large-scale deployment leave-one-out phrase model training large-scale deployment leave-one-out phrase model training large-scale deployment 
minimum error rate training often preferred method optimizing parameters statistical machine translation systems mert minimizes error rate using surrogate representation search space best lists hypergraphs offer incomplete view search space work instead minimize error rate directly integrating decoder minimizer approach yields two benefits first function optimized true error rate second lets us optimize parameters translations systems standard linear model features distortion limit since integrating decoder minimizer often slow practical also exploit statistical significance tests accelerate search quickly discarding unpromising models experiments phrasebased system show approach scalable optimizing parameters mert cannot handle brings improvements translation results direct error rate minimization statistical machine translation direct error rate minimization statistical machine translation direct error rate minimization statistical machine translation 
propose method improve accuracy parsing bilingual texts bitexts help statistical machine translation smt systems previous bitext parsing methods use bilingual treebanks hard obtain instead approach uses bilingual treebank produce bilingual constraints however bilingual treebank contains errors bilingual constraints noisy overcome problem use unannotated data verify constraints design set effective bilingual features parsing models based verified results experimental results show new parsers significantly outperform baselines moreover approach still able provide improvement use larger monolingual treebank results much stronger baseline especially notable approach used purely monolingual setting help smt smt helps bitext dependency parsing smt helps bitext dependency parsing smt helps bitext dependency parsing 
present novel approach parsing dop like dop models parser utilizes syntactic fragments arbitrary size treebank analyze new sentences crucially uses encountered least twice criterion allows us work relatively small representative set fragments employed symbolic backbone several probabilistic generative models parsing define approach allows us use standard pcfg technology making results easily replicable according standard parseval metrics best model par many parsers offering complementary benefits simple generative probability model explicit representation larger units grammar accurate parsing compact tree-substitution grammars: double-dop accurate parsing compact tree-substitution grammars: double-dop accurate parsing compact tree-substitution grammars: double-dop 
propose generalized bootstrapping algorithm categories described relevant seed features method introduces two unsupervised steps improve initial categorization step bootstrapping scheme using latent semantic space obtain generalized similarity measure instances features ii gaussian mixture algorithm obtain uniform classification probabilities unlabeled examples algorithm evaluated two text categorization tasks obtained performance using category names initial seeds investigating unsupervised learning text categorization bootstrapping investigating unsupervised learning text categorization bootstrapping investigating unsupervised learning text categorization bootstrapping 
present method speeding calculation tree kernels training calculation tree kernels still heavy even efficient dynamic programming dp procedures method maps trees small feature space inner product calculated much faster yields value tree kernel tree pairs training sped using dp procedure exceptional pairs describe algorithm detects exceptional pairs converts trees vectors feature space propose tree kernels marked labeled ordered trees show training svms semantic role labeling using kernels sped factor several tens speeding training tree kernels node relation labeling speeding training tree kernels node relation labeling speeding training tree kernels node relation labeling 
order promote study automatic summarization translation need accurate automatic evaluation method close human evaluation paper present evaluation method based convolution kernels measure similarities texts considering substructures conducted experiment using automatic summarization evaluation data developed text summarization challenge comparison conventional techniques shows method correlates closely human evaluations robust kernel-based approach automatic evaluation natural language generation technologies: application automatic summarization kernel-based approach automatic evaluation natural language generation technologies: application automatic summarization kernel-based approach automatic evaluation natural language generation technologies: application automatic summarization 
describe stochastic models local phrase movement incorporated statistical machine translation smt system models provide properly formulated probability distributions reordered phrase sequences implemented weighted finite state transducers describe parameter procedures based phrase alignment complete translation model incorporating reordering experiments show reordering model yields substantial improvements translation performance mt tasks also show procedure scales bitext size increased local phrase reordering models statistical machine translation local phrase reordering models statistical machine translation local phrase reordering models statistical machine translation 
introduce novel machine learning framework based recursive autoencoders prediction sentiment label distributions method learns vector space representations phrases sentiment prediction tasks representations outperform approaches commonly used datasets movie reviews without using sentiment lexica polarity shifting rules also evaluate model ability predict sentiment distributions new dataset based confessions experience project dataset consists personal user stories annotated multiple labels aggregated form multinomial distribution captures emotional reactions algorithm accurately predict distributions labels compared several competitive baselines semi-supervised recursive autoencoders predicting sentiment distributions semi-supervised recursive autoencoders predicting sentiment distributions semi-supervised recursive autoencoders predicting sentiment distributions 
statistical translation systems based phrase translation pairs blocks obtained mainly word alignment use blocks infer better word alignment improved word alignment turn leads better inference blocks propose two new probabilistic models based innerouter segmentations use em algorithms estimating models parameters first model recovers ibm special case models outperform bidirectional ibm terms word alignment accuracy absolute using blocks obtained models actual translation systems yields statistically significant improvements smt evaluation inner-outer bracket models word alignment using hidden blocks inner-outer bracket models word alignment using hidden blocks inner-outer bracket models word alignment using hidden blocks 
present new approach learns errors made existing word alignment systems corrects adapting transformationbased learning problem word alignment project new alignment links already existing links using features pos tags show alignment link projection approach yields significantly lower alignment error rate best performing alignment system relative reduction englishspanish data relative reduction data alignment link projection using transformation-based learning alignment link projection using transformation-based learning alignment link projection using transformation-based learning 
paper proposes new discriminative training method called minimum sample risk msr estimating parameters language models text input existing discriminative training methods use loss function optimized easily approaches approximately objective minimum error rate msr minimizes training error directly using heuristic training procedure evaluations task japanese text input show msr handle large number features training samples significantly outperforms regular trigram model trained using maximum likelihood estimation also outperforms two widely applied discriminative methods boosting perceptron algorithms small statistically significant margin minimum sample risk methods language modeling minimum sample risk methods language modeling minimum sample risk methods language modeling 
proceedings human language technology conference conference empirical methods natural language processing hlt emnlp pages vancouver october association computational linguistics automatically learning cognitive status summarization newswire ani nenkova advaith siddharthan kathleen mckeown department computer science columbia university automatically learning cognitive status multi-document summarization newswire automatically learning cognitive status multi-document summarization newswire automatically learning cognitive status multi-document summarization newswire 
paper presents comparative experimental results four techniques language model adaptation including maximum posteriori map method three discriminative training methods boosting algorithm average perceptron minimum sample risk method task japanese conversion evaluate techniques beyond simply using character error rate cer cer results interpreted using metric domain similarity background adaptation domains evaluated correlating novel metric measuring side effects adapted models using metrics show discriminative methods superior method terms achieving larger cer reduction also robust similarity background adaptation domains achieve larger cer reduction fewer side effects comparative study language model adaptation techniques using new evaluation metrics comparative study language model adaptation techniques using new evaluation metrics comparative study language model adaptation techniques using new evaluation metrics 
parsing models often trained optimizing likelihood would prefer optimise metric like fmeasure convex objective models minimises bound expected risk given loss function na ve application requires loss decompose predicted structure true use softmaxmargin optimise ccg parser variety loss functions demonstrate novel dynamic programming algorithm enables us use leading substantial gains accuracy ccgbank embed parser larger model includes supertagging features incorporated via belief propagation obtain improvements achieve labelled unlabelled dependency gold tags automatic tags best reported results task training log-linear parser loss functions via softmax-margin training log-linear parser loss functions via softmax-margin training log-linear parser loss functions via softmax-margin 
explore efficient domain adaptation task statistical machine translation based extracting sentences large generaldomain parallel corpus relevant target domain sentences may selected simple based methods present three sentences identical data call pseudo subcorpora subcorpora size original used train small statistical machine translation smt systems outperform systems trained entire corpus performance improved use models combination true model results show training data always better best results attained via proper data selection well combining systems decoding domain adaptation via pseudo in-domain data selection domain adaptation via pseudo in-domain data selection domain adaptation via pseudo in-domain data selection 
investigate differences language models compiled original texts compiled texts manually translated target language corroborating established observations translation studies demonstrate latter significantly better predictors translated sentences former hence fit reference set better furthermore translated texts yield better language models statistical machine translation original texts language models machine translation: original vs. translated texts language models machine translation: original vs. translated texts language models machine translation: original vs. translated texts 
research aimed problem disambiguating toponyms place names terms classification derived merging information two publicly available gazetteers establish difficulty problem measured degree ambiguity respect gazetteer toponyms news found toponyms found corpus ambiguous gazetteer lacked local discriminator text given scarcity humanannotated data method used unsupervised machine learning develop disambiguation rules toponyms automatically tagged information found gazetteer toponym ambiguous gazetteer automatically disambiguated based preference heuristics automatically tagged data used train machine learner disambiguated toponyms news corpus accuracy disambiguating toponyms news disambiguating toponyms news disambiguating toponyms news 
deep linguistic grammars able provide rich highly complex grammatical representations sentences capturing instance dependencies returning semantic representation grammars lack robustness sense gracefully handle words missing lexicon several approaches explored handle problem many consist input grammar shallow processing tools tools however use features based fixed window context investigate whether use features encode discrete structures namely grammatical dependencies improve performance machine learning classifier assigns deep lexical types paper report design evaluation classifier assigning deep lexical types using structured classifier features grammatical dependencies assigning deep lexical types using structured classifier features grammatical dependencies assigning deep lexical types using structured classifier features grammatical dependencies 
bootstrapping methods learning require small amount supervision seed learning process show sometimes possible eliminate last bit supervision trying many candidate seeds selecting one plausible outcome discuss strapping methods general exhibit particular method strapping wordsense classifiers ambiguous words experiments canadian hansards show unsupervised technique significantly effective picking seeds hand yarowsky turn known rival supervised methods bootstrapping without boot bootstrapping without boot bootstrapping without boot 
text analysis conference tac ranks summarization systems average score collection document sets investigate statistical appropriateness score propose alternative better distinguishes human machine evaluation systems ranking human machine summarization systems ranking human machine summarization systems ranking human machine summarization systems 
proceedings human language technology conference conference empirical methods natural language processing hlt emnlp pages vancouver october association computational linguistics sense distributions predominant sense acquisition rob koeling diana mccarthy john carroll department informatics university sussex brighton bn qh uk domain-specific sense distributions predominant sense acquisition domain-specific sense distributions predominant sense acquisition domain-specific sense distributions predominant sense acquisition 
twitter micro blogging website users post messages short text called tweets tweets contain user opinion sentiment towards object person sentiment information useful various aspects business governments paper present method performs task tweet sentiment identification using corpus tweets present sentiment scoring function uses prior information classify binary classification weight various sentiment bearing words phrases tweets using scoring function achieve classification accuracy stanford dataset mejaj dataset using supervised machine learning approach achieve classification accuracy stanford dataset mining sentiments tweets mining sentiments tweets mining sentiments tweets 
classification opinion texts positive negative tackled evaluating separate key words limited approach propose approach based order words without using syntactic semantic information consists building one probabilistic model positive another one negative opinions test opinions compared models decision confidence measure calculated order reduce complexity training corpus first lemmatize texts replace namedentities wildcards present accuracy spanish opinions financial products domain opinum: statistical sentiment analysis opinion classification opinum: statistical sentiment analysis opinion classification opinum: statistical sentiment analysis opinion classification 
word alignment models form important part building statistical machine translation systems word alignment aims improve accuracy automatic word alignment incorporating full partial alignments acquired humans dedicated elicitation effort often expensive depends availability bilingual speakers paper study active learning query strategies carefully identify highly uncertain informative alignment links proposed unsupervised word alignment model manual correction informative links applied create labeled dataset used word alignment model experiments show using active learning leads maximal reduction alignment error rates reduced human effort active semi-supervised learning improving word alignment active semi-supervised learning improving word alignment active semi-supervised learning improving word alignment 
last decade seen many interesting applications question answering qa technology jeopardy quiz show certainly one fascinating viewpoints broad domain complexity language paper study kernel methods applied syntactic semantic structures accurate classification jeopardy definition questions extensive empirical analysis shows classification models largely improve classifiers based models classifiers also used qa pipeline constituting watson ibm jeopardy system experiments measuring impact watson show enhancements qa accuracy consequent increase amount money earned evaluation using syntactic semantic structural kernels classifying definition questions jeopardy! using syntactic semantic structural kernels classifying definition questions jeopardy! using syntactic semantic structural kernels classifying definition questions jeopardy! 
paper present new ranking scheme collaborative ranking cr contrast traditional ranking scheme solely relies strengths isolated queries one ranking algorithm new scheme integrates strengths multiple collaborators query strengths multiple ranking algorithms elaborate three specific forms collaborative ranking namely micro collaborative ranking micr macro collaborative ranking macr collaborative ranking mimacr experiments entity linking task show proposed scheme indeed effective promising collaborative ranking: case study entity linking collaborative ranking: case study entity linking collaborative ranking: case study entity linking 
disambiguating named entities naturallanguage text maps mentions ambiguous names onto canonical entities like people places registered knowledge base dbpedia yago paper presents robust method collective disambiguation harnessing context knowledge bases using new form coherence graph unifies prior approaches comprehensive framework combines three measures prior probability entity mentioned similarity contexts mention candidate entity well coherence among candidate entities mentions together method builds weighted graph mentions candidate entities computes dense subgraph approximates best joint mapping experiments show new method significantly outperforms prior methods terms accuracy robust behavior across variety inputs robust disambiguation named entities text robust disambiguation named entities text robust disambiguation named entities text 
analyze models semantic role assignment defining abstracts features learning paradigms based concept role confusability defined terms predicts roles realized less specific grammatical functions difficult assign find confusability strongly correlated performance classifiers based syntactic features classifiers including semantic features indicates syntactic features approximate description grammatical functions semantic features provide independent second view data analyzing models semantic role assignment using confusability analyzing models semantic role assignment using confusability analyzing models semantic role assignment using confusability 
paper propose novel human computation game sentiment analysis game aims annotating sentiments collection text documents simultaneously constructing highly discriminative lexicon positive negative phrases human computation games widely used recent years acquire human knowledge use solve problems infeasible solve machine intelligence package problems lexicon construction sentiment detection single human computation game compare results obtained game sentiment detection approaches obtained results promising show improvements traditional approaches sentiment analysis using novel human computation game sentiment analysis using novel human computation game sentiment analysis using novel human computation game 
consider problem training logistic regression models binary classification information extraction information retrieval tasks fitting probabilistic models use tasks take account demands taskspecific utility function case combines recall precision global measure utility develop training procedure based empirical risk minimization utility maximization evaluate simple extraction task maximum expected f-measure training logistic regression models maximum expected f-measure training logistic regression models maximum expected f-measure training logistic regression models 
reordering remains one biggest challenges facing machine translation derive soft constraints source dependency parsing directly address reordering problem hierarchical phrasebased model approach significantly improves chinese english machine translation task bleu points average moreover switch tuning function bleu lrscore promotes reordering observe total improvements bleu lrscore ter baseline average approach improves reordering precision recall absolute points respectively found especially effective reodering soft dependency constraints reordering hierarchical phrase-based translation soft dependency constraints reordering hierarchical phrase-based translation soft dependency constraints reordering hierarchical phrase-based translation 
look entire corpus web know two words associated powerful sampling technique called sketches originally introduced remove duplicate web pages generalize sketches estimate contingency tables associations using maximum likelihood estimator find likely contingency table given sample margins document frequencies size collection unsurprisingly computational work statistical accuracy variance errors depend sampling rate shown theoretically empirically sampling methods become important larger larger collections web scale sampling rates low may suffice using sketches estimate associations using sketches estimate associations using sketches estimate associations 
although discriminative training guarantees improve statistical machine translation incorporating large amount overlapping features hard scale large data due decoding complexity propose new algorithm generate translation forest training data linear time help word alignment algorithm also alleviates oracle selection problem ensuring forest always contains derivations exactly yield reference translation millions features trained sentences second per sentence system achieves significant improvement bleu baseline system nist test sets fast generation translation forest large-scale smt discriminative training fast generation translation forest large-scale smt discriminative training fast generation translation forest large-scale smt discriminative training 
learn similarity measures task extracting word synonyms corpus parsed text constrained graph walk variant successfully applied past similar settings shown outperform syntactic vectorbased approach task show learning specialized similarity measures different word types advantageous graph based similarity measures synonym extraction parsed text graph based similarity measures synonym extraction parsed text graph based similarity measures synonym extraction parsed text 
introduce blanc family dynamic trainable evaluation metrics machine translation flexible parametrized models learned past data automatically optimized correlate well human judgments different criteria adequacy fluency using different correlation measures towards end discuss acs common skipngrams practical algorithm trainable parameters estimates referencecandidate translation overlap computing weighted sum common skipngrams polynomial time show bleu rouge metric families special cases blanc compare correlations human judgments across three metric families analyze algorithmic complexity acs argue powerful modeling local meaning structure offering practicality established algorithms generalizes blanc: learning evaluation metrics mt blanc: learning evaluation metrics mt blanc: learning evaluation metrics mt 
discuss analyze problem finding distribution minimizes relative entropy prior distribution satisfying constraints respect observed distribution setting generalizes classical maximum entropy problems relaxes standard constraints observed values tackle problem introducing unknown distribution distilled single scalar describe homotopy relaxation parameter distribution characterizing parameter homotopy also reveals aesthetic symmetry prior distribution observed distribution use reformulated problem describe space time efficient algorithm tracking entire relaxation path derivations based compact geometric view relaxation path piecewise linear function two dimensional space parameters demonstrate usability approach applying problem zipfian distributions large alphabet entire relaxation path maximum entropy problems entire relaxation path maximum entropy problems entire relaxation path maximum entropy problems 
word sense disambiguation system attempts determine sense word contextual features major barriers building word sense disambiguation system include difficulty labeling data task predicting sense distinctions issues stem partly fact task treated isolation possible uses automatically disambiguated data paper consider related task word translation wish determine correct translation word context use parallel language corpora large supply partially labeled data task present algorithms solving word translation problem demonstrate significant improvement baseline system show system used improve performance simplified machinetranslation task effectively accurately prune set candidate translations word word-sense disambiguation machine translation word-sense disambiguation machine translation word-sense disambiguation machine translation 
hmeant lo wu manual mt evaluation technique focuses structure sentence relate hmeant established linguistic theory highlighting possibilities reusing existing knowledge resources interpreting automating hmeant apply hmeant new language czech particular evaluating set mt systems hmeant proves correlate manual rankings sentence level better range automatic metrics however main contribution paper identification several issues hmeant annotation proposal resolve towards predicate-argument evaluation mt towards predicate-argument evaluation mt towards predicate-argument evaluation mt 
present unsupervised approach estimate appropriate degree contribution semantic role type semantic translation evaluation yielding semantic mt evaluation metric whose correlation human adequacy judgments comparable recent supervised approaches without high cost training corpus new unsupervised estimation approach motivated analysis showing weights learned supervised training distributed similar fashion relative frequencies semantic roles empirical results show even without training corpus human adequacy rankings optimize correlation using instead relative frequency weighting scheme approximate importance semantic role type leads semantic mt evaluation metric correlates comparable human adequacy judgments previous metrics require far expensive human rankings adequacy training corpus result cost semantic mt evaluation greatly reduced unsupervised vs. supervised weight estimation semantic mt evaluation metrics unsupervised vs. supervised weight estimation semantic mt evaluation metrics unsupervised vs. supervised weight estimation semantic mt evaluation metrics 
proceedings human language technology conference conference empirical methods natural language processing hlt emnlp pages vancouver october association computational linguistics incremental ltag parsing libin shen aravind joshi department computer information science university pennsylvania philadelphia pa usa incremental ltag parsing incremental ltag parsing incremental ltag parsing 
paper presents novel method computation word meaning context make use factorization model words together context words dependency relations linked latent dimensions factorization model allows us determine dimensions important particular context adapt feature vector word accordingly evaluation lexical substitution task carried english french indicates approach able reach better results methods lexical substitution time providing accurate meaning representations latent vector weighting word meaning context latent vector weighting word meaning context latent vector weighting word meaning context 
verb plays crucial role specifying action function performed sentence translating english morphologically richer language like hindi organization order verbal constructs contributes fluency language mere statistical methods machine translation sufficient enough consider aspect identification verb parts sentence essential understanding constitute single entity considering single entity improves translation verbal construct thus overall quality translation paper describes strategy identification verb parts source target language corpora steps taken towards reducing sparsity helped improving translation results improving statistical machine translation co-joining parts verbal constructs english-hindi translation improving statistical machine translation co-joining parts verbal constructs english-hindi translation improving statistical machine translation co-joining parts verbal constructs english-hindi translation 
lexical important cue detecting word associations propose new measure word association based new notion statistical significance lexical existing measures typically rely global unigram frequencies determine expected counts instead focus documents contain terms candidate ask distribution observed spans resembles random null model would imply words pair related strongly enough one word influence placement however words found occur closer together explainable null model hypothesize direct association words extensive empirical evaluation publicly available benchmark data sets show advantages measure existing measures lexical co-occurrence, statistical significance, word association lexical co-occurrence, statistical significance, word association lexical co-occurrence, statistical significance, word association 
develop unsupervised semantic role labelling system relies direct application information predicate lexicon combined simple probability model demonstrate usefulness predicate lexicons role labelling well feasibility modifying existing corpus evaluating different set semantic roles achieve substantial improvement informed baseline exploiting verb lexicon automatic semantic role labelling exploiting verb lexicon automatic semantic role labelling exploiting verb lexicon automatic semantic role labelling 
consider problem questionfocused sentence retrieval complex news articles describing stories published time annotators generated list questions central understanding story corpus dynamic nature stories many questions many victims found judges found sentences providing answer question address sentence retrieval problem apply stochastic method comparing relative importance textual units previously used successfully generic summarization currently present version method hypothesize outperform competitive baseline compares similarity sentence input question via word overlap experiments method achieves trdr score significantly higher baseline using random walks question-focused sentence retrieval using random walks question-focused sentence retrieval using random walks question-focused sentence retrieval 
following recent developments automatic evaluation machine translation document summarization present similar approach implemented measure called pourpre automatically evaluating answers definition questions way assess correctness answers questions involves manual determination whether information nugget appears system response lack automatic methods scoring system output impediment progress field address work experiments trec trec qa tracks indicate rankings produced metric correlate highly official rankings pourpre outperforms direct application existing metrics automatically evaluating answers definition questions automatically evaluating answers definition questions automatically evaluating answers definition questions 
paper describes phrase transliteration system news shared task track back transliteration maps character source side target character directly however segmentation english side cause ambiguity alignment step paper utilize model solve machine transliteration mapping chinese characters english syllables rather english characters two heuristic rulebased syllable segmentation algorithms applied transliteration model also incorporates three phonetic features enhance discriminative ability phrase primary system achieved terms accuracy syllable-based machine transliteration extra phrase features syllable-based machine transliteration extra phrase features syllable-based machine transliteration extra phrase features 
paper develops framework syntactic dependency parse correction dependencies input parse tree revised selecting given dependent best governor within small set candidates use discriminative linear ranking model select best governor group candidates dependent model includes rich feature set encodes syntactic structure input parse tree parse correction framework correct attachments using either generic model specialized models tailored difficult attachment types like coordination experiments show parse correction combining generic model specialized models difficult attachment types successfully improve quality predicted parse trees output several representative dependency parsers french parse correction specialized models difficult attachment types parse correction specialized models difficult attachment types parse correction specialized models difficult attachment types 
work addresses task identifying thematic correspondences across subcorpora focused different topics introduce unsupervised algorithmic framework based distributional data clustering generalizes previous initial works task empirical results reveal interesting commonalities different religions evaluate results measuring overlap clusters clusters compiled manually experts tested variants framework shown outperform alternative methods applicable task generalized framework revealing analogous themese across related topics generalized framework revealing analogous themese across related topics generalized framework revealing analogous themese across related topics 
work presents machine transliteration system based conditional random fields crf models accessor variety av additional feature approximate local context source language experiment results show crf method outperforms opponent since former costs less encode features finer grained labels latter cost-benefit analysis two-stage conditional random fields based english-to-chinese machine transliteration cost-benefit analysis two-stage conditional random fields based english-to-chinese machine transliteration cost-benefit analysis two-stage conditional random fields based english-to-chinese machine transliteration 
describe method identifying systematic patterns translation data using tag sequences incorporate analysis diagnostic tool intended developers machine translation systems demonstrate application used developers explore patterns machine translation output pattern visualization machine translation output pattern visualization machine translation output pattern visualization machine translation output 
paper present method unsupervised semantic role induction formalize graph partitioning problem argument instances verb represented vertices graph whose edge weights quantify similarity graph partitioning realized algorithm iteratively assigns vertices clusters based cluster assignments neighboring vertices method algorithmically conceptually simple especially respect knowledge incorporated model experimental results conll benchmark dataset demonstrate model competitive unsupervised approaches terms whilst attaining significantly higher cluster purity unsupervised semantic role induction graph partitioning unsupervised semantic role induction graph partitioning unsupervised semantic role induction graph partitioning 
offer simple effective scalable method statistical machine translation parameter tuning based pairwise approach ranking herbrich et al unlike popular mert algorithm och pairwise ranking optimization pro method limited handful parameters easily handle systems thousands features moreover unlike recent approaches built upon mira algorithm crammer singer watanabe et al chiang et al pro easy implement uses linear binary classifier software built top existing mert framework matter hours establish pro scalability effectiveness comparing mert mira demonstrate parity systems variety language pairs using large scale data scenarios tuning ranking tuning ranking tuning ranking 
word similarity measured multiple dimensions example lung breath similar thematically authoritative superficial occur similar syntactic contexts share little semantic similarity notions similarity play role determining word meaning hence lexical semantic models must take account towards end develop novel model mixture mvm represents words multiple overlapping clusterings mvm finds multiple data partitions based different subsets features subject marginal constraint feature subsets distributed according latent dirichlet allocation intuitively constraint favors feature partitions coherent topical semantics furthermore mvm uses soft feature assignment hence contribution data point clustering view variable isolating impact data views assign features series experiments demonstrate utility mvm inductive bias capturing relations words intuitive humans outperforming related models latent dirichlet allocation cross-cutting models lexical semantics cross-cutting models lexical semantics cross-cutting models lexical semantics 
proceedings hlt emnlp demonstration abstracts pages vancouver october opinionfinder system subjectivity analysis theresa wilson paul hoffmann swapna somasundaran jason kessler janyce wiebe yejin choi claire cardie ellen riloff siddharth patwardhan intelligent systems program university pittsburgh pittsburgh pa department computer science university pittsburgh pittsburgh pa department computer science cornell university ithaca ny school computing university utah salt lake city ut twilson hoffmanp swapna jsk wiebe cs pitt edu ychoi cardie cs cornell edu riloff sidd cs utah edu opinionfinder: system subjectivity analysis opinionfinder: system subjectivity analysis opinionfinder: system subjectivity analysis 
propose novel forest reranking algorithm discriminative dependency parsing based variant eisner generative model framework define two kinds generative model reranking one learned training data offline forest generated baseline parser fly final prediction reranking stage performed using linear interpolation models discriminative model order efficiently train model decode hypergraph data structure representing forest apply extended inside outside viterbi algorithms experimental results show proposed forest reranking algorithm achieves significant improvement compared conventional approaches third-order variational reranking packed-shared dependency forests third-order variational reranking packed-shared dependency forests third-order variational reranking packed-shared dependency forests 
present named entity recognition ner system extracting product attributes values listing titles information extraction short listing titles present unique challenge lack informative context grammatical structure work combine supervised ner bootstrapping expand seed list output normalized results focusing listings ebay clothing shoes categories bootstrapped ner system able identify new brands corresponding spelling variants typographical errors known brands well identifying novel brands among top new brands predicted system achieves precision output normalized attribute values explore several string comparison algorithms found substring matching work well practice bootstrapped named entity recognition product attribute extraction bootstrapped named entity recognition product attribute extraction bootstrapped named entity recognition product attribute extraction 
paper presents approach statistical machine translation modelling framework implemented means composition weighted transducers moses system used machine translation reference order validate results comparison experiments ted corpus achieve similar performance yielded moses finite-state approach phrase-based statistical machine translation finite-state approach phrase-based statistical machine translation finite-state approach phrase-based statistical machine translation 
minimum error rate training mert method training parameters loglinear model one advantage method training use large number hypotheses encoded translation lattice training data demonstrate mert line optimisation modelled computing shortest distance weighted transducer using tropical polynomial semiring lattice-based minimum error rate training using weighted finite-state transducers tropical polynomial weights lattice-based minimum error rate training using weighted finite-state transducers tropical polynomial weights lattice-based minimum error rate training using weighted finite-state transducers tropical polynomial weights 
syntactic processing using generalized perceptron beam search yue zhang university cambridge stephen clark university cambridge study range syntactic processing tasks using general statistical framework consists global linear model trained generalized perceptron together generic beamsearch decoder apply framework word segmentation joint segmentation postagging dependency parsing parsing components framework conceptually computationally simple decoder requires syntactic processing task broken sequence decisions stage process decoder able consider candidates generate possibilities next stage decoder defined applied training data using trivial updates according generalized perceptron induce model simple framework performs surprisingly well giving accuracy results competitive tasks consider computational simplicity decoder training algorithm leads significantly higher test speeds lower training times main alternatives including training algorithms decoding moreover framework offers freedom define arbitrary features make alternative training decoding algorithms prohibitively slow discuss general framework applied problems studied article making comparisons alternative learning decoding algorithms also show comparability candidates considered beam important factor performance argue conceptual computational simplicity framework together nature make competitive choice range syntactic processing tasks one considered comparison developers alternative approaches syntactic processing using generalized perceptron beam search syntactic processing using generalized perceptron beam search syntactic processing using generalized perceptron beam search 
reordering major challenge machine translation distant languages recent work shown evaluation metrics explicitly account target language word order correlate better human judgments translation quality present simple framework evaluating word order independently lexical choice comparing system reordering source sentence reference reordering data generated manually translations used evaluate system performs reordering preprocessing step framework allows parser reordering rules evaluated extremely quickly without machine translation experiments novelty approach translations used generate reordering reference data generated fashion show alignments generated significantly effect robustness evaluation also outline ways framework allowed group analyze reordering errors english japanese machine translation lightweight evaluation framework machine translation reordering lightweight evaluation framework machine translation reordering lightweight evaluation framework machine translation reordering 
dominant yet ageing ibm hmm word alignment models underpin popular statistical machine translation implementations use today though beset limitations implausible independence assumptions intractable optimisation problems excess tunable parameters models provide scalable reliable starting point inducing translation systems paper build upon venerable base recasting models bayesian framework replacing categorical distributions core hierarchical processes use collapsed gibbs sampling provide flexible formulation sidestep original heuristic optimisation techniques resulting models highly extendible naturally permitting systematic bayesian treatment ibm alignment models systematic bayesian treatment ibm alignment models systematic bayesian treatment ibm alignment models 
present pilot study evaluation method able rank translation outputs reference translation given source sentence system employs statistical classifier trained upon existing human rankings using several features derived analysis source target sentences development experiments one language pair showed method considerably good correlation human ranking using features obtained pcfg parser evaluate confidence estimation: machine ranking translation outputs using grammatical features evaluate confidence estimation: machine ranking translation outputs using grammatical features evaluate confidence estimation: machine ranking translation outputs using grammatical features 
paper proposes new automatic machine translation evaluation metric amber based metric bleu incorporates recall extra penalties text processing variants little linguistic information amber evaluate correlation consistency scores human rankings wmt shared evaluation task amber achieves performance amber: modified bleu, enhanced ranking metric amber: modified bleu, enhanced ranking metric amber: modified bleu, enhanced ranking metric 
paper examines tuning statistical machine translation smt respect multiple evaluation metrics propose several novel methods tuning towards multiple objectives including based ensemble decoding methods natural way think optimization mmo methods effectively combine several solutions obviating need choose one best performing ensemble tuning method new algorithm optimization searches ensemble models study effectiveness methods experiments multiple well single reference datasets experiments show simultaneous gains across several metrics bleu ribes without significant reduction metrics contrasts traditional tuning gains usually limited single metric human evaluation results confirm order produce better mt output optimizing multiple metrics better optimizing one multi-metric optimization using ensemble tuning multi-metric optimization using ensemble tuning multi-metric optimization using ensemble tuning 
previous research domain adaptation da statistical machine translation smt mainly focused translation model tm language model lm best knowledge previous work reordering model rm adaptation phrasebased smt paper demonstrate mixture model adaptation lexicalized rm significantly improve smt performance even system already contains tm lm find surprisingly different training corpora vary widely reordering characteristics particular phrase pairs furthermore particular training corpora may highly suitable training tm lm unsuitable training rm vice versa mixture weights models estimated separately additional contribution paper propose two improvements mixture model adaptation smoothing sample weighting instances document frequency applied mixture rms experiments techniques especially smoothing yield significant performance improvements adaptation reordering models statistical machine translation adaptation reordering models statistical machine translation adaptation reordering models statistical machine translation 
sempos automatic metric machine translation quality czech english focused content words correlates well human judgments computationally costly hard adapt languages relies analysis system output reference remedy attempt approximating sempos using tagger output heuristics little expense correlation human judgments evaluate mt systems much faster additionally describe submission tunable metrics task wmt approximating deep-syntactic metric mt evaluation tuning approximating deep-syntactic metric mt evaluation tuning approximating deep-syntactic metric mt evaluation tuning 
current metrics evaluating machine translation quality huge drawback require reference translations propose truly automatic evaluation metric based ibm lexicon probabilities need reference translations several variants ibm scores systematically explored order find promising directions correlations new metrics human judgments calculated data third fourth fifth shared tasks statistical machine translation workshop five different european languages taken account english spanish french german czech results show ibm scores competitive classic evaluation metrics promising ibm scores calculated morphemes grams evaluation without references: ibm1 scores evaluation metrics evaluation without references: ibm1 scores evaluation metrics evaluation without references: ibm1 scores evaluation metrics 
describe submissions wmt shared mt evaluation task mterater metrics use features automated essay scoring engine designed assess writing proficiency despite using features without comparing translations mterater achieves sentencelevel correlation human rankings equivalent bleu since mterater assesses fluency build mteraterplus incorporates adequacy combining mterater mt evaluation metrics heuristics higher correlation human rankings either mterater individual mt metrics alone however also find features may significant impact correlation every case e-rating machine translation e-rating machine translation e-rating machine translation 
meeting often desirable extract keywords utterance soon spoken thus paper proposes keyword extraction meeting transcripts proposed method considers two major factors make different keyword extraction normal texts first factor temporal history preceding utterances grants higher importance recent utterances old ones second topic relevance forces preceding utterances relevant current utterance considered keyword extraction experiments two data sets english korean show consideration factors results performance improvement keyword extraction meeting transcripts just-in-time keyword extraction meeting transcripts just-in-time keyword extraction meeting transcripts just-in-time keyword extraction meeting transcripts 
automatic evaluation metrics fundamentally important machine translation allowing comparison systems performance efficient training current evaluation metrics fall two classes heuristic approaches like bleu using supervised learning trained human judgement data many trained metrics provide better match human judgements comes cost including lots features leading unwieldy slow metrics paper introduce new trained metric rose uses simple features easy portable quick compute addition rose opposed allowing used wider range settings results show rose performs well many tasks ranking system syntactic constituents results competitive bleu moreover still holds rose trained human judgements translations different language compared use testing regression ranking based optimisation sentence level mt evaluation regression ranking based optimisation sentence level mt evaluation regression ranking based optimisation sentence level mt evaluation 
paper explore potential quantum theory formal framework capturing lexical meaning present novel semantic space model syntactically aware takes word order account features key quantum aspects superposition entanglement define hilbert space show represent meaning words density matrices encode dependency neighborhoods experiments word similarity association reveal model achieves results competitive variety classical models quantum-theoretic approach distributional semantics quantum-theoretic approach distributional semantics quantum-theoretic approach distributional semantics 
paper presents submissions pattern recognition human language technology prhlt group system combination task sixth workshop statistical machine translation wmt submissions generated minimum bayes risk mbr technique technique uses mbr decision rule linear combination component systems probability distributions search minimum risk translation among sentences target language upv-prhlt combination system wmt 2011 upv-prhlt combination system wmt 2011 upv-prhlt combination system wmt 2011 
paper describes submissions ten tracks workshop machine translation system combination task show combination scheme operates flexibly aligning system outputs searching space constructed alignments humans judged combination best eight ten tracks cmu system combination wmt 2011 cmu system combination wmt 2011 cmu system combination wmt 2011 
rwth participated system combination task sixth workshop statistical machine translation wmt three language pairs combined systems single consensus translation metacombination scheme combining six different system combination setups three different engines applied french english language pair depending language pair improvements versus best single system range abs bleu abs ter novel techniques compared rwth submission wmt include two additional system combination engines additional word alignment technique meta combination additional optimization techniques rwth system combination system wmt 2011 rwth system combination system wmt 2011 rwth system combination system wmt 2011 
bbn submitted system combination outputs spanishenglish language pairs combinations based confusion network decoding confusion networks built using incremental hypothesis alignment algorithm flexible matching novel count feature penalize present input hypotheses corresponding source sentence introduced addition usual decoder features system combination weights tuned using graph based expected bleu objective function incrementally expanding networks contexts expected bleu tuning described paper naturally generalizes hypergraphs used optimize thousands weights combination gained bleu points best individual systems official wmt language pairs system multisource combination achieved bleu point gain expected bleu training graphs: bbn system description wmt11 system combination task expected bleu training graphs: bbn system description wmt11 system combination task expected bleu training graphs: bbn system description wmt11 system combination task 
paper describes uzh system used wmt system combination shared task submission participated system combination task translation directions de en en de system uses moses backbone outputs best individual systems integrated additional phrase tables system compares well system combination submissions submission significantly better comparison individual systems however indicates achieves significant gains best individual system uzh system combination system wmt 2011 uzh system combination system wmt 2011 uzh system combination system wmt 2011 
consider using online language models translating multiple streams naturally arise web establishing using one stream degrade translations different domains present series simple approaches tackle problem maintaining translation performance streams small space exploiting differing throughputs stream decoder translates prior test points stream show translation performance equal specialised language models single language model using far less space results hold even adding three billion tokens additional text background language model multiple-stream language models statistical machine translation multiple-stream language models statistical machine translation multiple-stream language models statistical machine translation 
quality statistical machine translation often suffers result standard smt systems inability perform specifically needed translate arabic sentences problem exacerbated low performance arabic parsers subject subject span detection paper present two parse fuzzification techniques allow translation system select among range possible approach demonstrate improvement bleu score maximum possible using gold parses corresponding improvement percentage syntactically subjects manual evaluation fuzzy syntactic reordering phrase-based statistical machine translation fuzzy syntactic reordering phrase-based statistical machine translation fuzzy syntactic reordering phrase-based statistical machine translation 
continuous space language models recently demonstrated outstanding results across variety tasks paper examine word representations implicitly learned weights find representations surprisingly good capturing syntactic semantic regularities language relationship characterized vector offset allows reasoning based offsets words example male female relationship automatically learned induced vector representations king man woman results vector close queen demonstrate word vectors capture syntactic regularities means syntactic analogy questions provided paper able correctly answer almost questions demonstrate word vectors capture semantic regularities using vector offset method answer task questions remarkably method outperforms best previous systems linguistic regularities continuous space word representations linguistic regularities continuous space word representations linguistic regularities continuous space word representations 
paper describes limsi submissions sixth workshop statistical machine translation report results frenchenglish shared translation tasks directions systems use open source statistical machine translation system based bilingual task focussed finding efficient ways take advantage large heterogeneous training parallel data particular using simple filtering strategy helped improve processing time translation quality translate english french german also investigated use soul language model machine translation showed significant improvements soul model also briefly report experiments several alternatives standard mert procedure leading significant limsi @ wmt11 limsi @ wmt11 limsi @ wmt11 
hierarchical hpb translation provides powerful mechanism capture short long distance phrase reorderings however phrase reorderings lack contextual information conventional hpb systems paper proposes contextdependent phrase reordering approach uses maximum entropy maxent model help hpb decoder select appropriate reordering patterns classify translation rules several reordering patterns build maxent model pattern based various contextual features integrate maxent models hpb model experimental results show approach achieves significant improvements standard hpb system translation tasks translation absolute improvements bleu caseinsensitive range maximum entropy based phrase reordering hierarchical phrase-based translation maximum entropy based phrase reordering hierarchical phrase-based translation maximum entropy based phrase reordering hierarchical phrase-based translation 
paper describes translation system developed ark research group carnegie mellon university sixth workshop machine translation wmt present results several modeling training improvements core hierarchical translation system including feature engineering improve modeling derivation structure translations better handing oovs using development set translations languages create additional pseudoreferences training cmu-ark german-english translation system cmu-ark german-english translation system cmu-ark german-english translation system 
paper describes joint quaero submission wmt machine translation evaluation four groups rwth aachen university karlsruhe institute technology systran quaero project submitted joint translation wmt german english task group translated data sets systems rwth system combination combines translations better one paper describe single systems group present results system combination give short description rwth aachen system combination approach overview quaero european research development program goal developing multimedia multilingual indexing management tools professional general public applications http www quaero org research machine translation mainly assigned four groups participating joint submission aim wmt submission show quality joint translation combining knowledge four project partners group develop maintain different machine translation system single systems differ general approach also preprocessing training test data take advantage differences translation system combined hypotheses different systems using rwth system combination approach data sets wmt quaero partner trained systems parallel europarl news commentary corpora single systems tuned newstest dev set newstest dev set used train system combination parameters finally newstest dev set used compare results different system combination approaches settings translation systems rwth aachen joint wmt submission quaero project joint wmt submission quaero project joint wmt submission quaero project 
present carnegie mellon university group submission wmt shared translation task built hybrid syntactic mt system french english using joshua decoder automatically acquired scfg new work year includes training data selection grammar filtering expanded training data selection significantly increased translation scores lowered oov rates results grammar filtering mixed cmu syntax-based machine translation wmt 2011 cmu syntax-based machine translation wmt 2011 cmu syntax-based machine translation wmt 2011 
present novel approach translation model tm adaptation using phrase training proposed adaptation procedure initialized standard tm used perform phrase training smaller set way bias probabilities general tm towards distribution experimental results two different lectures translation tasks show significant improvements adapted systems general ones additionally compare results mixture modeling report gains using suggested phrase training adaptation method phrase training based adaptation statistical machine translation phrase training based adaptation statistical machine translation phrase training based adaptation statistical machine translation 
paper describes statistical machine translation system submitted wmt featured translation task involves translating haitian creole sms messages english experiments try address issue noise training data well lack parallel training data spelling normalization applied reduce words corpus using semantic role labeling rules expand available training corpus additionally investigate extracting parallel sentences comparable data enhance available parallel data cmu haitian creole-english translation system wmt 2011 cmu haitian creole-english translation system wmt 2011 cmu haitian creole-english translation system wmt 2011 
present simple reparameterization ibm model overcomes problems arising model strong assumptions model overparameterization efficient inference likelihood evaluation parameter estimation algorithms provided training model consistently ten times faster model three translation tasks systems built using alignment model outperform ibm model implementation alignment model described paper available http github com clab fast align simple, fast, effective reparameterization ibm model 2 simple, fast, effective reparameterization ibm model 2 simple, fast, effective reparameterization ibm model 2 
paper describes statistical machine translation smt systems developed rwth aachen university translation task emnlp sixth workshop statistical machine translation phrasebased hierarchical smt systems trained constrained tasks directions experiments conducted compare different training data sets training methods optimization criteria well additional models dependency structure phrase reordering applied system combination technique create consensus hypothesis several different systems overview sketch baseline architecture rwth setups wmt shared translation task providing overview translation systems section addition baseline features adopted several novel methods presented section details respective setups translation results language pairs translation directions given sections finally conclude paper section translation systems wmt evaluation utilized rwth hierarchical translation systems well system combination framework giza och ney employed train word alignments language models created srilm toolkit stolcke system applied translation pbt system similar one described zens ney phrase pairs extracted bilingual corpus translation probability directions estimated relative frequencies standard feature set moreover includes language model lexicons lexicalize reordering discriminative reordering model zens ney used parameters optimized algorithm nelder mead word graph hierarchical system hierarchical setups described paper open source jane toolkit vilar et al employed jane developed rwth implements hierarchical approach introduced chiang extensions hierarchical translation weighted synchronous grammar induced parallel text addition contiguous lexical phrases hierarchical phrases rwth aachen machine translation system wmt 2011 rwth aachen machine translation system wmt 2011 rwth aachen machine translation system wmt 2011 
dependency analysis relies morphosyntactic evidence well semantic evidence cases however morphosyntactic evidence seems conflict semantic evidence reason dependency grammar theories annotation guidelines conversion schemes often differ analyze various syntactic constructions experiments treebanks penn treebank converted dependency treebanks rely blindly one widely used conversion schemes paper evaluates effect choice conversion scheme showing dramatic impact end results down-stream effects tree-to-dependency conversions down-stream effects tree-to-dependency conversions down-stream effects tree-to-dependency conversions 
accuracy dependency parsers one key factors limiting quality dependencybased machine translation paper deals influence various dependency parsing approaches also different training data size overall performance statistical translation system implemented treex framework also study relationship parsing accuracy terms unlabeled attachment score machine translation quality terms bleu influence parser choice dependency-based mt influence parser choice dependency-based mt influence parser choice dependency-based mt 
describe system news commentary translation task wmt submitted run direction combination two systems developed lig lia laboratories report experiments improve standard model using statistical information retrieval methods subsample parallel corpora rover combine list hypotheses output different systems liga (lig/lia) machine translation system wmt 2011 liga (lig/lia) machine translation system wmt 2011 liga (lig/lia) machine translation system wmt 2011 
work describes ole english statistical machine translation system built barcelona media innovation center bm institute infocomm research th workshop statistical machine translation wmt system carefully processes available data uses standard system enhanced source context semantic feature helps conducting better lexical selection feature orthogonalization procedure helps making mert optimization reliable stable system ranked first among total participant systems conducted human evaluation bm-i2r haitian-cr&#233;ole-to-english translation system description wmt 2011 evaluation campaign bm-i2r haitian-cr&#233;ole-to-english translation system description wmt 2011 evaluation campaign bm-i2r haitian-cr&#233;ole-to-english translation system description wmt 2011 evaluation campaign 
paper describes machine translation mt system developed transducens research group universitat alacant spain wmt shared translation task submitted hybrid system spanish english language pair consisting statistical mt system whose phrase table enriched bilingual phrase pairs matching transfer rules dictionary entries apertium shallowtransfer mt platform hybrid system outperforms terms bleu gtm meteor standard statistical mt system trained corpus received second best bleu score automatic evaluation universitat d'alacant hybrid machine translation system wmt 2011 universitat d'alacant hybrid machine translation system wmt 2011 universitat d'alacant hybrid machine translation system wmt 2011 
paper describes development french english english french statistical machine translation systems wmt shared task evaluation main systems standard statistical systems based moses decoder trained provided data also performed initial experiments hierarchical systems additional new features year include improved translation model adaptation using monolingual data continuous space language model treatment unknown words lium&#8217;s smt machine translation systems wmt 2011 lium&#8217;s smt machine translation systems wmt 2011 lium&#8217;s smt machine translation systems wmt 2011 
incorporating semantic structure translation model challenging since semantic structures closely tied syntax paper propose approach exploiting structure reordering hierarchical translation model first introduce linguistically motivated constraints hierarchical model guiding translation phrase choices favor respect syntactic boundaries second based translation phrases propose structure reordering model predicts reordering argument predicate also two arguments experiments translation demonstrate advances significantly improve translation accuracy modeling syntactic semantic structures hierarchical phrase-based translation modeling syntactic semantic structures hierarchical phrase-based translation modeling syntactic semantic structures hierarchical phrase-based translation 
present dfki hybrid translation system wmt workshop three smt two rbmt systems combined level final translation output translation results show hybrid system significantly outperformed individual systems exploring strengths statistical translations dfki hybrid machine translation system wmt 2011 - integration smt rbmt dfki hybrid machine translation system wmt 2011 - integration smt rbmt dfki hybrid machine translation system wmt 2011 - integration smt rbmt 
paper describes system presented translation task collaboration upv wmt comparison independent translation models interpolation available training corpora tested giving improvement bleu points baseline output lists rescored via target neural network language model improvement one bleu point baseline obtained adding two features giving bleu ter primary system computed lowercased detokenized outputs system positioned second final ranking ceu-upv english-spanish system wmt11 ceu-upv english-spanish system wmt11 ceu-upv english-spanish system wmt11 
present distributed framework largescale discriminative language models integrated within large vocabulary continuous speech recognition lvcsr system using lattice rescoring intentionally use weakened acoustic model baseline lvcsr system generate candidate hypotheses data allows us utilize large amounts unsupervised data train models propose efficient scalable mapreduce framework uses distributed training strategy handle large amounts data report small significant improvements recognition accuracies standard data set using discriminative reranking model also provide analysis various parameters models including model size types features size partitions mapreduce framework help supporting experiments large-scale discriminative language model reranking voice-search large-scale discriminative language model reranking voice-search large-scale discriminative language model reranking voice-search 
present novel approach extracting minimal synchronous grammar scfg statistical machine translation using bayesian framework approach designed extract rules licensed word alignments heuristically extracted phrase pairs bayesian model limits number scfg rules extracted sampling space possible hierarchical rules additionally informed prior based lexical alignment probabilities biases grammar extract high quality rules leading improved generalization automatic identification commonly rules show bayesian model able extract minimal set hierarchical phrase rules without impacting translation quality measured bleu score bayesian extraction minimal scfg rules hierarchical phrase-based translation bayesian extraction minimal scfg rules hierarchical phrase-based translation bayesian extraction minimal scfg rules hierarchical phrase-based translation 
report results work automating transliteration decision named entities english arabic machine translation construct framework automate decision evaluate classifier limited news diverse wikipedia domains achieve promising accuracy moreover demonstrate reduction translation error improvement performance machine translation system dudley north visits north london: learning transliterate arabic dudley north visits north london: learning transliterate arabic dudley north visits north london: learning transliterate arabic 
paper describes approach improve summaries collection twitter posts created using phrase reinforcement pr algorithm sharifi et al pr algorithm often generates summaries excess text noisy speech parse summaries using dependency parser use dependencies eliminate excess text build summaries compare results obtained using pr algorithm better twitter summaries? better twitter summaries? better twitter summaries? 
online learning algorithms perceptron mira become popular many nlp tasks thanks simpler architecture faster convergence batch learning methods however batch learning crf easily parallelizable online learning much harder parallelize previous efforts often witness decrease converged accuracy speedup typically small even many processors instead present much simpler architecture based trivially parallelizable show unlike previous methods minibatch learning serial mode actually improves converged accuracy perceptron mira learning combined simple parallelization minibatch leads significant speedups processors parsing tagging systems minibatch parallelization online large margin structured learning minibatch parallelization online large margin structured learning minibatch parallelization online large margin structured learning 
paper examine idea communication partner aac user make guesses intended messages included user word completion prediction interface run human trials simulate new interface concept subjects predicting words user intended message generated real time specified typing speeds results indicate people provide substantial keystroke savings providing word completion prediction savings high language models interestingly language model human predictions complementary certain key ways humans better job circumstances contextually salient nouns discuss implications enhanced coconstruction interface message generation aac direct selection devices towards technology-assisted co-construction communication partners towards technology-assisted co-construction communication partners towards technology-assisted co-construction communication partners 
recently application discriminative training log statistical machine translation limited tuning weights limited number features training features limited number parameters paper propose scale discriminative training deng train features million parameters one order magnitude higher previously published effort apply discriminative training redistribute probability mass lost due model pruning experimental results confirm effectiveness proposals nist mt set strong baseline discriminative training 150 million translation parameters application pruning discriminative training 150 million translation parameters application pruning discriminative training 150 million translation parameters application pruning 
compression msc task generating short single sentence summary cluster related sentences paper presents reranking method based keyphrase extraction compression candidates generated word msc approach reranked according number relevance keyphrases contain manual automatic evaluations performed using dataset made clusters newswire sentences results show proposed method significantly improves informativity generated compressions keyphrase extraction n-best reranking multi-sentence compression keyphrase extraction n-best reranking multi-sentence compression keyphrase extraction n-best reranking multi-sentence compression 
addressee detection ad important problem dialog systems scenarios contexts involving multiple people system systemdirected speech must distinguished speech recent work ad shriberg et al showed good results using prosodic lexical features trained data data however expensive collect new domain study focus lexical models investigate well data either outside domain scenarios fill matched data find speech modeled using conversational speech transcripts utterances modeled using data resulting ad system outperforms system trained matched data gains reduction equal error rate obtained models interpolated finally examine parts utterance useful find first seconds utterance contain lexical information ad analyze lexical items convey overall conclude scenario approximated combining data scenarios work done first author intern microsoft using out-of-domain data lexical addressee detection human-human-computer dialog using out-of-domain data lexical addressee detection human-human-computer dialog using out-of-domain data lexical addressee detection human-human-computer dialog 
pcfgs highly successful model natural language parsing recent work cohen et al introduced spectral algorithm parameter estimation unlike em algorithm guaranteed give consistent parameter estimates guarantees sample complexity paper describes experiments using spectral algorithm show algorithm provides models accuracy em order magnitude efficient describe number key steps used obtain level performance relevant work application spectral learning algorithms view results strong empirical evidence viability spectral methods alternative em experiments spectral learning latent-variable pcfgs experiments spectral learning latent-variable pcfgs experiments spectral learning latent-variable pcfgs 
work learning taggers based unrealistic assumptions amount quality training data paper attempt create true scenarios allowing linguist two hours annotate data evaluating languages kinyarwanda malagasy given severely limited amounts either type supervision tag dictionaries token supervision labeled sentences able dramatically improve learning hidden markov model method automatically generalizing annotations reducing noise inducing frequency information learning part-of-speech tagger two hours annotation learning part-of-speech tagger two hours annotation learning part-of-speech tagger two hours annotation 
formal distributional semantic models offer complementary benefits modeling meaning categorical compositional distributional model meaning coecke et al abbreviated discocat title combines aspects provide general framework meanings words obtained distributionally composed using methods logical setting form sentence meaning concrete consequences general abstract setting applications empirical data active study grefenstette et al grefenstette sadrzadeh paper extend study examining transitive verbs represented matrices discocat discuss three ways constructing matrices evaluate method disambiguation task developed grefenstette sadrzadeh background categorical distributional compositional model meaning coecke et al combines modularity formal semantic models empirical nature vector space models lexical semantics meaning sentence defined application grammatical structure represented model kronecker product meanings words computed distributional model concrete experimental consequences setting models aim bring together logical distributional approaches active topics current natural language semantics research see grefenstette et al grefenstette sadrzadeh clark et al baroni zamparelli guevara mitchell lapata paper focus recent concrete discocat model grefenstette sadrzadeh particular nouns composed transitive verbs whereby meaning transitive sentence sub tverb obj obtained taking componentwise multiplication matrix verb kronecker product vectors subject object sub tverb obj tverb sub obj logical models transitive verbs modeled relations categorical model relational experimenting transitive verbs discocat experimenting transitive verbs discocat experimenting transitive verbs discocat 
propose new approach identifying semantically similar words across languages approach based idea two words different languages similar likely generate similar words includes source target language words top semantic word responses semantic word responding concept cognitive science addresses detecting likely words humans output free word associations given cue word method consists two main steps utilizes probabilistic multilingual topic model trained comparable data learn quantify semantic word responses provides ranked lists similar words according similarity semantic word response vectors evaluate approach task bilingual lexicon extraction ble variety language pairs show settings without language pair dependent knowledge method similarity robust outperforms current art methods directly operate semantic space latent concepts topics cross-lingual semantic similarity words similarity semantic word responses cross-lingual semantic similarity words similarity semantic word responses cross-lingual semantic similarity words similarity semantic word responses 
sentence compression attracted much interest recent years sentence compressors extractive delete words lack appropriate datasets train evaluate abstractive sentence compressors methods apart deleting words also rephrase expressions present new dataset contains candidate extractive abstractive compressions source sentences candidate compressions annotated human judgements grammaticality meaning preservation discuss dataset created used abstractive sentence compressors also report experimental results novel abstractive sentence compressor uses dataset new sentence compression dataset use abstractive generate-and-rank sentence compressor new sentence compression dataset use abstractive generate-and-rank sentence compressor new sentence compression dataset use abstractive generate-and-rank sentence compressor 
current word alignment models statistical machine translation address morphology beyond merely splitting words present alignment model distinguishes words morphemes embed ibm model inside hmm based word alignment model model jointly induces word morpheme alignments using em algorithm evaluated model parallel data obtained significant improvement bleu scores ibm model results indicate utilizing information morphology improves quality word alignments simultaneous word-morpheme alignment statistical machine translation simultaneous word-morpheme alignment statistical machine translation simultaneous word-morpheme alignment statistical machine translation 
many recent investigations methods tune smt systems using large numbers sparse features however nearly many examples helpful sparse features especially phrasebased systems use sparse features address reordering often considered weak point translation using hierarchical reordering model baseline show simple features coupling phrase orientation frequent words wordclusters improve translation quality boosts bleu points chineseenglish compare solution traditional maximum entropy approach probability model similar features trained wordaligned bitext show sparse decoder features outperform maximum entropy handily indicating major advantages optimizing reordering features directly bleu decoder loop improved reordering phrase-based translation using sparse features improved reordering phrase-based translation using sparse features improved reordering phrase-based translation using sparse features 
standard translation models explicitly model context dependence translation units result rely large phrase pairs target language models recover contextual effects translation work explore models minimal translation units mtus explicitly capture contextual dependencies across phrase boundaries channel model single best direction contextual information flow explore multiple decomposition structures well dynamic bidirectional decomposition resulting models evaluated intrinsic task lexical selection mt well full mt system reranking experiments demonstrate additional contextual modeling indeed benefit system direction conditioning important integrating multiple conditioning orders provides consistent benefit important directions differ language pair beyond left-to-right: multiple decomposition structures smt beyond left-to-right: multiple decomposition structures smt beyond left-to-right: multiple decomposition structures smt 
models counterparts alternative smt framework techniques pros cons framework provides better model captures source target contexts avoids spurious phrasal segmentation ability memorize produce larger translation units gives edge systems decoding terms better search performance superior selection translation units paper combine modeling decoding obtain benefits approaches experiments show using combination improves search accuracy model also improves bleu scores system outperforms systems moses phrasal systems significant margin german french spanish english translation tasks model minimal translation units, decode phrases model minimal translation units, decode phrases model minimal translation units, decode phrases 
defining reordering search space crucial issue smt distant languages fact optimal tradeoff accuracy complexity decoding nowadays reached harshly limiting input permutation space propose method dynamically shape space thus capture word movements without hurting translation quality decoding time space defined loose reordering constraints dynamically pruned binary classifier predicts whether given input word translated right another integration model decoder improves strong baseline already including early distortion cost moore quirk hierarchical phrase orientation models galley manning significant improvements reordering verbs achieved system notably faster baseline bleu meteor remain stable even increase high distortion limit dynamically shaping reordering search space phrase-based statistical machine translation dynamically shaping reordering search space phrase-based statistical machine translation dynamically shaping reordering search space phrase-based statistical machine translation 
information retrieval often important align words similar meaning two corpora written different languages previous research shows using context similarity align words helpful dictionary entry available suggest new method selects subset words pivot words associated query matches words across languages detect word associations demonstrate new bayesian method estimating mutual information provides improved accuracy second step matching done novel way calculates chance accidental overlap pivot words using hypergeometric distribution implemented wide variety previously suggested methods testing two conditions small comparable corpora pair large unrelated corpora pair written disparate languages show approach consistently outperforms systems robust measurement comparison context similarity finding translation pairs robust measurement comparison context similarity finding translation pairs robust measurement comparison context similarity finding translation pairs 
propose series learned arc filters speed dependency parsing cascade filters identify implausible pairs time complexity first linear quadratic length sentence linear filters reliably predict context words roots leaves dependency trees words likely heads left right use information quickly prune arcs dependency graph total arcs pruned retaining true dependencies filters improve speed two dependency parsers low overhead negligible loss accuracy fast accurate arc filtering dependency parsing fast accurate arc filtering dependency parsing fast accurate arc filtering dependency parsing 
paper considers problem sentiment detection proposing hierarchical classifier algorithm accounts similarity tagged texts type classifier also provides natural mechanism reducing feature space problem results show approach improves predictive performance movie reviews fourstar ratings simultaneously reducing training times memory requirements hierarchical classifier applied multi-way sentiment detection hierarchical classifier applied multi-way sentiment detection hierarchical classifier applied multi-way sentiment detection 
due nature complex nlp problems structured prediction algorithms important modeling tools wide range tasks exists evidence showing linear structural support vector machine ssvm algorithm performs better structured perceptron ssvm algorithm still less frequently chosen nlp community relatively slow training speed paper propose fast dual coordinate descent algorithm ssvms unlike algorithms perceptron stochastic gradient descent method keeps track dual variables updates weight vector aggressively result training process efficient existing online learning methods yet derives consistently better models evaluated four benchmark nlp datasets tagging recognition dependency parsing dual coordinate descent algorithms efficient large margin structured prediction dual coordinate descent algorithms efficient large margin structured prediction dual coordinate descent algorithms efficient large margin structured prediction 
addition high accuracy short parsing training times important properties parser however parsing training times still relatively long determine analyzed time usage dependency parser illustrate mapping features onto weights support vector machine major factor time complexity resolve problem implemented perceptron algorithm hash kernel hash kernel substantially improves parsing times takes account features negative examples built training lead higher accuracy could increase parsing training speed parallel feature extraction parallel parsing algorithm convinced hash kernel parallelization applied successful nlp applications well transition based dependency parsers phrase structrue parsers machine translation top accuracy fast dependency parsing contradiction top accuracy fast dependency parsing contradiction top accuracy fast dependency parsing contradiction 
paper proposes discriminative forest reranking algorithm dependency parsing seen form efficient stacked parsing dynamic programming parser produces packed derivation forest scored discriminative reranker using tree output parser guide features addition features improve efficiency accuracy paper also proposes novel parser eliminates spurious ambiguity arcstandard transition systems testing english penn treebank data forest reranking gave unlabeled dependency accuracy efficient stacked dependency parsing forest reranking efficient stacked dependency parsing forest reranking efficient stacked dependency parsing forest reranking 
introduce novel nonparametric bayesian model induction combinatory categorial grammars text achieves state art performance number languages induces linguistically plausible lexicons hdp model inducing combinatory categorial grammars hdp model inducing combinatory categorial grammars hdp model inducing combinatory categorial grammars 
paper propose unsupervised approach identifying bipolar person names set topic documents employ principal component analysis pca discover bipolar word usage patterns person names documents show signs entries principal eigenvector pca partition person names bipolar groups spontaneously empirical evaluations demonstrate efficacy proposed approach identifying bipolar person names topics bipolar person name identification topic documents using principal component analysis bipolar person name identification topic documents using principal component analysis bipolar person name identification topic documents using principal component analysis 
graph based dependency parsing inefficient handling features due high computational complexity inference paper proposed exact efficient decoding algorithm based branch bound framework nonlocal features bounded linear combination local features dynamic programming used search upper bound experiments conducted english ptb chinese ctb datasets achieved competitive unlabeled attachment score uas additional resources available english chinese parsing speed words per second english words per second chinese algorithm general adapted nonprojective dependency parsing graphical models branch bound algorithm dependency parsing non-local features branch bound algorithm dependency parsing non-local features branch bound algorithm dependency parsing non-local features 
computing lexical contrast saif mohammad national research council canada bonnie dorr university maryland graeme hirst university toronto peter turney national research council canada knowing degree semantic contrast words widespread application natural language processing including machine translation information retrieval dialogue systems manually created lexicons focus opposites hot cold opposites many kinds antipodals complementaries gradable existing lexicons often classify opposites different kinds however also explicitly list word pairs opposites yet degree contrast meaning warm cold tropical freezing propose automatic method identify contrasting word pairs based hypothesis pair words contrasting pair opposites strongly related strongly related example exists pair opposites hot cold tropical related hot freezing related cold call contrast hypothesis begin large crowdsourcing experiment determine amount human agreement concept oppositeness different kinds process flesh key features different kinds opposites present automatic empirical measure lexical contrast relies contrast hypothesis corpus statistics structure thesaurus show using four different data sets evaluated approach two different tasks solving contrasting word questions distinguishing synonyms opposites results analyzed across four parts speech across five different kinds opposites show proposed measure lexical contrast obtains high precision large coverage outperforming existing methods national research council canada saif mohammad gc ca department computer science institute advanced computer studies university maryland bonnie umiacs umd edu department computer science university toronto gh cs toronto edu national research council canada peter turney gc ca submission received january revised submission received june accepted publication july doi coli association computational linguistics computational linguistics volume number computing lexical contrast computing lexical contrast computing lexical contrast 
integration facts derived information extraction systems existing knowledge bases requires system disambiguate entity mentions text challenging due issues variations entity names mention ambiguity entities absent knowledge base present state art system entity disambiguation addresses challenges also scales knowledge bases several million entries using little resources approach achieves performance entities mentioned newswire public test set designed include challenging queries entity disambiguation knowledge base population entity disambiguation knowledge base population entity disambiguation knowledge base population 
syntactic reordering effective way handling word order differences de construction flexible ubiquitous syntactic structure chinese major source error translation quality paper propose new classifier model discriminative latent variable model dplvm classify de construction improve accuracy classification hence translation quality also propose new feature automatically learn reordering rules certain extent experimental results show mt systems using data reordered proposed model outperform baseline systems relative points terms bleu score hierarchical mt respectively addition analyse impact de annotation word alignment smt phrase table discriminative latent variable-based "de" classifier chinese-english smt discriminative latent variable-based "de" classifier chinese-english smt discriminative latent variable-based "de" classifier chinese-english smt 
previous methods improving translation quality employing multiple smt models usually carry secondpass decision procedure hypotheses multiple systems using extra features instead using features existing models depth paper propose translation model generalization tmg approach updates probability feature values translation model used based model set auxiliary models aiming enhance translation quality firstpass decoding validate approach translation models based auxiliary models built two different ways also introduce novel probability variance features models improvements conclude approach developed independently integrated current smt pipeline directly demonstrate bleu improvements nist mt tasks decodings system combination approach model combination approach translation model generalization using probability averaging machine translation translation model generalization using probability averaging machine translation translation model generalization using probability averaging machine translation 
present mixture minimum bayes risk mmmbr decoding approach makes use multiple smt systems improve translation accuracy unlike existing mbr decoding methods defined basis single smt systems mmmbr decoder reranks translation outputs combined search space multiple systems using mbr decision rule mixture distribution component smt models translation hypotheses mmmbr decoding general method independent specific smt models applied various commonly used search spaces experimental results nist mt evaluation tasks show approach brings significant improvements single mbr decoding outperforms system combination method mixture model-based minimum bayes risk decoding using multiple machine translation systems mixture model-based minimum bayes risk decoding using multiple machine translation systems mixture model-based minimum bayes risk decoding using multiple machine translation systems 
present novel summarization framework opinosis generates concise abstractive summaries highly redundant opinions evaluation results summarizing user reviews show opinosis summaries better agreement human summaries compared baseline extractive method summaries readable reasonably informative enough convey major opinions opinosis: graph based approach abstractive summarization highly redundant opinions opinosis: graph based approach abstractive summarization highly redundant opinions opinosis: graph based approach abstractive summarization highly redundant opinions 
paper proposes novel semisupervised word alignment technique called emdc integrates discriminative generative methods discriminative aligner used find high precision partial alignments serve constraints generative aligner implements constrained version em algorithm experiments chinese arabic tasks show consistent improvements aer also experimented chinese machine translation tasks got average point improvement bleu scores across five standard nist test sets four test sets emdc: semi-supervised approach word alignment emdc: semi-supervised approach word alignment emdc: semi-supervised approach word alignment 
hierarchical machine translation capture global reordering synchronous grammar little ability evaluate correctness word orderings decoding propose method integrate reordering model hierarchical phrasebased machine translation overcome weakness approach extends synchronous grammar rules hierarchical model include reordered source strings allowing efficient calculation reordering model scores decoding experimental results basic travel expression corpus showed bleu scores obtained proposed system better obtained standard hierarchical machine translation system hierarchical phrase-based machine translation word-based reordering model hierarchical phrase-based machine translation word-based reordering model hierarchical phrase-based machine translation word-based reordering model 
phrase reordering great importance statistical machine translation according movement phrase translation pattern phrase reordering divided three classes monotone btg bracket transduction grammar hierarchy good way use different styles reordering models reorder different phrases according characteristics reordering models phrases paper novel reordering model based phrase prml proposed source sentence segmented different layers phrases different reordering models applied get final translation model advantages different styles phrase reordering models easily incorporated together complicated reordering model employed limited smaller scope replaced easier reordering model larger scope model better translation speed performance simultaneously novel reordering model based multi-layer phrase statistical machine translation novel reordering model based multi-layer phrase statistical machine translation novel reordering model based multi-layer phrase statistical machine translation 
paper proposes new approach phrase rescoring statistical machine translation smt set novel features capturing translingual equivalence source target phrase pair introduced features combined linear regression model neural network predict quality score phrase translation pair phrase scores used discriminatively rescore baseline mt system phrase library boost good phrase translations prune bad ones approach significantly improves machine translation quality also reduces model size considerable margin feature-rich discriminative phrase rescoring smt feature-rich discriminative phrase rescoring smt feature-rich discriminative phrase rescoring smt 
text understanding systems often commit single best interpretation sentence analyzing subsequent text interpretation chosen resolving ambiguous alternatives one highest confidence given context available time commitment subsequent text however may contain information changes confidence alternatives may especially case multiple redundant texts topic ideally systems would delay choosing among ambiguous alternatives text read one solution maintain multiple candidate interpretations sentence system acquires disambiguating evidence unfortunately number alternatives explodes quickly paper propose packed graphical pg representation efficiently represent large number alternative interpretations along dependencies among also present algorithm combining multiple pg representations help resolve ambiguity prune alternatives time comes commit single interpretation controlled experiments show delaying ambiguity resolution multiple texts read prototype accuracy higher committing interpretations improving quality text understanding delaying ambiguity resolution improving quality text understanding delaying ambiguity resolution improving quality text understanding delaying ambiguity resolution 
paper describes cluster together phrases statistical machine translation smt system using information phrase table clustering symmetric recursive applied sourcelanguage phrases clustering one language helps determine clustering phrase clusters many possible uses paper looks one uses smoothing conditional translation model tm probabilities employed smt system incorporated probability estimates baseline loglinear feature combination included relative frequency conditional probability estimates chineseenglish learning curve experiments obtained gain baseline tests maximum gain bleu points though gains fairly small largest gains came medium sentence pairs rather small less sentence pairs amounts training data contrary one would expect paraphrasing literature begun explore original smoothing approach described phrase clustering smoothing tm probabilities - or, extract paraphrases phrase tables phrase clustering smoothing tm probabilities - or, extract paraphrases phrase tables phrase clustering smoothing tm probabilities - or, extract paraphrases phrase tables 
polarity shifting marked various linguistic structures challenge automatic sentiment classification paper propose machine learning approach incorporate polarity shifting information sentiment classification system first feature selection method adopted automatically generate training data binary classifier polarity shifting detection sentences using obtained binary classifier document original polarity classification training data split two partitions used train two base classifiers respectively classifier combination experimental results across four different domains demonstrate effectiveness approach sentiment classification polarity shifting sentiment classification polarity shifting sentiment classification polarity shifting 
paper addresses problem dynamic model parameter selection loglinear model based statistical machine translation smt systems work propose principled method task transforming test data dependent development set selection problem present two algorithms automatic development set construction evaluated method several nist data sets translation task experimental results show method effectively adapt model parameters different test data consistently achieves good translation performance compared conventional methods use fixed model parameter setting across different data sets adaptive development data selection log-linear model statistical machine translation adaptive development data selection log-linear model statistical machine translation adaptive development data selection log-linear model statistical machine translation 
paper present simplified shallow semantic parsing approach learning scope negation son done formulating shallow semantic parsing problem negation signal predicate negation scope arguments parsing approach son learning differs chunking ones two aspects first extend son learning chunking level parse tree level structured syntactic information available second focus determining whether constituent rather word negated via simplified shallow semantic parsing framework evaluation bioscope corpus shows structured syntactic information effective capturing domination relationship negation signal dominated arguments also shows parsing approach much outperforms chunking ones learning scope negation via shallow semantic parsing learning scope negation via shallow semantic parsing learning scope negation via shallow semantic parsing 
several researchers proposed learning methods adapting event extraction systems new event types paper investigates two kinds bootstrapping methods used event extraction approaches proposes filtered ranking method combines advantages two use range extraction tasks compare generality method previous work analyze results using two evaluation metrics observe effect different training corpora experiments show new ranking method achieves higher performance different evaluation metrics also stable across different bootstrapping corpora filtered ranking bootstrapping event extraction filtered ranking bootstrapping event extraction filtered ranking bootstrapping event extraction 
paper presents web application web service diagnostic evaluation machine translation mt tools built top delic mt opensource software package assesses performance mt systems linguistic phenomena lexical morphological syntactic semantic advantage scenario clear compared standalone tool user need carry installation configuration maintenance tool automatic evaluation machine translation beyond overall scores machine translation mt output evaluated using different approaches essentially divided human automatic however present number shortcomings human evaluation tends reliable number ways tailored variety situations rather expensive terms resources time difficult replicate hand standard automatic mt evaluation metrics bleu papineni et al meteor banerjee lavie considerably cheaper provide faster results return rather crude scores difficult interpret mt users developers alike crucially current standard automatic mt evaluation metrics also lack diagnostic value cannot identify specific weaknesses mt output diagnostic information extremely valuable mt developers users improve performance system decide output suited particular scenarios interesting alternative traditional mt evaluation metrics evaluate performance mt systems specific linguistic phenomena retaining main advantage automatic metrics low cost approach provides finegrained evaluation linguistic phenomena also referred linguistic checkpoints defined terms linguistic information different levels lexical morphological syntactic semantic etc appear source language examples linguistic checkpoints translation information represent relevance mt provided table checkpoint relevance mt lexical words web application diagnostic evaluation machine translation specific linguistic phenomena web application diagnostic evaluation machine translation specific linguistic phenomena web application diagnostic evaluation machine translation specific linguistic phenomena 
paper describes submission national university singapore wmt shared evaluation task tunable metric task entry tesla three different configurations new tesla wmt 2011: translation evaluation tunable metric tesla wmt 2011: translation evaluation tunable metric tesla wmt 2011: translation evaluation tunable metric 
evaluate two dependency parsers mstparser maltparser respect capacity recover unbounded dependencies english type evaluation applied grammarbased parsers statistical phrase structure parsers dependency parsers evaluation shows combined simple heuristics parsers correctly recall unbounded dependencies roughly time slightly worse two parsers specifically designed cope dependencies evaluation dependency parsers unbounded dependencies evaluation dependency parsers unbounded dependencies evaluation dependency parsers unbounded dependencies 
text summarization solves problem extracting important information huge amount text data various methods literature aim find summaries one commonly used methods latent semantic analysis lsa paper different lsa based summarization algorithms explained two new lsa based summarization algorithms proposed algorithms evaluated turkish documents performances compared using scores one algorithms produces best scores text summarization turkish texts using latent semantic analysis text summarization turkish texts using latent semantic analysis text summarization turkish texts using latent semantic analysis 
although much work nlp focused simply determining document means also must know whether believe algorithms attempt identify truth among competing claims corpus fail take advantage user prior knowledge presume truth universal objective rather subjective introduce framework incorporating prior knowledge factfinding algorithm expressing general reasoning specific facts already known user logic translating tractable linear program results show approach scales well even large problems reducing error allowing system determine truth respective user rather majority additionally introduce three new algorithms capable outperforming existing many experiments knowing believe (when already know something) knowing believe (when already know something) knowing believe (when already know something) 
route directions natural language nl statements specify given navigational task automatically computed route representation sequence actions followed user reach goal corpusbased approach generate route directions involves selection elements along route need mentioned ii induction mapping route elements linguistic structures used basis nl generation paper presents em based algorithm aligns geographical route representations semantically annotated nl directions basis tasks formulate one basic two extended models latter capturing special properties route direction task although current data set small extended models achieve better results simple model random baseline best results achieved combination extensions outperform random baseline simple model order magnitude computing em-based alignments routes route directions basis natural language generation computing em-based alignments routes route directions basis natural language generation computing em-based alignments routes route directions basis natural language generation 
approach task using range heuristics rely information appropriate metadata fields type similarity addition train linear regressor type similarity results indicate linear regression key good performance best system ranked third task ubc_uos-typed: regression typed-similarity ubc_uos-typed: regression typed-similarity ubc_uos-typed: regression typed-similarity 
year semantic textual similarity evaluation explore contribution models provide soft similarity scores across spans multiple words previous year system end explored use neural probabilistic language models weighted variant explicit semantic analysis neural language model systems used vector representations individual words vectors derived training context words encountered thus reflect distributional characteristics usage generate similarity score spans experimented using tiled vectors restricted boltzmann machines identify similar encodings find soft similarity methods generally outperformed previous year systems albeit perform well overall rankings simple analysis soft similarity resources two word phrases provided future areas improvement described sriubc-core: multiword soft similarity models textual similarity sriubc-core: multiword soft similarity models textual similarity sriubc-core: multiword soft similarity models textual similarity 
martins et al presented best knowledge still ranks best overall result conllx shared task datasets paper shows triads stacked dependency parsers described martins et al label unlabeled data way similar produce end parsers significantly better stacked input parsers evaluate system five datasets shared task obtain error reductions incl best reported results four compare approach semisupervised learning algorithms semi-supervised dependency parsing using generalized tri-training semi-supervised dependency parsing using generalized tri-training semi-supervised dependency parsing using generalized tri-training 
tagging approach dominant technique chinese word segmentation discriminative generative models adopted framework however generative discriminative approaches significantly different complement simple joint model combining generative model discriminative one thus proposed paper take advantage approaches experiments second sighan bakeoff show joint approach achieves relative error reduction discriminative model generative one addition closed tests also show proposed joint model outperforms existing approaches reported literature achieves best fscore four five corpora character-based joint model chinese word segmentation character-based joint model chinese word segmentation character-based joint model chinese word segmentation 
paper explores two hypotheses regarding vector space models predict compositionality german compounds intuition demonstrate rather distributional features perform better predictions adjectives verbs nouns represent salient overall best result reaching spearman wordspace model nominal features word window billion word web corpus significant differences predicting compound modifier vs compound head ratings compositionality show modifier rather head properties predominantly influence degree compositionality compound exploring vector space models predict compositionality german noun-noun compounds exploring vector space models predict compositionality german noun-noun compounds exploring vector space models predict compositionality german noun-noun compounds 
distributional semantics studies growing attention compositionally determining distributional meaning word sequences yet compositional distributional models depend large set parameters explored paper propose novel approach estimate parameters class compositional distributional models additive models approach leverages two main ideas firstly novel idea extracting compositional distributional semantics examples secondly estimation method based regression models multiple dependent variables experiments demonstrate approach outperforms existing methods determining good model compositional distributional semantics estimating linear models compositional distributional semantics estimating linear models compositional distributional semantics estimating linear models compositional distributional semantics 
automatic evaluation machine translation mt quality essential developing highquality mt systems various evaluation metrics proposed bleu used de facto standard metric however consider translation distant language pairs japanese english popular metrics bleu nist per ter work well well known japanese english completely different word orders special care must paid word order translation otherwise translations wrong word order often lead misunderstanding incomprehensibility instance translators tend translate thus word order important problem distant language translation however conventional evaluation metrics significantly penalize word order mistakes therefore locally optimizing metrics leads inadequate translations paper propose automatic evaluation metric based rank correlation coefficients modified precision patmt je task data shows metric outperforms conventional metrics automatic evaluation translation quality distant language pairs automatic evaluation translation quality distant language pairs automatic evaluation translation quality distant language pairs 
paper proposes method leverages multiple machine translation mt engines paraphrase generation pg method includes two stages firstly use approach acquire set candidate paraphrases source sentence employ two kinds techniques namely technique technique produce best paraphrase using candidates acquired first stage experimental results show approach effective obtaining plenty valuable candidate paraphrases selectionbased techniques make good use candidates produce paraphrases moreover two techniques complementary proposed method outperforms paraphrase generation approach leveraging multiple mt engines paraphrase generation leveraging multiple mt engines paraphrase generation leveraging multiple mt engines paraphrase generation 
unrehearsed spoken language often contains disfluencies order correctly interpret spoken utterance disfluencies must identified removed otherwise dealt operating transcripts speech contain disfluencies particular focus identification correction speech repairs using noisy channel model aim develop mechanism identify speech repairs incremental fashion utterance processed also address issue evaluation incremental systems propose novel approach evaluation evaluates performance detecting correcting disfluencies incrementally rather assessing performance processing utterance complete demonstrates shortcomings basic incremental model demonstrate technique improves performance detection disfluencies happen detecting speech repairs incrementally using noisy channel approach detecting speech repairs incrementally using noisy channel approach detecting speech repairs incrementally using noisy channel approach 
paper propose approach automatically detect sentiments twitter messages tweets explores characteristics tweets written words compose messages moreover leverage sources noisy labels training data noisy labels provided sentiment detection websites twitter data experiments show since features able capture abstract representation tweets solution effective previous ones also robust regarding biased noisy data kind data provided sources robust sentiment detection twitter biased noisy data robust sentiment detection twitter biased noisy data robust sentiment detection twitter biased noisy data 
address problem unsupervised independent alignment symmetrical asymmetrical parallel corpora asymmetrical parallel corpora contain large proportion sentence correspondences developed novel approach fast allows us achieve high accuracy terms alignment asymmetrical symmetrical parallel corpora source code aligner test sets freely available improved unsupervised sentence alignment symmetrical asymmetrical parallel corpora improved unsupervised sentence alignment symmetrical asymmetrical parallel corpora improved unsupervised sentence alignment symmetrical asymmetrical parallel corpora 
present supervised learning approach textual entailment explores statistical word alignment models predict entailment relations sentences written different languages approach language independent used participate clte task task organized within semeval negri et al four runs submitted one language combination covered test data spanish english german english french english italian english achieved encouraging results terms accuracy performance ranges german english italian english italian english spanish english test sets systems ranked second among five participants close top results respectively altn: word alignment features cross-lingual textual entailment altn: word alignment features cross-lingual textual entailment altn: word alignment features cross-lingual textual entailment 
paper describes system submitted melodi team task free paraphrases noun compounds hendrickx et al approach combines strength unsupervised distributional word space model supervised classification model distributional model yields feature representation particular compound noun subsequently used classifier induce number appropriate paraphrases melodi: supervised distributional approach free paraphrasing noun compounds melodi: supervised distributional approach free paraphrasing noun compounds melodi: supervised distributional approach free paraphrasing noun compounds 
paper proposes approach improve dependency parsing using decision history introduce mechanism considers short dependencies computed earlier stages parsing improve accuracy long dependencies later stages relies fact short dependencies generally accurate long dependencies models may used features help parse long dependencies mechanism easily implemented modifying graphbased parsing model introducing set new features experimental results show system achieves accuracy standard ptb test set english standard penn chinese treebank ctb test set chinese improving graph-based dependency parsing decision history improving graph-based dependency parsing decision history improving graph-based dependency parsing decision history 
present system wsd participated disambiguation task semeval lefever hoste system closely resembles winning system task semeval based neighbour classifiers map words local global context features onto translation sense system participated task five languages obtained winning scores four asked predict best translation tested various configurations system focusing various levels hyperparameter optimisation feature selection final results indicate hyperparameter optimisation lead best results indicating overfitting optimisation method aspect feature selection modest positive impact wsd2: parameter optimisation memory-based cross-lingual word-sense disambiguation wsd2: parameter optimisation memory-based cross-lingual word-sense disambiguation wsd2: parameter optimisation memory-based cross-lingual word-sense disambiguation 
present new reordering model estimated standard language model units built morphosyntactic information source target languages seen model translates structure input sentence contrast standard translation models take care surface word forms take advantage fact units less sparse standard translation units increase size bilingual context considered translation process thus effectively accounting reorderings empirical results germanenglish translation tasks show model achieves higher translation accuracy levels obtained widely used lexicalized reordering model improving reordering linguistically informed bilingual n-grams improving reordering linguistically informed bilingual n-grams improving reordering linguistically informed bilingual n-grams 
paper present hybrid decoding novel statistical machine translation smt decoding paradigm using multiple smt systems work addition component smt systems system combination method also employed generating partial translation hypotheses throughout decoding process smaller hypotheses generated component decoder hypotheses combination used following decoding steps generate larger hypotheses experimental results nist evaluation data sets machine translation mt task show method achieve significant improvements individual decoders also bring substantial gains compared system combination method hybrid decoding: decoding partial hypotheses combination multiple smt systems hybrid decoding: decoding partial hypotheses combination multiple smt systems hybrid decoding: decoding partial hypotheses combination multiple smt systems 
automated identification diverse sentiment types beneficial many nlp systems review summarization public media analysis systems option assigning sentiment value single sentence short text paper propose supervised sentiment classification framework based data twitter popular microblogging service utilizing twitter tags smileys sentiment labels framework avoids need labor intensive manual annotation allowing identification classification diverse sentiment types short texts evaluate contribution different feature types sentiment classification show framework successfully identifies sentiment types untagged sentences quality sentiment identification also confirmed human judges also explore dependencies overlap different sentiment types represented smileys twitter hashtags enhanced sentiment learning using twitter hashtags smileys enhanced sentiment learning using twitter hashtags smileys enhanced sentiment learning using twitter hashtags smileys 
paper describes novel method computing consensus translation outputs multiple machine translation mt systems outputs combined possibly new translation hypothesis generated similarly rover approach fiscus combining speech recognition hypotheses consensus translation computed voting confusion network create confusion network produce pairwise word alignments original machine translation hypotheses enhanced statistical alignment algorithm explicitly models word reordering context whole document translations rather single sentence taken account produce alignment proposed alignment voting approach evaluated several machine translation tasks including large vocabulary task method also tested framework speech translation tasks conditions achieved significant improvements translation quality increasing bleu score much relative computing consensus translation multiple machine translation systems using enhanced hypothesis alignment computing consensus translation multiple machine translation systems using enhanced hypothesis alignment computing consensus translation multiple machine translation systems using enhanced hypothesis alignment 
paper presents fuzzy set theory based approach chinese sentiment classification compared traditional text classification techniques fuzzy set theory provides straightforward way model intrinsic fuzziness sentiment polarity classes approach fuzzy sentiment classification first propose strategy estimate sentence sentiment intensity define three fuzzy sets represent respective sentiment polarity classes namely positive negative neutral sentiments based sentence sentiment intensities build membership functions indicate degrees opinionated sentence different fuzzy sets finally determine polarity maximum membership principle show approach achieve promising performance test set chinese opinion analysis pilot task chinese sentence-level sentiment classification based fuzzy sets chinese sentence-level sentiment classification based fuzzy sets chinese sentence-level sentiment classification based fuzzy sets 
paper propose novel framework enrich translation memory tm systems statistical machine translation smt outputs using ranking order offer human translators multiple choices instead using top smt output top tm hit merge output smt system hits highest fuzzy match scores tm system merged list ranked according prospective effort provided translators aid work experiments show ranked output achieve precision top precision top framework facilitates tight integration smt tm full advantage taken tm high quality smt output availed improve productivity human translators integrating n-best smt outputs tm system integrating n-best smt outputs tm system integrating n-best smt outputs tm system 
hierarchical models provide powerful mechanism capture phrase reorderings statistical machine translation smt however many phrase reorderings arbitrary models weak determining phrase boundaries patternmatching paper presents novel approach learn phrase boundaries directly corpus without using syntactical information use phrase boundaries indicate beginning ending phrase reordering soft constraints decoding experimental results analysis show approach yields significant improvements baseline translation learning phrase boundaries hierarchical phrase-based translation learning phrase boundaries hierarchical phrase-based translation learning phrase boundaries hierarchical phrase-based translation 
paper describes systems submitted avaya labs avaya task sentiment analysis twitter constrained conditions message polarity classification contextual polarity disambiguation subtasks approach centers training linear classifiers combination lexical syntactic features constrained message polarity model used tag nearly half million unlabeled tweets automatically labeled data used two purposes discover prior polarities words provide additional training examples systems performed competitively placing top five subtasks data conditions importantly results show expanding polarity lexicon augmenting training data unlabeled tweets yield improvements precision recall classifying polarity messages contexts avaya: sentiment analysis twitter self-training polarity lexicon expansion avaya: sentiment analysis twitter self-training polarity lexicon expansion avaya: sentiment analysis twitter self-training polarity lexicon expansion 
paper describe system participated task sentiment analysis twitter approach consists adapting naive bayes probabilities order take account prior knowledge represented form sentiment lexicon propose two different methods efficiently incorporate prior knowledge show approach outperforms classical naive bayes method shows competitive results svm less computational complexity ami&eric: learn naive bayes prior knowledge: application sentiment analysis ami&eric: learn naive bayes prior knowledge: application sentiment analysis ami&eric: learn naive bayes prior knowledge: application sentiment analysis 
choosing right parameters word sense disambiguation task critical success experiments explore idea prepositions often overlooked word class examine parameters must considered preposition disambiguation namely context features granularity delivers increased performance significantly improves two systems shows potential improving word sense disambiguation tasks report accuracies coarse preposition sense disambiguation respectively what&rsquo;s preposition? dimensions sense disambiguation interesting word class what&rsquo;s preposition? dimensions sense disambiguation interesting word class what&rsquo;s preposition? dimensions sense disambiguation interesting word class 
paper presents system tjp participated semeval task part contextual polarity disambiguation goal task predict whether marked contexts positive neutral negative however scores positive negative class used calculate evaluation result using chose work constrained used provided training development data without additional sentiment annotated resources approach considered unigram bigram trigram using na ve bayes training model objective establishing simpleapproach baseline system achieved fscore results sms messages tweets respectively tjp: using twitter analyze polarity contexts tjp: using twitter analyze polarity contexts tjp: using twitter analyze polarity contexts 
paper describes system participating semeval task kozareva et al sentiment analysis twitter given message system classifies whether message positive negative neutral sentiment uses rate model training data constrained data provided task organizers tweet data used consider types features use subset submitted system see contribution type features experimental study features leaving one type features time results suggest unigrams important features bigrams pos tags seem helpful stopwords retained achieve best results overall results system promising regarding constrained features data use ut-db: experimental study sentiment analysis twitter ut-db: experimental study sentiment analysis twitter ut-db: experimental study sentiment analysis twitter 
paper presents contribution team task semeval sentiment analysis twitter submitted constrained run two subtasks contextual polarity disambiguation subtask use sentiment lexicon approach combined polarity shift detection tree kernel based classifiers message polarity classification subtask focus influence domain information sentiment classification [lvic-limsi]: using syntactic features multi-polarity words sentiment analysis twitter [lvic-limsi]: using syntactic features multi-polarity words sentiment analysis twitter [lvic-limsi]: using syntactic features multi-polarity words sentiment analysis twitter 
paper overview swatcs system submitted task contextual polarity disambiguation sentiment individual phrases within tweet labeled using combination classifiers trained range lexical features classifiers combined estimating accuracy classifiers tweet performance measured using provided training data separately including external data swatcs: combining simple classifiers estimated accuracy swatcs: combining simple classifiers estimated accuracy swatcs: combining simple classifiers estimated accuracy 
paper presents novel approach dialogue act recognition employing multilevel information features addition features context information words utterances recognition task utilizes syntactic semantic relations acquired information extraction methods features utilized bayesian network classifier dialogue act recognition evaluation results show clear improvement accuracy baseline word features accuracy achieved extended feature set using syntactic semantic based relations dialogue act recognition using syntactic semantic based relations dialogue act recognition using syntactic semantic based relations dialogue act recognition 
sentiment analysis twitter become important task due huge content published media analysis could useful many domains marketing finance politics social propose use many features order improve trained classifier twitter messages features extend feature vector model concepts extracted dbpedia verb groups similar adjectives extracted wordnet sentifeatures extracted using sentiwordnet useful domain specific features also built dictionary emotion icons abbreviation slang words tweets useful extending tweets different features adding features improved accuracy svm naivebayes experiments dbpedia, wordnet sentiwordnet resources sentiment analysis micro-blogging experiments dbpedia, wordnet sentiwordnet resources sentiment analysis micro-blogging experiments dbpedia, wordnet sentiwordnet resources sentiment analysis micro-blogging 
statistical word alignment often suffers data sparseness often incorporated nlp tasks reduce data sparseness paper attempt mitigate problem reflecting alignment tendency statistical word alignment approach rely knowledge simple purely statistic applied language pairs evaluation shows proposed method improve quality statistical word alignment performance statistical machine translation post-processing approach statistical word alignment reflecting alignment tendency part-of-speeches post-processing approach statistical word alignment reflecting alignment tendency part-of-speeches post-processing approach statistical word alignment reflecting alignment tendency part-of-speeches 
sentiment analysis refers automatically extracting sentiment present given natural language text present participation semeval competition sentiment analysis twitter sms messages approach task combination two sentiment analysis subsystems combined together build final system subsystems use supervised learning using features based various polarity lexicons su-sentilab : classification system sentiment analysis twitter su-sentilab : classification system sentiment analysis twitter su-sentilab : classification system sentiment analysis twitter 
evaluate naive machine learning approach sentiment classification focused twitter context sentiment analysis task employ classifier based random forests algorithm determine whether tweet expresses overall positive negative neutral sentiment classifier trained provided dataset uses main features word vectors lexicon word counts average three classes twitter evaluation dataset average positive negative classes optional sms evaluation dataset overall average average positive negative fscores reaction: naive machine learning approach sentiment classification reaction: naive machine learning approach sentiment classification reaction: naive machine learning approach sentiment classification 
paper presents novel featurebased semantic role labeling srl method uses constituent dependency syntactic views comparing traditional srl method relying one syntactic view method much richer set syntactic features first select several important features existing studies basic features propose statistical method select discriminative combined features composed basic features srl achieved using svm classifier basic features combined features experimental results chinese proposition bank cpb show method outperforms traditional srl methods combining constituent dependency syntactic views chinese semantic role labeling combining constituent dependency syntactic views chinese semantic role labeling combining constituent dependency syntactic views chinese semantic role labeling 
paper describes specifications results unsupervised system presented semeval sentiment analysis twitter task wilson et al proposal system includes three phases data preprocessing contextual word polarity detection message classification preprocessing phase comprises treatment emoticon slang terms lemmatization word polarity detection carried taking account sentiment associated context appears use new contextual sentiment classification method based word sense disambiguation using wordnet miller sense inventory sentiment inventory built sentiwordnet baccianella et al finally overall sentiment determined using classifier may observed results obtained twitter sms sentiment classification good considering proposal unsupervised ssa-uo: unsupervised sentiment analysis twitter ssa-uo: unsupervised sentiment analysis twitter ssa-uo: unsupervised sentiment analysis twitter 
article describes sentiment analysis sa system named senti built participation task twitter sa challenge challenge subtasks used supervised machine learning approach including two classifiers pipeline semantic oriented features polarized term presence index negation presence system achieved better score task task first subtask better result sms obtained trained type data tweets senti.ue-en: approach informally written short texts semeval-2013 sentiment analysis task senti.ue-en: approach informally written short texts semeval-2013 sentiment analysis task senti.ue-en: approach informally written short texts semeval-2013 sentiment analysis task 
paper briefly reports system task sentiment analysis twitter first used svm classifier wide range features including bag word features unigram bigram pos features stylistic features readability scores statistics tweet analyzed domain names abbreviations emoticons twitter text investigated effectiveness features also used character language models address problem high lexical variation twitter text combined two approaches obtain final results system robust achieves good performance twitter test data well sms test data codex: combining svm classifier character n-gram language models sentiment analysis twitter text codex: combining svm classifier character n-gram language models sentiment analysis twitter text codex: combining svm classifier character n-gram language models sentiment analysis twitter text 
paper describe system task sentiment analysis twitter formed features take account context expression take supervised approach towards subjectivity polarity classification experiments performed features find whether suited subjectivity polarity classification tested model sentiment polarity classification twitter well sms chat expressions analyzed scores drew interesting conclusions sielers : feature analysis polarity classification expressions twitter sms data sielers : feature analysis polarity classification expressions twitter sms data sielers : feature analysis polarity classification expressions twitter sms data 
itg many desirable properties word alignment still suffers limitation matching existing approaches relax limitation using phrase pairs propose itg formalism even handles units words using simple hierarchical phrase pairs also propose parameter estimation method combines merits supervised unsupervised learning itg formalism itg alignment system achieves significant improvement word alignment quality translation performance improved discriminative itg alignment using hierarchical phrase pairs semi-supervised training improved discriminative itg alignment using hierarchical phrase pairs semi-supervised training improved discriminative itg alignment using hierarchical phrase pairs semi-supervised training 
paper describe system submitted sentiment analysis task semeval task implemented combination explicit semantic analysis esa naive bayes classifier esa represents text high dimensional vector explicitly defined topics following distributional semantic model approach novel sense esa used sentiment analysis literature best knowledge uom: using explicit semantic analysis classifying sentiments uom: using explicit semantic analysis classifying sentiments uom: using explicit semantic analysis classifying sentiments 
statistical mt smt milestone mt however translation model phrase based smt structure free greatly limits reordering capacity address issue propose headmodifier based reordering model word level utilizing constituent based parse tree source side experimental results nist chineseenglish benchmarking data show small size model method significantly outperforms baseline bleu score head-modifier relation based non-lexical reordering model phrase-based translation head-modifier relation based non-lexical reordering model phrase-based translation head-modifier relation based non-lexical reordering model phrase-based translation 
paper describes system developed serendio team task competition task use lexicon based approach discovering sentiments lexicon built serendio taxonomy serendio taxonomy consists positive negative negation stop words phrases typical tweet contains word variations emoticons hashtags etc use preprocessing steps stemming emoticon detection normalization exaggerated word shortening hashtag detection preprocessing system classifies tweets positive negative based contextual sentiment orientation words system yields test dataset serendio: simple practical lexicon based approach sentiment analysis serendio: simple practical lexicon based approach sentiment analysis serendio: simple practical lexicon based approach sentiment analysis 
widespread use twitter makes interesting determine opinions sentiments expressed users shortness length highly informal nature tweets render difficult automatically detect information paper reports results challenge set forth task determine positive neutral negative sentiments tweets two systems explained system determining sentiment phrase within tweet system determining sentiment tweet approaches rely rich feature sets explained detail bounce: sentiment classification twitter using rich feature sets bounce: sentiment classification twitter using rich feature sets bounce: sentiment classification twitter using rich feature sets 
paper describes systems participated task sentiment analysis twitter semeval specifically message polarity classification used pipeline approach employing linear svm classifier stage several features including bow features pos based features lexicon based features also experimented naive bayes classifiers trained bow features nlp.cs.aueb.gr: two stage sentiment analysis nlp.cs.aueb.gr: two stage sentiment analysis nlp.cs.aueb.gr: two stage sentiment analysis 
paper investigates new problem automatic sense induction instance names using automatically extracted attribute sets several clustering strategies data sources described evaluated also discuss drawbacks evaluation metrics commonly used similar clustering tasks results show improvements metrics respect baselines especially polysemous instances instance sense induction attribute sets instance sense induction attribute sets instance sense induction attribute sets 
traditional translation pipelines suffer major drawback errors best outputs inevitably introduced module propagate accumulate along pipeline order alleviate problem use compact structures lattice forest module instead results integrate lattice forest single system explore algorithms lattice parsing rule extraction decoding importantly model takes account probabilities different steps segmentation parsing translation main advantage model make global decision search best segmentation translation one step experiments show improvement bleu points baseline machine translation lattices forests machine translation lattices forests machine translation lattices forests 
paper present approach acquire japanese unknown morphemes text full pos tags assigned first acquire unknown morphemes making morphologylevel distinction apply semantic classification acquired nouns one advantage approach second stage exploit syntactic clues addition morphological ones result first stage acquisition rely automatic parsing japanese semantic classification poses interesting challenge proper nouns need distinguished common nouns japanese orthographic distinction common proper nouns apparent morphosyntactic distinction explore clues extracted automatically parsed text investigate effects semantic classification automatically acquired nouns using lexico-syntactic clues semantic classification automatically acquired nouns using lexico-syntactic clues semantic classification automatically acquired nouns using lexico-syntactic clues 
paper presents uos word sense induction system attempts find applicable senses target word given context grading sense according suitability context senses target word induced use clustering algorithm returns maximal connected components target word graph vertex pairs assigned cluster either vertex highest edge weight uos participated task word sense induction graded senses two system submitted systems returned results comparable best performing systems uos: graph-based system graded word sense induction uos: graph-based system graded word sense induction uos: graph-based system graded word sense induction 
demonstrate use context features namely names places unlabelled data detection personal name language origin early work used either methods statistical models determine name language origin use discriminative classification maximum entropy model view task classification task perform bootstrapping learning using list names context known origin using algorithm train model large corpus names unknown origin context features using relatively small unlabelled corpus improve accuracy name origin recognition names written chinese significant reduction error rate improvement infrequent japanese names even greater without context features context features improving name origin recognition context features unlabelled data improving name origin recognition context features unlabelled data improving name origin recognition context features unlabelled data 
introduce tiered clustering mixture model capable accounting varying degrees shared feature structure demonstrate applicability inferring distributed representations word meaning common tasks lexical semantics word relatedness selectional preference benefit modeling structure polysemous word usage often governed common background metaphoric usage senses line run likewise modeling selectional preference verbs relies identifying commonalities shared typical arguments tiered clustering also viewed form soft feature selection features contribute meaningfully clustering excluded demonstrate applicability tiered clustering highlighting particular cases modeling shared structure beneficial detrimental mixture model sharing lexical semantics mixture model sharing lexical semantics mixture model sharing lexical semantics 
paper propose method mediatory summarization novel technique facilitating users assessments credibility information web mediatory summary generated extracting passage web documents summary generated basis relevance given query fairness density keywords features summaries constructed determine credibility information web demonstrate effectiveness generated mediatory summary comparison summaries web documents produced web search engines method automatically generating mediatory summary verify credibility information web method automatically generating mediatory summary verify credibility information web method automatically generating mediatory summary verify credibility information web 
paper proposes approach wsd based selectional preferences approach exploits syntagmatic paradigmatic semantic redundancy semantic system uses association computation minimum description length task wsd experiments collocations collocations polysemous predicates chinese show proposed approach achieves precision higher semanticassociation based baseline semisupervised nature approach makes promising constructing large scale selectional preference knowledge base semi-supervised wsd selectional preferences semantic redundancy semi-supervised wsd selectional preferences semantic redundancy semi-supervised wsd selectional preferences semantic redundancy 
unsupervised dialogue act modeling holds great promise decreasing time build dialogue systems work date utilized manual synthetic task evaluate dialogue act models evaluation approaches limitations paper presents evaluation framework dialogue act model within dialogue clusters generated model mapped tutor responses handcrafted policy applied unseen test data evaluated judges results suggest evaluation may better reflect performance model comparing manual dialogue act labels in-context evaluation unsupervised dialogue act models tutorial dialogue in-context evaluation unsupervised dialogue act models tutorial dialogue in-context evaluation unsupervised dialogue act models tutorial dialogue 
present first known empirical results sequence labeling based maximum margin markov networks incorporate kernel methods efficiently deal feature spaces probabilistic graphical models capture correlations structured data provide efficient algorithm stochastic gradient descent sgd speedup training procedure using official dataset noun phrase np chunking case study resulting optimizer converges quality solution order magnitude faster structured sequential minimal optimization structured smo model compares favorably current sequence labeling approaches importantly model easily applied sequence labeling tasks accelerated training maximum margin markov models sequence labeling: case study np chunking accelerated training maximum margin markov models sequence labeling: case study np chunking accelerated training maximum margin markov models sequence labeling: case study np chunking 
given increasing need process massive amounts textual data efficiency nlp tools becoming pressing concern parsers based lexicalised grammar formalisms tag ccg made efficient using supertagging ccg effective every derivation consistent supertagger output stored packed chart however ccg parsers still produce large number derivations typical newspaper wikipedia sentences paper investigate two forms chart pruning develop novel method pruning complete cells parse chart result widecoverage ccg parser process almost sentences per second little loss accuracy baseline pruning chart pruning fast lexicalised-grammar parsing chart pruning fast lexicalised-grammar parsing chart pruning fast lexicalised-grammar parsing 
paper presents novel semisupervised learning algorithm called active deep networks adn address sentiment classification problem active learning first propose learning method adn adn constructed restricted boltzmann machines rbm unsupervised learning using labeled data abundant unlabeled data constructed structure finetuned based supervised learning exponential loss function second apply active learning learning framework identify reviews labeled training data adn architecture trained selected labeled data unlabeled data experiments five sentiment classification datasets show adn outperforms learning algorithm deep learning techniques applied sentiment classification active deep networks semi-supervised sentiment classification active deep networks semi-supervised sentiment classification active deep networks semi-supervised sentiment classification 
metrics automatic machine translation mt evaluation widely applied mt research meanwhile linguistic motivated metrics suggested improve metrics sentencelevel evaluation work attempt change original calculation units granularities metrics generate new features propose powerful automatic mt evaluation metric combining features various granularities based svm rank regression models experimental results show new features various granularities contribute automatic evaluation translation quality ii proposed metrics multiple granularities based svm regression model achieve higher correlations human assessments automatic metrics strings: powerful string-based automatic mt evaluation metric multiple granularities strings: powerful string-based automatic mt evaluation metric multiple granularities strings: powerful string-based automatic mt evaluation metric multiple granularities 
present probabilistic approach interpretation pointing gestures together spoken utterances mechanism models dependencies spatial temporal aspects gestures features utterances evaluation collected corpus requests optionally included pointing results show pointing information improves interpretation accuracy interpreting pointing gestures spoken requests &#x2013; probabilistic, salience-based approach interpreting pointing gestures spoken requests &#x2013; probabilistic, salience-based approach interpreting pointing gestures spoken requests &#x2013; probabilistic, salience-based approach 
participated bionlp shared tasks addressing genia ge cancer genetics cg event extraction tasks event extraction based system recently proposed mining relations events involving genes proteins biomedical literature using novel approximate subgraph approach addition handling ge task involving event types uniformly related molecular biology generalized system address cg task targeting challenging set event types related cancer biology various arguments involving kinds biological entities moreover attempted integrate distributional similarity model system extend graph matching scheme events addition evaluated impact using paths possible lengths among event participants key contextual dependencies extract potential events compared using shortest paths within framework system achieved cg task ge task ranking rd th respectively consistent performance confirms system generalizes well various event extraction tasks scales handle large number event entity types generalizing approximate subgraph matching-based system extract events molecular biology cancer genetics generalizing approximate subgraph matching-based system extract events molecular biology cancer genetics generalizing approximate subgraph matching-based system extract events molecular biology cancer genetics 
goal task evaluate feasibility multilingual wsd newly developed multilingual lexical sample data set participants asked automatically determine contextually appropriate translation given english noun five languages viz dutch german italian spanish french paper reports sixteen submissions five different participating teams semeval-2010 task 3: cross-lingual word sense disambiguation semeval-2010 task 3: cross-lingual word sense disambiguation semeval-2010 task 3: cross-lingual word sense disambiguation 
sentiment ambiguous adjectives cause major difficulties existing algorithms sentiment analysis present evaluation task designed provide framework comparing different approaches problem define task describe data creation list participating systems discuss results teams systems semeval-2010 task 18: disambiguating sentiment ambiguous adjectives semeval-2010 task 18: disambiguating sentiment ambiguous adjectives semeval-2010 task 18: disambiguating sentiment ambiguous adjectives 
paper describes algorithm exact decoding translation models based lagrangian relaxation method recovers exact solutions certificates optimality test examples method much efficient approaches based linear programming lp integer linear programming ilp solvers methods feasible anything short sentences compare method moses koehn et al give precise estimates number magnitude search errors moses makes exact decoding phrase-based translation models lagrangian relaxation exact decoding phrase-based translation models lagrangian relaxation exact decoding phrase-based translation models lagrangian relaxation 
statistical machine translation word lattices used represent ambiguities preprocessing source sentence word segmentation chinese morphological analysis german several approaches proposed define probability different paths lattice external tools like word segmenters applying indicator features introduce novel lattice design explicitly distinguishes different preprocessing alternatives source sentence allows us make use specific features preprocessing type lexicalize choice lattice path directly phrase translation model argue forced alignment training used learn lattice path phrase translation model simultaneously newscommentary portion german english wmt task show moderate improvements bleu baseline system phrase model training statistical machine translation word lattices preprocessing alternatives phrase model training statistical machine translation word lattices preprocessing alternatives phrase model training statistical machine translation word lattices preprocessing alternatives 
present two systems select appropriate spanish substitutes marked word english test sentence systems official entries lexical substitution task first system finds spanish substitutions first finding english substitutions english sentence translating substitutions spanish using dictionary second system translates english sentence spanish finds spanish substitutions spanish sentence systems exceeded baseline participating systems wide margin using one two official scoring metrics swat: cross-lingual lexical substitution using local context matching, bilingual dictionaries machine translation swat: cross-lingual lexical substitution using local context matching, bilingual dictionaries machine translation swat: cross-lingual lexical substitution using local context matching, bilingual dictionaries machine translation 
paper present word sense disambiguation wsd based system multilingual lexical substitution method depends wsd system english automatic word alignment method crucially approach relies parallel corpora task sinha et al apply supervised wsd system derive english word senses task lefever hoste apply unsupervised approach training test data systems participated task achieve decent ranking among participating systems task achieve highest ranking several language pairs french german italian colepl colslm: unsupervised wsd approach multilingual lexical substitution, tasks 2 3 semeval 2010 colepl colslm: unsupervised wsd approach multilingual lexical substitution, tasks 2 3 semeval 2010 colepl colslm: unsupervised wsd approach multilingual lexical substitution, tasks 2 3 semeval 2010 
describe university heidelberg uhd system word sense disambiguation task system performs clwsd applying graph algorithms previously developed monolingual word sense disambiguation multilingual cooccurrence graphs uhd participated best oof evaluations ranked among competitive systems task thus indicating approaches represent powerful alternative task uhd: cross-lingual word sense disambiguation using multilingual co-occurrence graphs uhd: cross-lingual word sense disambiguation using multilingual co-occurrence graphs uhd: cross-lingual word sense disambiguation using multilingual co-occurrence graphs 
report work english french word sense disambiguation task find best french translation target english word depending context used approach relies identifying nearest neighbors test sentence training data using pairwise similarity measure proposed measure finds affinity two sentences calculating weighted sum word overlap semantic overlap semantic overlap calculated using standard wordnet similarity measures nearest neighbors identified best translation found taking majority vote french translations nearest neighbors owns: cross-lingual word sense disambiguation using weighted overlap counts wordnet based similarity measures owns: cross-lingual word sense disambiguation using weighted overlap counts wordnet based similarity measures owns: cross-lingual word sense disambiguation using weighted overlap counts wordnet based similarity measures 
paper presents results wmt metrics shared task asked participants task score outputs mt systems involved wmt shared translation task collected scores metrics research groups addition computed scores standard metrics bleu wer per baselines collected scores evaluated terms system level correlation well metric scores correlate wmt official human scores terms segment level correlation often metric agrees humans comparing two translations particular sentence results wmt13 metrics shared task results wmt13 metrics shared task results wmt13 metrics shared task 
recent surge interest semantic machine translation standard automatic metrics struggle evaluate family measures called meant proposed uses semantic role labels srl overcome problem human variant hmeant largely evaluated using correlation human contrastive evaluations standard human evaluation metric wmt shared tasks paper claim human metric useful needs evaluated intrinsic properties needs reliable needs work across different language pairs needs lightweight importantly however human metric must discerning conclude hmeant step right direction serious flaws reliance verbs heads frames assumption annotators need minimal guidelines particularly problematic feasibility hmeant human mt evaluation metric feasibility hmeant human mt evaluation metric feasibility hmeant human mt evaluation metric 
describe cmu systems submitted wmt shared task machine translation participated three language pairs french english russian english english russian particular innovations include labelcoarsening scheme syntactic translation use specialized modules create synthetic translation options generalize beyond directly observed parallel training data use rich source language context decide phrase translate context cmu machine translation systems wmt 2013: syntax, synthetic translation options, pseudo-references cmu machine translation systems wmt 2013: syntax, synthetic translation options, pseudo-references cmu machine translation systems wmt 2013: syntax, synthetic translation options, pseudo-references 
paper describes statistical machine translation smt systems developed yandex school data analysis shared translation task acl eighth workshop statistical machine translation adopted smt approach evaluated number different techniques including data filtering spelling correction alignment lemmatized word forms transliteration altogether yielded bleu improvement enru language pairs also report experiments positive effect provide analysis problems encountered development systems yandex school data analysis machine translation systems wmt13 yandex school data analysis machine translation systems wmt13 yandex school data analysis machine translation systems wmt13 
paper describes ub ilgem statistical machine translation smt systems submitted eighth workshop statistical machine translation wmt shared translation task language pair directions implement smt systems standard parameters present results using big tuning data effect averaging tuning weights different seeds additionally performed linguistically motivated compound splitting smt system tÃœbÄ°tak-bÄ°lgem german-english machine translation systems w13 tÃœbÄ°tak-bÄ°lgem german-english machine translation systems w13 tÃœbÄ°tak-bÄ°lgem german-english machine translation systems w13 
present system developed provide efficient discriminative training machine translation describe integrate mapreduce using hadoop streaming allow arbitrarily scaling tuning set utilizing sparse feature set report findings russianenglish translation discuss benefits well obstacles tuning larger development sets drawn parallel training data towards efficient large-scale feature-rich statistical machine translation towards efficient large-scale feature-rich statistical machine translation towards efficient large-scale feature-rich statistical machine translation 
paper describes talp participation wmt evaluation campaign participation based combination several statistical machine translation systems based standard phrasebased moses systems variations include techniques morphology generation training sentence filtering domain adaptation unit derivation results show coherent improvement ter meteor nist bleu scores compared baseline system talp-upc phrase-based translation systems wmt13: system combination morphology generation, domain adaptation corpus filtering talp-upc phrase-based translation systems wmt13: system combination morphology generation, domain adaptation corpus filtering talp-upc phrase-based translation systems wmt13: system combination morphology generation, domain adaptation corpus filtering 
present two systems took part wmt shared task tectomt phrasefix former system latter standard statistical spe applied top tectomt brief survey put spe context system combination techniques evaluate spe vs another simple system combination technique using synthetic parallel data tectomt train statistical mt system smt confirm phrasefix spe improves output tectomt use analyze errors tectomt however also show extending data smt effective phrasefix: statistical post-editing tectomt phrasefix: statistical post-editing tectomt phrasefix: statistical post-editing tectomt 
present novel approach automatic collocation error correction learner english based paraphrases extracted parallel corpora key assumption collocation errors often caused semantic similarity first language language writer analysis large corpus annotated learner english confirms assumption evaluate approach learner data show paraphrases outperform traditional approaches based edit distance homophones wordnet synonyms correcting semantic collocation errors l1-induced paraphrases correcting semantic collocation errors l1-induced paraphrases correcting semantic collocation errors l1-induced paraphrases 
describe lia machine translation systems translation tasks various factored translation systems built using moses take account morphological complexity russian experimented romanization untranslated russian words factored machine translation systems russian-english factored machine translation systems russian-english factored machine translation systems russian-english 
compare several state art dependency parsers parser based linear classification technique primary goal therefore use syntactic information order keep comparison parsers fair possible demonstrate despite inferior result using standard evaluation metrics parsers like uas las standard test data system achieves comparable results used application evaluation exercise pete submission achieved th position participating systems however since uses linear classifier works times faster state parsers instance maltparser stanford parser 372:comparing benefit different dependency parsers textual entailment using syntactic constraints 372:comparing benefit different dependency parsers textual entailment using syntactic constraints 372:comparing benefit different dependency parsers textual entailment using syntactic constraints 
paper describes joint submission quaero project german english translation task acl eighth workshop statistical machine translation wmt submission system combination output four different translation systems provided rwth aachen university karlsruhe institute technology kit systran software inc translations joined using rwth system combination approach experimental results show improvements points bleu points ter compared best single translation joint wmt 2013 submission quaero project joint wmt 2013 submission quaero project joint wmt 2013 submission quaero project 
paper describes statistical machine translation smt systems developed rwth aachen university translation task acl eighth workshop statistical machine translation wmt participated evaluation campaign language pairs translation directions hierarchical smt systems applied number different techniques evaluated including hierarchical phrase reordering translation model interpolation domain adaptation techniques weighted phrase extraction word class language model continuous space language model system combination application methods achieve considerable improvements respective baseline systems rwth aachen machine translation system wmt 2013 rwth aachen machine translation system wmt 2013 rwth aachen machine translation system wmt 2013 
paper describes university cambridge submission eighth workshop statistical machine translation report results russianenglish translation task use multiple segmentations russian input language employ hadoop framework extract rules decoder hifst hierarchical decoder implemented using weighted finitestate transducers lattices rescored higher order language model minimum objective university cambridge russian-english system wmt13 university cambridge russian-english system wmt13 university cambridge russian-english system wmt13 
describe improvements made past year joshua translation system machine translation main contributions past year significant improvements speed usability grammar extraction decoding steps also rewritten decoder use sparse feature representation enabling training large numbers features discriminative training methods joshua 5.0: sparser, better, faster, server joshua 5.0: sparser, better, faster, server joshua 5.0: sparser, better, faster, server 
paper presents experiments conducted machine translation group dcu prompsit language engineering wmt translation task three language pairs considered spanishenglish directions direction pair use linguistic information select parallel data investigated frenchenglish pair usefulness small indomain parallel corpus evaluated compared parallel data method finally system describe work addressing long distance reordering problem system combination strategy cngl-dcu-prompsit translation systems wmt13 cngl-dcu-prompsit translation systems wmt13 cngl-dcu-prompsit translation systems wmt13 
paper describes submission dataset eighth workshop statistical machine translation generate improved word alignment training data incorporating unsupervised transliteration mining module giza build machine translation system tuning use variation pro provides better weights optimizing bleu transliterate words postprocessing step using transliteration system built transliteration pairs extracted using unsupervised transliteration mining system russian english translation direction apply linguistically motivated russian side data qcri-mes submission wmt13: using transliteration mining improve statistical machine translation qcri-mes submission wmt13: using transliteration mining improve statistical machine translation qcri-mes submission wmt13: using transliteration mining improve statistical machine translation 
describe uppsala university system wmt translation use docent decoder local search decoder translates document level add tunable distortion limits soft constraints maximum distortion allowed docent also investigate cleaning noisy common crawl corpus show use filtering cleaning good results finally investigate effects corpus selection recasing tunable distortion limits corpus cleaning smt tunable distortion limits corpus cleaning smt tunable distortion limits corpus cleaning smt 
word sense induction discrimination wsid identifies senses ambiguous word assigns instances word one senses build wsid system exploits syntactic semantic features based results natural language parser component achieve high robustness good generalization capabilities designed system work restricted grammatically rich set features based results evaluations system provides promising performance robustness kcdc: word sense induction using grammatical dependencies sentence phrase structure kcdc: word sense induction using grammatical dependencies sentence phrase structure kcdc: word sense induction using grammatical dependencies sentence phrase structure 
paper presents unsupervised method automatic word sense induction disambiguation innovative part method assignment either word word pair vertex constructed graph word senses induced clustering constructed graph disambiguation stage induced cluster scored according number vertices found context target word system participated word sense induction disambiguation task uoy: graphs unambiguous vertices word sense induction disambiguation uoy: graphs unambiguous vertices word sense induction disambiguation uoy: graphs unambiguous vertices word sense induction disambiguation 
propose technique improving quality translation systems creating synthetic translation options phrasal translations generated auxiliary translation postediting processes augment default phrase inventory learned parallel data apply technique problem producing english determiners translating russian czech languages lack definiteness morphemes approach augments english side phrase table using classifier predict english articles might plausibly added removed decode usual obtain significant improvements quality relative standard baseline complete translations classifier generating english determiners phrase-based translation synthetic translation options generating english determiners phrase-based translation synthetic translation options generating english determiners phrase-based translation synthetic translation options 
learning shown effective various applications including discriminative smt present experimental evaluation question whether learning depends natural division data tasks balance shared individual knowledge whether inherent regularization makes learning broadly applicable remedy overfitting investigate question compare natural tasks defined sections international patent classification versus random tasks defined random shards context patent smt find versions learning improve equally well independent pooled baselines gain nearly bleu points standard mert tuning multi-task learning improved discriminative training smt multi-task learning improved discriminative training smt multi-task learning improved discriminative training smt 
present iterative technique generate phrase tables smt based training data modified translation decoder different previous work completely avoid use word alignment phrase extraction heuristics moving towards principled phrase generation probability estimation training allow decoder generate new phrases increment maximum phrase length iteration experiments carried iwslt task able reach moderate improvements baseline training method resulting phrase table shows small overlap heuristically extracted one demonstrates restrictiveness limiting phrase selection word alignment heuristics interpolating heuristic trained phrase table improve baseline bleu ter length-incremental phrase training smt length-incremental phrase training smt length-incremental phrase training smt 
present positive diversity tuning newmethod tuningmachine translation models specifically improved performance system combination system combination gains often limited fact translations produced different component systems similar propose method reducing excess similarity optimizing joint objective simultaneously rewards models producing translations similar reference translations also punishing translations similar produced systems formulation positive diversity objective easy implement allows quick integration machine translation tuning pipelines find individual systems tuned data positive diversity even diverse systems built using different data sets still obtaining good bleu scores individual systems used together system combination approach allows significant gains bleu even combination performed using small number otherwise identical individual systems positive diversity tuning machine translation system combination positive diversity tuning machine translation system combination positive diversity tuning machine translation system combination 
paper studies application web selectors word sense disambiguation system specific domain system primarily applied without domain tuning incorporation domain predominant sense information explored results indicated system performs relatively domain predominant sense information without scoring well random baseline still percentage points results using first sense ucf-ws: domain word sense disambiguation using web selectors ucf-ws: domain word sense disambiguation using web selectors ucf-ws: domain word sense disambiguation using web selectors 
models developed alignment words phrases bitext models formulated alignment parameter estimation performed efficiently find chineseenglish word alignment performance comparable ibm even large training bitexts phrase pairs extracted word alignments generated model also used translation chinese english arabic english translation performance comparable systems based alignments direct phrase pair induction model described shown improve translation performance hmm word phrase alignment statistical machine translation hmm word phrase alignment statistical machine translation hmm word phrase alignment statistical machine translation 
paper present approach system setup joint participation fondazione bruno kessler university edinburgh wmt quality estimation submissions focused tasks whose aim predicting translation edit rate time task respectively designed features built resources automatic word alignment candidate translation lists word posterior probabilities models consistently overcome baselines tasks performed particularly well task ranking first among seven participants fbk-uedin participation wmt13 quality estimation shared task fbk-uedin participation wmt13 quality estimation shared task fbk-uedin participation wmt13 quality estimation shared task 
paper present entry wmt shared task quality estimation qe machine translation mt participated qe system trained features diverse information sources like mt decoder features lists corpora giza training models system shows competitive results workshop shared task mt quality estimation: cmu system wmtâ€™13 mt quality estimation: cmu system wmtâ€™13 mt quality estimation: cmu system wmtâ€™13 
describe two systems submitted team task wmt shared task quality estimation machine translation task involve estimating postediting effort translation pairs news domain two systems use wide variety features effective frequency language model pseudoreferences ones systems perform similarly high level two tasks scoring ranking translations although evidence systems training data dcu-symantec wmt 2013 quality estimation shared task dcu-symantec wmt 2013 quality estimation shared task dcu-symantec wmt 2013 quality estimation shared task 
paper describe machine translation evaluation systems used participation wmt shared metrics task metrics task submitted two automatic mt evaluation systems nlepor baseline lepor nlepor baseline based language independent mt evaluation metric employing factors modified sentence length penalty position difference penalty precision recall nlepor baseline measures similarity system output translations reference translations word sequences lepor new version lepor metric using mathematical harmonic mean group factors employing linguistic features information evaluation results wmt show lepor yields highest averagescore human judgments systemlevel using pearson correlation criterion fr de es cs ru language pairs description tunable machine translation evaluation systems wmt13 metrics task description tunable machine translation evaluation systems wmt13 metrics task description tunable machine translation evaluation systems wmt13 metrics task 
linguistically transparentmeant umeant metrics tunable simple yet highly effective fully automatic approximation human hmeant mt evaluation metric measures semantic frame similarity mt output reference translations paper describe hkust submission wmt metrics evaluation task meant umeant meant optimized tuning small number weights one semantic role label maximize correlation human adequacy judgment development set umeant unsupervised version weights semantic role label estimated via inexpensive unsupervised approach opposed meant supervised method relying expensive grid search paper present battery experiments optimizing meant different development sets determine set weights maximize meant accuracy stability evaluated test sets wmt metrics evaluation bothmeant umeant achieve competitive correlations human judgments using nothing monolingual corpus automatic shallow semantic parser meant wmt 2013: tunable, accurate yet inexpensive semantic frame based mt evaluation metric meant wmt 2013: tunable, accurate yet inexpensive semantic frame based mt evaluation metric meant wmt 2013: tunable, accurate yet inexpensive semantic frame based mt evaluation metric 
work show active learning target domain leverage information different related source domain present algorithm harnesses source domain data learn best possible initializer hypothesis active learning target domain resulting improved label complexity also present variant algorithm additionally uses domain divergence information selectively query informative points target domain leading reductions label complexity experimental results variety datasets establish efficacy proposed methods domain adaptation meets active learning domain adaptation meets active learning domain adaptation meets active learning 
despite closely related languages german english characterized important word order differences longrange reordering verbs particular represents real challenge smt systems one main reasons translation quality often poor language pair work review several solutions improve accuracy word reordering preserving efficiency decoding among consider novel technique dynamically shape reordering search space effectively capture reordering phenomena extensive evaluation including diverse translation quality metrics show solutions significantly narrow gap hierarchical smt efficient solutions word reordering german-english phrase-based statistical machine translation efficient solutions word reordering german-english phrase-based statistical machine translation efficient solutions word reordering german-english phrase-based statistical machine translation 
introduce lexicalized reordering model hierarchical machine translation model scores monotone swap discontinuous phrase orientations manner one presented tillmann type lexicalized reordering model valuable component standard statistical machine translation systems koehn et al however commonly employed hierarchical decoders describe phrase orientation probabilities extracted wordaligned training data use hierarchical phrase inventories show orientations scored hierarchical decoding model empirically evaluated nist chinese english translation task achieve significant improvement bleu typical hierarchical baseline setup improvement bleu hierarchical setup french german translation task obtain gain bleu phrase orientation model hierarchical machine translation phrase orientation model hierarchical machine translation phrase orientation model hierarchical machine translation 
present method inference hierarchical translation optimisation sampling performed common exact inference framework related adaptive rejection sampling also present first implementation method along experimental results shedding light fundamental issues hierarchical translation inference needs performed distribution defined intersection translation hypergraph target language model replace intractable distribution sequence tractable exact optimisers samplers easy obtain experiments show exact inference feasible using fraction time space would required full intersection without recourse pruning techniques provide approximate solutions current implementation limited size inputs handle reasonable time experiments provide insights towards obtaining future speedups staying general framework investigations exact inference hierarchical translation investigations exact inference hierarchical translation investigations exact inference hierarchical translation 
explore use continuous rating scales human evaluation context machine translation evaluation comparing two qualitycontrol techniques rely agreement expert judgments experiments employing amazon mechanical turk service show techniques made possible use continuous scale show dramatic improvements agreement kappa coefficient agreement increasing additional standardization scores applied continuous measurement scales human evaluation machine translation continuous measurement scales human evaluation machine translation continuous measurement scales human evaluation machine translation 
work propose novel representation text based patterns derived linguistic annotation graphs use subgraph mining algorithm automatically derive features frequent subgraphs annotation graph process generates large number features many highly correlated propose genetic programming based approach feature construction creates fixed number strong classification predictors subgraphs evaluate benefit gained evolved structured features used addition features sentiment classification task sentiment classification using automatically extracted subgraph features sentiment classification using automatically extracted subgraph features sentiment classification using automatically extracted subgraph features 
paper presents unsupervised method automatic chinese word sense induction algorithm based clustering similar words according contexts occur first target word needs disambiguated represented vector contexts reconstruct matrix constituted vectors target words singular value decomposition svd method use vectors cluster similar words system participants clp back task word sense induction iscas: system chinese word sense induction based k-means algorithm iscas: system chinese word sense induction based k-means algorithm iscas: system chinese word sense induction based k-means algorithm 
despite many methods effectively solve sentiment classification task widely used languages english clear answer methods suitable languages substantially different paper attempt solve internet comments sentiment classification task lithuanian using two classification approaches supervised machine learning explore influence sentiment word dictionaries based different adjectives adverbs nouns verbs method different feature types lemmas word character machine learning methods techniques emoticons replacement sentiment words diacritics replacement etc approaches despite supervised machine learning methods support vector machine na ve bayes multinomial significantly outperform proposed method obtained results baseline best accuracy achieved na ve bayes multinomial token unigrams plus bigrams involved diacritics replacement comparison approaches sentiment classification lithuanian internet comments comparison approaches sentiment classification lithuanian internet comments comparison approaches sentiment classification lithuanian internet comments 
present approach natural language parsing dependency constituency parses acquired simultaneously leads accurate parses represented specific way richer constituency dependency tree also allows reducing parsing time complexity within proposed approach show treat significant phenomena russian language also perform brief evaluation parser implementation known dictascope syntax parsing russian: hybrid approach parsing russian: hybrid approach parsing russian: hybrid approach 
word alignment important preprocessing step machine translation project aims incorporating manual alignments amazon mechanical turk mturk help improve word alignment quality global crowdsourcing service mturk provide flexible abundant labor force therefore reduce cost obtaining labels interface developed simplify labeling process compare alignment results turkers experts incorporate alignments word alignment tool improve quality labels also compared two pricing strategies word alignment task experimental results show high precision alignments provided turkers approach achieved absolute reduction alignment error rate semi-supervised word alignment mechanical turk semi-supervised word alignment mechanical turk semi-supervised word alignment mechanical turk 
paper discuss problem low recall named entity ne recognition task polish discuss extent recall ne recognition improved reducing space ne categories also present several extensions binary model give improvement recall extensions include new features application external knowledge partial evaluation final model obtained recall precision corpus economic news recognition named entities boundaries polish texts recognition named entities boundaries polish texts recognition named entities boundaries polish texts 
hopper thompson defined theory transitivity goes beyond simple syntactic transitivity captures much action takes place sentence detecting features requires deep understanding lexical semantics pragmatics propose two general approaches creating corpus sentences labeled respect transitivity schema using amazon mechanical turk approaches assume existing resources incorporate necessary annotation single system done allow future generalization languages first task attempts use languageneutral videos elicit sentences specified transitivity attributes second task uses iterative process first label actors objects sentences annotate sentences transitivity examine success techniques perform preliminary classification transitivity data hopper thompson created theory transitivity describes volition subject affectedness object duration action short theory goes beyond simple grammatical notion transitivity whether verbs take objects transitive intransitive captures much action takes place sentence notions transitivity apparent surface features alone identical syntactic constructions vastly different transitivity linguistic theory however useful applications without corpus given substantive corpus conventional machine learning techniques could help determine transitivity verbs within sentences transitivity found play role called syntactic framing expresses implicit sentiment greene resnik use capital differentiate conventional syntactic transitivity throughout paper contexts perspective sentiment writer reflected constructions used express ideas example less transitive construction might used deflect responsibility john killed vs benjamin killed john rest paper review hopperthompson transitivity schema propose two measuring transitivity using untrained annotators measuring transitivity using untrained annotators measuring transitivity using untrained annotators 
building machine translation mt test sets relatively expensive task mt becomes increasingly desired language pairs domains becomes necessary build test sets case paper investigate using amazon mechanical turk mturk make mt test sets cheaply find mturk used make test sets much cheaper test sets importantly experiments multiple mt systems find test sets yield essentially conclusions regarding system performance test sets yield using mechanical turk build machine translation evaluation sets using mechanical turk build machine translation evaluation sets using mechanical turk build machine translation evaluation sets 
paper investigate presentational relative clause prc construction linguistic nlp literature relative clauses considered contain background information directly relevant highly useful semantic analysis text summarization particular information contained relative clauses often removed viewed content topic discourse discuss importance distinguishing prc construction relative clause types show prc relative clause rather main clause contains assertion utterance based linguistic analysis suggest informative features may used automatic extraction prc constructions believe identifying construction useful discriminating central information peripheral identifying assertions text discourse: presentational relative clause construction identifying assertions text discourse: presentational relative clause construction identifying assertions text discourse: presentational relative clause construction 
various ways one refer clinical concept needs accounted semantic resource snomed ct developing terminological resources manually however prohibitively expensive likely result low coverage especially given high variability language use clinical text support process distributional methods employed conjunction large corpus electronic health records extract synonym candidates clinical terms paper exemplify potential proposed method using swedish version snomed ct currently lacks synonyms medical expert inspects two thousand term pairs generated two semantic spaces one models multiword terms addition single words one hundred preferred terms semantic types disorder finding corpus-driven terminology development: populating swedish snomed ct synonyms extracted electronic health records corpus-driven terminology development: populating swedish snomed ct synonyms extracted electronic health records corpus-driven terminology development: populating swedish snomed ct synonyms extracted electronic health records 
paper new self training method domain adaptation illustrated selection reliable parses carried unsupervised linguistically driven algorithm ulisse method tested biomedical texts results showing significant improvement respect considered baselines demonstrates ability capture reliability parses domain specificity linguistic constructions unsupervised linguistically-driven reliable dependency parses detection self-training adaptation biomedical domain unsupervised linguistically-driven reliable dependency parses detection self-training adaptation biomedical domain unsupervised linguistically-driven reliable dependency parses detection self-training adaptation biomedical domain 
one main bottlenecks natural language processing lack comprehensive lexicalized relation resource contains fine grained knowledge predicates paper present prismatic large scale lexicalized relation resource automatically created gb text specifically describe kind information collected prismatic compares existing lexical resources main focus building infrastructure gathering data although still early stages applying prismatic wide variety applications believe resource tremendous value ai researchers discuss potential applications paper prismatic: inducing knowledge large scale lexicalized relation resource prismatic: inducing knowledge large scale lexicalized relation resource prismatic: inducing knowledge large scale lexicalized relation resource 
reordering stage statistical machine translation smt system words source sentence reordered per syntax target language proposing rich set rules better reordering idea facilitate training process better alignments parallel phrase extraction phrase based smt system reordering also helps decoding process hence improving machine translation quality observed significant improvements translation quality using approach baseline smt used bleu nist word error rate position independent error rate judging improvements exploited open source smt toolkit moses develop system reordering rules english-hindi smt reordering rules english-hindi smt reordering rules english-hindi smt 
explore intersection statistical approaches machine translation particular focus past current work microsoft research ten years ago machine translation systems worth using along came statistical approaches use large corpora directly guide translations toward expressions people would actually say rather making local decisions writing conditioning rules goodness translation modeled numerically free parameters selected optimize goodness led huge improvements translation quality data consumed necessity pendulum swinging towards inclusion linguistic features mt systems describe statistical attempts incorporate linguistic insights machine translation systems showing currently working well isn also look using linguistic knowledge rules language pair particular eye return investment training data increases size controlled ascent: imbuing statistical mt linguistic knowledge controlled ascent: imbuing statistical mt linguistic knowledge controlled ascent: imbuing statistical mt linguistic knowledge 
present minimalist unsupervised learning model induces relatively clean phrasal inversion transduction grammars employing minimum description length principle drive search space defined two opposing extreme types itgs comparison current smt approaches model learns parsimonious phrase translation lexicons provide obvious basis generalization abstract translation schemas model maintains internal consistency avoiding use mismatched unrelated models word alignments probabilities ibm models model introduces novel strategy avoiding pitfalls premature pruning chunking approaches incrementally splitting itgwhile using second itg guide search unsupervised transduction grammar induction via minimum description length unsupervised transduction grammar induction via minimum description length unsupervised transduction grammar induction via minimum description length 
present article provides comprehensive review work carried developing presemt hybrid machine translation mt methodology methodology designed facilitate rapid creation mt systems unconstrained language pairs setting lowest possible requirements specialised resources tools given limited availability resources many languages small bilingual corpus required language modelling performed sampling large target language tl monolingual corpus article summarises implementation decisions using language pair test case evaluation results reported objective subjective metrics finally main error sources identified directions described improve hybrid mt methodology language-independent hybrid mt presemt language-independent hybrid mt presemt language-independent hybrid mt presemt 
article addresses lack common approaches text simplification evaluation presenting first attempt common evaluation metrics article proposes reading comprehension evaluation method evaluating results text simplification ts experiment example application evaluation method well three formulae quantify reading comprehension presented formulae produce unique score gives estimation user reading comprehension certain text score used evaluate performance text simplification engine pairs complex simplified texts compare performances different ts methods using texts approach particularly useful modern crowdsourcing approaches employing amazon mechanical turk crowdflower aim paper thus propose evaluation approach motivate ts community start relevant discussion order come common evaluation metrics task context motivation currently area text simplification ts getting attention starting early chandrasekar et al proposed approach ts step feeding text parser next http aws amazon com mturk last accessed may rd http crowdflower com last accessed june th pset project devlin canning proposed two modules simplifying text aphasic readers text simplification approaches continued siddharthan inui et al recent explosion ts approaches recently several workshops took place pitr williams et al slpat alexandersson et al nlp ita confirmation text simplification definition process reducing text complexity different levels temnikova ts approaches tackle variety text complexity aspects c-score â€?proposing reading comprehension metrics common evaluation measure text simplification c-score â€?proposing reading comprehension metrics common evaluation measure text simplification c-score â€?proposing reading comprehension metrics common evaluation measure text simplification 
paper present three term weighting approaches document summarization give results duc data well multilingual wikipedia feature articles data set introduce new intervalbounded nonnegative matrix factorization use new method latent semantic analysis lsa latent dirichlet alocation lda give three methods summarization results duc tac data well multiling data demonstrate methods promising since achieve oracle coverage scores range humans test languages finally present three term weighting approaches multiling single document summarization task wikipedia featured articles submissions significantly outperformed baseline languages approach single summarization past years research yielded bounty successful methods single document summarization sds summarization mds techniques statistics machine learning numerical optimization graph theory combinatorics generally languageindependent applied single extractive summarization data paper extend work research group recently discussed davis et al summarization apply single multilingual document summarization extractive summarization performs following steps sentence boundary detection tokenization term identification matrix generation term weight determination sentence selection sentence ordering sentence boundary detection tokenization language dependent steps language independent briefly discuss steps use rule based sentence splitter fasste fast accurate sentence splitter text english conroy et al multilingual extensions conroy multilingual summarization: dimensionality reduction step towards optimal term coverage multilingual summarization: dimensionality reduction step towards optimal term coverage multilingual summarization: dimensionality reduction step towards optimal term coverage 
investigate performance easyfirst dependency parser hebrew dependency treebank show basic feature set greedy parser accuracy par globally optimized mst parser addition feature improves parsing accuracy making globally optimized mst parser improvement due morphological agreement information persistent morphological information used easy-first dependency parsing modern hebrew easy-first dependency parsing modern hebrew easy-first dependency parsing modern hebrew 
multilingual sentence extractor muse aimed multilingual summarization muse implements supervised summarization approach based optimization multiple sentence ranking methods using genetic algorithm main advantage muse using statistical sentence features calculated sentences language previous work performance muse found significantly better best known extractive summarization approaches tools three different languages english hebrew arabic moreover experimental results domain suggest muse need retrained summarization corpus new language weighting model used across several languages last litvak muse participated multiling single document summarization task three languages english hebrew arabic due limited time given participants run systems multiling data results submitted evaluation obtained summarizing documents using models different corpora training performed multiling corpus multilingual sentence extractor muse overview methodology muse implements supervised learning approach extractive summarization best set weights linear combination sentence scoring methods found genetic algorithm trained collection documents summaries weighting vector thus obtained used sentence scoring future summarizations since sentence scoring methods linear computational complexity training phase approach using muse user choose subset totally sentence metrics included linear combination available metrics based various text representation models since rely knowledge figure demonstrates taxonomy metrics divided three main categories according text representation model subcategory contains group metrics using scoring method detailed description sentence metrics used muse found last litvak best linear multilingual single-document summarization muse multilingual single-document summarization muse multilingual single-document summarization muse 
present system deciding whether given sentence inferred text sentence represented directed graph extracted dependency parser nodes represent words phrases links represent syntactic semantic relationships develop learned graph matching approach approximate entailment using amount sentence semantic content contained text present results recognizing textual entailment dataset dagan et al show approach outperforms models addition explore common sources errors approach remedy robust textual inference via graph matching robust textual inference via graph matching robust textual inference via graph matching 
classification learning algorithms use syntactic structures proxies source sentences feature vectors paper explore alternative path use syntax feature spaces distributed representation parsers drp core idea straightforward drps directly obtain syntactic feature vectors sentences without explicitly producing symbolic syntactic interpretations results show drps produce feature spaces significantly better obtained existing methods conditions competitive obtained existing methods lexical information transducing sentences syntactic feature vectors: alternative way parse? transducing sentences syntactic feature vectors: alternative way parse? transducing sentences syntactic feature vectors: alternative way parse? 
paper reports ongoing work applying common sense knowledge machine translation aiming generating culturally contextualized translations common sense defined knowledge shared group people given time space culture knowledge represented semantic network called conceptnet machine translation turn automatic process generating equivalent translated version source sentence work intend use knowledge represented two conceptnets one brazilian portuguese another english fix filter translations built automatically paper presents initial ideas work steps taken far well opportunities collaboration using common sense generate culturally contextualized machine translation using common sense generate culturally contextualized machine translation using common sense generate culturally contextualized machine translation 
dependency parsing shown improve nlp systems certain languages many cases helps achieve state art results nlp applications particular applications free word order languages morphologically rich languages often short training data require much higher amounts training data due increased size lexicon paper examines new approach addressing morphologically rich languages little training data start using tamil test language create dependency parse models limited amount training data using models train svm classifier using model agreements features use svm classifier edge edge decision form ensemble parse tree using model agreements features allows method remain language independent applicable wide range morphologically rich languages show statistically significant improvement average dependency model statistically significant improvement best individual system using svm ensemble system improved tamil dependency parsing using svm ensemble system improved tamil dependency parsing using svm ensemble system improved tamil dependency parsing 
one key issues natural language understanding generation appropriate processing multiword expressions mwes mwe defined semantic issue phrase meaning phrase may obtained constituents straightforward manner paper presents approach identifying bigram mwes bengali corpus clustering semantically related nouns incorporating vector space model similarity measurement additional inclusion english wordnet similarity module also improves results considerably present approach also contributes locate clusters synonymous noun words present document experimental results draw satisfactory conclusion analyzing precision recall values semantic clustering: attempt identify multiword expressions bengali semantic clustering: attempt identify multiword expressions bengali semantic clustering: attempt identify multiword expressions bengali 
present word alignment framework incorporate partial manual alignments core approach novel algorithm extending widely used ibm models constrained em algorithm partial manual alignments obtained human labelling automatically heuristics demonstrate usages methods selecting alignment links manually aligned corpus apply links generated bilingual dictionary unlabelled data first method conduct controlled experiments chineseenglish translation tasks compare quality word alignment measure effects two different methods selecting alignment links manually aligned corpus second method experimented translation task experiment results show average improvement bleu point across test sets semi-supervised word alignment algorithm partial manual alignments semi-supervised word alignment algorithm partial manual alignments semi-supervised word alignment algorithm partial manual alignments 
paper presents fast consensus hypothesis regeneration approach machine translation combines advantages fast consensus decoding hypothesis regeneration approach efficient previous work hypothesis regeneration explores wider search space consensus decoding resulting improved performance experimental results show consistent improvements across language pairs improvement bleu obtained competitive baseline nist task fast consensus hypothesis regeneration machine translation fast consensus hypothesis regeneration machine translation fast consensus hypothesis regeneration machine translation 
paper describes statistical machine translation systems wmt evaluation limsi participated two language pairs directions concentrated normalizing german side proper preprocessing aimed reducing lexical redundancy splitting complex compounds studied two extensions decoder firstly effect integrating new bilingual reordering model second use adaptation techniques translation model set experiments report improvements obtained development test data limsi&rsquo;s statistical translation systems wmt&rsquo;10 limsi&rsquo;s statistical translation systems wmt&rsquo;10 limsi&rsquo;s statistical translation systems wmt&rsquo;10 
paper describes experiments machine translation wmt focusing primarily translation czech additions standard moses mt pipeline include translation overcome data sparseness optimization towards sempos metric better suited evaluating czech unfortunately none approaches bring significant improvement standard setup 2010 failures english-czech phrase-based mt 2010 failures english-czech phrase-based mt 2010 failures english-czech phrase-based mt 
paper describes statistical machine translation system participation wmt shared task based moses system capable translating german french spanish english main contribution work effective parameter tuning discover significant performance gap different development sets adopted finally ten groups development sets used optimize model weights help us obtain stable evaluation result empirical study development set selection strategy machine translation learning empirical study development set selection strategy machine translation learning empirical study development set selection strategy machine translation learning 
paper describes system developed improve translation news text shared task fifth workshop statistical machine translation working within cdec open source modular framework machine translation explore benefits several modifications hierarchical model including segmentation lattices minimum bayes risk decoding grammar extraction methods varying language models furthermore analyze decoder speed memory performance across set models show important needs made university maryland statistical machine translation system fifth workshop machine translation university maryland statistical machine translation system fifth workshop machine translation university maryland statistical machine translation system fifth workshop machine translation 
describe hybrid machine translation system developed used wmt shared task compute translations rulebased mt system combine resulting translation templates partial phrases phrasebased statistical mt engine phrase substitution guided several decision factors continuation previous work within group shared task computed translations six language pairs including english german french spanish experiments shown shallow substitution approach effectively improve translation result rbmt system however also become clear deeper integration needed improve translation quality experiments shallow hybrid mt systems experiments shallow hybrid mt systems experiments shallow hybrid mt systems 
paper describe statistical machine translation system rwth aachen university developed translation task fifth workshop statistical machine translation hierarchical statistical mt systems augmented appropriate enhancements well alternative phrase training methods extended lexicon models tasks system combination best systems used generate final hypothesis participated constrained condition germanenglish translation direction rwth aachen machine translation system wmt 2010 rwth aachen machine translation system wmt 2010 rwth aachen machine translation system wmt 2010 
describe system translation task wmt system developed frenchenglish directions based moses trained using resources supplied workshop report experiments enhance parallel corpora list french grammatical checker rali machine translation system wmt 2010 rali machine translation system wmt 2010 rali machine translation system wmt 2010 
report efforts build translation systems eight european language pairs achieve gains use larger training corpora basic modeling also show promising results integrating linguistic annotation linguistic annotation statistical machine translation linguistic annotation statistical machine translation linguistic annotation statistical machine translation 
paper describes development french english english french machine translation systems wmt shared task evaluation systems standard statistical systems based moses decoder trained provided data efforts devoted choice extraction bilingual data used training filtered bilingual corpora pruned phrase table also investigated impact adding two types additional bilingual texts extracted automatically available monolingual data first collected bilingual data performing automatic translations monolingual texts second type bilingual text harvested comparable corpora information retrieval techniques lium smt machine translation system wmt 2010 lium smt machine translation system wmt 2010 lium smt machine translation system wmt 2010 
discuss morphological segmentation word forms segmented morphs surface forms morphemes focus lowresource learning setting small amount annotated word forms available model training unannotated word forms available abundance current methods exploit annotated unannotated data manner learn morph lexicons subsequently uncover segmentations generating likely morph sequences contrast discuss employing annotated data supervised manner entirely ignoring unannotated data directly learning predict morph boundaries given local contexts instead learning morph lexicons specifically employ conditional random fields popular discriminative model segmentation present experiments two data sets comprising five diverse languages show fully supervised boundary prediction approach outperforms morph lexicon approaches languages using annotated data sets supervised morphological segmentation low-resource learning setting using conditional random fields supervised morphological segmentation low-resource learning setting using conditional random fields supervised morphological segmentation low-resource learning setting using conditional random fields 
present flexible formulation semisupervised learning structured models seamlessly incorporates graphbased general supervision extending posterior regularization pr framework extension allows regularizer convex differentiable function appropriate marginals show surprisingly regularization increase complexity learning provided use multiplicative updates structured exponentiated gradient algorithm illustrate extended framework learning conditional random fields crfs quadratic penalties arising graph laplacian sequential prediction tasks handwriting recognition pos tagging method makes significant gains strong baselines graph-based posterior regularization semi-supervised structured prediction graph-based posterior regularization semi-supervised structured prediction graph-based posterior regularization semi-supervised structured prediction 
paper describes statistical machine translation smt system wmt translation task submitted translations german english english german translation tasks compared systems preformed additional preprocessing used discriminative word alignment approach word reordering modeled using pos information extended translation model additional features karlsruhe institute technology translation system acl-wmt 2010 karlsruhe institute technology translation system acl-wmt 2010 karlsruhe institute technology translation system acl-wmt 2010 
paper describes dcu machine translation system evaluation campaign joint fifth workshop statistical machine translation metrics describe modular design machine translation mt system particular focus components used participation participated english spanish english czech translation tasks employed multiengine architecture translate also participated system combination task carried mbr decoder confusion network decoder matrex: dcu mt system wmt 2010 matrex: dcu mt system wmt 2010 matrex: dcu mt system wmt 2010 
paper describes system submitted laboratory informatics grenoble lig fifth workshop statistical machine translation participated news shared translation task language pair investigated differents techniques simply deal words statistical machine translation system analyze impact translation quality final submission combination standard system using moses decoder appropriate setups lemmatized system deal conjugated verbs lig machine translation system wmt 2010 lig machine translation system wmt 2010 lig machine translation system wmt 2010 
explore possibility using stochastic bracketing linear inversion transduction grammars german english translation task conjunction alignments induced giza rationale transduction grammars details system results presented linear inversion transduction grammar alignments second translation path linear inversion transduction grammar alignments second translation path linear inversion transduction grammar alignments second translation path 
paper system submitted prhlt group fifth workshop statistical machine translation acl presented evaluation campaign worked english spanish language pair putting special emphasis two problems derived large amount data available first one optimize use monolingual data within language model second one make good use bilingual data provided without making use unnecessary computational resources upv-prhlt english&#x2013;spanish system wmt10 upv-prhlt english&#x2013;spanish system wmt10 upv-prhlt english&#x2013;spanish system wmt10 
present johns hopkins university submission wmt shared translation task describe processing steps using open data open source software used submission provide scripts configurations required train tune test machine translation system reproducible results parsing-based machine translation: jhu shared task submission reproducible results parsing-based machine translation: jhu shared task submission reproducible results parsing-based machine translation: jhu shared task submission 
paper report experiments three preprocessing strategies improving translation output statistical mt system training two reordering strategies studied reorder basis alignments giza ii reorder moving verbs end segments translation words preprocessed fashion identify likely equivalent three strategies implemented english german system submitted wmt shared task combining lead improvements language directions vs oovs: two problems translation german english vs oovs: two problems translation german english vs oovs: two problems translation german english 
report results submissions wmt shared translation task applied system includes adaptive language translation models adaptation implemented using exponentially decaying caches storing previous translations history new predictions evidence cache mixed global background model main problem setup error propagation submissions essentially failed improve competitive baseline slight improvements lexical choice global performance decreases terms bleu scores motivation main motivation submission test use adaptive language translation models standard smt setting adaptation wider context beyond sentence boundaries adaptive language models long tradition speech recognition community various approaches proposed reduce model perplexity way general task adjust statistical models essential properties natural language usually captured standard models local dependency models first known repetition common especially among content words see example words like honey milk land flowing figure cases repeated occurrence content word much likely first appearance predicted way static language model secondly use expressions related topic current discourse chance using topicrelated expressions running text higher model would predict translation another phenomenon observed namely consistency translations polysemous terms usually ambiguous context hence translations become consistent according contextual sense even choice synonymous translations rather consistent translated texts see example subtitle translations figure taken opus corpus tiedemann commandments kerd ma lui land flowing milk honey till ett land fullt av mjo lk och honung ve never tasted honey jag har aldrig cache cache? experiments adaptive models statistical machine translation cache cache? experiments adaptive models statistical machine translation cache cache? experiments adaptive models statistical machine translation 
paper describes aalto submission translation tasks acl joint fifth workshop statistical machine translation metricsmatr statistical machine translation focused using words longer phrases constructed words tokens system contrast apply different morphological decompositions words using unsupervised morfessor algorithms translation models trained using morphological decompositions improve bleu scores show minimum bayes risk combination translation model produces significant improvements translation however see improvements translations applying morphological decompositions statistical machine translation applying morphological decompositions statistical machine translation applying morphological decompositions statistical machine translation 
maximum entropy principle used successfully various nlp tasks paper propose forward translation model consisting set maximum entropy classifiers separate classifier trained sufficiently frequent lemma way estimates translation probabilities sensitive large number features derived source sentence including features features making use sentence syntactic structure etc integrated translation scenario implemented tectomt framework new translation model significantly outperforms baseline model mle terms bleu performance boosted configuration inspired hidden tree markov models combines maximum entropy translation model dependency tree model maximum entropy translation model dependency-based mt framework maximum entropy translation model dependency-based mt framework maximum entropy translation model dependency-based mt framework 
paper describes system developed collabaration uch upv wmt year workshop present system englishspanish translation output lists rescored via target neural network language model yielding improvements final translation quality measured bleu ter uch-upv english&#x2013;spanish system wmt10 uch-upv english&#x2013;spanish system wmt10 uch-upv english&#x2013;spanish system wmt10 
paper presents collapsed variational bayesian inference algorithm pcfgs advantages two dominant bayesian training algorithms pcfgs namely variational bayesian inference markov chain monte carlo three kinds experiments illustrate algorithm achieves close performance hastings sampling algorithm using order magnitude less training time outperforms standard variational bayesian inference em algorithms similar training time collapsed variational bayesian inference pcfgs collapsed variational bayesian inference pcfgs collapsed variational bayesian inference pcfgs 
present jane rwth hierarchical translation system open sourced scientific community system development rwth last two years successfully applied different machine translation evaluations includes extensions hierarchical approach developed rwth well research institutions paper give overview main features also introduce novel reordering model hierarchical approach enhances translation performance analyze effect recent extended lexicon models performance system jane: open source hierarchical translation, extended reordering lexicon models jane: open source hierarchical translation, extended reordering lexicon models jane: open source hierarchical translation, extended reordering lexicon models 
paper describes augmented threepass system combination framework dublin city university dcu mt group wmt system combination task basic framework includes building individual confusion networks cns super network modified minimum mconmbr decoder augmented parts wmt tasks include rescoring component used lists generated individual cns super network new hypothesis alignment metric terp used carry hypothesis alignment different cns employed increase diversity mconmbr decoding phase took part combination tasks experimental results show proposed combination framework achieved absolute points relative points absolute points relative points terms bleu score tasks respectively best single system also achieved better performance human evaluation augmented three-pass system combination framework: dcu combination system wmt 2010 augmented three-pass system combination framework: dcu combination system wmt 2010 augmented three-pass system combination framework: dcu combination system wmt 2010 
participated system combination task fifth workshop statistical machine translation wmt translation direction submitted systems combined consensus translation consensus translations always improve translation quality best individual system upv-prhlt combination system wmt 2010 upv-prhlt combination system wmt 2010 upv-prhlt combination system wmt 2010 
paper describes submission wmt machine translation system combination task using constrained resources participated nine language pairs namely translating english czech french german spanish well combining english translations multiple languages combination proceeds aligning pairs system outputs navigating aligned outputs left right path candidate combination candidate combinations scored length agreement underlying systems language model tuning data improvement bleu best system depends language pair ranges mean cmu multi-engine machine translation wmt 2010 cmu multi-engine machine translation wmt 2010 cmu multi-engine machine translation wmt 2010 
paper describes cmu entry system combination shared task wmt combination method hypothesis selection uses information lists input mt systems available sentence level features used independent mt systems involved compared baseline added word alignment based features trained system weights feature set combined mt systems french english german english using provided data cmu system combination via hypothesis selection wmt&rsquo;10 cmu system combination via hypothesis selection wmt&rsquo;10 cmu system combination via hypothesis selection wmt&rsquo;10 
paper describes jhu system combination scheme used wmt submission incremental alignment scheme karakos et al used confusion network generation system order alignment sentence learned using svms following work karakos et al additionally google corpus used build language models improved quality combination output experiments spanishenglish language pairs conducted results show approximately bleu point ter points improvement best individual system jhu system combination scheme wmt 2010 jhu system combination scheme wmt 2010 jhu system combination scheme wmt 2010 
rwth participated system combination task fifth workshop statistical machine translation wmt language pairs combine systems single consensus translation using additional reranking techniques two language pairs depending language pair improvements versus best single system range bleu ter novel techniques compared rwth submission wmt include utilization reranking techniques consensus true casing approach different tuning algorithm separate selection input systems cn construction primary skeleton hypotheses hyplm true casing rwth system combination system wmt 2010 rwth system combination system wmt 2010 rwth system combination system wmt 2010 
bbn submitted system combination outputs allenglish language pairs combinations based confusion network decoding incremental hypothesis alignment algorithm flexible matching used build networks decoding weights single source language translations tuned directly maximize bleu score decoding output approximate expected bleu used objective function gradient based optimization combination weights system language combination system combination gained around bleu points best individual systems single source conditions condition system combination gained bleu points bbn system description wmt10 system combination task bbn system description wmt10 system combination task bbn system description wmt10 system combination task 
ability measure quality word order translations important goal research machine translation current machine translation metrics adequately measure reordering performance translation systems present novel metric lrscore directly measures reordering success reordering component balanced lexical metric capturing two important elements translation success simple combined metric one parameter results intuitive shallow language independent metric lrscore evaluating lexical reordering quality mt lrscore evaluating lexical reordering quality mt lrscore evaluating lexical reordering quality mt 
paper describes latest version atec metric automatic mt evaluation parameters optimized word choice word order two fundamental features language metric relies former assessed matching various linguistic levels weighting informativeness matched unmatched words latter quantified term word position information flow also discuss aspects language yet covered existing evaluation metrics carefully considered formulation metric parameter-optimized atec metric mt evaluation parameter-optimized atec metric mt evaluation parameter-optimized atec metric mt evaluation 
present unified approach performing minimum risk training minimum bayes risk mbr decoding bleu model key approach use gibbs sampler allows us explore entire probability distribution maintain strict probabilistic formulation across pipeline also describe new sampling algorithm called corpus sampling allows us training time use bleu instead approximation thereof approach theoretically sound gives better bleu stable results standard mert optimization algorithm comparing approach lattice mbr also able gain crucial insights methods unified approach minimum risk training decoding unified approach minimum risk training decoding unified approach minimum risk training decoding 
structured perceptrons attractive due simplicity speed used successfully tuning weights binary features machine translation system attempting apply tuning weights features highly skewed distributions found work well paper describes modification update step compares performance resulting algorithm standard minimum training mert addition preliminary results combining mert tuning feature weights coordinate ascent translation system parameters presented taming structured perceptrons wild feature vectors taming structured perceptrons wild feature vectors taming structured perceptrons wild feature vectors 
paper proposes novel method long distance reordering statistical machine translation smt proposed method separately translates clauses source sentence reconstructs target sentence using clause translations nonterminals placeholders embedded clauses reduce complicated reordering simple wordlevel reordering translation model trained using bilingual corpus alignment automatically annotated alignment algorithm syntactic parser source language achieved significant improvements bleu ter using moses bleu ter using hierarchical smt translation research paper abstracts medical domain divide translate: improving long distance reordering statistical machine translation divide translate: improving long distance reordering statistical machine translation divide translate: improving long distance reordering statistical machine translation 
present system automatically identifying native language writer experiment large set features train corpus essays written english speakers different languages system achieved accuracy test data improved improved feature normalization paper present features used system describe experiments provide analysis results experimental results native language identification shared task experimental results native language identification shared task experimental results native language identification shared task 
paper describes mitre participation native language identification nli task best effort performed accuracy nli task placing statistical tie best performing systems describe variety machine learning approaches explored including winnow language modeling logistic regression models primary features word character also describe several ensemble methods employed combining base systems discriminating non-native english 350 words discriminating non-native english 350 words discriminating non-native english 350 words 
submission nli shared task used part standard features found recent work focus instead two aspects system high level possible ways constructing ensembles multiple classifiers low level granularity tags used features found choice ensemble combination method lead much difference results although exploiting varying behaviours linear versus logistic regression svm classifiers could promising future work tagsets showed noticeable differences also note overall architecture feature set ensemble approach accuracy test set trained training data development data supplied close best result task suggests basically throwing together features previous work achieve roughly state art nli shared task 2013: mq submission nli shared task 2013: mq submission nli shared task 2013: mq submission 
efforts nli shared task focused potential benefits external corpora show including training data multiple corpora highly effective robust nli task particularly form domain adaptation also applied method also used boost performance even training data corpus available task however task despite testing number new features see much improvement simple model based earlier work using learner corpora 2013 nli shared task using learner corpora 2013 nli shared task using learner corpora 2013 nli shared task 
show possible learn identify high accuracy native language english test takers content essays write method uses standard text classification techniques based multiclass logistic regression combining individually weak indicators predict probable native language set possibilities describe various features used classification well settings classifier yielded highest accuracy identifying l1 non-native writers: cmu-haifa system identifying l1 non-native writers: cmu-haifa system identifying l1 non-native writers: cmu-haifa system 
paper discusses preliminary work investigating application machine translation mt metrics toward evaluation translations written human novice student translators describe study apply metric terp translation edit rate plus corpus translations spanish english compare judgments terp assessments provided translation instructor applying machine translation metrics student-written translations applying machine translation metrics student-written translations applying machine translation metrics student-written translations 
paper empirically investigate impact critical configuration parameters popular cube pruning algorithm decoding hierarchical statistical machine translation specifically study choice generation size affects translation quality resource requirements hierarchical search furthermore examine influence two different granularities hypothesis recombination experiments conducted chinese english arabic english nist translation tasks besides standard hierarchical grammars also explore search restricted recursion depth hierarchical rules based grammars performance study cube pruning large-scale hierarchical machine translation performance study cube pruning large-scale hierarchical machine translation performance study cube pruning large-scale hierarchical machine translation 
conditional random fields crf applied perform named entity recognition ner task many biomedical text mining information extraction systems however crf cannot capture long distance dependency common biomedical literature paper propose novel study capturing long distance dependency defining two principles constructing skipedges crf linking similar words linking words typed dependencies approach applied recognize gene protein mentions literature tested biocreative ii gene mention dataset genia corpus approach contributes significant improvements crf also present error analysis inconsistent labeling study influence quality skip edges labeling performance recognizing biomedical named entities using skip-chain conditional random fields recognizing biomedical named entities using skip-chain conditional random fields recognizing biomedical named entities using skip-chain conditional random fields 
deciding whether synchronous grammar formalism generates given word alignment alignment coverage problem depends finding adequate instance grammar using parse word alignment mean parse word alignment synchronous grammar formally undefined define unambiguous mapping grammatical derivations alignments paper proposes initial formal characterization alignment coverage intersecting two partially ordered sets graphs translation equivalence units one derived grammar instance another defined word alignment first sanity check report extensive coverage results itg automatic manual alignments even itg formalism formal characterization makes explicit many algorithmic choices often left underspecified earlier work formal characterization parsing word alignments synchronous grammars empirical evidence itg hypothesis. formal characterization parsing word alignments synchronous grammars empirical evidence itg hypothesis. formal characterization parsing word alignments synchronous grammars empirical evidence itg hypothesis. 
hierarchical hidden markov model hhmm parsers proposed psycholinguistic models due broad coverage within working memory limits schuler et al ability model human reading time behavior according various complexity metrics wu et al hhmms evaluated previously wide beams several thousand parallel hypotheses weakening claims model efficiency psychological relevance paper examines effects varying beam width parsing accuracy speed model showing parsing accuracy degrades gracefully beam width decreases dramatically width used achieve previous top results without sacrificing gains baseline cky parser hhmm parsing limited parallelism hhmm parsing limited parallelism hhmm parsing limited parallelism 
provide detailed comparison strategies implementing frequency phenomena german adverbial participles broadcoverage parsing system show allowing general adverb conversion participles german lfg grammar seriously affects overall performance due increased spurious ambiguity solution present induction technique detects adverbially used participles parallel text grammarbased evaluation show automatically induced resource appropriately restricts adverb conversion limited class participles improves parsing quantitatively well qualitatively cross-lingual induction technique german adverbial participles cross-lingual induction technique german adverbial participles cross-lingual induction technique german adverbial participles 
perform series sentiment classification experiments set tweets produced irish general elections february even though tweets labelled sarcastic omitted set still represents difficult test set highest accuracy achieve using supervised learning feature set consisting scores twitterspecific features top discriminative words superior various naive unsupervised approaches use subjectivity lexicons compute overall sentiment score tweet political party pair sentiment analysis political tweets: towards accurate classifier sentiment analysis political tweets: towards accurate classifier sentiment analysis political tweets: towards accurate classifier 
paper presents preliminary results using authorship attribution methods detection sockpuppeteering wikipedia sockpuppets fake accounts created malicious users bypass wikipedia regulations dataset composed comments made editors talk pages overcome limitations short lengths comments use voting scheme combine predictions made individual user entries show approach promising viable alternative current human process wikipedia uses resolve suspected sockpuppet cases case study sockpuppet detection wikipedia case study sockpuppet detection wikipedia case study sockpuppet detection wikipedia 
automatic translation tweets already investigated different scenarios aware attempt translate tweets created government agencies study report experimental results obtained translating twitter feeds published agencies organizations government canada using art statistical machine translation smt engine black box translation device mine parallel web pages linked urls contained pairs tweets order create tuning training material twitter feed would otherwise difficult translate report significant gains translation quality using strategy furthermore give detailed account problems still face hashtag translation well generation tweets legal length translating government agenciesâ€™ tweet feeds: specificities, problems (a few) solutions translating government agenciesâ€™ tweet feeds: specificities, problems (a few) solutions translating government agenciesâ€™ tweet feeds: specificities, problems (a few) solutions 
work described aims create wordnet automatically semantic network based terms clustering procedure ran synonymy network order obtain synsets term arguments relational triple assigned latter originating wordnet experiments towards goal reported results validated towards automatic creation wordnet term-based lexical network towards automatic creation wordnet term-based lexical network towards automatic creation wordnet term-based lexical network 
report documents transliteration generation shared task conducted part named entities workshop news acl workshop shared task features machine transliteration proper names english languages languages english total tasks provided teams different countries participated evaluations finally standard runs submitted diverse transliteration methodologies explored reported evaluation data report results performance metrics believe shared task successfully achieved objective providing common benchmarking platform research community evaluate technologies benefit future research development report news 2010 transliteration generation shared task report news 2010 transliteration generation shared task report news 2010 transliteration generation shared task 
transliteration defined phonetic translation names across languages transliteration named entities nes necessary many applications machine translation corpus alignment ir information extraction automatic lexicon acquisition systems call transliteration focus shared task news workshop objective shared task promote machine transliteration research providing common benchmarking platform community evaluate technologies task description task develop machine transliteration system one specified language pairs considered task language pair consists source target language training development data sets released language pair used developing transliteration system whatever way participants find appropriate evaluation time test set source names would released participants expected produce ranked list transliteration candidates another language transliterations evaluated using common metrics every language pair participants must submit least one run uses data provided news workshop organisers given language pair designated standard run primary submission users may submit stanrard runs may also submit several runs language pair http translit edu sg news use data provided news workshop runs would evaluated reported separately important dates research paper submission deadline may shared task registration opens feb registration closes mar training development data release feb test data release mar results submission due mar results announcement mar task short papers due apr submissions acceptance notification may workshop date jul participation registration feb news shared task opens registration prospective whitepaper news 2010 shared task transliteration generation whitepaper news 2010 shared task transliteration generation whitepaper news 2010 shared task transliteration generation 
effective transliteration proper names via grapheme conversion needs find transliteration patterns training data generate optimized candidates testing samples accordingly however accuracy generated candidates cannot good right one ranked top tackle issue propose rerank output candidates better order using averaged perceptron multiple features paper describes recent work direction participation news transliteration evaluation official results confirm effectiveness bidirectional transliteration reranking multiple features better transliteration reranking multiple features better transliteration reranking multiple features better transliteration 
paper propose method uses corpora phrases annotated positive negative objective neutral achieve new sentiment resources involving words dictionaries associated polarity method created build sentiment words inventories based sentisemantic evidences obtained exploring text annotated sentiment polarity information process algorithm used obtain values characterize sentiment polarities well used sentiment analysis tasks assessment effectiveness obtained resource sentiment classification made achieving objective instances ra-sr: using ranking algorithm automatically building resources subjectivity analysis annotated corpora ra-sr: using ranking algorithm automatically building resources subjectivity analysis annotated corpora ra-sr: using ranking algorithm automatically building resources subjectivity analysis annotated corpora 
paper presents modeling transliteration machine translation system used popular phrasebased machine translation system machine transliteration achieved accuracy test set used basic rules modulate existing transliteration system experiments show machine translation systems adopted modulating system fit transliteration problem phrase-based transliteration simple heuristics phrase-based transliteration simple heuristics phrase-based transliteration simple heuristics 
sentiment analysis means extract opinion users review documents sentiment classification using machine learning ml methods faces problem high dimensionality feature vector therefore feature selection method required eliminate irrelevant noisy features feature vector efficient working ml algorithms rough set theory based feature selection method finds optimal feature subset eliminating redundant features paper rough set theory rst based feature selection method applied sentiment classification hybrid feature selection method based rst information gain ig proposed sentiment classification proposed methods evaluated four standard datasets viz movie review product book dvd electronics review dataset experimental results show hybrid feature selection method outperforms feature selection methods sentiment classification sentiment classification using rough set based hybrid feature selection sentiment classification using rough set based hybrid feature selection sentiment classification using rough set based hybrid feature selection 
introduce parsing algorithm translation algorithm generates dependency trees partial translations decoding allows efficient integration dependency language models resolve conflicts parsing propose maximum entropy model trained derivation graph training data approach combines merits models achieves significant improvements two baselines nist datasets shift-reduce parsing algorithm phrase-based string-to-dependency translation shift-reduce parsing algorithm phrase-based string-to-dependency translation shift-reduce parsing algorithm phrase-based string-to-dependency translation 
since statistical machine translation smt translation memory tm complement matched unmatched regions integrated models proposed paper incorporate tm information smt unlike previous pipeline approaches directly merge tm result final output proposed models refer corresponding tm information associated phrase smt decoding chinese english tm database experiments show proposed integrated significantly better either smt tm systems fuzzy match score furthermore integrated achieves overall bleu points improvement ter points reduction comparison pure smt system besides proposed models also outperform previous approaches significantly integrating translation memory phrase-based machine translation decoding integrating translation memory phrase-based machine translation decoding integrating translation memory phrase-based machine translation decoding 
paper focuses semantic role labeling using syntactic information simple robust strategy system combination presented allows partially recover input parsing errors significantly boost results individual systems combination scheme also flexible since individual systems required provide information solution extensive experimental evaluation conll shared task framework supports previous claims proposed architecture outperforms best results reported evaluation exercise robust combination strategy semantic role labeling robust combination strategy semantic role labeling robust combination strategy semantic role labeling 
consider synchronous tree substitution grammars stsg help characterization expressive power stsg terms weighted tree bimorphisms show forward backward application stsg preserve recognizability weighted tree languages reasonable cases consequence domain range stsg without chain rules recognizable weighted tree languages preservation recognizability synchronous tree substitution grammars preservation recognizability synchronous tree substitution grammars preservation recognizability synchronous tree substitution grammars 
discuss problem model adaptation task named entity recognition respect variation label distributions data different domains investigate adaptive extension sequence perceptron adaptive component includes parameters estimated unlabelled data combination background knowledge form gazetteers apply idea empirically adaptation experiments involving two newswire datasets different domains compare popular methods self training structural correspondence learning adaptive parameters entity recognition perceptron hmms adaptive parameters entity recognition perceptron hmms adaptive parameters entity recognition perceptron hmms 
present novel greedy dependency parser implements flexible mix strategies new strategy allows parser postpone difficult decisions relevant information becomes available novel parser error reduction unlabeled attachment score parser factor transition-based dependency parser using dynamic parsing strategy transition-based dependency parser using dynamic parsing strategy transition-based dependency parser using dynamic parsing strategy 
supervised language processing systems show significant performance tested text comes domain significantly different domain training data sequence labeling systems like taggers typically trained newswire text tests error rate example biomedical data triple worse investigate techniques building sequence labeling systems approach ideal system whose accuracy high constant across domains particular investigate unsupervised techniques representation learning provide new features stable across domains predictive training test data experiments novel techniques reduce error much relative previous state art text exploring representation-learning approaches domain adaptation exploring representation-learning approaches domain adaptation exploring representation-learning approaches domain adaptation 
paper explore novel bilingual word alignment approach based dnn deep neural network proven effective various machine learning tasks collobert et al describe detail adapt extend dahl et al method introduced speech recognition hmmbased word alignment model bilingual word embedding discriminatively learnt capture lexical translation information surrounding words leveraged model context information bilingual sentences capable model rich bilingual correspondence method generates compact model much fewer parameters experiments large scale englishchinese word alignment task show proposed method outperforms hmm ibm model baselines points word alignment modeling context dependent deep neural network word alignment modeling context dependent deep neural network word alignment modeling context dependent deep neural network 
work propose semisupervised extension supervised domain adaptation approach ea daume iii proposed approach ea builds notion augmented space introduced ea harnesses unlabeled data target domain ameliorate transfer information source target semisupervised approach domain adaptation extremely simple implement applied step supervised learner experimental results sequential labeling tasks demonstrate efficacy proposed method frustratingly easy semi-supervised domain adaptation frustratingly easy semi-supervised domain adaptation frustratingly easy semi-supervised domain adaptation 
dimensionality reduction shown improve processing information extraction high dimensional data word space algorithms typically employ linear reduction techniques assume space euclidean investigate effects extracting nonlinear structure word space using locality preserving projections reduction algorithm performs manifold learning apply reduction two common word space models show improved performance original models benchmarks capturing nonlinear structure word spaces dimensionality reduction capturing nonlinear structure word spaces dimensionality reduction capturing nonlinear structure word spaces dimensionality reduction 
propose new variant treeadjoining grammar allows adjunction full wrapping trees still bears expressivity provide transformation form reduction probabilistic model size factorization pooling parameters collapsed form used implement efficient grammar estimation parsing algorithms perform parsing experiments penn treebank draw comparisons treesubstitution grammars different variations probabilistic model design examination probable derivations reveals examples linguistically relevant structure variant makes possible context free tag variant context free tag variant context free tag variant 
describe algebraic approach computing vector based semantics tensor product proposed method composition undesirable property strings different length incomparable consider quotient algebra tensor algebra allow comparisons made offering possibility models semantic composition semantic composition quotient algebras semantic composition quotient algebras semantic composition quotient algebras 
paper propose novel reordering model based sequence labeling techniques model converts reordering problem sequence labeling problem tagging task results five nist tasks show model improves baseline system bleu ter average results comparative study seven widely used reordering models also reported advancements reordering models statistical machine translation advancements reordering models statistical machine translation advancements reordering models statistical machine translation 
modern machine translation systems use phrase pairs translation units allowing accurate modelling phraseinternal translation reordering however approaches much less able model sentence level effects different propose new model address imbalance based markov model translation generates target translations model encodes word phrase level phenomena conditioning translation decisions previous decisions uses hierarchical process prior provide dynamic adaptive smoothing mechanism implicitly supports traditional phrase pairs also gapping phrases source experiments chinese english arabic english translation show consistent improvements competitive baselines bleu markov model machine translation using non-parametric bayesian inference markov model machine translation using non-parametric bayesian inference markov model machine translation using non-parametric bayesian inference 
learning ssl methods augment standard machine learning ml techniques leverage unlabeled data ssl techniques often effective text classification labeled data scarce large unlabeled corpora readily available however existing ssl techniques typically require multiple passes entirety unlabeled data meaning techniques applicable large corpora produced today paper show improving marginal word frequency estimates using unlabeled data enable text classification scales massive unlabeled data sets present novel learning algorithm optimizes naive bayes model accord statistics calculated unlabeled corpus experiments text topic classification sentiment analysis show method scalable accurate ssl techniques previous work scaling semi-supervised naive bayes feature marginals scaling semi-supervised naive bayes feature marginals scaling semi-supervised naive bayes feature marginals 
paper propose new bayesian inference method train statistical machine translation systems using nonparallel corpora following probabilistic decipherment approach first introduce new framework decipherment training flexible enough incorporate number type features besides simple used estimating translation models order perform fast efficient bayesian inference framework derive hash sampling strategy inspired work ahmed et al new translation hash sampler enables us scale elegantly complex models first time large vocabulary corpora sizes show empirical results opus data method yields best bleu scores compared existing approaches achieving significant computational speedups several orders faster also report first time bleu score results largescale mt task using data emea corpus scalable decipherment machine translation via hash sampling scalable decipherment machine translation via hash sampling scalable decipherment machine translation via hash sampling 
clustering central technique nlp consequently clustering evaluation great importance many clustering algorithms evaluated success tagging corpus tokens paper discuss type level evaluation reflects class membership independent token statistics particular reference corpus type level evaluation casts light merits algorithms applications natural measure algorithm quality propose new type level evaluation measures contrary existing measures applicable items polysemous common case nlp demonstrate benefits measures using detailed case study pos induction experiment seven leading algorithms obtaining useful insights showing token type level measures weakly even negatively correlate underscores fact two approaches reveal different aspects clustering quality type level clustering evaluation: new measures pos induction case study type level clustering evaluation: new measures pos induction case study type level clustering evaluation: new measures pos induction case study 
prior work training translation model based suboptimal methods computing viterbi alignments paper present first method guaranteed produce globally optimal alignments results improved alignments also gives us opportunity evaluate quality standard hillclimbing methods indeed hillclimbing works reasonably well practice still fails find global optimum sentence pairs probabilities several tens orders magnitude away viterbi alignment reformulating alignment problem integer linear program use standard machinery global optimization theory compute solutions use method also show customized specific problem discussed paper fact large number alignments excluded start without losing global optimality computing optimal alignments ibm-3 translation model computing optimal alignments ibm-3 translation model computing optimal alignments ibm-3 translation model 
spoken dialog systems statistical state tracking aims improve robustness speech recognition errors tracking posterior distribution hidden dialog states current approaches based generative discriminative models different important shortcomings limit accuracy paper discuss limitations introduce new approach discriminative state tracking overcomes leveraging problem structure offline evaluation dialog data collected real users shows improvements state tracking accuracy quality posterior probabilities features encode speech recognition error patterns particularly helpful training requires relatively dialogs discriminative state tracking spoken dialog systems discriminative state tracking spoken dialog systems discriminative state tracking spoken dialog systems 
availability substantial parallel corpora critical development statistical machine translation smt systems corpora however expensive produce due labor intensive nature manual translation propose alleviate problem novel semisupervised active learning strategy attempts maximize indomain coverage selecting sentences represent balance domain match translation difficulty batch diversity simulation experiments translation task show proposed strategy outperforms random selection baseline also traditional active learning techniques based dissimilarity existing training data approach achieves relative improvement bleu seed baseline closest competitor gained number selected sentences semi-supervised batch-mode active learning strategy improved statistical machine translation semi-supervised batch-mode active learning strategy improved statistical machine translation semi-supervised batch-mode active learning strategy improved statistical machine translation 
supervised learning recently used improve performance word alignment however due limited amount labeled data performance pure supervised learning used labeled data limited result many existing methods employ features learnt large amount unlabeled data assist task paper propose ensemble method better incorporate labeled unlabeled data learning firstly employ ensemble learning framework effectively uses alignment results different unsupervised alignment models propose use learning method namely train classifiers using labeled unlabeled data collaboratively improve result experimental results show methods substantially improve quality word alignment final translation quality translation system slightly improved well improving word alignment semi-supervised ensemble improving word alignment semi-supervised ensemble improving word alignment semi-supervised ensemble 
paper presents comparative study three closely related bayesian models unsupervised document level sentiment classification namely latent sentiment model lsm joint sentimenttopic jst model model extensive experiments conducted two corpora movie review dataset sentiment dataset found three models achieve either better comparable performance two corpora compared existing unsupervised sentiment classification approaches jst able extract topics addition always performs worse jst suggesting jst model appropriate joint sentiment topic detection comparative study bayesian models unsupervised sentiment detection comparative study bayesian models unsupervised sentiment detection comparative study bayesian models unsupervised sentiment detection 
paratactic syntactic structures notoriously difficult represent dependency formalisms painful consequences high frequency parsing errors related coordination words coordination pending problem dependency analysis natural languages paper tries shed light area bringing systematizing view various formal means developed encoding coordination structures introduce novel taxonomy approaches apply treebanks across typologically diverse range languages addition empirical observations convertibility selected styles representations shown coordination structures dependency treebanks coordination structures dependency treebanks coordination structures dependency treebanks 
recent training models like found statistical nlp exploit distributed computing either multicore cloud architectures rapidly converging online learning algorithms aim combine two focus distributed learners make frequent updates asynchronously nedic et al langford et al generalize existing asynchronous algorithms experiment extensively structured prediction problems nlp including discriminative unsupervised learning scenarios results show asynchronous learning provide substantial speedups compared distributed singleprocessor algorithms signs error arising approximate nature technique distributed asynchronous online learning natural language processing distributed asynchronous online learning natural language processing distributed asynchronous online learning natural language processing 
paper provide theoretical framework feature selection tree kernel spaces based components machines show huge number features discarded without significant decrease accuracy selection algorithm accurate much efficient proposed previous work comparative experiments three interesting diverse classification tasks question classification relation extraction semantic role labeling support theoretical findings demonstrate algorithm performance reverse feature engineering syntactic tree kernels reverse feature engineering syntactic tree kernels reverse feature engineering syntactic tree kernels 
propose notion structural bias inherent parsing system respect language aiming parse structural bias characterizes behaviour parsing system terms structures tends produce propose method uncovering structural bias inherent parsing systems apply method four english dependency parsers parsers parsers show four parsers biased respect kind annotation trained parse present detailed analysis biases highlights specific differences commonalities parsing systems improves understanding strengths weaknesses inspecting structural biases dependency parsing algorithms inspecting structural biases dependency parsing algorithms inspecting structural biases dependency parsing algorithms 
models word alignment built sequences links limited expressive power easy decode word aligners model alignment matrix express arbitrary alignments difficult decode propose alignment matrix model correction algorithm underlying sequencebased aligner greedy decoding algorithm enables full expressive power alignment matrix formulation improved alignment performance shown nine language pairs tested improved alignments also improved translation quality chinese english english italian correction model word alignments correction model word alignments correction model word alignments 
modern machine translation systems make extensive use wordbased translation models inducing alignments parallel corpora problematic systems incapable accurately modelling many translation phenomena decompose translation paper presents novel method inducing translation units directly parallel data frame learning inverse transduction grammar itg using recursive bayesian prior overall leads model learns translations entire sentences also learning decomposition smaller units recursively terminating word translations experiments arabic urdu farsi english demonstrate improvements competitive baseline systems infinite hierarchical bayesian model phrasal translation infinite hierarchical bayesian model phrasal translation infinite hierarchical bayesian model phrasal translation 
statistical machine translation smt systems modeled using loglinear framework although model achieves success smt still suffers limitations features required linear respect model features cannot interpreted reach potential neural network reasonable method address pitfalls however modeling smt neural network trivial especially taking decoding efficiency consideration paper propose variant neural network additive neural networks smt go beyond translation model addition word embedding employed input neural network encodes word feature vector model outperforms translation models without embedding features translation tasks additive neural networks statistical machine translation additive neural networks statistical machine translation additive neural networks statistical machine translation 
present new translation model integrating shallow local multi bottomup tree transducer perform largescale empirical evaluation obtained system demonstrates significantly beat realistic baseline wmt english german translation task additional contribution make developed software complete publicly available experimentation shallow local multi-bottom-up tree transducers statistical machine translation shallow local multi-bottom-up tree transducers statistical machine translation shallow local multi-bottom-up tree transducers statistical machine translation 
paper proposes novel smoothing model combinatorial optimization scheme word sense disambiguation untagged corpora generalizing discrete senses continuum introduce smoothing space cope resulting large variety linguistic context sense well exploit senseinterdependency among words text string smoothing optimal senses obtained one time maximum marginal likelihood criterion competitive probabilistic kernels made reinforce one another among nearby words suppress conflicting sense hypotheses within word experimental results confirmed superiority proposed method conventional ones showing better performances beyond baseline performance none semeval unsupervised systems reached density maximization context-sense metric space all-words wsd density maximization context-sense metric space all-words wsd density maximization context-sense metric space all-words wsd 
modelling compositional process meaning utterance arises meaning parts fundamental task natural language processing paper draw upon recent advances learning vector space representations sentential semantics transparent interface syntax semantics provided combinatory categorial grammar introduce combinatory categorial autoencoders model leverages ccg combinatory operators guide transformation meaning within sentence use model learn high dimensional embeddings sentences evaluate range tasks demonstrating incorporation syntax allows concise model learn representations effective general role syntax vector space models compositional semantics role syntax vector space models compositional semantics role syntax vector space models compositional semantics 
paper presents survey role negation sentiment analysis negation common linguistic construction affects polarity therefore needs taken consideration sentiment analysis present various computational approaches modeling negation sentiment analysis particular focus aspects level representation used sentiment analysis negation word detection scope negation also discuss limits challenges negation modeling task survey role negation sentiment analysis survey role negation sentiment analysis survey role negation sentiment analysis 
paper propose framework verb semantic description order organize different granularity similarity verbs since verb meanings highly depend arguments propose verb thesaurus basis possible shared meanings structure motivations work construct practical lexicon dealing alternations paraphrases entailment relations predicates provide basic database statistical learning system well theoretical lexicon study generative lexicon lexical conceptual structure one characteristics description assume several granularities semantic classes characterize verb meanings thesaurus form allows us provide several granularities shared meanings thus gives us revision applying detailed analyses verb meanings thesaurus predicate-argument structure japanese verbs deal granularity verb meanings thesaurus predicate-argument structure japanese verbs deal granularity verb meanings thesaurus predicate-argument structure japanese verbs deal granularity verb meanings 
confidence measures machine translation method labeling word automatically generated translation correct incorrect paper present new approach confidence estimation advantage rely system output best lists word graphs many confidence measures thus applicable kind machine translation system experimental evaluation performed translation technical manuals three different language pairs results presented different machine translation systems show new approach independent underlying machine translation system generated translations best knowledge performance new confidence measure better existing confidence measure word-level confidence estimation machine translation using phrase-based translation models word-level confidence estimation machine translation using phrase-based translation models word-level confidence estimation machine translation using phrase-based translation models 
paper semantic role labeling srl chinese framenet divided subtasks boundary identification bi semantic role classification src subtasks regarded sequential tagging problem word level respectively use conditional random fields crfs model train test data set extracted features include shallow syntactic features derived automatic base chunk parsing use orthogonal array statistics arrange experiment best feature template selected experimental results show given target word within sentence best srl achieve bi src subtasks best fmeasures respectively statistical shows improvement srl model significant appending base chunk features sequential tagging semantic roles chinese framenet sequential tagging semantic roles chinese framenet sequential tagging semantic roles chinese framenet 
active dual supervision informative examples also features selected labeling build high quality classifier low cost however measure informativeness examples feature scale well solved paper propose matrix factorization based approach address issue first extend matrix factorization framework explicitly model corresponding relationships feature classes examples classes making use reconstruction error propose unified scheme determine feature example classifier likely benefit labeled empirical results demonstrate effectiveness proposed methods non-negative matrix factorization based approach active dual supervision document word labels non-negative matrix factorization based approach active dual supervision document word labels non-negative matrix factorization based approach active dual supervision document word labels 
present novel approach called selectional branching uses confidence estimates decide employ beam providing accuracy beam search speeds close greedy dependency parsing approach selectional branching guaranteed perform fewer number transitions beam search yet performs accurately also present new dependency parsing algorithm gives complexity projective parsing expected linear time speed parsing standard setup parser shows unlabeled attachment score parsing speed milliseconds per sentence faster accurate current transitionbased parser uses beam search transition-based dependency parsing selectional branching transition-based dependency parsing selectional branching transition-based dependency parsing selectional branching 
smallest elements languages rich morphology information morphemes often integrated statistical machine translation improve translation quality paper proposes approach novelly uses morphemes pivot language chained machine translation system machine translation based method used therein find mapping relations morphemes words experiments show effectiveness approach achieving percent increase bleu score baseline machine translation system chained machine translation using morphemes pivot language chained machine translation using morphemes pivot language chained machine translation using morphemes pivot language 
describe new representation content vocabulary text call word association profile captures proportions highly associated mildly associated unassociated pairs words given text illustrate shape distirbution observe variation genre target audience present study relationship quality writing word association profiles set essays written college graduates number general topics show higher scoring essays tend higher percentages highly associated pairs lower percentages mildly associated pairs words finally use word association profiles improve system automated scoring essays word association profiles use automated scoring essays word association profiles use automated scoring essays word association profiles use automated scoring essays 
paper look comparing highaccuracy parsers highaccuracy shallow parsers several shallow parsing tasks show previously reported comparisons greatly performance parsers tasks also demonstrate contextfree parsers train effectively relatively little training data robust domain shift shallow parsing tasks previously reported finally establish combining output finitestate parsers gives much higher results published results several common tasks efficiency benefit models inarguable results presented show corresponding cost accuracy higher previously thought comparing combining finite-state context-free parsers comparing combining finite-state context-free parsers comparing combining finite-state context-free parsers 
two texts inclusion relation relationship called entailment task mechanically distinguishing relation called recognising textual entailment rte basically kind semantic analysis variety methods proposed rte however previous methods combined performances clear utilized method feature machine learning order combine methods dealt binary classification problem two texts exhibiting inclusion proposed method uses machine learning judge whether two texts present content built program capable perform entailment judgment basis word overlap matching rate words two texts mutual information similarity respective syntax trees subpath set word overlap calclated utilizing bilingual evaluation understudy bleu mutual information based frequency subpath set determined using japanise wordnet confidenceweighted score obtained mutual information experiment rte mutual information use three methods svm shown effective textual entailmaint recognition using word overlap, mutual information subpath set textual entailmaint recognition using word overlap, mutual information subpath set textual entailmaint recognition using word overlap, mutual information subpath set 
long distance reordering remains one greatest challenges statistical machine translation research key contextual information may well beyond confine translation units paper propose orientation tno model jointly models orientation decisions anchors two neighboring chunks may cross phrase rule boundaries explicitly model longest span chunks referred maximal orientation span serve global parameter constrains underlying local decisions integrate proposed model translation system demonstrate efficacy proposal translation task nist mt set advanced model brings around bleu ter improvement two-neighbor orientation model cross-boundary global contexts two-neighbor orientation model cross-boundary global contexts two-neighbor orientation model cross-boundary global contexts 
preordering source language sentence match target word order proved useful improving machine translation systems previous work shown reordering model learned high quality manual word alignments improve machine translation performance paper focus improving performance reordering model thereby machine translation using larger corpus sentence aligned data manual word alignments available automatic machine generated alignments available main challenge tackle generate quality data training reordering model spite machine alignments noisy mitigate effect noisy machine alignments propose novel approach improves reorderings produced given noisy alignments also improves word alignments using information reordering model approach generates alignments points better baseline supervised aligner data generated allows us train reordering model gives improvement bleu points nist evaluation set reordering model uses manual word alignments gain bleu points standard baseline cut noise: mutually reinforcing reordering alignments improved machine translation cut noise: mutually reinforcing reordering alignments improved machine translation cut noise: mutually reinforcing reordering alignments improved machine translation 
paper proposes new approach domain adaptation statistical machine translation smt based vector space model vsm general idea first create vector profile development dev set profile might instance vector dimensionality equal number training subcorpora entry vector reflects contribution particular subcorpus phrase pairs extracted dev set phrase pair extracted training data create vector features defined way calculate similarity score vector representing dev set thus obtain decoding feature whose value represents phrase pair closeness dev simple computationally cheap form instance weighting phrase pairs experiments large scale nist evaluation data show improvements strong baselines bleu arabic english bleu chinese english baseline significant improvements circumstances baselines linear mixture model adaptation informal analysis suggests vsm adaptation may help making good choice among words meaning basis style genre vector space model adaptation statistical machine translation vector space model adaptation statistical machine translation vector space model adaptation statistical machine translation 
rationale effectiveness adopting notions depth density semantic similarity measures show intuition including notions similarity measures always stand empirical examination particular traditional definitions depth density ordinal integer values hierarchical structure wordnet always correlate human judgment lexical semantic similarity imposes strong limitations contribution accurate similarity measure thus propose several novel definitions depth density yield significant improvement degree correlation similarity used semantic similarity measures new definitions consistently improve performance task correlating human judgment refining notions depth density wordnet-based semantic similarity measures refining notions depth density wordnet-based semantic similarity measures refining notions depth density wordnet-based semantic similarity measures 
parallel text fuel drives modern machine translation systems web comprehensive source preexisting parallel text crawling entire web impossible largest companies bring parallel text masses mining common crawl public web crawl hosted amazon elastic cloud starting nothing set common language codes extension strand algorithm mined terabytes crawl day cost experiment uncovers large amounts parallel text dozens language pairs across variety domains genres previously unavailable curated datasets even minimal cleaning filtering resulting data boosts translation performance across board five different language pairs news domain open domain test sets see improvements bleu make code data available researchers seeking mine rich new data resource dirt cheap web-scale parallel text common crawl dirt cheap web-scale parallel text common crawl dirt cheap web-scale parallel text common crawl 
present two contributions grammar driven translation first since inversion transduction grammar linear inversion transduction grammars shown produce better alignments standard word alignment tool investigate speed translation quality extends choice grammar formalism second prove linear transduction grammars ltgs generate transductions linear inversion transduction grammars present scheme arriving ltgs bilingualizing linear grammars also present method obtaining inversion transduction grammars linear inversion transduction grammars speed grammar induction parallel corpora dramatically systematic comparison inversion transduction grammar linear transduction grammar word alignment systematic comparison inversion transduction grammar linear transduction grammar word alignment systematic comparison inversion transduction grammar linear transduction grammar word alignment 
inspired previous syntactic reordering methods smt paper focuses using automatically learned syntactic reordering patterns functional words indicate structural reorderings source target language approach takes advantage phrase alignments parse trees pattern extraction filters patterns without functional words word lattices transformed generated patterns fed pbsmt systems incorporate potential reorderings inputs experiments carried corpus chinese english smt task proposed method outperforms baseline system relative randomly selected testset relative nist testset terms bleu score furthermore system patterns filtered functional words obtains comparable performance unfiltered one randomly selected testset achieves relative improvements nist testset source-side syntactic reordering patterns functional words improved phrase-based smt source-side syntactic reordering patterns functional words improved phrase-based smt source-side syntactic reordering patterns functional words improved phrase-based smt 
paper present approach statistical machine translation combines power discriminative model training model machine translation standard based decoding technique translation input sentence discriminative approach learning lexical selection reordering utilizes large set feature functions thereby providing power incorporate greater contextual linguistic information leads effective training models model used standard moses decoder koehn et al translation input sentence conducted experiments language pair used maximum entropy model experiments show performance approach using simple lexical features comparable statistical mt system koehn et al additional syntactic features pos tags paper used boost performance likely improve richer syntactic features incorporated model phrase based decoding using discriminative model phrase based decoding using discriminative model phrase based decoding using discriminative model 
hiero translation models two limitations compared models limited hypothesis space lexicalized reordering model propose extension hiero called phrasalhiero address hiero second problem still hypothesis space original hiero incorporates distance cost feature lexicalized reodering features chart decoder work consists two parts hiero translation derivation find corresponding discontinuous path extend chart decoder incorporate features path achieve significant improvement hiero baselines arabicenglish germanenglish translation integrating phrase-based reordering features chart-based decoder machine translation integrating phrase-based reordering features chart-based decoder machine translation integrating phrase-based reordering features chart-based decoder machine translation 
paper propose dependency based statistical system uses discriminative techniques train parameters conducted experiments englishhindi parallel corpora use syntax dependency tree allows us address large english hindi discriminative training allows us use rich feature sets including linguistic features useful machine translation task present results experimental implementation system paper discriminative approach dependency based statistical machine translation discriminative approach dependency based statistical machine translation discriminative approach dependency based statistical machine translation 
lack annotated data obstacle development many natural language processing applications problem especially severe data previous studies suggested possibility acquiring resources languages bootstrapping high quality english nlp tools parallel corpora however success approaches seems limited dissimilar language pairs paper propose novel approach combining bootstrapped resource small amount manually annotated data compare proposed approach bootstrapping methods context training chinese tagger experimental results show proposed approach achieves significant improvement em systems trained manual annotations backoff model bootstrapping resources non-english languages backoff model bootstrapping resources non-english languages backoff model bootstrapping resources non-english languages 
analyzed details distributional data japanese nominal terms two aims one aim examine distributionally similar terms fact equated semantically similar terms extent investigate kind semantic relations constitute strongly distributionally similar terms results show pairs terms derived highly similar terms turned semantically similar way ratio classmate synonymous meronymic relations classified data respectively look inside distributionally similar terms look inside distributionally similar terms look inside distributionally similar terms 
understanding connotation words plays important role interpreting subtle shades sentiment beyond denotative surface meaning text seemingly objective statements often allude nuanced sentiment writer even purposefully conjure emotion readers minds focus paper drawing nuanced connotative sentiments even words objective surface intelligence human cheesecake propose induction algorithms encoding diverse set linguistic insights semantic prosody distributional similarity semantic parallelism coordination prior knowledge drawn lexical resources resulting first connotation lexicon connotation lexicon: dash sentiment beneath surface meaning connotation lexicon: dash sentiment beneath surface meaning connotation lexicon: dash sentiment beneath surface meaning 
paper presents new word alignment method incorporates knowledge bilingual expressions bmwes method word alignment first extracts bmwes bidirectional way given corpus starts conventional word alignment considering properties bmwes grouping well alignment links give partial annotation alignment links prior knowledge word alignment process replacing maximum likelihood estimate ibm models maximum posteriori map estimate prior knowledge bmwes embedded prior map estimate experiments saw improvement bleu points absolute jp en except one case method gave better results method using bmwes grouping even though paper directly address issues crosslingual information retrieval clir discusses approach direct relevance field approach could viewed opposite current trends clir semantic space incorporate notion order model multi-word expression-sensitive word alignment multi-word expression-sensitive word alignment multi-word expression-sensitive word alignment 
notion fertility word alignment number words emitted single state useful difficult model initial attempts modeling fertility used heuristic search methods recent approaches instead use principled approximate inference techniques gibbs sampling parameter estimation yet practice also need single best alignment difficult find using gibbs building recent advances dual decomposition paper introduces exact algorithm finding single best alignment fertility hmm finding best alignment appears important model leads substantial improvement alignment quality exact maximum inference fertility hidden markov model exact maximum inference fertility hidden markov model exact maximum inference fertility hidden markov model 
experimenting tuning long sentences made unexpected discovery pro falls victim monsters overly long negative examples low bleu scores unsuitable learning cause testing bleu drop several points absolute propose several effective ways address problem using bleu based outlier filters stochastic sampling random acceptance best fixes slay protect monsters also yield higher stability pro well improved testtime bleu scores thus recommend anybody using pro monsterbeliever upon time years standard way statistical machine translation parameter tuning use minimum training mert och however researchers started using models thousands parameters new scalable optimization algorithms mira watanabe et al chiang et al pro hopkins may emerged algorithms relatively new still quite well understood studying properties active area research example nakov et al pointed pro tends generate translations consistently shorter desired blamed inadequate smoothing pro optimization objective namely sentencelevel bleu addressed problem using sensible smoothing wondered whether issue could partially relieved simply tuning longer sentences effect smoothing would naturally smaller surprise tuning longer tuning sentences disastrous effect pro causing absolute drop three bleu points testing time mert mira problem investigating reasons discovered hundreds monsters creeping pro surface tale continues follows first explain monsters section present theory slayed section put theory test practice section discuss related efforts section finally present moral tale hint planned future tale pro monsters tale pro monsters tale pro monsters 
multilingual feedback multiprf framework improve prf source language taking help another language called assisting language paper extend multiprf framework include multiple assisting languages consider three different configurations incorporate multiple assisting languages parallel assisting languages combined simultaneously serial assisting languages combined sequence one another selective dynamically selecting best feedback model query study effect multiprf performance results using multiple assisting languages mixed helps boosting multiprf accuracy cases also observe multiprf becomes robust increase number assisting languages languages, map?: study multiple assisting languages multilingual prf languages, map?: study multiple assisting languages multilingual prf languages, map?: study multiple assisting languages multilingual prf 
main drawback previous chinese character error detection systems high false alarm rate solve problem propose system combines statistic method template matching detect chinese character errors error types include pronunciationrelated errors errors possible errors character collected form confusion set system automatically generates templates help dictionary confusion sets templates used detect correct errors essays paper compare three methods proposed previous works experiment results show system reduce false alarm significantly give best performance fscore reducing false alarm rate chinese character error detection correction reducing false alarm rate chinese character error detection correction reducing false alarm rate chinese character error detection correction 
translation adequacy preference evaluation tool (tap-et) translation adequacy preference evaluation tool (tap-et) translation adequacy preference evaluation tool (tap-et) 
reranking models successfully applied many tasks natural language processing however two aspects approach need deeper investigation assessment hypotheses generated reranking classification phase baseline models generate list hypotheses used reranking without assessment ii detection cases reranking models provide worst result best hypothesis provided reranking model assumed always best result cases reranking model provides incorrect hypothesis baseline best hypothesis correct especially baseline models accurate paper propose solutions two aspects semantic inconsistency metric select possibly correct hypotheses large set generated slu basiline model selected hypotheses reranked applying model based partial tree kernels encode slu hypotheses support vector machines complex structured features ii finally apply decision strategy based confidence values select final hypothesis first ranked hypothesis provided baseline slu model first ranked hypothesis provided show effectiveness solutions presenting comparative results obtained reranking hypotheses generated accurate conditional random field model evaluate approach french media corpus results show significant improvements respect current previous models hypotheses selection criteria reranking framework spoken language understanding hypotheses selection criteria reranking framework spoken language understanding hypotheses selection criteria reranking framework spoken language understanding 
clustering task clustering web search results within context propose new methodology adapts classical algorithm similarity measure initially developed nlp tasks results obtained definition new stopping criterion moresque gold standard datasets evidence proposal outperforms reported approaches post-retrieval clustering using third-order similarity measures post-retrieval clustering using third-order similarity measures post-retrieval clustering using third-order similarity measures 
paper describe system task chinese word segmentation focused performance chinese word segmentation algorithms use online algorithm domain invariant information chinese word segmentation adaptive chinese word segmentation online passive-aggressive algorithm adaptive chinese word segmentation online passive-aggressive algorithm adaptive chinese word segmentation online passive-aggressive algorithm 
transliteration defined phonetic translation names across languages transliteration named entities nes necessary many applications machine translation corpus alignment ir information extraction automatic lexicon acquisition systems call transliteration focus shared task news workshop objective shared task promote machine transliteration research providing common benchmarking platform community evaluate technologies task description task develop machine transliteration system one specified language pairs considered task language pair consists source target language training development data sets released language pair used developing transliteration system whatever way participants find appropriate evaluation time test set source names would released participants expected produce ranked list transliteration candidates another language transliterations evaluated using common metrics every language pair participants must submit least one run uses data provided news workshop organisers given language pair designated standard run primary submission users may submit stanrard runs may also submit several runs language pair http translit edu sg news use data provided news workshop runs would evaluated reported separately important dates research paper submission deadline march shared task registration opens jan registration closes mar training development data release jan test data release mar results submission due mar results announcement mar task short papers due mar submissions acceptance notification april copy deadline april workshop date july participation registration jan whitepaper news 2012 shared task machine transliteration whitepaper news 2012 shared task machine transliteration whitepaper news 2012 shared task machine transliteration 
paper explore use distance information language modeling attempt extract information ten words size found complements well model inherently suffers data scarcity learning long evaluated wsj corpus bigram trigram model perplexity reduced respectively compared distant bigram show effectively modeled terms distance occurrence modeling term-distance term-occurrence information improving n-gram language model performance modeling term-distance term-occurrence information improving n-gram language model performance modeling term-distance term-occurrence information improving n-gram language model performance 
paper presents work participation shared task chinese syntactic constituent tree parsing use dependency parsers constituent parsing task based formal dependencyconstituent transformation method converts dependency constituent structures using machine learning approach conditional random fields crf tagger adopted head information recognition experiments shows acceptable parsing head tagging results obtained approaches dependency parser chinese constituent parsing dependency parser chinese constituent parsing dependency parser chinese constituent parsing 
chinese parsing received attention paper use toolkit perform parsing data tsinghua chinese treebank tct used cips use conditional random fields crfs train specific model head recognition last compare different results different pos results crf tagging head recognition based stanford parser crf tagging head recognition based stanford parser crf tagging head recognition based stanford parser 
paper describes chinese word sense induction wsi system international chinese language processing bakeoff computing longest common substrings two contexts ambiguous word system extracts collocations features depend extra tools chinese word segmenters also design constrained clustering algorithm task experiemental results show system could achieve scores fscore development data set sighan bakeoff neunlplab chinese word sense induction system sighan bakeoff 2010 neunlplab chinese word sense induction system sighan bakeoff 2010 neunlplab chinese word sense induction system sighan bakeoff 2010 
present simple yet effective approach syntactic reordering statistical machine translation smt instead solely relying rule source sentence preordering generalize fully lexicalized rules partially lexicalized unlexicalized rules broaden rule coverage furthermore consider multiple permutations matching rules select final reordering path based weighed sum reordering probabilities rules experiments translations demonstrate effectiveness proposed approach observe consistent significant improvement translation quality across multiple test sets language pairs judged humans automatic metric generalized reordering rules improved smt generalized reordering rules improved smt generalized reordering rules improved smt 
machine transliteration essential task many nlp applications however names loan words typically originate various languages obey different transliteration rules therefore may benefit modeled independently recently transliteration models based bayesian learning overcome issues allowing alignment training transliteration models propose novel coupled dirichlet process mixture model cdpmm simultaneously clusters bilingually aligns transliteration data within single unified model unified model decomposes two classes bayesian component models dirichlet process mixture model clustering set multinomial dirichlet process models perform bilingual alignment independently cluster experimental results show method considerably outperforms conventional alignment models tightly-coupled unsupervised clustering bilingual alignment model transliteration tightly-coupled unsupervised clustering bilingual alignment model transliteration tightly-coupled unsupervised clustering bilingual alignment model transliteration 
smt frameworks complement former better able memorize latter provides principled model captures dependencies across phrasal boundaries work done combine insights two frameworks recent successful attempt showed advantage using phrasebased search top model probe question reverse direction investigating whether integrating translation reordering models decoder helps overcome problematic phrasal independence assumption large scale evaluation language pairs shows performance significantly improve markov models minimal translation units help phrase-based smt? markov models minimal translation units help phrase-based smt? markov models minimal translation units help phrase-based smt? 
investigate weights generative models underperform heuristic estimates phrasebased machine translation first propose simple generative model verify estimates inferior given surface statistics performance gap stems primarily addition hidden segmentation variable increases capacity overfitting maximum likelihood training em particular word level models benefit greatly models crucial difference distinct word alignments cannot correct distinct segmentations alternate segmentations rather alternate alignments compete resulting increased determinization phrase table decreased generalization decreased final bleu score also show interpolation two methods result modest increase bleu score generative phrase models underperform surface heuristics generative phrase models underperform surface heuristics generative phrase models underperform surface heuristics 
experiment adding semantic role information machine translation system based rule extraction procedure galley et al compare methods based augmenting set nonterminals adding semantic role labels altering rule extraction process produce separate set rules predicate encompass entire structure results demonstrate second approach effective increasing quality translations semantic roles string tree machine translation semantic roles string tree machine translation semantic roles string tree machine translation 
paper investigates relationship results extrinsic taskbased evaluation nlg system various metrics measuring surface deep semantic textual properties including relevance latter rely heavily domain knowledge show correlate systematically measures performance core argument paper domain metrics shed light relationship deep semantic properties text task performance textual properties task-based evaluation: investigating role surface properties, structure content textual properties task-based evaluation: investigating role surface properties, structure content textual properties task-based evaluation: investigating role surface properties, structure content 
fluency rankers used modern sentence generation systems pick sentences grammatical also fluent shown models maximum entropy models work well task since maximum entropy models allow incorporation arbitrary features often attractive create general feature templates create huge number features select discriminative features feature selection applied paper compare three feature selection methods selection generalization maximum entropy feature selection ranking tasks realvalued features new selection method based feature value correlation show selection performs badly compared maximum entropy feature selection models hundred features competitive models feature selection applied experiments described paper compressed model approximately features features feature selection fluency ranking feature selection fluency ranking feature selection fluency ranking 
bow popular way model text machine learning based sentiment classification however performance approach sometimes remains rather limited due fundamental deficiencies bow model paper focus polarity shift problem propose novel approach called dual training dual prediction dtdp address basic idea dtdp first generate artificial samples original samples polarity reversion leverage original opposite samples dual training dual prediction experimental results four datasets demonstrate effectiveness proposed approach polarity classification dual training dual prediction polarity classification dual training dual prediction polarity classification dual training dual prediction polarity classification 
three grec tasks generation challenges required participating systems identify people references texts grecneg systems selected coreference chains people entities texts grecfull combined ner neg tasks systems identified appropriate replaced references people texts five teams submitted systems total additionally created baseline systems task systems evaluated automatically using range intrinsic metrics addition systems assessed human judges using preference strength judgements report presents evaluation results along descriptions three grec tasks evaluation methods participating systems grec challenges 2010: overview evaluation results grec challenges 2010: overview evaluation results grec challenges 2010: overview evaluation results 
quality estimation models provide feedback quality machine translated texts usually trained humanannotated datasets costly due nature investigate active learning techniques reduce size datasets thus annotation effort experiments number datasets show little training instances possible obtain similar superior performance compared complete datasets words active learning query strategies reduce annotation effort also result better quality predictors reducing annotation effort quality estimation via active learning reducing annotation effort quality estimation via active learning reducing annotation effort quality estimation via active learning 
timeline summarization aims generating concise summaries giving readers faster better access understand evolution news new challenge combines salience ranking problem novelty detection previous researches field seldom explore evolutionary pattern topics birth splitting merging developing death paper develop novel model called evolutionary hierarchical dirichlet process ehdp capture topic evolution pattern timeline summarization ehdp time varying information formulated series hdps considering information experiments different datasets contain documents demonstrates good performance system regard rouge scores evolutionary hierarchical dirichlet process timeline summarization evolutionary hierarchical dirichlet process timeline summarization evolutionary hierarchical dirichlet process timeline summarization 
report describes methods results system developed grec named entity recognition grec named entity regeneration challenges explain process automatically annotating surface text well use output select improved referring expressions named entities udel: named entity recognition reference regeneration surface text udel: named entity recognition reference regeneration surface text udel: named entity recognition reference regeneration surface text 
many areas nlp reuse utility tools parsers pos taggers common still rare nlg subfield surface realisation perhaps come closest present still lack basis different surface realisers could compared chiefly wide variety different input representations used different realisers paper outlines idea shared task surface realisation inputs provided representation formalism participants map types input required system inputs derived existing annotated corpora developed language analysis parsing etc outputs realisations evaluated automatic comparison text corpora well human assessors background reading paper reporting new nlp system common days find authors taken nlp utility tool shelf reused researchers frequently reuse parsers named entity recognisers coreference resolvers many tools real choice range different systems performing task also evaluation methodologies help determine state art natural language generation nlg far developed generic tools methods comparing extent natural language analysis nla subfield nlg perhaps come closest developing generic tools surface realisation surface realisers penman nigel mann mathiesen fuf surge elhadad robin realpro lavoie rambow intended less modules tended require significant amount work adapt integrate required highly specific inputs incorporating several hundred finding common ground: towards surface realisation shared task finding common ground: towards surface realisation shared task finding common ground: towards surface realisation shared task 
present new training methods aim mitigate local optima slow convergence unsupervised training using additional imperfect objectives simplest form lateen em alternates two objectives ordinary soft hard expectation maximization em algorithms switching objectives stuck help escape local optima find applying single alternation already yields results english dependency grammar induction elaborate lateen strategies track objectives validating moves proposed disagreements signal earlier opportunities switch terminate saving iterations fixed points ways eliminates guesswork tuning em evaluation suite unsupervised dependency parsing tasks variety languages showed lateen strategies significantly speed training em algorithms improve accuracy hard em lateen em: unsupervised training multiple objectives, applied dependency grammar induction lateen em: unsupervised training multiple objectives, applied dependency grammar induction lateen em: unsupervised training multiple objectives, applied dependency grammar induction 
beam search incremental parsers accurate fast could demonstrate contrary popular belief current implementations beam parsers fact run rather linear time statetransition actually implemented operation present improved implementation based tree structured stack tss transition performed resulting real lineartime algorithm verified empirically improve parsing speed sharing dotproduct across beam items practically methods combined offer speedup strong baselines penn treebank sentences orders magnitude faster much longer sentences efficient implementation beam-search incremental parsers efficient implementation beam-search incremental parsers efficient implementation beam-search incremental parsers 
analogical learning strings holistic model investigated authors means map forms source language forms target language study revisit learning paradigm apply transliteration task show alone performs worse statistical machine translation engine combination approaches outperforms one taken separately demonstrating usefulness information captured formal analogy mapping source target strings without alignment analogical learning: case study transliteration mapping source target strings without alignment analogical learning: case study transliteration mapping source target strings without alignment analogical learning: case study transliteration 
present efficient algorithm estimate large modified models including interpolation streaming sorting enables algorithm scale much larger models using fixed amount ram variable amount disk using one machine gb ram days built unpruned model billion tokens machine translation experiments model show improvement bleu point constrained systems workshop machine translation task three language pairs algorithm also faster small models estimated model million tokens using ram wall time taken srilm code open source part kenlm scalable modified kneser-ney language model estimation scalable modified kneser-ney language model estimation scalable modified kneser-ney language model estimation 
propose verb suggestion method uses candidate sets domain adaptation incorporate error patterns produced esl learners candidate sets constructed large scale learner corpus cover various error patterns made learners furthermore model trained using native corpus learner corpus via domain adaptation technique experiments two learner corpora show candidate sets increase coverage error patterns domain adaptation improves performance verb suggestion learner corpus-based approach verb suggestion esl learner corpus-based approach verb suggestion esl learner corpus-based approach verb suggestion esl 
present results study uses syntactically semantically motivated information group segments sentences unbreakable units purpose typesetting sentences region fixed width using otherwise standard dynamic programming line breaking algorithm minimize raggedness addition baseline segmenter use modest size text manually annotated positions breaks train maximum entropy classifier relying extensive set lexical syntactic features predict whether break certain word position sentence also use simple genetic algorithm search subset features optimizing arrive set features delivers precision recall test set improving baseline points classifier trained features point typesetting improved readability using lexical syntactic information typesetting improved readability using lexical syntactic information typesetting improved readability using lexical syntactic information 
sentiment word identification swi basic technique many sentiment analysis applications existing researches exploit seed words lead low robustness paper propose novel model swi unlike previous approaches model exploits sentiment labels documents instead seed words several experiments real datasets show weed effective outperforms methods seed words identifying sentiment words using optimization-based model without seed words identifying sentiment words using optimization-based model without seed words identifying sentiment words using optimization-based model without seed words 
thwarting sarcasm two uncharted territories sentiment analysis former lack training corpora latter enormous amount world knowledge demands paper propose working definition thwarting amenable machine learning create system detects document thwarted focus identifying thwarting product reviews especially camera domain ontology camera domain created thwarting looked upon phenomenon polarity reversal higher level ontology compared polarity expressed lower level notion thwarting defined respect ontology novel best knowledge rule based implementation building upon idea forms baseline show machine learning annotated corpora thwarted nonthwarted effective rule based system skewed distribution thwarting adopt measure performance best knowledge first attempt difficult problem thwarting detection hope least provide baseline system compare credits authors thank lexicographers center indian language technology cfilt iit bombay support work detecting turnarounds sentiment analysis: thwarting detecting turnarounds sentiment analysis: thwarting detecting turnarounds sentiment analysis: thwarting 
hierarchical translation weighted transducers grammars adria de gispert university cambridge gonzalo iglesias university vigo graeme blackwood university cambridge eduardo banga university vigo william byrne university cambridge article describe hifst decoder hierarchical translation alignment decoder implemented standard weighted transducer wfst operations alternative cube pruning procedure find use wfsts rather lists requires less pruning translation search resulting fewer search errors better parameter optimization improved translation performance direct generation translation lattices target language improve subsequent rescoring procedures yielding gains applying language models minimum bayes risk decoding also provide insights control size search space defined hierarchical rules show grammars rule catenation search constraints help match power translation system specific language pairs hierarchical phrase-based translation weighted finite-state transducers shallow-n grammars hierarchical phrase-based translation weighted finite-state transducers shallow-n grammars hierarchical phrase-based translation weighted finite-state transducers shallow-n grammars 
though substantial research concerning extraction information clinical notes date less work concerning extraction useful content using dataset comprised online support group discussion content paper investigates two dimensions may important experiences text significant individuals groups use regard former describes approach involving important figures family doctors etc affect suggests possible applications techniques concerning online social support well integration search interfaces patients additionally paper demonstrates extraction side effects sentiment different phases patient medication use adoption current use discontinuation switching demonstrates utility application drug safety monitoring online discussion forums patient experience online support forums: modeling interpersonal interactions medication use patient experience online support forums: modeling interpersonal interactions medication use patient experience online support forums: modeling interpersonal interactions medication use 
article present method combining different information retrieval models order increase retrieval performance speech information retrieval task formulas combining models tuned training data system evaluated test data task particularly difficult text collection automatically transcribed spontaneous speech many recognition errors also topics real information needs difficult satisfy information retrieval systems able obtain good results data set except case manual summaries included evaluating complement-modifier distinctions semantically annotated corpus evaluating complement-modifier distinctions semantically annotated corpus evaluating complement-modifier distinctions semantically annotated corpus 
article present method combining different information retrieval models order increase retrieval performance speech information retrieval task formulas combining models tuned training data system evaluated test data task particularly difficult text collection automatically transcribed spontaneous speech many recognition errors also topics real information needs difficult satisfy information retrieval systems able obtain good results data set except case manual summaries included subdomain sensitive statistical parsing using raw corpora subdomain sensitive statistical parsing using raw corpora subdomain sensitive statistical parsing using raw corpora 
deepfix statistical system improving quality statistical machine translation outputs attempts correct errors valency using deep syntactic analysis simple probabilistic model valency translation pair show statistical statistical machine translation leads improvement translation quality helped deep linguistic knowledge deepfix: statistical post-editing statistical machine translation using deep syntactic analysis deepfix: statistical post-editing statistical machine translation using deep syntactic analysis deepfix: statistical post-editing statistical machine translation using deep syntactic analysis 
growing need chinese natural language processing nlp largely range research commercial applications however currently chinese nlp tools components still wide range issues need improved developed fudannlp open source toolkit chinese natural language processing nlp uses methods deal chinese nlp tasks word segmentation tagging named entity recognition dependency parsing time phrase recognition anaphora resolution fudannlp: toolkit chinese natural language processing fudannlp: toolkit chinese natural language processing fudannlp: toolkit chinese natural language processing 
quality automatic translation affected many factors one divergence specific source target languages another lies source text texts complex others one way handle texts modify prior translation yet important factor often overlooked source translatability respect specific translation system specific model used paper present interactive system source modifications induced confidence estimates derived translation model use modifications automatically generated proposed user approval system reduce postediting effort replacing done monolinguals sort: interactive source-rewriting tool improved translation sort: interactive source-rewriting tool improved translation sort: interactive source-rewriting tool improved translation 
developing sophisticated nlp pipelines composed multiple processing tools components available different providers may pose challenge terms interoperability unstructured information management architecture uima industry standard whose aim ensure interoperability defining common data structures interfaces architecture gaining attention industry academia alike resulting large volume processing components paper demonstrate argo workbench development processing nlp pipelines workflows workbench based upon uima thus potential using many existing uima resources present features show examples facilitating distributed development components analysis processing results latter includes annotation visualisers editors well serialisation rdf format enables flexible querying addition data manipulation thanks semantic query language sparql distributed development feature allows users seamlessly connect tools workflows running argo thus take advantage available library components without need installing locally analytical tools development analysis nlp pipelines argo development analysis nlp pipelines argo development analysis nlp pipelines argo 
work presents tsearch application provides mechanisms complex searches collection translation cases evaluated large set diverse measures tsearch uses evaluation results obtained asiya toolkit mt evaluation connected gui makes possible graphical visualization interactive access evaluation results search engine offers flexible query language allowing find translation examples matching combination numerical structural features associated calculation quality metrics database design permits fast response time queries supported test beds summary tsearch used asiya offers developers mt systems evaluation metrics powerful tool helping translation error analysis tsearch: flexible fast search automatic translations improved quality/error analysis tsearch: flexible fast search automatic translations improved quality/error analysis tsearch: flexible fast search automatic translations improved quality/error analysis 
romanian semantic role resource romanian semantic role resource romanian semantic role resource 
beam search fast empirically effective method translation decoding lacks formal guarantees search error develop new decoding algorithm combines speed beam search optimal certificate property lagrangian relaxation apply translation decoding new method efficient utilizes standard mt algorithms returns exact solution majority translation examples test data algorithm times faster optimized incremental decoder translation times faster translation optimal beam search machine translation optimal beam search machine translation optimal beam search machine translation 
using log-linear models tuning machine translation output using log-linear models tuning machine translation output using log-linear models tuning machine translation output 
current automatic machine translation systems able generate translations human intervention often required correct output alternatively interactive framework integrates human knowledge translation process presented previous works describe new interactive machine translation approach able work hierarchical translation models integrates unified statistical framework experiments approach outperforms previous interactive translation systems achieves estimated effort reductions much relative traditional system interactive machine translation using hierarchical translation models interactive machine translation using hierarchical translation models interactive machine translation using hierarchical translation models 
using parsed corpora estimating stochastic inversion transduction grammars using parsed corpora estimating stochastic inversion transduction grammars using parsed corpora estimating stochastic inversion transduction grammars 
general methodology mapping eurowordnets suggested upper merged ontology general methodology mapping eurowordnets suggested upper merged ontology general methodology mapping eurowordnets suggested upper merged ontology 
improving statistical machine translation efficiency triangulation improving statistical machine translation efficiency triangulation improving statistical machine translation efficiency triangulation 
phrase-based machine translation based simulated annealing phrase-based machine translation based simulated annealing phrase-based machine translation based simulated annealing 
evaluation context-dependent phrasal translation lexicons statistical machine translation evaluation context-dependent phrasal translation lexicons statistical machine translation evaluation context-dependent phrasal translation lexicons statistical machine translation 
multi-genre smt system arabic french multi-genre smt system arabic french multi-genre smt system arabic french 
reordering poses one greatest challenges statistical machine translation research key contextual information may well beyond confine translation units present anchor graph ag model use graph structure model global contextual information crucial reordering key ingredient ag model edges capture relationship reordering around set selected translation units refer anchors edges link anchors may span multiple translation units decoding time ag model effectively encodes global contextual information previously absent integrate proposed model translation system demonstrate efficacy proposal largescale translation task anchor graph: global reordering contexts statistical machine translation anchor graph: global reordering contexts statistical machine translation anchor graph: global reordering contexts statistical machine translation 
present simple novel preordering approach unlike existing preordering models train discriminative classifiers directly predict word order approach combines strengths lexical reordering syntactic preordering models performing reorderings using structure parse tree utilizing discriminative model rich set features including lexical features present extensive experiments language pairs including preordering english languages obtain improvements bleu language pairs wmt shared task languages different families improvements often exceed bleu many gains also significant human evaluations source-side classifier preordering machine translation source-side classifier preordering machine translation source-side classifier preordering machine translation 
sensitivity automated mt evaluation metrics higher quality mt output: bleu vs task-based evaluation methods sensitivity automated mt evaluation metrics higher quality mt output: bleu vs task-based evaluation methods sensitivity automated mt evaluation metrics higher quality mt output: bleu vs task-based evaluation methods 
machine translation benefits system combination propose flexible interaction hypergraphs novel technique combining different translation models within one decoder introduce features controlling interactions two systems explore three interaction schemes hiero models specification generalization interchange experiments carried large training data strong baselines utilizing rich sets dense sparse features three schemes significantly improve results single system four testsets find specification constrained scheme almost entirely uses rules optionally uses hiero rules shorter spans comes strongest yielding improvement points also provide detailed experimental qualitative analysis results flexible efficient hypergraph interactions joint hierarchical forest-to-string decoding flexible efficient hypergraph interactions joint hierarchical forest-to-string decoding flexible efficient hypergraph interactions joint hierarchical forest-to-string decoding 
paper describes factored approach incorporating soft source syntactic constraints hierarchical translation system contrast traditional approaches directly introduce syntactic constraints translation rules explicitly decorating syntactic annotations often exacerbate data sparsity problem cause problems approach keeps translation rules intact factorizes use syntactic constraints two separate models syntax mismatch model associates nonterminal translation rule distribution tags used measure degree syntactic compatibility translation rule source spans reordering model predicts whether pair sibling constituents constituent parse tree source sentence reordered translated target language features produced models used soft constraints guide translation process experiments translation show proposed approach significantly improves strong translation system multiple evaluation sets factored soft source syntactic constraints hierarchical machine translation factored soft source syntactic constraints hierarchical machine translation factored soft source syntactic constraints hierarchical machine translation 
inversion transduction grammar itg well suited modeling ordering shifts languages make applying two reordering rules straight inverted dependent actual blocks merged remains challenge unlike previous work uses boundary words propose use recursive autoencoders make full use entire merging blocks alternatively recursive autoencoders capable generating vector space representations phrases enable predicting orders exploit syntactic semantic information neural language modeling perspective experiments nist dataset show system significantly improves maxent classifier bleu points recursive autoencoders itg-based translation recursive autoencoders itg-based translation recursive autoencoders itg-based translation 
induction treebank-aligned lexical resources induction treebank-aligned lexical resources induction treebank-aligned lexical resources 
detecting errors semantic annotation detecting errors semantic annotation detecting errors semantic annotation 
statistical machine translation process generating single translation multiple inputs previous work focused primarily selecting potential outputs separate translation systems solely corpora test sets demonstrate translation adapted multiple monolingual inputs also examine different approaches dealing multiple sources including consensus decoding present novel method input combination generate lattices translation within single translation model word lattices multi-source translation word lattices multi-source translation word lattices multi-source translation 
present first provably optimal polynomial time dynamic programming dp algorithm parsing applies dp idea huang sagae parser sagae lavie way reducing complexity latter exponential polynomial prove correctness algorithm rigorously experiments confirm dp leads significant speedup probablistic parser makes exact search model tractable first time optimal incremental parsing via best-first dynamic programming optimal incremental parsing via best-first dynamic programming optimal incremental parsing via best-first dynamic programming 
using multilingual central repository graph-based word sense disambiguation using multilingual central repository graph-based word sense disambiguation using multilingual central repository graph-based word sense disambiguation 
mira based tuning methods widely used statistical machine translation smt system large number features since bleu decomposable mira approaches usually define variety sentencelevel bleus model losses instead present new mira method employs exact bleu compute model loss method simpler implementation experiments translation show effectiveness two mira implementations corpus level mira tuning strategy machine translation corpus level mira tuning strategy machine translation corpus level mira tuning strategy machine translation 
ontology-based xquerying xml-encoded language resources multiple annotation layers ontology-based xquerying xml-encoded language resources multiple annotation layers ontology-based xquerying xml-encoded language resources multiple annotation layers 
introduce new highly scalable approach computing distributional thesauri dts employing pruning techniques distributed framework make computation large corpora feasible comparably small computational resources demonstrate releasing dt whole vocabulary google books syntactic evaluating lexical resources using two measures show approach produces higher quality dts previous approaches thus preferable terms speed quality large corpora scaling large3 data: efficient effective method compute distributional thesauri scaling large3 data: efficient effective method compute distributional thesauri scaling large3 data: efficient effective method compute distributional thesauri 
extensive experiments validated effectiveness method classifying word sentiment polarity however work done comparing different corpora polarity classification task nowadays twitter aggregated huge amount data full people sentiments paper empirically evaluate performance different corpora sentiment similarity measurement fundamental task word polarity classification experiment results show twitter data achieve much better performance google web wikipedia based methods twitter better corpus measuring sentiment similarity? twitter better corpus measuring sentiment similarity? twitter better corpus measuring sentiment similarity? 
article present method combining different information retrieval models order increase retrieval performance speech information retrieval task formulas combining models tuned training data system evaluated test data task particularly difficult text collection automatically transcribed spontaneous speech many recognition errors also topics real information needs difficult satisfy information retrieval systems able obtain good results data set except case manual summaries included towards vector space model framenet-like resources towards vector space model framenet-like resources towards vector space model framenet-like resources 
paper propose method inferring emotion speaker conversing dialog system semantic content utterance first fully automatically obtain huge collection event instances web japanese chosen target language million emotion provoking event instances extracted using emotion lexicon lexical patterns decompose emotion classification task two sentiment polarity classification coarsegrained emotion classification emotion classification emotion classification subtask collection event instances used labelled examples train classifier results experiments indicate method significantly outperforms baseline method also find compared singlestep model applies emotion classifier directly inputs model significantly reduces sentiment polarity errors considered fatal errors real dialog applications emotion classification using massive examples extracted web emotion classification using massive examples extracted web emotion classification using massive examples extracted web 
lr decoding watanabe et al promising decoding algorithm hierarchical translation hiero generates target sentence extending hypotheses right edge lr decoding complexity input words beam size compared cky algorithm requires single language model lm history target hypothesis rather two lm histories per hypothesis cky paper present augmented lr decoding algorithm builds original algorithm watanabe et al unlike algorithm using experiments multiple language pairs show two new results lr decoding algorithm provides demonstrably efficient decoding cky hiero four times faster introducing new distortion reordering features lr decoding maintains translation quality bleu scores obtained cky hiero translation model efficient left-to-right hierarchical phrase-based translation improved reordering efficient left-to-right hierarchical phrase-based translation improved reordering efficient left-to-right hierarchical phrase-based translation improved reordering 
paper addresses problem producing diverse set plausible translations present simple procedure used statistical machine translation mt system explore three ways using diverse translations system combination discriminative reranking rich features novel scenario multiple translations presented users find diversity improve performance tasks especially sentences difficult mt systematic exploration diversity machine translation systematic exploration diversity machine translation systematic exploration diversity machine translation 
discriminative training triumphed many nlp problems definite success machine translation largely elusive recent efforts along line scalable training small dev set features top frequent words overly complicated instead present simple yet theoretically motivated approach extending recent framework perceptron using forced decoding compute target derivations extensive translation experiments tasks show substantial gains bleu dev test mert thanks sparse features first successful effort online discriminative training mt max-violation perceptron forced decoding scalable mt training max-violation perceptron forced decoding scalable mt training max-violation perceptron forced decoding scalable mt training 
applying machine translation mt literary texts involves domain shift challenges arise sublanguage medical scientific however also introduces additional challenges one focus discussion translation theory humanities human translator role staying faithful original text versus adapting make familiar readers contrast domains one objective literary translation preserve experience reading text moving target language use existing mt systems translate samples french literature english use qualitative analysis grounded translation theory real example outputs order address makes literary translation particularly hard potential role machine (un)faithful machine translator (un)faithful machine translator (un)faithful machine translator 
parallel multi-theory annotations syntactic structure parallel multi-theory annotations syntactic structure parallel multi-theory annotations syntactic structure 
current dependency parsing models conventional features base features defined surface words tags relatively feature space may suffer data sparseness problem thus exhibit less discriminative power unseen data paper propose novel approach addressing problem transforming base features features meta features help large amount automatically parsed data meta features used together base features final parser studies indicate proposed approach effective processing unseen data features experiments chinese english data sets show final parser achieves accuracy chinese data comparable accuracy best known parsers english data semi-supervised feature transformation dependency parsing semi-supervised feature transformation dependency parsing semi-supervised feature transformation dependency parsing 
named entity recognition digitised historical texts named entity recognition digitised historical texts named entity recognition digitised historical texts 
paper presents novel word reordering model employs parser inversion transduction grammars model uses rich syntax parsing features word reordering runs linear time apply postordering machine translation pbmt patent tasks experimental results show method achieves significant improvement bleu scores bleu scores baseline pbmt system shift-reduce word reordering machine translation shift-reduce word reordering machine translation shift-reduce word reordering machine translation 
explore application neural language models machine translation develop new model combines neural probabilistic language model bengio et al rectified linear units estimation incorporate machine translation system reranking lists direct integration decoder experiments across four language pairs show neural language model improves translation quality bleu decoding large-scale neural language models improves translation decoding large-scale neural language models improves translation decoding large-scale neural language models improves translation 
paper present novel approach automatic creation anchor texts hyperlinks document pointing similar documents methods used approach rank parts document based similarity presumably related document ranks used automatically construct best anchor text link inside original document compared document number different methods information retrieval natural language processing adapted task automatically constructed anchor texts manually evaluated terms relatedness linked documents compared baseline consisting originally inserted anchor texts additionally use crowdsourcing evaluation original anchors automatically constructed anchors results show best adapted methods rival precision baseline method application localized similarity web documents application localized similarity web documents application localized similarity web documents 
lmm: owl-dl metamodel represent heterogeneous lexical knowledge lmm: owl-dl metamodel represent heterogeneous lexical knowledge lmm: owl-dl metamodel represent heterogeneous lexical knowledge 
towards semi automatic construction lexical ontology persian towards semi automatic construction lexical ontology persian towards semi automatic construction lexical ontology persian 
automatic acquisition usage information language resources automatic acquisition usage information language resources automatic acquisition usage information language resources 
ibm translation models hugely influential statistical machine translation basis alignment models used modern translation systems excluding ibm model ibm translation models practically variants proposed literature relied optimization likelihood functions similar functions hence multiple local optima paper introduce convex relaxation ibm model describe optimization algorithm relaxation based subgradient method combined updates approach gives level alignment accuracy ibm model convex alternative ibm model 2 convex alternative ibm model 2 convex alternative ibm model 2 
pronunciation dictionaries provide readily available parallel corpus learning transduce character strings phoneme strings vice versa translation models used derive paraphrases either side transduction allowing automatic derivation alternative pronunciations spellings examine finitestate methods related tasks demonstrate tasks different characteristics finding alternative spellings harder alternative pronunciations benefits algorithms also show increase accuracy modeling syllable stress pair language models deriving alternative pronunciations spellings pronunciation dictionaries pair language models deriving alternative pronunciations spellings pronunciation dictionaries pair language models deriving alternative pronunciations spellings pronunciation dictionaries 
semantic word spaces useful cannot express meaning longer phrases principled way progress towards understanding compositionality tasks sentiment detection requires richer supervised training evaluation resources powerful models composition remedy introduce sentiment treebank includes fine grained sentiment labels phrases parse trees sentences presents new challenges sentiment compositionality address introduce recursive neural tensor network trained new treebank model outperforms previous methods several metrics pushes state art single sentence positive negative classification accuracy predicting sentiment labels phrases reaches improvement bag features baselines lastly model accurately capture effects negation scope various tree levels positive negative phrases recursive deep models semantic compositionality sentiment treebank recursive deep models semantic compositionality sentiment treebank recursive deep models semantic compositionality sentiment treebank 
automatic document quality control automatic document quality control automatic document quality control 
saw tree trees park: correct real-word spelling mistakes saw tree trees park: correct real-word spelling mistakes saw tree trees park: correct real-word spelling mistakes 
paper presents approach detecting promotional content wikipedia incorporating stylometric features including features based pcfg language models demonstrate improved accuracy identifying promotional articles compared using lexical information metafeatures detecting promotional content wikipedia detecting promotional content wikipedia detecting promotional content wikipedia 
constituency parsing rich grammars remains computational challenge graphics processing units gpus previously used accelerate cky chart evaluation gains cpu parsers modest paper describe collection new techniques enable chart evaluation close gpu practical maximum speed teraflop around rule evaluations per second net parser performance system thousand length sentences second trillion rules sec general sentences second berkeley parser grammar techniques introduce include grammar compilation recursive symbol blocking multi-teraflop constituency parser using gpus multi-teraflop constituency parser using gpus multi-teraflop constituency parser using gpus 
work argue measures shown quantify degree semantic plausibility phrases obtained distributional semantic representations resolve syntactic ambiguities exploit idea choose correct parsing nps live fish transporter rather live fish transporter show plausibility cues outperform strong baseline significantly improve performance used combination features fish transporters miracle homes: compositional distributional semantics help np parsing fish transporters miracle homes: compositional distributional semantics help np parsing fish transporters miracle homes: compositional distributional semantics help np parsing 
minimum error rate training mert remains one preferred methods tuning linear parameters machine translation systems yet faces significant issues first mert unregularized learner therefore prone overfitting second commonly used noisy loss function becomes difficult optimize number parameters increases address issues study addition regularization term mert objective function since standard regularizers inapplicable mert due scale invariance objective function turn two regularizers modification present methods efficiently integrating search improve search large parameter spaces also present new direction finding algorithm uses gradient expected bleu orient mert exact line searches experiments features show extensions mert yield results comparable pro learner often used large feature sets regularized minimum error rate training regularized minimum error rate training regularized minimum error rate training 
new functions framesql multilingual framenets new functions framesql multilingual framenets new functions framesql multilingual framenets 
division example sentences based meaning target word using semi-supervised clustering division example sentences based meaning target word using semi-supervised clustering division example sentences based meaning target word using semi-supervised clustering 
present number parsing experiments irish language carried using small seed set manually parsed trees larger yet still relatively small set unlabelled sentences take two popular dependency parsers one one compare results results show using semisupervised learning form yields modest improvements parsing accuracy also try use morphological information targeted way fail see improvements working small dataset - semi-supervised dependency parsing irish working small dataset - semi-supervised dependency parsing irish working small dataset - semi-supervised dependency parsing irish 
paper describes meteor submission emnlp workshop statistical machine translation automatic evaluation metric tasks new metric features include improved text normalization paraphrase matching discrimination content function words include ranking adequacy versions metric shown high correlation human judgments translation quality well balanced tuning version shown outperform bleu minimum error rate training system meteor 1.3: automatic metric reliable optimization evaluation machine translation systems meteor 1.3: automatic metric reliable optimization evaluation machine translation systems meteor 1.3: automatic metric reliable optimization evaluation machine translation systems 
evaluation natural language tools italian: evalita 2007 evaluation natural language tools italian: evalita 2007 evaluation natural language tools italian: evalita 2007 
paper reports first shared task statistical parsing morphologically rich languages mrls task features data sets nine languages available constituency dependency annotation report preparation data sets proposed parsing scenarios evaluation metrics parsing mrls given different representation types present analyze parsing results obtained task participants provide analysis comparison parsers across languages frameworks reported gold input well realistic parsing scenarios overview spmrl 2013 shared task: cross-framework evaluation parsing morphologically rich languages overview spmrl 2013 shared task: cross-framework evaluation parsing morphologically rich languages overview spmrl 2013 shared task: cross-framework evaluation parsing morphologically rich languages 
producing test collection patent machine translation seventh ntcir workshop producing test collection patent machine translation seventh ntcir workshop producing test collection patent machine translation seventh ntcir workshop 
bootstrapping recently become focus much attention natural language processing reduce labeling cost bootstrapping unlabeled instances harvested initial labeled seed set selected seed set affects accuracy select good seed set yet clear thus iterative seeding framework proposed bootstrapping reduce labeling cost framework iteratively selects unlabeled instance best goodness seed labels unlabeled instance seed set framework deepens understanding seeding process bootstrapping deriving dual problem propose method called expected model rotation emr works well data frequently occur realistic data experimental results show emr select seed sets provide significantly higher mean reciprocal rank realistic data existing naive selection methods random seed sets understanding seed selection bootstrapping understanding seed selection bootstrapping understanding seed selection bootstrapping 
cross-corpus evaluation word alignment cross-corpus evaluation word alignment cross-corpus evaluation word alignment 
describe tine new automatic evaluation metric machine translation aims assessing adequacy lexical similarity used indicators adequacy machine reference translations metric based combination lexical matching component adequacy component lexical matching performed comparing without linguistic annotation adequacy component consists using ontologies align predicates verbs ii using semantic roles align predicate arguments core arguments modifiers iii matching predicate arguments using distributional semantics tine performance comparable previous metrics segment level several language pairs average kendall tau correlation show addition component improves performance simple lexical matching strategies metrics bleu tine: metric assess mt adequacy tine: metric assess mt adequacy tine: metric assess mt adequacy 
linguistic resources evaluation techniques evaluation cross-document automatic content extraction linguistic resources evaluation techniques evaluation cross-document automatic content extraction linguistic resources evaluation techniques evaluation cross-document automatic content extraction 
lets argue semantics lets argue semantics lets argue semantics 
evaluate quality generated text? evaluate quality generated text? evaluate quality generated text? 
sentiment analysis use extrinsic datasets evaluation sentiment analysis use extrinsic datasets evaluation sentiment analysis use extrinsic datasets evaluation 
article present method combining different information retrieval models order increase retrieval performance speech information retrieval task formulas combining models tuned training data system evaluated test data task particularly difficult text collection automatically transcribed spontaneous speech many recognition errors also topics real information needs difficult satisfy information retrieval systems able obtain good results data set except case manual summaries included performance evaluation speech translation systems performance evaluation speech translation systems performance evaluation speech translation systems 
ontology-based interface specifications nlp pipeline architecture ontology-based interface specifications nlp pipeline architecture ontology-based interface specifications nlp pipeline architecture 
clios: cross-lingual induction speech recognition grammars clios: cross-lingual induction speech recognition grammars clios: cross-lingual induction speech recognition grammars 
cross-domain dialogue act tagging cross-domain dialogue act tagging cross-domain dialogue act tagging 
linguistic resources reconstructing spontaneous speech text linguistic resources reconstructing spontaneous speech text linguistic resources reconstructing spontaneous speech text 
word-based morpheme-based? annotation strategies modern hebrew clitics word-based morpheme-based? annotation strategies modern hebrew clitics word-based morpheme-based? annotation strategies modern hebrew clitics 
generating morphological lexicon organization entity names generating morphological lexicon organization entity names generating morphological lexicon organization entity names 
designing evaluating russian tagset designing evaluating russian tagset designing evaluating russian tagset 
using reordering statistical machine translation based alignment block classification using reordering statistical machine translation based alignment block classification using reordering statistical machine translation based alignment block classification 
statistical machine translation systems normally optimised chosen gain function metric using mert find best model weights algorithm suffers stability problems cannot scale beyond features present alternative algorithm discriminative training phrasebasedmt systems samplerank scales hundreds features equals beats mert small medium sized systems permits use sentence document level features samplerank proceeds repeatedly updating model weights ensure ranking output sentences induced model induced gain function samplerank training phrase-based machine translation samplerank training phrase-based machine translation samplerank training phrase-based machine translation 
enriching germanet verb-noun relations - case study lexical acquisition enriching germanet verb-noun relations - case study lexical acquisition enriching germanet verb-noun relations - case study lexical acquisition 
article present method combining different information retrieval models order increase retrieval performance speech information retrieval task formulas combining models tuned training data system evaluated test data task particularly difficult text collection automatically transcribed spontaneous speech many recognition errors also topics real information needs difficult satisfy information retrieval systems able obtain good results data set except case manual summaries included semantic role labeling tools trained cast3lb-connl-semrol corpus semantic role labeling tools trained cast3lb-connl-semrol corpus semantic role labeling tools trained cast3lb-connl-semrol corpus 
sentiment analysis based probabilistic models using inter-sentence information sentiment analysis based probabilistic models using inter-sentence information sentiment analysis based probabilistic models using inter-sentence information 
present translation model enriched shallow syntactic semantic information source language labels semantic role labels incorporated hierarchical model creating shallow semantic trees results show increase performance bleu scores translation standard smt baseline shallow semantic trees smt shallow semantic trees smt shallow semantic trees smt 
present propbank semantic role labeling system english integrated dependency parser tackle problem joint syntactic semantic analysis system relies syntactic semantic subcomponent syntactic model projective parser using transformations semantic model uses global inference mechanisms top pipeline classifiers complete syntactic semantic output selected candidate pool generated subsystems evaluate system conll test sets using metrics using metric system achieves near figure wsj brown test set punctuation treated consistently using metric figure system test set system first semantic role labeler propbank rivals systems terms performance dependency-based semantic role labeling propbank dependency-based semantic role labeling propbank dependency-based semantic role labeling propbank 
paper presents new hypothesis alignment method combining outputs multiple machine translation mt systems indirect hidden markov model ihmm proposed address synonym matching word ordering issues hypothesis alignment unlike traditional hmms whose parameters trained via maximum likelihood estimation mle parameters ihmm estimated indirectly variety sources including word semantic similarity word surface similarity distortion penalty method significantly outperforms alignment model experiments nist benchmark datasets combined smt system using proposed method achieved best translation result constrained training track nist open mt evaluation indirect-hmm-based hypothesis alignment combining outputs machine translation systems indirect-hmm-based hypothesis alignment combining outputs machine translation systems indirect-hmm-based hypothesis alignment combining outputs machine translation systems 
intersection tree translation models language models results huge dynamic programs machine translation decoding propose multipass approach language model complexity incrementally introduced contrast previous orderbased approaches focus methods use clustered encoding target language across various encoding schemes multiple language pairs show times decoding improving bleu score moreover entire decoding cascade trigram language models faster corresponding bigram pass alone decoder coarse-to-fine syntactic machine translation using language projections coarse-to-fine syntactic machine translation using language projections coarse-to-fine syntactic machine translation using language projections 
paper present novel method based crfs response two special characteristics contextual dependency label redundancy sentence sentiment classification try capture contextual constraints sentence sentiment using crfs introducing redundant labels original sentimental label set organizing labels hierarchy method add redundant features training capturing label redundancy experimental results prove method outperforms traditional methods like nb svm maxent standard chain crfs comparison cascaded model method effectively alleviate error propagation among different layers obtain better performance layer adding redundant features crfs-based sentence sentiment classification adding redundant features crfs-based sentence sentiment classification adding redundant features crfs-based sentence sentiment classification 
explore stacked framework learning predict dependency structures natural language sentences typical approach dependency parsing assume factorized model local features used global function optimized mcdonald et al recently nivre mcdonald used output one dependency parser provide features another show example stacked learning second predictor trained improve performance first argue technique novel way approximating rich features second parser without sacrificing efficient prediction experiments twelve languages show stacking graphbased parsers improves performance existing dependency parsers stacking dependency parsers stacking dependency parsers stacking dependency parsers 
translation rule extraction fundamental problem machine translation especially linguistically systems need parse trees either sides bitext current dominant practice uses trees adversely affects rule set quality due parsing errors propose novel approach extracts rules packed forest compactly encodes exponentially many parses experiments show method improves translation quality bleu point system points better twice fast extracting best parses combined previous work decoding achieves bleu points improvement baseline even outperforms hierarchical system hiero points forest-based translation rule extraction forest-based translation rule extraction forest-based translation rule extraction 
named entity recognition ner task garnering significant attention nlp helps improve performance many natural language processing applications paper investigate impact using different sets features two discriminative machine learning frameworks namely support vector machines conditional random fields using arabic data explore lexical contextual morphological features eight standardized different genres measure impact different features isolation rank according impact named entity class incrementally combine order infer optimal machine learning approach feature set system yields performance ace broadcast news data arabic named entity recognition using optimized feature sets arabic named entity recognition using optimized feature sets arabic named entity recognition using optimized feature sets 
lexical gaps queries questions documents major issue question retrieval large online question answer collections previous studies address issue implicitly expanding queries help translation models using statistical techniques however since possible unimportant words words common words included translation models lack noise control models cause degradation retrieval performance paper investigates number empirical methods eliminating unimportant words order construct compact translation models retrieval purposes experiments conducted real world collection show substantial improvements retrieval performance achieved using compact translation models bridging lexical gaps queries questions large online q&a collections compact translation models bridging lexical gaps queries questions large online q&a collections compact translation models bridging lexical gaps queries questions large online q&a collections compact translation models 
attempts integrate framenet nlp systems far failed limited coverage paper investigate applicability distributional wordnetbased models task lexical unit induction expansion framenet new lexical units experimental results show distributional models achieve good level accuracy coverage especially combined automatic induction framenet lexical units automatic induction framenet lexical units automatic induction framenet lexical units 
paper first introduce new architecture parsing bidirectional incremental parsing propose novel algorithm incremental construction applied many structure learning problems nlp apply algorithm ltag dependency parsing achieve significant improvement accuracy previous best result data set ltag dependency parsing bidirectional incremental construction ltag dependency parsing bidirectional incremental construction ltag dependency parsing bidirectional incremental construction 
examine problem content selection statistical novel sentence generation approach models processes performed professional editors incorporating material additional sentences support initially chosen key summary sentence process refer sentence augmentation propose evaluate method called seed grow selecting auxiliary information additionally argue performed using schemata represented demonstrate use statistical summary sentence generation evaluation results supportive indicating schemata model significantly improves baseline seed grow: augmenting statistically generated summary sentences using schematic word patterns seed grow: augmenting statistically generated summary sentences using schematic word patterns seed grow: augmenting statistically generated summary sentences using schematic word patterns 
approaches dependency parsing adopt different views problem view strengths limitations study approaches framework beamsearch developing dependency parser show decoder competitive choice methods importantly propose parser combines transitionbased parsing single system training decoding showing outperforms pure pure parsers testing english chinese penn treebank data combined system gave accuracies respectively tale two parsers: investigating combining graph-based transition-based dependency parsing tale two parsers: investigating combining graph-based transition-based dependency parsing tale two parsers: investigating combining graph-based transition-based dependency parsing 
present label propagation algorithm acquiring opendomain labeled classes instances combination unstructured structured text sources acquisition method significantly improves coverage compared previous set labeled classes instances derived free text achieving comparable precision weakly-supervised acquisition labeled class instances using graph random walks weakly-supervised acquisition labeled class instances using graph random walks weakly-supervised acquisition labeled class instances using graph random walks 
present minimum mbr decoding translation lattices compactly encode huge number translation hypotheses describe conditions loss function enable efficient implementation mbr decoders lattices introduce approximation bleu score papineni et al satisfies conditions mbr decoding approximate bleu realized using weighted finite state automata experiments show lattice mbr decoder yields moderate consistent gains translation performance mbr decoding translation tasks conduct range experiments understand lattice mbr improves upon mbr study impact various parameters mbr performance lattice minimum bayes-risk decoding statistical machine translation lattice minimum bayes-risk decoding statistical machine translation lattice minimum bayes-risk decoding statistical machine translation 
conditional phrase translation probabilities constitute principal components machine translation systems probabilities estimated using heuristic method seem optimize reasonable objective function parallel training corpus earlier efforts devising better understood estimator either scale reasonably sized training data lead deteriorating performance paper explore new approach based three ingredients generative model prior latent segmentations derived inversion transduction grammar itg phrase table containing phrase pairs without length limit smoothing learning objective using novel version deleted estimation working others conclude latent segmentations lead overfitting deteriorating performance show three ingredients give performance equivalent heuristic method reasonably sized training data motivation major component statistical machine translation pbsmt zens et al koehn et al table conditional probabilities phrase translation pairs pervading method estimating probabilities simple heuristic based relative frequency phrase pair phrase pairs extracted corpus koehn et al heuristic estimator gives good empirical results seem optimize intuitively reasonable objective function wordaligned parallel corpus see denero et al mounting number efforts attacking problem last years denero et al marcu wong birch et al moore quirk zhang et al exhibits difficulty far none lead alternative method performs well heuristic reasonably sized data approx sentence pair given parallel corpus estimator phrasetables pbsmt involves two interacting decisions phrase pairs extract assign probabilities extracted pairs heuristic estimator employs phrase translation probabilities itg priors smoothing learning objective phrase translation probabilities itg priors smoothing learning objective phrase translation probabilities itg priors smoothing learning objective 
paper give description machine translation system developed dcu used participation evaluation campaign third workshop statistical machine translation acl describe modular design datadriven mt system particular focus components used participation also describe significant modules unused task participated europarl task following translation directions spanish english french english employed hybrid architecture translate also participated czech english news news commentary tasks represented previously untested language pair system report results provided development test sets matrex: dcu mt system wmt 2008 matrex: dcu mt system wmt 2008 matrex: dcu mt system wmt 2008 
determining polarity sentimentbearing expression requires simple approach particular words constituents within expression interact yield particular overall polarity paper view subsentential interactions light compositional semantics present novel learningbased approach incorporates structural inference motivated compositional semantics learning procedure experiments show simple heuristics based compositional semantics perform better methods incorporate compositional semantics accuracy vs method integrates compositional semantics learning performs better alternatives also find contentword negators widely employed previous work play important role determining polarity finally contrast conventional wisdom find classification accuracy uniformly decreases additional potentially disambiguating context considered learning compositional semantics structural inference subsentential sentiment analysis learning compositional semantics structural inference subsentential sentiment analysis learning compositional semantics structural inference subsentential sentiment analysis 
confusion networks simple representation multiple speech recognition translation hypotheses machine translation system typical operation confusion network find path minimizes maximizes certain evaluation metric article show problem generally popular bleu metric well smaller variants bleu also holds complex representations like generic word graphs addition give efficient algorithm calculate unigram bleu confusion networks show even small generalizations data structure render problem since finding optimal solution thus always feasible introduce approximating algorithm based decoder finds necessarily optimal solution bleu polynomial time complexity finding bleu-optimal hypothesis confusion network complexity finding bleu-optimal hypothesis confusion network complexity finding bleu-optimal hypothesis confusion network 
statistical machine translation systems currently deliver performance remain weak word order changes current phrase reordering models properly handle swaps adjacent phrases typically lack ability perform kind reorderings possible systems paper present novel hierarchical phrase reordering model aimed improving reorderings seamlessly integrates standard system little loss computational efficiency show model successfully handle key examples often used motivate systems rotation prepositional phrase around noun phrase contrast model reordering models commonly used systems show approach provides statistically significant bleu point gains two language pairs mt mt mt simple effective hierarchical phrase reordering model simple effective hierarchical phrase reordering model simple effective hierarchical phrase reordering model 
address task computing vector space representations meaning word occurrences vary widely according context task crucial step towards robust compositional account sentence meaning argue existing models task take syntactic structure sufficiently account present novel structured vector space model addresses issues incorporating selectional preferences words argument positions makes possible integrate syntax computation word meaning context addition model performs state art modeling contextual adequacy paraphrases structured vector space model word meaning context structured vector space model word meaning context structured vector space model word meaning context 
consider parsed text corpus instance labelled directed graph nodes represent words weighted directed edges represent syntactic relations show graph walks combined existing techniques supervised learning used derive word similarity measure graph also propose new graph walk method graph walk process guided knowledge meaningful edge sequences paths empirical evaluation task named entity coordinate term extraction shows framework preferable models smallsized corpora also shown pathconstrained graph walk algorithm yields performance scalability gains learning graph walk based similarity measures parsed text learning graph walk based similarity measures parsed text learning graph walk based similarity measures parsed text 
paper presents model acquisition lexical syntactic representations representations model learns graded propose new evaluation methodology syntactic acquisition framework exemplar theory applied childes corpus evaluation shows model graded syntactic representations perform better previously proposed categorical representations graph-theoretic model lexical syntactic acquisition graph-theoretic model lexical syntactic acquisition graph-theoretic model lexical syntactic acquisition 
proceedings conference empirical methods natural language processing pages honolulu october association computational linguistics computing antonymy saif mohammad bonnie dorr computing word-pair antonymy computing word-pair antonymy computing word-pair antonymy 
accuracy current word sense disambiguation wsd systems affected sense inventory wordnet well lack training examples using wsd examples provided ontonotes conduct first wsd evaluation involving hundreds word types tens thousands examples adopting sense inventory show though wsd systems trained large number examples obtain high level accuracy nevertheless suffer substantial drop accuracy applied different domain address issue propose combining domain adaptation technique using feature augmentation active learning results show approach effective reducing annotation effort required adapt wsd system new domain finally propose one maximize dual benefits reducing annotation effort ensuring increase wsd accuracy performing active learning set frequently occurring word types word sense disambiguation using ontonotes: empirical study word sense disambiguation using ontonotes: empirical study word sense disambiguation using ontonotes: empirical study 
traditional text categorization usually task subtle demand information retrieval distinguish positive negative view text topic paper new method explored solve problem firstly batch concerned concepts researched domain predefined secondly special knowledge representing positive negative context concepts within sentences built last evaluating function based knowledge defined sentiment classification free text introduce linguistic knowledge procedures make method effective result new method proves better compared svm experimenting chinese texts certain topic new method sentiment classification text retrieval new method sentiment classification text retrieval new method sentiment classification text retrieval 
partial parsing techniques try recover syntactic information efficiently reliably sacrificing completeness depth analysis one difficulties partial parsing finding means extract grammar involved automatically paper present method automatically extracting partial parsing rules corpus using decision tree induction define partial parsing rules decide structure substring input sentence deterministically decision considered classification substring input sentence proper structure chosen among structures occurred corpus classification use decision tree induction induce partial parsing rules decision tree acquired grammar similar phrase structure grammar contextual lexical information allows building structures depth one experiments showed proposed partial parser using automatically extracted rules accurate efficient also achieves reasonable coverage korean automatic partial parsing rule acquisition using decision tree induction automatic partial parsing rule acquisition using decision tree induction automatic partial parsing rule acquisition using decision tree induction 
propose novel type document classification task quantifies much given document review appreciates target object using binary polarity good bad continuous measure called sentiment polarity score gives concise summary review provides information binary classification difficulty task lies quantification polarity paper use support vector regression svr tackle problem experiments book reviews scales show svr outperforms classification method using support vector machines results close human performance assigning polarity scores reviews using machine learning techniques assigning polarity scores reviews using machine learning techniques assigning polarity scores reviews using machine learning techniques 
machine transliteration automatic method generate characters words one alphabetical system corresponding characters another alphabetical system increasing concern machine transliteration assistant machine translation information retrieval three machine transliteration models including model phonemebased model hybrid model proposed however works trying make use correspondence source grapheme phoneme although correspondence plays important role machine transliteration furthermore works dynamically handle source grapheme phoneme paper propose new transliteration model based ensemble grapheme phoneme model makes use correspondence dynamically uses source grapheme phoneme method shows better performance previous works transliteration transliteration ensemble grapheme phoneme machine transliteration ensemble grapheme phoneme machine transliteration ensemble grapheme phoneme machine transliteration 
paper proposes approach improve statistical word alignment ensemble methods two ensemble methods investigated bagging committees two methods weighted voting unweighted voting compared word alignment task addition analyze effect different sizes training sets bagging method experimental results indicate bagging committees improve word alignment results regardless weighted voting unweighted voting weighted voting performs consistently better unweighted voting different sizes training sets improving statistical word alignment ensemble methods improving statistical word alignment ensemble methods improving statistical word alignment ensemble methods 
paper present empirical study utilizes information improve translation quality three kinds language pairs matched according similarity difference investigate effects various information base form relative positional information word statistical machine translation framework learn translation models also language models manipulating morphological relative positional information integrate models model experiments multilingual translations showed morphological information base form effective improving performance morphologically rich language pairs relative positional features word group useful reordering local word orders moreover use language model improves performance alleviating data sparseness problem language model empirical study utilizing morph-syntactic information smt empirical study utilizing morph-syntactic information smt empirical study utilizing morph-syntactic information smt 
paper proposes chunking strategy detect unknown words chinese word segmentation first raw sentence sequence word atoms using maximum matching algorithm chunking model applied detect unknown words chunking one word atoms together according word formation patterns word atoms paper discriminative markov model named mutual information independence model miim adopted chunking besides maximum entropy model applied integrate various types contexts resolve data sparseness problem miim moreover learning approach proposed learn useful contexts maximum entropy model way number contexts maximum entropy model significantly reduced without performance decrease makes possible improving performance considering various types contexts evaluation pk ctb corpora first sighan chinese word segmentation bakeoff shows chunking approach successfully detects unknown words corpora outperforms systems unknown word detection respectively chunking strategy towards unknown word detection chinese word segmentation chunking strategy towards unknown word detection chinese word segmentation chunking strategy towards unknown word detection chinese word segmentation 
recognition expressions mwes relative compositionality crucial natural language processing various statistical techniques proposed recognize mwes paper integrate existing statistical features investigate range classifiers suitability recognizing collocations task ranking collocations based relative compositionality show correlation ranks computed classifier human ranking significantly better correlation ranking individual features human ranking also show properties distributed frequency object defined nearest mutual information adapted contribute greatly recognition mwes type ranking collocations based relative compositionality relative compositionality multi-word expressions: study verb-noun (v-n) collocations relative compositionality multi-word expressions: study verb-noun (v-n) collocations relative compositionality multi-word expressions: study verb-noun (v-n) collocations 
merit statistical machine translation often reduced complexity construct paper address issues statistical machine translation namely size phrase translation table use underlying translation model probability length phrase unit present lod approach agglomerative approach learning alignment experiments show lod approach significantly improves performance approach lod demonstrates clear advantage phrase translation table grows maximum phrase length performance comparable approaches phrase-based statistical machine translation: level detail approach phrase-based statistical machine translation: level detail approach phrase-based statistical machine translation: level detail approach 
ordering information difficult important task natural language generation applications wrong order information makes difficult understand also conveys entirely different idea reader paper proposes algorithm learns orderings set human ordered texts model consists set ordering experts expert gives precedence preference two sentences combine preferences order sentences also propose two new metrics evaluation sentence orderings experimental results show proposed algorithm outperforms existing methods evaluation metrics machine learning approach sentence ordering multidocument summarization evaluation machine learning approach sentence ordering multidocument summarization evaluation machine learning approach sentence ordering multidocument summarization evaluation 
propose method labelling prepositional phrases according two different semantic role classifications contained penn treebank conll semantic role labelling data set results illustrate difficulties determining preposition semantics also demonstrate potential pp semantic role labelling improve performance holistic semantic role labelling system semantic role labelling prepositional phrases semantic role labelling prepositional phrases semantic role labelling prepositional phrases 
paper describes novel method word sense disambiguation utilizes relatives synonyms hypernyms meronyms etc wordnet target word raw corpora method disambiguates senses target word selecting relative probably occurs new sentence including target word one cooccurrence frequency matrix utilized efficiently disambiguate senses many target words experiments several english datum present proposed method achieves good performance word sense disambiguation relative selection word sense disambiguation relative selection word sense disambiguation relative selection 
paper shows wsd system using rich linguistic features achieved high accuracy classification english senseval verbs senses describe three specific enhancements treatment rich linguistic features present separate combined contributions system performance experiments showed system robust performance test data without high quality rich features towards robust high performance word sense disambiguation english verbs using rich linguistic features towards robust high performance word sense disambiguation english verbs using rich linguistic features towards robust high performance word sense disambiguation english verbs using rich linguistic features 
paper studies issues compiling bilingual lexicon technical terms task estimating bilingual term correspondences technical terms usually quite difficult find existing corpus domain technical terms paper take approach collecting corpus domain technical terms web method translation estimation technical terms propose compositional translation estimation technique experimental evaluation show domain topic specific corpus contributes improving performance compositional translation estimation effect domain-specific corpus compositional translation estimation technical terms effect domain-specific corpus compositional translation estimation technical terms effect domain-specific corpus compositional translation estimation technical terms 
paper present hybridtrim system uses machine learning technique combine linguistic statistical positional information identify topic labels headlines text compare system topiary system contrast uses statistical learning approach finding topic descriptors headlines topiary system developed university maryland bbn top performing headline generation system duc headlines consist number general topic labels followed compressed version lead sentence news story topiary system uses statistical learning approach finding topic labels performance systems evaluated using rouge evaluation suite duc news stories collection machine learning approach augmenting news headline generation machine learning approach augmenting news headline generation machine learning approach augmenting news headline generation 
chinese language verb may dependents left right sides ambiguity resolution dependencies essential dependency parsing sentences two verbs previous works shiftreduce dependency parsers may guarantee connectivity dependency tree due weakness resolving dependencies paper proposes dependency parser based svm learning leftside dependents nominal dependents detected phase rightside verbal dependents decided phase ii experimental evaluation proposed method outperforms previous dependency parsers chine language showing improvement dependency accuracy two-phase shift-reduce deterministic dependency parser chinese two-phase shift-reduce deterministic dependency parser chinese two-phase shift-reduce deterministic dependency parser chinese 
many named entities contain named entities inside despite fact field named entity recognition almost entirely ignored nested named entity recognition due technological rather ideological reasons paper present new technique recognizing nested named entities using discriminative constituency parser train model transform sentence tree constituents named entity syntactic structure present results newspaper biomedical corpora contain nested named entities three four sets experiments model outperforms standard traditional entities time improve overall flat model unable recover nested entities nested named entity recognition nested named entity recognition nested named entity recognition 
current ner approaches include machine learning since consolidated nomenclature biomedical nes ner systems relying limited dictionaries rules perform satisfactorily paper apply maximum entropy construct ner framework represent shallow linguistic information linguistic features model genia corpus system achieves satisfactory protein overall without using dictionary system performs significantly better systems using partial match criteria system achieves using appropriate domain knowledge modify boundaries system potential achieve using maximum entropy extract biomedical named entities without dictionaries using maximum entropy extract biomedical named entities without dictionaries using maximum entropy extract biomedical named entities without dictionaries 
hierarchical hidden markov model hhmm based approach product named entity recognition ner chinese free text presented paper characteristics challenges product ner also investigated analyzed deliberately compared general ner within unified statistical framework approach proposed able make probabilistically reasonable decisions global optimization leveraging diverse range linguistic features knowledge sources experimental results show approach performs quite well two different domains product named entity recognition based hierarchical hidden markov model product named entity recognition based hierarchical hidden markov model product named entity recognition based hierarchical hidden markov model 
paper describes hybrid chinese word segmenter developed part larger chinese unknown word resolution system segmenter consists two components tagging component uses learning algorithm tag character position word merging component transforms tagged character sequence sentence addition tags assigned characters merging component makes use number heuristics handle characters numeric type compounds long words segmenter achieved recall oov words closed track peking university corpus second international chinese word segmentation bakeoff towards hybrid model chinese word segmentation towards hybrid model chinese word segmentation towards hybrid model chinese word segmentation 
chinese word segmentation fundamental important issue chinese information processing order find unified approach chinese word segmentation author develop chinese lexical analyzer pcws using direct maximum entropy model paper presents general description pcws well result analysis performance second international chinese word segmentation bakeoff chinese word segmentation based direct maximum entropy model chinese word segmentation based direct maximum entropy model chinese word segmentation based direct maximum entropy model 
paper present chinese word segmentation system consisted four components basic segmentation named entity recognition learner new word detector basic segmentation named entity recognition implemented based conditional random fields used generate initial segmentation results two components used refine results system participated tests open closed tracks beijing university pku microsoft research msr actual evaluation results show system performs well msr open track msr closed track pku open track hybrid approach chinese word segmentation around crfs hybrid approach chinese word segmentation around crfs hybrid approach chinese word segmentation around crfs 
question answering system qa attached great attention capacity providing compact precise results xsers question classification essential part system affecting accuracy paper studies question classification machine learning approaches namely different classifiers multiple classifier combination method using compositive statistic rule classifiers introducing dependency structure minipar linguistic knowledge wordnet question representation research shows high accuracy question classification question classification using multiple classifiers question classification using multiple classifiers question classification using multiple classifiers 
propose method automatically generates paraphrase sets seed sentences used reference sets objective machine translation evaluation measures like bleu nist measured quality paraphrases produced experiment grammaticality least correct sentences ii equivalence meaning least correct paraphrases either meaning equivalence entailment iii amount internal lexical syntactical variation set paraphrases slightly superior sets paraphrase sets produced method thus seem adequate reference sets used mt evaluation automatic generation paraphrases used translation references objective evaluation measures machine translation automatic generation paraphrases used translation references objective evaluation measures machine translation automatic generation paraphrases used translation references objective evaluation measures machine translation 
automatic acquisition lexico-semantic knowledge qa automatic acquisition lexico-semantic knowledge qa automatic acquisition lexico-semantic knowledge qa 
paper proposes convolution tree kernel pronoun resolution resolves two critical problems previous researches two ways first given parse tree pair anaphor antecedent candidate implements scheme automatically determine proper tree span pronoun resolution taking antecedent information consideration second applies convolution tree kernel enumerates considering ancestor node paths contexts evaluation ace corpus shows tree span scheme well cover necessary structured information parse tree pronoun resolution tree kernel much outperforms previous tree kernels context-sensitive convolution tree kernel pronoun resolution context-sensitive convolution tree kernel pronoun resolution context-sensitive convolution tree kernel pronoun resolution 
name origin recognition identify source language personal location name early work used either rulebased statistical methods single knowledge source paper cast name origin recognition classification problem approach problem using maximum entropy method investigate use different features including phonetic rules ngram statistics character position information name origin recognition experiments publicly available personal name database show proposed approach achieves overall accuracy names written english names written chinese significantly consistently better reported work name origin recognition using maximum entropy model diverse features name origin recognition using maximum entropy model diverse features name origin recognition using maximum entropy model diverse features 
paper explore benefits shortcomings noun phrase rewriting summarization news approach leads different content summary comparison extractive summary produced using underlying approach showing promise technique offer addition summaries produced using rewrite higher linguistic quality comparison system improvement also seen content selection extractive summarization measured pyramid method evaluation entity-driven rewrite multi-document summarization entity-driven rewrite multi-document summarization entity-driven rewrite multi-document summarization 
propose general approach translating chinese unknown words unk smt approach takes advantage properties chinese word composition rules chinese words formed sequential characters according proposed approach unknown word subword sequence followed subword translation subwordbased translation model subword unit character long word found proposed approach significantly improved translation quality test data nist mt mt also found translation quality improved applied named entity translation translate parts unknown words using translation chinese unknown word translation subword re-segmentation chinese unknown word translation subword re-segmentation chinese unknown word translation subword re-segmentation 
current chinese word alignment tasks often adopt word segmentation systems firstly identify words however problems exist languages degrade performance word alignment paper propose two unsupervised methods adjust word segmentation make tokens mapping many possible corresponding sentences first method learning affix rules bilingual terminology bank second method using concept impurity measure motivated decision tree experiments showed adjusting methods improve performance word alignment significantly improving word alignment adjusting chinese word segmentation improving word alignment adjusting chinese word segmentation improving word alignment adjusting chinese word segmentation 
propose machine learning based method sentiment classification sentences using polarity polarities words sentence always sentence negation expressions proposed method models model trained two different ways learning learning model trained prediction sentence polarities accurate model also combined features used previous work empirically show method almost always improves performance sentiment classification sentences especially small amount training data learning shift polarity words sentiment classification learning shift polarity words sentiment classification learning shift polarity words sentiment classification 
address problem sentiment objectivity classification product reviews chinese approach distinctive treats positive negative sentiment subjectivity objectivity distinct classes rather continuum argue desirable perspective customers read reviews use novel unsupervised techniques including vocabulary iterative retraining sentiment processing criterion determining extent document opinionated classifier achieves sentiment polarity detection unsupervised classification sentiment objectivity chinese text unsupervised classification sentiment objectivity chinese text unsupervised classification sentiment objectivity chinese text 
propose method learning semantic categories words minimal supervision web search query logs method based espresso algorithm pantel pennacchiotti extracting binary lexical relations makes important modifications handle query log data task acquiring semantic categories present experimental results comparing method two minimally supervised lexical knowledge extraction systems using japanese query log data show method achieves higher precision previously proposed methods also show proposed method offers additional advantage knowledge acquisition asian language word segmentation issue method utilizes prior knowledge word segmentation able harvest new terms correct word segmentation minimally supervised learning semantic knowledge query logs minimally supervised learning semantic knowledge query logs minimally supervised learning semantic knowledge query logs 
paper address problem knowing stop process active learning propose new statistical learning approach called minimum expected error strategy defining stopping criterion estimation classifier expected error future unlabeled examples active learning process experiments active learning word sense disambiguation text classification tasks experimental results show new proposed stopping criterion reduce approximately human labeling costs word sense disambiguation degradation average accuracy approximately costs text classification degradation average accuracy learning stopping criterion active learning word sense disambiguation text classification learning stopping criterion active learning word sense disambiguation text classification learning stopping criterion active learning word sense disambiguation text classification 
objective prior knowledge rhetorical structure scientific abstracts useful various tasks information extraction information retrieval automatic summarization paper presents novel approach categorize sentences scientific abstracts four sections objective methods results conclusions method formalizing categorization task sequential labeling problem employ conditional random fields crfs annotate section labels abstract sentences training corpus acquired automatically medline abstracts results proposed method outperformed previous approaches achieving accuracy accuracy conclusion experimental results showed crfs could model rhetorical structure abstracts suitably identifying sections scientific abstracts using conditional random fields identifying sections scientific abstracts using conditional random fields identifying sections scientific abstracts using conditional random fields 
bracketing transduction grammar btg well studied used statistical machine translation smt promising results however two major issues smt first effective mechanism available predicting orders neighboring blocks original btg second computational cost high paper introduce two refinements smt achieve better reordering decoding include reordering heuristics prevent incorrect swapping reduce search space special phrases tags indicate sentence beginning ending two refinements integrated smt system trained largescale parallel data experimental results nist task show proposed refinements contribute significant improvement bleu score baseline system refinements btg-based statistical machine translation refinements btg-based statistical machine translation refinements btg-based statistical machine translation 
distributional similarity widely used concept capture semantic relatedness words various nlp tasks however accurate similarity calculation requires large number contexts leads impractically high computational complexity alleviate problem investigated effectiveness automatic context selection applying feature selection methods explored mainly text categorization experiments synonym acquisition shown keeping sometimes increasing performance drastically reduce unique contexts original size also extended measures cover context categories result shows considerable correlation measures performance enabling automatic selection effective context categories distributional similarity context feature selection distributional similarity context feature selection distributional similarity context feature selection distributional similarity 
recent years various approaches aimed automatic acquisition predominant senses words information exploited powerful backoff strategy word sense disambiguation given zipfian distribution word senses approaches require manually data proposed english exploiting lexical resources available notably wordnet approaches distributional similarity coupled semantic similarity measure ties distributionally related words sense inventory semantic similarity measures used taken advantage hierarchical information wordnet investigate applicability japanese demonstrate feasibility measure uses information dictionary definitions contrast previous work english uses hierarchical information addition dictionary definitions extend definition based semantic similarity measure distributional similarity applied words different definitions increases recall method cases precision well gloss-based semantic similarity metrics predominant sense acquisition gloss-based semantic similarity metrics predominant sense acquisition gloss-based semantic similarity metrics predominant sense acquisition 
present online cascaded approach biomedical named entity recognition approach uses online training method substantially reduce training time required cascaded framework relax memory requirement conduct detailed experiments bionlp dataset jnlpba shared task compare results systems published works experimental results show approach achieves comparable performance great reductions time space requirements online cascaded approach biomedical named entity recognition online cascaded approach biomedical named entity recognition online cascaded approach biomedical named entity recognition 
transliterate foreign words japanese korean phonograms katakana hangul used chinese pronunciation source word spelled using kanji characters kanji ideogrammatic representation different kanji characters associated pronunciation potentially convey different meanings impressions select appropriate kanji characters existing method requests user provide one related terms source word expensive paper reduce human effort use world wide web extract related terms source words show effectiveness method experimentally effects related term extraction transliteration chinese effects related term extraction transliteration chinese effects related term extraction transliteration chinese 
target task matched parallel corpora required statistical translation model training however training corpora sometimes include target task matched unmatched sentences case training set selection reduce size translation model paper propose training set selection method translation model training using linear translation model interpolation language model technique according experimental results proposed method reduces translation model size improves bleu score comparison baseline training corpus usage method selecting training data build compact efficient translation model method selecting training data build compact efficient translation model method selecting training data build compact efficient translation model 
paper presents methods combine large language models trained diverse text sources applies french english arabic english machine translation system show gains bleu points strong baseline using continuous space language models large diverse language models statistical machine translation large diverse language models statistical machine translation large diverse language models statistical machine translation 
present approach text navigation conceived cognitive process exploiting linguistic information present texts claim navigational knowledge involved process modeled declarative way sextant language since sextant refers exhaustively specific linguistic phenomena defined customized text representation different components implemented text navigation system navitexte two applications navitexte described linguistic navigational knowledge approach text navigation linguistic navigational knowledge approach text navigation linguistic navigational knowledge approach text navigation 
accuracy parsing exceeded recently high enough use parsing results practically natural language processing nlp applications paraphrase acquisition relation extraction present method detecting reliable parses outputs single dependency parser technique also applied domain adaptation dependency parsing goal improve performance dependency parser data set domain adaptation track conll shared task formidable challenge learning reliability parses domain adaptation dependency parsing learning reliability parses domain adaptation dependency parsing learning reliability parses domain adaptation dependency parsing 
automatic summarization important task form human support technology propose paper new summarization method based approach using approach summarization task following three advantages high modularity absence necessity score importance word high applicability local context experimental results proven summarization system attains approximately accuracy human judgment summarization analogy: example-based approach news articles summarization analogy: example-based approach news articles summarization analogy: example-based approach news articles 
present experiments analyze necessity using highly interconnected word sense graph unsupervised allwords word sense disambiguation show allowing grammatically related words influence senses leads disambiguation results par best systems greatly reducing computation load also compare two methods computing selectional preferences senses every two grammatically related words one using measure wordnet using dependency relations british national corpus best configuration uses graph selectional preferences computed corpus pagerank algorithm especially note good performance disambiguating verbs grammatically constrained links unsupervised all-words word sense disambiguation grammatical dependencies unsupervised all-words word sense disambiguation grammatical dependencies unsupervised all-words word sense disambiguation grammatical dependencies 
paper shows discriminative reranking averaged perceptron model yields substantial improvements realization quality ccg paper confirms utility including language model log probabilities features model prior work discriminative training log linear models hpsg realization called question perceptron model allows combination multiple models optimized augmented syntactic features discriminative features full model yields bleu score section ccgbank knowledge best score reported date using reversible grammar perceptron reranking ccg realization perceptron reranking ccg realization perceptron reranking ccg realization 
semantic role labeling srl shallow semantic parsing causes attention recently shortage manually tagged data one main obstacles supervised learning even serious srl transductive svm tsvm novel learning method special small mount tagged data paper introduce application tsvm chinese srl improve performance tsvm heuristics designed semantic perspective experiment results chinese propbank showed tsvm outperforms svm small tagged data using heuristics performs better semantic role labeling chinese using transductive svm semantic heuristics semantic role labeling chinese using transductive svm semantic heuristics semantic role labeling chinese using transductive svm semantic heuristics 
paper exploits unlabeled text data improve new word identification chinese word segmentation performance contributions twofold first new words lack semantic transparency person location transliteration names calculate association metrics adjacent character segments unlabeled data encode information features second construct internal dictionary using initial model extract words unlabeled training test set maintain balanced coverage training test set comparison baseline model uses features approach increases new word recall additionally approaches reduce segmentation errors system achieves performance closed open tasks sighan bakeoff exploiting unlabeled text extract new words different semantic transparency chinese word segmentation exploiting unlabeled text extract new words different semantic transparency chinese word segmentation exploiting unlabeled text extract new words different semantic transparency chinese word segmentation 
report experience applying techniques natural language processing algorithmically generating test items reading listening cloze items propose word sense disambiguationbased method locating sentences designated words carry specific senses apply method selecting distractors necessary cloze items experimental results indicate system able produce usable item every items returned also attempt measure distance sounds words considering phonetic features words help voice synthesizers able assist task composing listening cloze items providing reading listening cloze items would like offer somewhat adaptive system assisting taiwanese children learning english vocabulary applications lexical information algorithmically composing multiple-choice cloze items applications lexical information algorithmically composing multiple-choice cloze items applications lexical information algorithmically composing multiple-choice cloze items 
paper evaluates series freely available parsers standard benchmark well respect set data relevant measuring text cohesion outline advantages disadvantages existing technologies make recommendations performance report uses traditional measures based gold standard well novel dimensions parsing evaluation knowledge first attempt evaluate parsers accross genres grade levels implementation learning technology evaluating state-of-the-art treebank-style parsers coh-metrix learning technology environments evaluating state-of-the-art treebank-style parsers coh-metrix learning technology environments evaluating state-of-the-art treebank-style parsers coh-metrix learning technology environments 
dependency parsing gained attention natural language understanding representation dependency tree simple compact direct robust partial understanding task portability achieved easily however many dependency parsers make hard decisions local information selecting among next parse states consequence though obtained dependency trees good sense output guaranteed globally optimal general paper stochastic dependency parsing scheme based admissible search formally presented well representing parse state appropriately designing cost heuristic functions dependency parsing modeled search problem solved generic algorithm state space search evaluated chinese tree bank parser obtain dependency accuracy sentence accuracy node ratio dynamic heuristic parser output dependency trees integrate semantic processing search process easily stochastic dependency parsing based a* admissible search stochastic dependency parsing based a* admissible search stochastic dependency parsing based a* admissible search 
paper describes chinese tagging system based maximum entropy model presents novel approach using tags words sides current word chinese tagging system evaluated four corpora fourth sighan bakeoff close track chinese tagging task two-stage approach chinese part-of-speech tagging two-stage approach chinese part-of-speech tagging two-stage approach chinese part-of-speech tagging 
paper presents chinese word segmentation system developed nokia research center nrc evaluated fourth international chinese language processing bakeoff first cips chinese language processing evaluation organized sighan system preprocessing module used discover words occur repeatedly text improved model used segmentation post processing strategies adopted system recognize organization names new words took part three tracks called open closed track corpora state language commission ncc closed track corpora shanxi university sxu system achieved good performance especially open track ncc system ranks st among systems nokia research center beijing chinese word segmentation system sighan bakeoff 2007 nokia research center beijing chinese word segmentation system sighan bakeoff 2007 nokia research center beijing chinese word segmentation system sighan bakeoff 2007 
present results feature engineering experiments conducted temporal expression recognition task former explores use different kinds tagging schemes exploiting list core temporal expressions training latter concerned use list postprocessing output system based conditional random fields find incorporation knowledge sources training postprocessing improves recall use extended tagging schemes may help offset mildly negative impact precision approaches addresses different aspect overall recognition performance taken separately impact overall performance low combining approaches achieve high precision high recall scores feature engineering post-processing temporal expression recognition using conditional random fields feature engineering post-processing temporal expression recognition using conditional random fields feature engineering post-processing temporal expression recognition using conditional random fields 
paper present machine learning system identifying types examined determine relevant linguistic patterns patterns incorporated features machine learning system performs binary classification referential corpus selection relevant generalized patterns leads significant improvement performance identifying non-referential it: machine learning approach incorporating linguistically motivated patterns identifying non-referential it: machine learning approach incorporating linguistically motivated patterns identifying non-referential it: machine learning approach incorporating linguistically motivated patterns 
recent natural language learning research shown structural kernels effectively used induce accurate models linguistic phenomena paper show properties hold novel task related predicate argument classification tree kernel selecting subtrees encodes argument structures applied experiments support vector machines large data sets propbank collection show kernel improves recognition argument boundaries engineering syntactic features shallow semantic parsing engineering syntactic features shallow semantic parsing engineering syntactic features shallow semantic parsing 
paper proposes use global features chinese word segmentation global features combined local features using averaged perceptron algorithm candidate word segmentations candidates produced using conditional random field crf tagger word segmentation experiments show adding global features performance significantly improved compared crf tagger performance also improved compared using local features system obtains cityu corpus ckip corpus sxu corpus ncc corpus ctb corpus results closed track fourth sighan chinese word segmentation bakeoff training perceptron global local features chinese word segmentation training perceptron global local features chinese word segmentation training perceptron global local features chinese word segmentation 
paper briefly describes system fourth sighan bakeoff discriminative models including maximum entropy model conditional random fields utilized chinese word segmentation named entity recognition different tag sets features learning model used tagging evaluation shows system achieves ncc word segmentation close open tests msra name entity recognition open test pku tagging close open tests results get medium performances bakeoff tracks study chinese lexical analysis based discriminative models study chinese lexical analysis based discriminative models study chinese lexical analysis based discriminative models 
paper presents systems submitted close track fourth sighan bakeoff built three systems based conditional random field chinese word segmentation named entity recognition tagging respectively systems employed basic features well large number linguistic features segmentation task adjusted bio tags according confidence character final system achieve ctb ncc sxu segmentation msra named entity recognition pku tagging crf-based hybrid model word segmentation, ner even pos tagging crf-based hybrid model word segmentation, ner even pos tagging crf-based hybrid model word segmentation, ner even pos tagging 
proceedings th conference computational natural language learning conll pages ann arbor june association computational linguistics new experiments distributional representations synonymy dayne freitag matthias blume john byrnes edmond chow sadik kapadia richard rohwer zhiqiang wang hnc software llc valley centre drive san diego ca usa new experiments distributional representations synonymy new experiments distributional representations synonymy new experiments distributional representations synonymy 
traditionally word sense disambiguation wsd involves different context classification model individual word paper presents weakly supervised learning approach wsd based learning word independent context pair classification model statistical models trained classifying word contexts classifying pair contexts determining pair contexts ambiguous word refers different senses using approach annotated corpus target word explored disambiguate senses different word hence limited amount existing annotated corpus required order disambiguate entire vocabulary research maximum entropy modeling used train word independent context pair classification model based context pair classification results clustering performed word mentions extracted large raw corpus resulting context clusters mapped onto external thesaurus wordnet approach shows great flexibility efficiently integrate heterogeneous knowledge sources trigger words parsing structures based lexical sample standards approach achieves performance unsupervised learning category performs comparably supervised na ve bayes system word independent context pair classification model word sense disambiguation word independent context pair classification model word sense disambiguation word independent context pair classification model word sense disambiguation 
much work already done building named entity recognition systems however work concentrated english european languages hence building named entity recognition ner system south asian languages sal still open problem exhibit characteristics different english paper builds named entity recognizer also identifies nested name entities hindi language using machine learning algorithm trained annotated corpus however algorithm designed manner easily ported south asian languages provided necessary nlp tools like pos tagger chunker available language compare results hindi data english data conll shared task named entity recognition south asian languages named entity recognition south asian languages named entity recognition south asian languages 
abstract stub paper talks new approach recognize named entities indian languages phonetic matching technique used match strings different languages basis similar sounding property tested system comparable corpus english hindi language data approach language independent requires set rules appropriate language named entity recognition indian languages named entity recognition indian languages named entity recognition indian languages 
named entity recognition ner task identifying classifying tokens text document predefined set classes paper show experiments various feature combinations telugu ner also observed prefix suffix information helps lot finding class token also show effect training data performance system best performing model gave measure language independent features gave measure close measure obtained even including language dependent features experiments telugu ner: conditional random field approach experiments telugu ner: conditional random field approach experiments telugu ner: conditional random field approach 
report active learning experiment named entity recognition astronomy domain active learning shown reduce amount labelled data required train supervised learner selectively sampling informative data points human annotation inspect double annotation data domain quantify potential problems concerning annotators performance data selectively sampled according different selection metrics find lower agreement higher per token annotation times however overall results confirm utility active learning investigating effects selective sampling annotation task investigating effects selective sampling annotation task investigating effects selective sampling annotation task 
paper propose approach inferring semantic role using subcategorization frames maximum entropy model approach aims use information verb label mandatory arguments verb various possible ways ambiguity assignment roles mandatory arguments resolved using maximum entropy model unlabelled mandatory arguments optional arguments labelled directly using maximum entropy model labels one among frame elements frame used maximum entropy model preferred novel approach smoothing using approach obtained development set data provided shared task show approach performs well comparison approach uses maximum entropy model inferring semantic roles using sub-categorization frames maximum entropy model inferring semantic roles using sub-categorization frames maximum entropy model inferring semantic roles using sub-categorization frames maximum entropy model 
paper apply conditional random fields crfs semantic role labelling task define random field structure sentence syntactic parse tree node tree model must predict semantic role label interpreted labelling corresponding syntactic constituent show modelling task tree labelling problem allows use efficient crf inference algorithms also increasing generalisation performance compared equivalent maximum entropy classifier participated shared task closed challenge full syntactic information semantic role labelling tree conditional random fields semantic role labelling tree conditional random fields semantic role labelling tree conditional random fields 
present semantic role labeling system submitted closed track shared task system introduced toutanova et al implements joint model captures dependencies among arguments predicate using models discriminative framework also describe experiments aimed increasing robustness system presence syntactic parse errors final system achieves development wsj portion test set respectively joint model semantic role labeling joint model semantic role labeling joint model semantic role labeling 
maximum entropy classifier used semantic role labeling system takes syntactic constituents labeling units maximum entropy classifier trained identify classify predicates semantic arguments together constituents largest probability among embedding ones kept predicting arguments matching constituents full parsing trees simple applied correct arguments matching constituents trees useful features combinations evaluated semantic role labeling system using maximum entropy classifier semantic role labeling system using maximum entropy classifier semantic role labeling system using maximum entropy classifier 
paper present semantic role labeling system submitted conll shared task system makes use partial full syntactic information converts task sequential result labeling architecture simple building set features binary classifier label trained using adaboost fixed depth decision trees final system combines outputs two base systems performed official test set additionally provide results comparing system using partial vs full parsing input information goals system architecture goal work twofold one hand want test whether possible implement competitive srl system reducing task sequential tagging hand want investigate effect replacing partial parsing information full parsing built two different individual systems shared sequential strategy using upc charniak parses respectively refer systems ppupc fpcha hereinafter partial full parsing annotations provided input information hierarchical nature system navigates syntactic structures order select subset constituents organized sequentially non embedding propositions treated independently target verb generates sequence tokens annotated call step sequentialization sequential tokens selected exploring sentence spans regions defined clause boundaries syntactic constituents falling inside regions selected tokens note strategy independent input syntactic annotation explored provided contains clause boundaries happens case full parses node selection strategy equivalent pruning process defined xue palmer selects sibling nodes along path ancestors verb predicate root tree due pruning stage recall figures ppupc fpcha values give performance upper bounds respectively semantic role labeling sequential tagging semantic role labeling sequential tagging semantic role labeling sequential tagging 
propose transformation based sentence splitting method statistical machine translation transformations expanded improve machine translation quality automatically obtained manually split corpus series experiments show transformation based sentence splitting effective long sentence translation transformation-based sentence splitting method statistical machine translation transformation-based sentence splitting method statistical machine translation transformation-based sentence splitting method statistical machine translation 
present hierarchical srl strategy generalizes classical approach boundary detection classification achieve split classification step grouping together roles share linguistic properties core roles versus adjuncts results show nonoptimized hierarchical approach computationally efficient traditional systems preserves accuracy hierarchical semantic role labeling hierarchical semantic role labeling hierarchical semantic role labeling 
describe system conll shared task semantic role labeling system implements architecture first identify arguments label predicate components implemented svm classifiers using libsvm features adapted tuned system including reduced set identifier classifier experiments conducted find kernel parameters radial basis function rbf kernel algorithm defined combine results argument labeling classifier according constraints argument labeling problem semantic role labeling using libsvm semantic role labeling using libsvm semantic role labeling using libsvm 
evaluating measures lexical semantic relatedness alexander budanitsky university toronto graeme hirst university toronto quantification lexical semantic relatedness many applications nlp many different measures proposed evaluate five measures use wordnet central resource comparing performance detecting correcting spelling errors based measure proposed jiang conrath found superior proposed hirst leacock chodorow lin resnik addition explain distributional similarity adequate proxy lexical semantic relatedness evaluating wordnet-based measures lexical semantic relatedness evaluating wordnet-based measures lexical semantic relatedness evaluating wordnet-based measures lexical semantic relatedness 
system semantic role labeling nature based tree pruning techniques statistical methods lexicalised feature encoding decision tree classifier use shallow deep syntactic information automatically generated chunks parse trees develop model learning semantic arguments predicates decision problem evaluate performance set relatively cheap features report score overall test set semantic role labeling using lexical statistical information semantic role labeling using lexical statistical information semantic role labeling using lexical statistical information 
paper describes semantic role labeling system uses features derived different syntactic views combines within chunking paradigm input sentence syntactic constituent structure parses generated charniak parser collins parser semantic role labels assigned constituents parse using support vector machine classifiers resulting semantic role labels converted iob representation iob representations used additional features along flat syntactic chunks chunking svm classifier produces final srl output strategy combining features three different syntactic views gives significant improvement performance roles produced using one syntactic views individually semantic role chunking combining complementary syntactic views semantic role chunking combining complementary syntactic views semantic role chunking combining complementary syntactic views 
paper introduce semantic role labeling system constructed top full syntactic analysis text labeling problem modeled using rich set lexical syntactic semantic attributes learned using adaboost classifiers results indicate even simple approach assumes semantic argument maps exactly one syntactic phrase obtains encouraging performance surpassing best system uses partial syntax almost semantic role labeling using complete syntactic analysis semantic role labeling using complete syntactic analysis semantic role labeling using complete syntactic analysis 
building using lexical knowledge base differences diana inkpen university ottawa graeme hirst university toronto choosing wrong word machine translation natural language generation system convey unwanted connotations implications attitudes choice error mistake slip blunder words share core meaning differ nuances made knowledge differences available present method automatically acquire new type lexical resource knowledge base differences develop unsupervised algorithm learns extraction patterns special dictionary synonym differences patterns used extract knowledge text dictionary initial knowledge base later enriched information dictionaries information collocational behavior acquired free text knowledge base used xenon natural language generation system shows new lexical resource used choose best specific situations words almost synonyms quite fully intersubstitutable vary shades denotation connotation components meaning emphasize may also vary grammatical collocational constraints example word foe emphasizes active warfare enemy gove distinction forest woods complex combination size proximity civilization wildness determined type animals plants therein room among differences task job collocational behavior word daunting daunting task better collocation daunting job examples given table hirst absolute synonyms exist dictionaries synonyms actually contain made clear dictionaries webster new dictionary synonyms gove choose right word hereafter ctrw hayakawa list clusters similar words explicate differences words cluster excerpt ctrw presented figure dictionaries effect dictionaries discrimination school information technology engineering ottawa canada diana site uottawa ca department computer science toronto canada gh cs toronto edu submission received october revised submission received june accepted publication november association computational linguistics computational linguistics volume number table examples variations type variation example stylistic formality pissed drunk inebriated stylistic force ruin annihilate expressed attitude building using lexical knowledge base near-synonym differences building using lexical knowledge base near-synonym differences building using lexical knowledge base near-synonym differences 
paper propose method exploits full parsing information representing features argument classification models constraints integer linear learning programs addition take advantage maximum argument classification models incorporate scoring matrices use combined matrix integer linear programs experimental results show full parsing information increases argument classification models also effectively removes labeling inconsistencies increases ensemble svm also boosts system achieves development set test wsj exploiting full parsing information label semantic roles using ensemble svm via integer linear programming exploiting full parsing information label semantic roles using ensemble svm via integer linear programming exploiting full parsing information label semantic roles using ensemble svm via integer linear programming 
paper describes system shared task semantic role labeling trained two parsers training corpus semantic argument information attached constituent labels used resulting parse trees input pipelined srl system present results combining output various srl systems using different parsers integration syntactic parsing semantic role labeling integration syntactic parsing semantic role labeling integration syntactic parsing semantic role labeling 
notion argument prepositional phrase attachment paola merlo university geneva eva esteve ferrer university sussex article refine formulation problem prepositional phrase pp attachment disambiguation problem argue interpreting pps knowledge site attachment traditional noun verb attachment distinction nature attachment distinction arguments adjuncts needed introduce method learn arguments adjuncts based definition arguments vector features series supervised classification experiments first explore features enable us learn distinction arguments adjuncts find linguistic diagnostics argumenthood lexical semantic classes useful second investigate best method reach classification potentially ambiguous prepositional phrases find whereas overall better solve problem single classification task verb arguments sometimes precisely identified classification done process first choosing attachment site labeling argument adjunct motivation incorrect attachment prepositional phrases pps often constitutes largest single source errors current parsing systems correct attachment pps necessary construct parse tree support proper interpretation constituents sentence consider timeworn example saw man telescope important determine pp telescope attached sister noun man restricting interpretation attached verb thereby indicating instrument main action described sentence based examples sort recent approaches formalized problem disambiguating pp attachments binary choice distinguishing attachment pp given verb verb direct object hindle rooth ratnaparkhi reynar roukos collins brooks merlo crocker berthouzoz stetina nagao ratnaparkhi zhao lin however simplification problem take nature attachment account precisely distinguish pp arguments linguistics department university geneva rue de candolle gene ve switzerland department informatics university sussex falmer brighton bn qh uk submission received november revised submission received june accepted publication november association computational linguistics computational linguistics volume number pp adjuncts consider following example contains two pps modifying verb notion argument prepositional phrase attachment notion argument prepositional phrase attachment notion argument prepositional phrase attachment 
similarity semantic relations peter turney national research council canada least two kinds similarity relational similarity correspondence relations contrast attributional similarity correspondence attributes two words high degree attributional similarity call synonyms two pairs words high degree relational similarity say relations analogous example word pair mason stone analogous pair carpenter wood article introduces latent relational analysis lra method measuring relational similarity lra potential applications many areas including information extraction word sense disambiguation information retrieval recently vector space model vsm information retrieval adapted measuring relational similarity achieving score collection word analogy questions vsm approach relation pair words characterized vector frequencies predefined patterns large corpus lra extends vsm approach three ways patterns derived automatically corpus singular value decomposition svd used smooth frequency data automatically generated synonyms used explore variations word pairs lra achieves analogy questions statistically equivalent average human score related problem classifying semantic relations lra achieves similar gains vsm similarity semantic relations similarity semantic relations similarity semantic relations 
machine translation jose marin rafael banchs josep crego adria de gispert patrik lambert jose fonollosa marta universitat polite cnica de catalunya article describes detail approach statistical machine translation approach consists combination translation model based bilingual units referred tuples along four specific feature functions translation performance happens state art demonstrated translations european parliament plenary sessions epps n-gram-based machine translation n-gram-based machine translation n-gram-based machine translation 
translation named entities nes person names organization names location names crucial cross lingual information retrieval machine translation many natural language processing applications newly named entities introduced daily basis newswire greatly complicates translation task also names translated others must transliterated still others mixed paper introduce integrated approach named entity translation deploying translation translation transliteration modules single framework arabic based approach introduced unified approach applied ne translation language pair integrated approach arabic-english named entity translation integrated approach arabic-english named entity translation integrated approach arabic-english named entity translation 
paper variant spectral clustering algorithm proposed bilingual word clustering proposed algorithm generates two sets clusters languages efficiently high semantic correlation within monolingual clusters high translation quality across clusters two languages cluster level translation considered bilingual concept generalizes words bilingual clusters scheme improves robustness statistical machine translation models two hmmbased translation models tested use bilingual clusters improved perplexity word alignment accuracy translation quality observed experiments bilingual word spectral clustering statistical machine translation bilingual word spectral clustering statistical machine translation bilingual word spectral clustering statistical machine translation 
paper presents task definition resources participating systems comparative results shared task word alignment organized part acl workshop building using parallel texts shared task included english inuktitut romanian english english hindi drew participation ten teams around world total systems defining word alignment shared task task word alignment consists finding correspondences words phrases parallel texts assuming sentence aligned bilingual corpus languages task word alignment system indicate word token corpus language corresponds word token corpus language year shared task follows success previous word alignment evaluation organized hlt naacl workshop building using parallel texts data driven machine translation beyond mihalcea pedersen however current edition distinct focus languages scarce resources participating teams provided training test data three language pairs accounting different levels data scarceness english inuktitut million words training data romanian english million words english hindi words similar previous word alignment evaluation machine translation evaluation exercises organized nist two different subtasks defined limited resources systems allowed use resources provided unlimited resources systems allowed use resources addition provided resources explicitly mentioned system description test data released one week prior deadline result submissions participating teams asked produce word alignments following common format specified submit output certain deadline results returned team within three days submission word alignment output word alignment languages scarce resources word alignment languages scarce resources word alignment languages scarce resources 
head splitting techniques successfully exploited improve asymptotic runtime parsing algorithms projective dependency trees model article extend techniques class dependency trees called dependency trees previously investigated literature define structural property allows head splitting trees present two algorithms improve runtime existing algorithms significant loss coverage efficient parsing head-split dependency trees efficient parsing head-split dependency trees efficient parsing head-split dependency trees 
recently decided develop new alignment algorithm purpose improving machine translation ebmt system performance since subsentential alignment critical locating correct translation matched fragment input unlike algorithms literature new symmetric probabilistic alignment spa algorithm treats source target languages symmetric fashion short paper outline basic algorithm extensions using context positional information compare alignment accuracy data shared task ibm model reported results prior workshop symmetric probabilistic alignment spa subsentential alignment mappings produced words phrases source language sentence words phrases target language sentence best express meaning alignment algorithm takes input bilingual corpus consisting corresponding sentence pairs strives find best possible alignment second selected sequences words first language alignments based number factors including bilingual dictionary preferably probabilistic one position words invariants numbers punctuation forth baseline algorithm make following simplifying assumptions intend relax future work last already partially relaxed fixed bilingual probabilistic dictionary available fragments word sequences translated independently surrounding context contiguous fragments source language text translated contiguous fragments target language text unlike work marcu wong alignment algorithm generative use idea bag concepts phrases sentence pair arise rather intended find corresponding phrase given specific phrase interest required ebmt system finding match input training data brown baseline algorithm baseline algorithm based maximizing probability translations individual words selected source language every possible corresponding paired target language sentence symmetric probabilistic alignment symmetric probabilistic alignment symmetric probabilistic alignment 
briefly describe word alignment system combines two different methods bitext correspondences identification first one hypotheses testing approach gale church melamed tufi second one closer model estimating approach brown et al och ney show combining two aligners results significantly improved compared individual aligner combined word alignments combined word alignments combined word alignments 
paper describe lihla lexical aligner uses bilingual probabilistic lexicons generated freely available set tools natools languageindependent heuristics find links single words multiword units parallel texts method achieved alignment error rate english inuktitut romanian english parallel sentences respectively lihla: shared task system description lihla: shared task system description lihla: shared task system description 
workshop parallel texts hosted shared task building statistical machine translation systems four european language pairs french english german english spanish english finnish english eleven groups participated event paper describes goals task definition resources well results analysis statistical machine translation currently dominant paradigm machine translation research annual competitions held chinese english arabic english nist sponsored us military funding agency darpa creates forum present compare novel ideas leads steady progress field one advantages statistical machine translation currently applied methods fairly building new machine translation system new language pair much matter running training process training corpus parallel text text one language paired translation another therefore possible hold competition research groups weeks build machine translation systems language pairs previously worked effectively demonstrated shared task instance seven teams built finnish english machine translation systems language pair certainly immediate concern contrast bigger nist competition wanted keep barrier entry low possible provided training data europarl corpus koehn also additional resources sentence word alignments decoder pharaoh koehn language model participation feasible even graduate level class project using million words translated text participants asked build statistical machine translation system focus task build probabilistic phrase translation table since resources provided statistical machine translation refer koehn et al participants systems compared shared task: statistical machine translation european languages shared task: statistical machine translation european languages shared task: statistical machine translation european languages 
statistical machine translation systems use combination one translation models language model significant body research addressing improvement translation models problem optimizing language models specific translation task received much attention typically standard word trigram models used component statistical machine translation system paper apply language modeling techniques proved beneficial automatic speech recognition acl machine translation shared data task demonstrate improvements baseline system standard language model improved language modeling statistical machine translation improved language modeling statistical machine translation improved language modeling statistical machine translation 
paper describes participation portage team nrc canada shared task acl workshop building using parallel texts discuss portage statistical machine translation system present experimental results four language pairs shared task first focus task using multiple resources techniques describe contribution language pairs using provided data shared task portage: phrase-based machine translation system portage: phrase-based machine translation system portage: phrase-based machine translation system 
work discusses translation results four euparl data sets made available shared task exploiting parallel texts statistical machine translation results presented generated using statistical machine translation system implements combination feature functions along bilingual translation model statistical machine translation euparl data using bilingual n-grams statistical machine translation euparl data using bilingual n-grams statistical machine translation euparl data using bilingual n-grams 
paper present phrase extraction algorithm using translation lexicon fertility model simple distortion model except models need explicit word alignments phrase extraction phrase pair block bilingual lexicon based score computed estimate translation quality source target phrase pairs fertility score computed estimate good lengths matched phrase pairs center distortion score computed estimate relative position divergence phrase pairs presented results experience shared tasks frenchenglish generalized alignment-free phrase extraction generalized alignment-free phrase extraction generalized alignment-free phrase extraction 
describe ldvcombo system shared task exploiting parallel texts statistical machine translation workshop building using parallel texts machine translation beyond approach explores possibility working alignments different levels abstraction using different degrees linguistic annotation several translation models built alignments combination significatively outperforms isolation moreover built wordbased translation model based wordnet used unknown words combining linguistic data views phrase-based smt combining linguistic data views phrase-based smt combining linguistic data views phrase-based smt 
nowadays statistical translation systems based phrases groups words paper study different improvements standard translation system describe modified method phrase extraction deals larger phrases keeping reasonable number phrases also propose additional features lead clear improvement performance translation present results europarl task direction spanish english results evaluation shared task exploiting parallel texts statistical machine translation acl workshop parallel texts improving phrase-based statistical translation modifying phrase extraction including several features improving phrase-based statistical translation modifying phrase extraction including several features improving phrase-based statistical translation modifying phrase extraction including several features 
paper describes novel algorithm dynamically set endpointing thresholds based rich set dialogue features detect end user utterances dialogue system analyzing relationship silences user speech spoken dialogue system wide range automatically extracted features discourse semantics prosody timing speaker characteristics found features correlate pause duration whether silence indicates end turn semantics timing informative based features proposed method reduces latency fixed threshold baseline offline evaluation results confirmed implementing proposed algorithm let go system optimizing endpointing thresholds using dialogue features spoken dialogue system optimizing endpointing thresholds using dialogue features spoken dialogue system optimizing endpointing thresholds using dialogue features spoken dialogue system 
article describes competitive grouping algorithm core integrated segmentation alignment isa model isa extracts phrase pairs bilingual corpus without requiring precalculated word alignment many phrase alignment models experiments conducted within shared task statistical machine translation demonstrate simplicity effectiveness approach competitive grouping integrated phrase segmentation alignment model competitive grouping integrated phrase segmentation alignment model competitive grouping integrated phrase segmentation alignment model 
patterns extracted parallel corpora used enhance translation resource statistical machine translation deploying part-of-speech patterns enhance statistical phrase-based machine translation resources deploying part-of-speech patterns enhance statistical phrase-based machine translation resources deploying part-of-speech patterns enhance statistical phrase-based machine translation resources 
paper presents novel approaches reordering statistical machine translation perform consistent reordering source sentences training estimate statistical translation model using model follow monotonic machine translation approach develop efficient flexible reordering framework allows easily introduce different reordering constraints translation apply source sentence reordering word level use reordering automaton input show compute reordering automata using ibm itg constraints also introduce two new types reordering constraints add weights reordering automata present detailed experimental results show reordering significantly improves translation quality novel reordering approaches phrase-based statistical machine translation novel reordering approaches phrase-based statistical machine translation novel reordering approaches phrase-based statistical machine translation 
translation memories provide assistance human translators production settings sometimes used machine translation assimilation settings produce highly fluent output rapidly paper describe evaluate simple translation memory placing new lower bound space machine translation systems result new way gauge far machine translation progressed compared easily understood baseline system evaluation also sheds light evaluation metric gives evidence showing gaming translation perfect fluency fool bleu way fools people gaming fluency: evaluating bounds expectations segment-based translation memory gaming fluency: evaluating bounds expectations segment-based translation memory gaming fluency: evaluating bounds expectations segment-based translation memory 
way gough provide indepth comparison machine translation ebmt system statistical machine translation smt system constructed freely available tools according wide variety automatic evaluation metrics demonstrated ebmt system outperformed smt system factor two one nevertheless test ebmt system smt system obtaining training test data english french carry number experiments using pharaoh smt decoder better results seen pharaoh seeded giza data compared ebmt alignments general better results obtained combinations hybrid data used construct translation probability models part ebmt system gough way outperforms flavour phrasebased smt systems constructed experiments combining data sets automatically induced giza ebmt system leads hybrid system improves ebmt system per se french english hybrid example-based smt: best worlds? hybrid example-based smt: best worlds? hybrid example-based smt: best worlds? 
decision rules explicitly account evaluation metrics machine translation typically require special training often estimate parameters exponential models govern search space selection candidate translations traditional maximum posteriori map decision rule optimized piecewise linear function greedy search parameter space minimum bayes risk mbr decision rule well suited technique condition makes past results difficult compare present novel training approach decision rules allowing us compare evaluate decision rules large scale translation task taking advantage high dimensional parameter space available phrase based pharaoh decoder comparison timely important decoders evolve represent complex search space decisions evaluated innovative evaluation metrics translation quality training evaluating error minimization decision rules statistical machine translation training evaluating error minimization decision rules statistical machine translation training evaluating error minimization decision rules statistical machine translation 
paper demonstrates usefulness summaries extrinsic task relevance judgment based new method measuring agreement compares subjects judgments summaries judgments full text documents demonstrate measure reliable previous measures able make stronger statistical statements benefits summarization found positive correlations rouge scores two different summary types weak negative correlations found using agreement measures however show rouge may sensitive choice summarization style discuss importance results implications future summarization evaluations methodology extrinsic evaluation text summarization: rouge correlate? methodology extrinsic evaluation text summarization: rouge correlate? methodology extrinsic evaluation text summarization: rouge correlate? 
evaluation measures machine translation depend several common methods preprocessing tokenization handling sentence boundaries choice reference length paper describe review new approaches compare methods experimentally look impact four established evaluation measures purpose study correlation automatic human evaluation scores three mt evaluation corpora experiments confirm tokenization method reference length selection scheme use sentence boundaries introduce increase correlation automatic human evaluation scores find ignoring case information normalizing evaluator scores positive effect sentence level correlation well preprocessing normalization automatic evaluation machine translation preprocessing normalization automatic evaluation machine translation preprocessing normalization automatic evaluation machine translation 
research explores schemes evaluating automatic summaries business meetings using icsi meeting corpus janin et al automatic subjective evaluations carried central interest whether two types evaluations correlate evaluation metrics used compare contrast differing approaches automatic summarization deterioration summary quality asr output versus manual transcripts determine whether manual extracts rated significantly higher automatic extracts evaluating automatic summaries meeting recordings evaluating automatic summaries meeting recordings evaluating automatic summaries meeting recordings 
investigate pitfalls regarding discriminatory power mt evaluation metrics accuracy statistical significance tests discriminative reranking experiment smt show nist metric sensitive bleu despite incorporation aspects fluency meaning adequacy mt evaluation experimental comparison two statistical significance tests show estimated conservatively approximate randomization bootstrap tests thus increasing likelihood error latter point pitfall randomly assessing significance multiple pairwise comparisons conclude recommendation combine nist approximate randomization stringent rejection levels currently standard pitfalls automatic evaluation significance testing mt pitfalls automatic evaluation significance testing mt pitfalls automatic evaluation significance testing mt 
recently many researches natural language learning considered representation complex linguistic phenomena means structural kernels particular tree kernels used represent verbal subcategorization frame scf information predicate argument classification scf relevant clue learn relation syntax semantic classification algorithm accuracy remarkable enhanced article extend work studying impact scf tree kernel propbank framenet semantic roles experiments support vector machines svms confirm strong link scf semantics verbal predicates well benefit using kernels diverse complex test conditions classification unseen verbs verb subcategorization kernels automatic semantic labeling verb subcategorization kernels automatic semantic labeling verb subcategorization kernels automatic semantic labeling 
propose range deep lexical acquisition methods make use morphological syntactic ontological language resources model word similarity bootstrap seed lexicon different methods deployed learning lexical items precision grammar shown strengths weaknesses different word classes particular focus paper relative accessibility different language resource types predicted bang buck associated deep lexical acquisition applications bootstrapping deep lexical resources: resources courses bootstrapping deep lexical resources: resources courses bootstrapping deep lexical resources: resources courses 
present development pipeline associated algorithms designed make grammarbased generation easier deploy implemented dialogue systems approach realizes practical capabilities system generation component authoring maintenance burdens imposed generation content author deployed system evaluate approach performed human rating study system builders work common largescale spoken dialogue system results demonstrate viability approach illustrate authoring performance text approach competing shallow statistical nlg technique making grammar-based generation easier deploy dialogue systems making grammar-based generation easier deploy dialogue systems making grammar-based generation easier deploy dialogue systems 
work explores computing distributional similarity fragments parse tree extension general lexical distributional similarity techniques way lexical distributional similarity used estimate lexical semantic similarity propose using distributional similarity subparses estimate semantic similarity phrases technique allow us identify paraphrases component words semantically similar demonstrate potential method applying small number examples showing paraphrases similar distributional similarity sub-parses distributional similarity sub-parses distributional similarity sub-parses 
paper presents method measuring semanticsimilarity texts large body previous work focused finding semantic similarity concepts words application wordoriented methods text similarity yet explored paper introduce method combines similarity metrics metric show method outperforms traditional text similarity metrics based lexical matching measuring semantic similarity texts measuring semantic similarity texts measuring semantic similarity texts 
paper presents new approach combining outputs existing word alignment systems alignment link represented set feature functions extracted linguistic features input alignments features used basis alignment decisions made maximum entropy approach learning method evaluated three language pairs yielding significant improvements input alignments three heuristic combination methods impact word alignment mt quality investigated using mt system maximum entropy approach combining word alignments maximum entropy approach combining word alignments maximum entropy approach combining word alignments 
north american computational linguistics olympiad (naclo) north american computational linguistics olympiad (naclo) north american computational linguistics olympiad (naclo) 
gene protein recognition ner normalization often treated process first step ner received considerable attention last years normalization received much less attention built dictionary based gene protein ner normalization system requires supervised training human intervention build dictionaries online genomics resources tested system genia corpus biocreative task mouse yeast corpora achieved level performance comparable systems require supervised learning manual dictionary creation technique also work organisms following similar naming conventions mouse human evaluation improvement gene protein ner normalization systems somewhat hampered lack larger test collections collections additional organisms human unsupervised gene/protein named entity normalization using automatically extracted dictionaries unsupervised gene/protein named entity normalization using automatically extracted dictionaries unsupervised gene/protein named entity normalization using automatically extracted dictionaries 
paper new discriminative word alignment method presented approach models directly alignment matrix conditional random field crf restrictions alignments made furthermore easy add features available information used since structure crfs get complex inference done approximately standard algorithms adapted addition different methods train model developed using approach alignment quality could improved percent different language pairs compared combination ibm alignments furthermore word alignment used generate new phrase tables could improve translation quality significantly discriminative word alignment via alignment matrix modeling discriminative word alignment via alignment matrix modeling discriminative word alignment via alignment matrix modeling 
minimum error rate training mert widely used learning procedure statistical machine translation models contrast three search strategies mert powell method variant coordinate descent found moses mert utility novel stochastic method shown stochastic method obtains test set gains bleu mt bleu mt also present method regularizing mert objective achieves statistically significant gains combined powell method coordinate descent regularization search minimum error rate training regularization search minimum error rate training regularization search minimum error rate training 
describe two methods improve smt accuracy using shallow syntax information first use chunks refine set word alignments typically used starting point smt systems second extend smt system chunk tags better account reorderings experiments reported task showing significant improvements human error analysis indicates reorderings captured effectively using shallow syntax information improve word alignment reordering smt using shallow syntax information improve word alignment reordering smt using shallow syntax information improve word alignment reordering smt 
paper analyzes translation quality machine translation systems language pairs translating czech english french german hungarian spanish report translation quality diverse translation systems based manual evaluation involving hundreds hours effort use human judgments systems analyze automatic evaluation metrics translation quality report strength correlation human judgments validate manual evaluation methodology measuring agreement collecting timing information meta-evaluation machine translation meta-evaluation machine translation meta-evaluation machine translation 
paper describes statistical machine translation systems based moses toolkit wmt shared task address europarl news conditions following language pairs english french german spanish europarl rescoring performed using enhanced neuronal language model news condition language models incorporate extra training data also report unconvincing results experiments factored models limsi’s statistical translation systems wmt?8 limsi’s statistical translation systems wmt?8 limsi’s statistical translation systems wmt?8 
present corrective model recovering dependency structures trees generated parsers continuity constraint constituencybased parsers makes impossible posit dependency trees analysis types dependency errors made parsers czech corpus show correct governor likely found within local neighborhood governor proposed parser model based maxent classifier improves overall dependency accuracy reduction error accuracy structures corrective modeling non-projective dependency parsing corrective modeling non-projective dependency parsing corrective modeling non-projective dependency parsing 
paper describes submissions machine translation evaluation shared task acl primary submission meteor metric tuned optimizing correlation human rankings translation hypotheses show significant improvement correlation compared earlier version metric tuned optimized correlation traditional adequacy fluency judgments also describe enhanced versions two widely used metrics bleu ter respectively extend exact word matching used metrics flexible matching based stemming wordnet meteor meteor, m-bleu m-ter: evaluation metrics high-correlation human rankings machine translation output meteor, m-bleu m-ter: evaluation metrics high-correlation human rankings machine translation output meteor, m-bleu m-ter: evaluation metrics high-correlation human rankings machine translation output 
paper describes initial version general purpose french english statistical machine translation system main features system moses decoder integration bilingual dictionary continuous space target language model analyze performance system test data wmt evaluation first steps towards general purpose french/english statistical machine translation system first steps towards general purpose french/english statistical machine translation system first steps towards general purpose french/english statistical machine translation system 
paper present university washington submission acl smt shared machine translation task two systems translation described main focus testing novel boosting framework list reranking handling german morphology system boosted list reranking yield improvements task simplifying german morphology part preprocessing step result significant gains university washington machine translation system acl wmt 2008 university washington machine translation system acl wmt 2008 university washington machine translation system acl wmt 2008 
paper reports participation talp research center upc universitat polit cnica de catalunya acl wmt evaluation campaign year system evolution one employed campaign main updates extensions involve linguistically motivated word reordering based reordering patterns technique addition system introduces target language model based linguistic classes morphology reduction inflectional language spanish improved optimization procedure results obtained development test sets spanish english way round translations traditional europarl challenging news stories tasks analyzed commented talp-upc ngram-based statistical machine translation system acl-wmt 2008 talp-upc ngram-based statistical machine translation system acl-wmt 2008 talp-upc ngram-based statistical machine translation system acl-wmt 2008 
describe cambridge university engineering department statistical machine translation system spanishenglish translation acl third workshop statistical machine translation shared task cued system follows generative model translation implemented composition component models realised weighted finite state transducers without use decoder details system tuning europarl news translation tasks provided european language translation weighted finite state transducers: cued mt system 2008 acl workshop smt european language translation weighted finite state transducers: cued mt system 2008 acl workshop smt european language translation weighted finite state transducers: cued mt system 2008 acl workshop smt 
investigated performance efficacy beam search parsing deep parsing techniques probabilistic hpsg parsing using penn treebank first tested beam thresholding iterative parsing developed pcfg parsing hpsg next tested three techniques originally developed deep parsing quick check large constituent inhibition hybrid parsing cfg chunk parser contributions large constituent inhibition global thresholding significant quick check chunk parser greatly contributed total parsing performance precision recall average parsing time penn treebank section ms respectively efficacy beam thresholding, unification filtering hybrid parsing probabilistic hpsg parsing efficacy beam thresholding, unification filtering hybrid parsing probabilistic hpsg parsing efficacy beam thresholding, unification filtering hybrid parsing probabilistic hpsg parsing 
edinburgh submissions shared task third workshop statistical machine translation incorporate recent advances open source moses system made special effort german english english german language pairs leading substantial improvements towards better machine translation quality german-english language pairs towards better machine translation quality german-english language pairs towards better machine translation quality german-english language pairs 
present parser produces constituent trees linear time parser uses basic shiftreduce algorithm employs classifier determine parser actions instead grammar seen extension deterministic dependency parser nivre scholz full constituent parsing show appropriate feature set used classification simple greedy parser perform level accuracy complex parsers evaluate parser section wsj section penn treebank obtain precision recall respectively classifier-based parser linear run-time complexity classifier-based parser linear run-time complexity classifier-based parser linear run-time complexity 
proceedings ninth international workshop parsing technologies iwpt pages vancouver october association computational linguistics chunk parsing revisited yoshimasa tsuruoka chunk parsing revisited chunk parsing revisited chunk parsing revisited 
ordinary classification techniques drive conceptually simple constituent parser achieves near accuracy standard test sets present parser avoids limitations discriminative parsers particular place restrictions upon types features allowed also present several innovations faster training discriminative parsers show training parallelized examples generated prior training without working parser independently trained never done parsing effectively combined working parser finally propose new bestfirst parsing inferences implementation freely available http cs nyu edu turian software parser constituent parsing classification constituent parsing classification constituent parsing classification 
paper explores possibilities improving parsing results combining outputs several parsers extent porting ideas henderson brill world dependency structures differ exploring context features deeply experiments conducted czech method able significantly improve best parsing result given setting known far moreover experiments show even parsers far state art contribute total improvement improving parsing accuracy combining diverse dependency parsers improving parsing accuracy combining diverse dependency parsers improving parsing accuracy combining diverse dependency parsers 
proceedings ninth international workshop parsing technologies iwpt pages vancouver october association computational linguistics statistical shallow semantic parsing despite little training data rahul bhagat information sciences institute university southern california marina del rey ca usa rahul isi edu anton leuski institute creative technologies university southern california marina del rey ca usa leuski ict usc edu eduard hovy information sciences institute university southern california marina del rey ca usa hovy isi edu statistical shallow semantic parsing despite little training data statistical shallow semantic parsing despite little training data statistical shallow semantic parsing despite little training data 
based architecture allows combine statistical machine translation smt machine translation rbmt setup present new results show type system combination actually increase lexical coverage resulting hybrid system least far measured via bleu score using moses integrate multiple rule-based machine translation engines hybrid system using moses integrate multiple rule-based machine translation engines hybrid system using moses integrate multiple rule-based machine translation engines hybrid system 
proceedings third workshop statistical machine translation pages columbus ohio usa june association computational linguistics incremental hypothesis alignment building confusion networks application machine translation system combination rosti bing zhang spyros matsoukas richard schwartz bbn technologies moulton street cambridge ma incremental hypothesis alignment building confusion networks application machine translation system combination incremental hypothesis alignment building confusion networks application machine translation system combination incremental hypothesis alignment building confusion networks application machine translation system combination 
previous studies shown automatic evaluation metrics reliable compared many human translations however multiple human references may always available common single human reference extracted parallel texts reference earlier work suggested one way address problem train metric evaluate sentence comparing pseudo references imperfect references produced mt systems paper examine approach terms training methodology terms role human pseudo references expanded experiments show approach generalizes well across multiple years different source languages role pseudo references mt evaluation role pseudo references mt evaluation role pseudo references mt evaluation 
describe supple open source natural language parsing system implemented prolog designed practical use language engineering le applications supple run application component within gate general architecture text engineering supple distributed example grammar developed number years across several le projects paper describes key characteristics parser distributed grammar supple: practical parser natural language engineering applications supple: practical parser natural language engineering applications supple: practical parser natural language engineering applications 
paper presents technique classdependent decoding statistical machine translation smt approach differs previous methods translation forms models integrated directly decoding process employ probabilistic mixture weights models change dynamically basis depending characteristics source segment effectiveness approach demonstrated evaluating performance travel conversation data used approach tackle translation questions declarative sentences using classdependent models achieve system integrated two sets models specifically built deal sentences fall one two classes dialog sentence questions declarations third set models built handle general class technique thoroughly evaluated data language pairs using machine translation evaluation metrics found results cases system able improve translation performance languages improvements substantial dynamic model interpolation statistical machine translation dynamic model interpolation statistical machine translation dynamic model interpolation statistical machine translation 
proceedings ninth international workshop parsing technologies iwpt pages vancouver october association computational linguistics robust extraction subcategorization data spoken language jianguo li chris brew eric department linguistics department computer science engineering ohio state university usa ohio state university usa jianguo cbrew ling edu fosler cse edu robust extraction subcategorization data spoken language robust extraction subcategorization data spoken language robust extraction subcategorization data spoken language 
paper presents improved formally smt model enriched linguistically syntactic knowledge obtained statistical constituent parsers propose prior derivation model score hypothesis derivations top baseline model translation decoding moreover devise fast training algorithm achieve improved models based tree kernel methods experiments task demonstrate proposed models outperformed baseline formally syntaxbased models achieved significant improvements smt system prior derivation models formally syntax-based translation using linguistically syntactic parsing tree kernels prior derivation models formally syntax-based translation using linguistically syntactic parsing tree kernels prior derivation models formally syntax-based translation using linguistically syntactic parsing tree kernels 
investigate translation modeling based exponential estimates generalize essential components standard translation models application hierarchical phrasebased system simplest generalization allows models lexical selection reordering conditioned arbitrary attributes source sentence annotation viewing estimates approximations probabilities motivates elaborations seek exploit general syntactic morphological patterns dimensionality control regularizers makes possible negotiate tradeoff translation quality decoding speed putting together extending several recent advances translation arrive flexible modeling framework allows efficient leveraging monolingual resources tools experiments features derived output chinese arabic parsers arabic lemmatizer show significant improvements strong baseline generalizing local translation models generalizing local translation models generalizing local translation models 
present novel approach word reordering successfully integrates syntactic structural knowledge smt done constructing lattice alternatives based automatically learned probabilistic syntactic rules decoding alternatives scored based output word order order input unlike previous approaches makes possible successfully integrate syntactic reordering smt englishdanish task achieve absolute improvement translation quality bleu manual evaluation supports claim present approach significantly superior previous approaches syntactic reordering integrated phrase-based smt syntactic reordering integrated phrase-based smt syntactic reordering integrated phrase-based smt 
paper presents method integrate multiple reordering strategies statistical machine translation recently much research effort reordering problems machine translation decoders incorporate sophisticated local reordering strategies little research unified approach incorporate various kinds reordering methods present decoder easily allows multiple reordering schemes show use framework perform reordering chiang hierarchical reordering also present two novel reordering methods one built tags based parse trees give experimental results using relatively easy implement methods standard tests multiple reorderings phrase-based machine translation multiple reorderings phrase-based machine translation multiple reorderings phrase-based machine translation 
introduce word alignment framework facilitates incorporation syntax encoded bilingual dependency tree pairs model consists two anchor word alignment model aims find set anchor links syntaxenhanced word alignment model focuses aligning remaining words relying dependency information invoked acquired anchor links show syntaxenhanced word alignment approach leads relative decrease alignment error rate compared generative word alignment model discriminative word alignment model respectively furthermore approach evaluated extrinsically using statistical machine translation system results show smt systems based word alignment approach tend generate shorter outputs without length penalty using word alignments yields statistically significant improvement chinese english machine translation comparison baseline word alignment improving word alignment using syntactic dependencies improving word alignment using syntactic dependencies improving word alignment using syntactic dependencies 
sentence fusion generation task takes related sentences input merges single output sentence paper describe ongoing work developing sentence fusion module dutch propose generalized version alignment indicates words phrases aligned also labels terms small set primitive semantic relations indicating words phrases two input sentences relate shown human labelers perform task high agreement fscore describe evaluate adaptation existing automatic alignment algorithm use resulting alignments plus semantic labels generalized fusion generation algorithm evaluation study reveals resulting sentences adequate good explorations sentence fusion explorations sentence fusion explorations sentence fusion 
natural language processing modules taggers recognizers syntactic parsers commonly evaluated isolation assumption artificial evaluation metrics individual parts predictive practical performance complex language technology systems perform practical tasks although important issue design engineering systems use natural language input often unclear accuracy application affected parameters affect individual nlp modules explore issue context specific task examining relationship accuracy syntactic parser overall performance information extraction system biomedical text includes parser one components present empirical investigation relationship factors affect accuracy syntactic analysis difference parse accuracy affects overall system evaluating effects treebank size practical application parsing evaluating effects treebank size practical application parsing evaluating effects treebank size practical application parsing 
training word alignment models large corpora processes paper describes two parallel implementations giza accelerate word alignment process one implementations runs computer clusters runs system using technology results show speedup according number cpus used alignment quality preserved parallel implementations word alignment tool parallel implementations word alignment tool parallel implementations word alignment tool 
paper presents pilot study use phrasal statistical machine translation smt techniques identify correct writing errors made learners english second language esl using examples mass noun errors found chinese learner error corpus clec guide creation engineered training set show application smt paradigm capture errors well addressed proofing tools designed native speakers system able correct mistakes set naturallyoccurring examples mass noun errors found world wide web suggesting efforts collect alignable corpora esl writing samples offer enable development writing assistance tools capable repairing many complex syntactic lexical problems found writing esl learners correcting esl errors using phrasal smt techniques correcting esl errors using phrasal smt techniques correcting esl errors using phrasal smt techniques 
present chinese named entity recognition ner system submitted close track sighan bakeoff define additional features via statistics training corpus system incorporates basic features additional features based conditional random fields crfs order correct inconsistently results perform postprocessing procedure according results given crfs model final system achieved msra cityu ldc chinese named entity recognition conditional random fields chinese named entity recognition conditional random fields chinese named entity recognition conditional random fields 
sequence labeling tasks applying different machine learning models feature sets usually leads different results paper exploit two ensemble methods order integrate multiple results generated different conditions one method based majority vote approach integrates maximum entropy conditional random field classifiers results indicate method outperform individual classifiers majority vote method cannot using ensemble methods chinese named entity recognition using ensemble methods chinese named entity recognition using ensemble methods chinese named entity recognition 
paper describes word segmentation system named entity recognition ner system participating third sighan bakeoff based character tagging use different tag sets different features evaluation results show word segmentation system achieved upuc msra open tests ner system got ldc msra open tests chinese word segmentation named entity recognition character tagging chinese word segmentation named entity recognition character tagging chinese word segmentation named entity recognition character tagging 
application statistical nlp systems resource constrained devices limited need maintain parameters large number features alphabet mapping features parameters introduce random feature mixing eliminate alphabet storage reduce number parameters without severely impacting model performance small statistical models random feature mixing small statistical models random feature mixing small statistical models random feature mixing 
participated three open tracks chinese word segmentation named entity recognition tasks sighan bakeoff take probabilistic feature based maximum entropy model basic frame combine multiple sources knowledge named entity recognizer achieved highest measure msra word segmenter achieved medium measure msra find effective combining external crucial improve performance word segmentation named entity recognition word segmentation named entity recognition sighan bakeoff3 word segmentation named entity recognition sighan bakeoff3 word segmentation named entity recognition sighan bakeoff3 
paper describes work chinese named entity recognition performed yahoo team third international chinese language processing bakeoff used two conditional probabilistic models task including conditional random fields crfs maximum entropy models particular trained two conditional random field recognizers one maximum entropy recognizer identifying names people places organizations unsegmented chinese texts best performance msra dataset cityu dataset chinese named entity recognition conditional probabilistic models chinese named entity recognition conditional probabilistic models chinese named entity recognition conditional probabilistic models 
reading difficulty measure described function model maps text numerical value corresponding difficulty grade level describe measure readability uses combination lexical features grammatical features derived subtrees syntactic parses also tested statistical models nominal ordinal interval scales measurement results indicate model ordinal regression proportional odds model using combination grammatical lexical features effective predicting reading difficulty analysis statistical models features reading difficulty prediction analysis statistical models features reading difficulty prediction analysis statistical models features reading difficulty prediction 
participated third international chinese word segmentation bakeoff specifically evaluated chinese word segmenter neucipseg close track four corpora namely academis sinica city university hong kong cityu microsoft research msra university pennsylvania university colorado upenn based support vector machines svms basic segmenter designed regarding chinese word segmentation problem tagging moreover proposed postprocessing rules specially taking account properties results brought basic segmenter system achieved good ranks four corpora chinese word segmenter built segmentation system following xue shen regarding chinese word segmentation problem tagging instead maximum entropy utilized support vector machines alternate svms learning algorithm owing success mainly ability control generalization error smooth integration kernel methods see details vapnik adopted specific implementation model problem formalization formalizing chinese word segmentation problem tagging http svmlight joachims org signed character one one four classes example given sequence chinese words southeast asia people character assigned category indicating beginning word assigned category indicating middle position word belongs category meaning ending chinese word last assigned category indicating single character word feature templates utilized four five basic feature templates suggested low et al described follows cn cncn pu refers chinese character first two templates specify context window size five characters stands current character former describes individual characters designing special post-processing rules svm-based chinese word segmentation designing special post-processing rules svm-based chinese word segmentation designing special post-processing rules svm-based chinese word segmentation 
present parser parses dependency structures constituent structures constituency representations automatically transformed dependency representations complex arc labels makes possible recover constituent structure constituent labels grammatical functions report labeled attachment score close dependency versions tiger tu bad treebanks moreover parser able recover constituent labels grammatical functions tu tiger dependency-driven parser german dependency constituency representations dependency-driven parser german dependency constituency representations dependency-driven parser german dependency constituency representations 
acl workshop parsing german features shared task parsing german goal shared task find reasons radically different behavior parsers different treebanks constituent dependency representations paper describe task data sets addition provide overview test results first analysis page 2008 shared task parsing german page 2008 shared task parsing german page 2008 shared task parsing german 
many information extraction ie systems rely manually annotated training data learn patterns rules extracting information events manually annotating data expensive however new data set must annotated domain ie training sets relatively small consequently ie patterns learned annotated training sets often limited coverage paper explore idea using web automatically identify ie patterns seen training data use ie patterns learned training set anchors identify web pages learn new ie patterns compute semantic affinity new pattern automatically infer type information extract experiments test set show new ie patterns improved recall small precision loss learning domain-specific information extraction patterns web learning domain-specific information extraction patterns web learning domain-specific information extraction patterns web 
paper present results experiments aiming validate twodimensional typology affective states suitable basis affective classification texts using corpus english weblog posts annotated mood authors trained support vector machine binary classifiers distinguish texts basis affiliation one region space report experiments go step using classifiers based automated scoring texts dimension typology results indicate possible extend standard binary sentiment analysis positive negative approach two dimensional model positive negative active passive provide evidence support classification along two axes towards validated model affective classification texts towards validated model affective classification texts towards validated model affective classification texts 
learning taxonomy technical terms difficult tedious task especially new terms included goal paper assign taxonomic relations among technical terms propose new approach problem relies term specificity similarity measures term specificity similarity necessary conditions taxonomy learning highly specific terms tend locate deep levels semantically similar terms close taxonomy analyzed various features used previous researches view term specificity similarity applied optimal features term specificity similarity method taxonomy learning using term specificity similarity taxonomy learning using term specificity similarity taxonomy learning using term specificity similarity 
paper proposes use convolution kernel parse trees model syntactic structure information relation extraction study reveals syntactic structure features embedded parse tree effective relation extraction features well captured convolution tree kernel evaluation ace corpus shows convolution kernel parse trees achieve comparable performance previous methods ace relation subtypes also shows method significantly outperforms previous two dependency tree kernels ace relation major types exploring syntactic features relation extraction using convolution tree kernel exploring syntactic features relation extraction using convolution tree kernel exploring syntactic features relation extraction using convolution tree kernel 
present comparative study corpusbased methods automatic synthesis email responses requests methods developed considering two operational dimensions technique granularity information particular investigate two techniques retrieval prediction applied information represented two levels granularity document level also developed hybrid method combines prediction retrieval results show different approaches applicable different situations addressing combined requests either complete partial responses automating help-desk responses: comparative study information-gathering approaches automating help-desk responses: comparative study information-gathering approaches automating help-desk responses: comparative study information-gathering approaches 
paper explore use structured content semantic constraints enhancing performance traditional document retrieval special domains first describe method automatic extraction semantic content form av pairs natural language texts based domain models constructed semistructured web resource explore effect combining ir system simple search system uses extracted av pairs evaluation results shown combination produces improvement ir performance ir system test collection exploring semantic constraints document retrieval exploring semantic constraints document retrieval exploring semantic constraints document retrieval 
many theoretical applied areas computational linguistics researchers operate notion linguistic distance conversely linguistic similarity focus present workshop many cl areas make frequent use notions received little focused attention honorable exception lebart rajman workshop brings number strands together highlighting number common issues linguistic distances linguistic distances linguistic distances 
paper outlines measure language similarity based structural similarity surface syntactic dependency trees unlike traditional measures measure tries reflect deeper correspondences among languages development measure inspired experience mt syntactically similar languages experience shows lexical similarity less important syntactic similarity claim supported number examples illustrating problems may arise measure language similarity relies much simple similarity texts different languages structural similarity measure structural similarity measure structural similarity measure 
cube pruning fast inexact method generating items beam decoder paper show cube pruning essentially equivalent search specific search space specific heuristics use insight develop faster exact variants cube pruning cube pruning heuristic search cube pruning heuristic search cube pruning heuristic search 
integration new utterances context central task model rational dialogues natural language paper approach specifying meaning utterances terms plans presented rational dialogue driven reaction dialogue participants find expectations changes environment satisfied observations outcome performed actions present computational model view dialogues illustrate examples application view dialogues rational dialogues based grice maxims conversation serve jointly executing task domain discourse called application domain following plan could solve task assigned participants dialogue therefore interpretation new contributions integration dialogue controlled global factors assumption dialogue participants behave cooperative manner work effectively towards completion joint task well local factors new contribution serve completing current shared plan ony factors represented effective efficient formal language dialogue systems implemented examples models implementation approach implemented system described larsson linguistically oriented approaches like models intentional models grosz sidner see grosz sidner even noted often discourse structure task structure isomorphic contributions dialogue research focus question structures interfere see sect paper emphasize important distinguish dialogue situation application situation former modified whenever speech acts performed whereas latter changes according effects action executed section use maptask dialogue show notions dialogue situation application situation intend mean presenting related work sect present approach first informally formally explaining ai algorithms apply order turn informal model computationally tractable one talking domain situations main hypothesis paper modifications dialogue situation triggered changes application situation response speech act dialogue participants perform series actions tracing actions helps understanding interactions tracing actions helps understanding interactions tracing actions helps understanding interactions 
identification action items meeting recordings provide immediate access salient information medium notoriously difficult search summarize end use maximum entropy model automatically detect action itemrelated utterances audio meeting recordings compare effect lexical temporal syntactic semantic prosodic features system performance show corpus action item annotations icsi meeting recordings characterized high imbalance low agreement system performs measure low compared tasks mature corpora relative usefulness features towards task indicative usefulness consistent annotations well related tasks automatically detecting action items audio meeting recordings automatically detecting action items audio meeting recordings automatically detecting action items audio meeting recordings 
consider task linear thematic segmentation text documents using features based word distributions text task typical often implicit assumption previous studies document one topic therefore many algorithms tested shown encouraging results artificial data sets generated putting together parts different documents show evaluation synthetic data potentially misleading fails give accurate evaluation performance real data moreover provide critical review existing evaluation metrics literature propose improved evaluation metric analysis quantitative aspects evaluation thematic segmentation algorithms analysis quantitative aspects evaluation thematic segmentation algorithms analysis quantitative aspects evaluation thematic segmentation algorithms 
human text characterised individual lexical choices specific author significant variations exist authors contrast natural language generation systems normally produce uniform texts paper apply distributional similarity measures help verb choice natural language generation system tries generate text similar individual author using distributional similarity ds measure corpora collected recipe domain get likely verbs individual authors accuracy matching verb pairs produced distributional similarity higher using synonym outputs verbs wordnet furthermore combination two methods provides best accuracy using distributional similarity identify individual verb choice using distributional similarity identify individual verb choice using distributional similarity identify individual verb choice 
paper presents new approach based equivalent pseudowords eps tackle word sense disambiguation wsd chinese language eps particular artificial ambiguous words used realize unsupervised wsd bayesian classifier implemented test efficacy ep solution chinese test set performance better results average experiment verifies value ep unsupervised wsd equivalent pseudoword solution chinese word sense disambiguation equivalent pseudoword solution chinese word sense disambiguation equivalent pseudoword solution chinese word sense disambiguation 
propose organise series sharedtask nlg events participants asked build systems similar input output functionalities systems evaluated range different evaluation techniques main purpose events allow us compare different evaluation techniques correlating results different evaluations systems entered events background evaluation becoming increasingly important natural language generation nlg areas natural language processing nlp nlg systems evaluated many different ways different associated resource requirements example taskeffectiveness study human subjects could last year cost us reiter et al hand comparison generated texts reference texts done manner days however latter kind study appealing terms cost time cheap reliable evaluation techniques would useful people developing testing new nlg techniques worth reason believe results tell us something useful generated texts real human users obvious case reiter sripada perhaps best way study reliability different evaluation techniques generally develop better empirical understanding strengths problems different evaluation techniques perform studies range different evaluation techniques used evaluate set nlg systems similar functionalities correlating results different evaluation techniques give us empirical insight well techniques work practice unfortunately studies carried perhaps date nlg systems built comparable functionality work area discussed hope surmount problem organising shared task events nlg researchers submit systems based supplied data set inputs text outputs carry evaluation experiments submitted systems hope events also make easier new researchers get involved nlg providing data sets evaluation geneval: proposal shared-task evaluation nlg geneval: proposal shared-task evaluation nlg geneval: proposal shared-task evaluation nlg 
proceedings th international workshop tree adjoining grammar related formalisms pages sydney july association computational linguistics weak generative capacity linear grammars david chiang information sciences institute university southern california admiralty way suite marina del rey ca usa chiang isi edu weak generative capacity linear tree-adjoining grammars weak generative capacity linear tree-adjoining grammars weak generative capacity linear tree-adjoining grammars 
semantic role labeling srl methods typically use features syntactic parse trees propose novel method uses lexicalized grammar ltag based features task convert parse trees ltag derivation trees semantic roles treated hidden information learned supervised learning annotated data derived propbank extracted various features ltag derivation trees trained discriminative decision list model predict semantic roles present results full conll srl task using ltag-based features semantic role labeling using ltag-based features semantic role labeling using ltag-based features semantic role labeling 
propose framework derive distance concepts distributional measures word use categories published thesaurus concepts allowing possible distance values stored concept concept matrix roughly size created existing measures show newly proposed measures outperform traditional distributional measures tasks ranking word pairs order semantic distance correcting realword spelling errors latter task measures proposed jiang conrath outperforms best distributional conceptdistance measures semantic distributional measures measures distance meaning two kinds first kind refer semantic measures rely structure resource wordnet cases semantic network hence measure distance concepts nodes resource represent examples include measure mesh proposed rada et al wordnet proposed leacock chodorow jiang conrath successful measures jiang conrath also use information content derived word frequency typically measures rely extensive hierarchy hyponymy relationships nouns therefore measures expected perform poorly used estimate distance senses pairs noun noun wordnet hierarchies parts speech less well developed also hierarchies different parts speech well connected second kind measures refer distributional measures inspired maxim shall know word company keeps firth measures rely simply raw text hence much less semantic measures measure distance words rather concepts measures two words considered close occur similar contexts context company target word represented distributional profile dp lists strength association target lexical syntactic semantic units commonly used measures strength association conditional probability pointwise mutual information distributional measures concept-distance: task-oriented evaluation distributional measures concept-distance: task-oriented evaluation distributional measures concept-distance: task-oriented evaluation 
introduce spmt new class statistical translation models use syntactified target language phrases spmt models outperform state art baseline model bleu points nist test corpus points humanbased quality metric ranks translations scale spmt: statistical machine translation syntactified target language phrases spmt: statistical machine translation syntactified target language phrases spmt: statistical machine translation syntactified target language phrases 
discuss different strategies smoothing phrasetable statistical mt give results range translation settings show type smoothing better idea relativefrequency estimates often used best smoothing techniques yield consistent gains approximately absolute according bleu metric phrasetable smoothing statistical machine translation phrasetable smoothing statistical machine translation phrasetable smoothing statistical machine translation 
investigate impact parse quality statistical machine translation system applied technical text vary parse quality varying amount data used train parser amount data increases parse quality improves leading improvements machine translation output results significantly outperform phrasal baseline impact parse quality syntactically-informed statistical machine translation impact parse quality syntactically-informed statistical machine translation impact parse quality syntactically-informed statistical machine translation 
reordering currently one important problems statistical machine translation systems paper presents novel strategy dealing statistical machine reordering smr consists using powerful techniques developed statistical machine translation smt translate source language reordered source language allows improved translation target language smt task changes leads monotonized word alignment shorter translation units addition use classes smr helps infer new word reorderings experiments reported esen wmt tasks zhen iwslt task show significant improvement translation quality statistical machine reordering statistical machine reordering statistical machine reordering 
paper present paraeval automatic evaluation framework uses paraphrases improve quality machine translation evaluations previous work focused fixed evaluation metrics coupled lexical identity matching paraeval addresses three important issues support paraphrase synonym matching recall measurement correlation human judgments show paraeval correlates significantly better bleu human assessment measurements fluency adequacy re-evaluating machine translation results paraphrase support re-evaluating machine translation results paraphrase support re-evaluating machine translation results paraphrase support 
discriminative learning methods widely used natural language processing methods work best training test data drawn distribution many nlp tasks however confronted new domains labeled data scarce cases seek adapt existing models resourcerich source domain target domain introduce structural correspondence learning automatically induce correspondences among features different domains test technique part speech tagging show performance gains varying amounts source target training data well improvements target domain parsing accuracy using improved tagger domain adaptation structural correspondence learning domain adaptation structural correspondence learning domain adaptation structural correspondence learning 
integer linear programming recently used decoding number probabilistic models order enforce global constraints however certain applications dependency parsing machine translation complete formulation decoding problem integer linear program renders solving intractable present approach solves problem incrementally thus avoid creating intractable integer linear programs approach applied dutch dependency parsing show addition linguistically motivated constraints yield significant improvement incremental integer linear programming non-projective dependency parsing incremental integer linear programming non-projective dependency parsing incremental integer linear programming non-projective dependency parsing 
paper describes attempt automatic semantic role labeling srl nombank project new york university annotate argument structures common nouns penn treebank ii corpus treat nombank srl task classification problem explore possibility adapting features previously shown useful srl systems various features explored test section best system achieves score correct automatic syntactic parse trees used knowledge first reported automatic nombank srl system semantic role labeling nombank: maximum entropy approach semantic role labeling nombank: maximum entropy approach semantic role labeling nombank: maximum entropy approach 
paper demonstrates two methods improve performance instancebased learning ibl algorithms problem semantic role labeling srl two ibl algorithms utilized neighbor knn priority maximum likelihood pml modified combination method experimental data wsj brown corpus test sets conll shared task shown applying predicateargument recognition algorithm para data preprocessing stage allows knn pml deliver respectively wsj brown corpus increase measurement recent published pml results problem palmer et al training times ibl algorithms much faster widely used techniques srl parsing support vector machines perceptrons etc feature reduction effects para yield testing processing speeds around second per sentence knn second per sentence pml respectively suggesting ibl could practical way perform srl nlp applications employed realtime machine translation automatic speech recognition semantic role labeling via instance-based learning semantic role labeling via instance-based learning semantic role labeling via instance-based learning 
develop admissible search heuristics synchronous parsing inversion transduction grammar present results bitext alignment machine translation decoding also combine dynamic programming hook trick search decoding techniques make possible find optimal alignments much quickly make possible find optimal translations first time even presence pruning able achieve higher bleu scores amount computation efficient search inversion transduction grammar efficient search inversion transduction grammar efficient search inversion transduction grammar 
transliterating foreign words chinese pronunciation source word spelled kanji characters kanji comprises ideograms individual pronunciation may represented one character however different kanji characters convey different meanings impressions characters must selected carefully paper propose transliteration method models pronunciation impression whereas existing methods model impression given source word impression keywords related source word method derives possible transliteration candidates sorts according probability evaluate method experimentally modeling impression probabilistic transliteration chinese modeling impression probabilistic transliteration chinese modeling impression probabilistic transliteration chinese 
paper describe coreference resolution method employs classification clusterization phase novel way clusterization produced graph cutting algorithm nodes graph correspond mentions text whereas edges graph constitute confidences derived coreference classification experiments graph cutting algorithm coreference resolution called bestcut achieves performance bestcut: graph algorithm coreference resolution bestcut: graph algorithm coreference resolution bestcut: graph algorithm coreference resolution 
adapting language models across styles topics lecture transcription involves combining generic style models content relevant target document work investigate use hidden markov model latent dirichlet allocation obtain syntactic state semantic topic assignments word instances training corpus labels construct style topic models better model target document extend traditional topic models experiments static model interpolation yielded perplexity relative word error rate wer reduction respectively adapted trigram baseline adaptive interpolation mixture components reduced perplexity wer modest style topic language model adaptation using hmm-lda style topic language model adaptation using hmm-lda style topic language model adaptation using hmm-lda 
supervised sense disambiguation methods instances target word senses instances defined sense inventories tagged instances senses training data used model order identification method avoid misclassification instances undefined senses discovering new senses mixed data tagged untagged corpora algorithm tries obtain natural partition mixed data maximizing stability criterion defined classification result extended label propagation algorithm possible values number senses sense number model order experimental results data indicate outperforms svm partially supervised classification algorithm clustering based model order identification algorithm tagged data incomplete partially supervised sense disambiguation learning sense number tagged untagged corpora partially supervised sense disambiguation learning sense number tagged untagged corpora partially supervised sense disambiguation learning sense number tagged untagged corpora 
markov conditional random fields crfs crfs two popular models sequence segmentation labeling models advantages terms type features naturally represent propose hybrid model capable representing types features describe efficient algorithms training inference demonstrate hybrid model achieves error reductions standard crf crf resp task chinese word segmentation also propose use powerful feature crf log conditional odds given token sequence constitutes chunk according generative model reduces error additional best system achieves highest reported score test set hybrid markov/semi-markov conditional random field sequence segmentation hybrid markov/semi-markov conditional random field sequence segmentation hybrid markov/semi-markov conditional random field sequence segmentation 
entity annotation involves attaching label name organization sequence tokens document current machine learningbased approaches task operate document level present new generic approach entity annotation uses inverse index typically created rapid based searching document collection define set operations inverse index allows us create annotations defined cascading regular expressions entity annotations entire document corpus created purely index need access original documents experiments two publicly available data sets show significant performance improvements documentbased annotators entity annotation based inverse index operations entity annotation based inverse index operations entity annotation based inverse index operations 
analysis used determine related words terms many applications query expansion information retrieval ir however related words usually determined respect single word without relevant information application context example word programming may considered strongly related java applied inappropriately expand query java travel solve problem propose add another context word relation specify appropriate context relation leading term relations form java travel indonesia extracted relations used query expansion ir experiments several trec collections show new type relations performs much better traditional relations context-dependent term relations information retrieval context-dependent term relations information retrieval context-dependent term relations information retrieval 
propose general method reranker construction targets choosing candidate least expected loss rather probable candidate different approaches expected loss approximation considered including estimating probabilistic model used generate candidates estimating discriminative model trained rerank candidates learning approximate expected loss proposed methods applied parse reranking task various baseline models achieving significant improvement probabilistic models discriminative rerankers neural network parser used probabilistic model voted perceptron algorithm kernels learning algorithm loss minimization model achieves labeled constituents score standard wsj parsing task loss minimization parse reranking loss minimization parse reranking loss minimization parse reranking 
overcome problem enough manually labeled relation instances supervised relation extraction methods paper propose label propagation lp based learning algorithm relation extraction task learn labeled unlabeled data evaluation ace corpus showed labeled examples available lp based relation extraction achieve better performance svm another bootstrapping method semi-supervised relation extraction label propagation semi-supervised relation extraction label propagation semi-supervised relation extraction label propagation 
paper explores use two graph algorithms unsupervised induction tagging nominal word senses based corpora main contribution optimization free parameters algorithms evaluation publicly available gold standards present thorough evaluation comprising supervised unsupervised modes tasks results show spite information loss inherent mapping induced senses optimization parameters based small sample nouns carries nouns performing close supervised systems lexical sample task yielding wsd systems task two graph-based algorithms state-of-the-art wsd two graph-based algorithms state-of-the-art wsd two graph-based algorithms state-of-the-art wsd 
paper presents method identifying token instances verb particle constructions vpcs automatically based output rasp parser proposed method pools together instances vpcs parser output uses sentential context instance differentiate vpcs show technique perform identifying vpcs wall street journal brown corpus data taken penn treebank automatic identification english verb particle constructions using linguistic features automatic identification english verb particle constructions using linguistic features automatic identification english verb particle constructions using linguistic features 
requirement large labelled training corpora widely recognized key bottleneck use learning algorithms information extraction present tplex learning algorithm information extraction acquire extraction patterns small amount labelled text conjunction large amount unlabelled text compared previous work tplex two novel features first algorithm require redundancy fragments extracted redundancy extraction patterns second bootstrapping methods identify highest quality fragments unlabelled data assume reliable manually labelled data subsequent iterations contrast tplex scoring mechanism prevents errors snowballing recording reliability fragments extracted unlabelled data experiments several benchmarks demonstrate tplex usually competitive various algorithms little labelled training data available transductive pattern learning information extraction transductive pattern learning information extraction transductive pattern learning information extraction 
paper extend existing statistical parsing model produce richer output parse trees annotated propbank semantic role labels results show model robustly extended produce complex output parse trees without loss performance suggest joint inference syntactic semantic representations viable alternative approaches based pipeline local processing steps robust parsing proposition bank robust parsing proposition bank robust parsing proposition bank 
paper proposes method learning discriminative parser machine translation reordering using aligned parallel text done treating parser derivation tree latent variable model trained maximize reordering accuracy demonstrate efficient training possible showing two measures reordering accuracy factored parse tree using model framework results significant gains translation accuracy standard phrasebased smt previously proposed unsupervised syntax induction methods inducing discriminative parser optimize machine translation reordering inducing discriminative parser optimize machine translation reordering inducing discriminative parser optimize machine translation reordering 
paper studies strategy identifying using expressions statistical machine translation performance proposed strategy various types expressions like nouns verbs evaluated terms alignment quality well translation accuracy evaluations performed using data namely european parliament corpus results translation tasks presented discussed grouping multi-word expressions according part-of-speech statistical machine translation grouping multi-word expressions according part-of-speech statistical machine translation grouping multi-word expressions according part-of-speech statistical machine translation 
granularity word senses current general purpose sense inventories often narrow sense distinctions irrelevant many nlp applications particularly problem wordnet widely used word sense disambiguation wsd several attempts group wordnet senses given number different information sources order reduce granularity propose relating senses matter degree permit softer notion relationships senses compared fixed groupings granularity varied according needs application compare two approaches produced humans work also contrast goldstandard another used previous research automatic methods relating senses use methods wsd relating wordnet senses word sense disambiguation relating wordnet senses word sense disambiguation relating wordnet senses word sense disambiguation 
investigate methods add syntactically motivated features statistical machine translation system reranking framework goal analyze whether shallow parsing techniques help identifying ungrammatical hypotheses show improvements possible utilizing supertagging lightweight dependency analysis link grammar parser based chunk parser adding features lists discriminatively training system development set increases bleu score test set reranking translation hypotheses using structural properties reranking translation hypotheses using structural properties reranking translation hypotheses using structural properties 
recent work design automatic systems semantic role labeling shown feature engineering complex task modeling implementation point view tree kernels alleviate complexity kernel functions generate features automatically require less software development data extraction paper study several tree kernel approaches boundary detection argument classification comparative experiments support vector machines kernels conll dataset show simple tree manipulations trigger automatic feature engineering highly improves accuracy efficiency phases moreover use different classifiers internal nodes maintains accuracy highly improves efficiency tree kernel engineering semantic role labeling systems tree kernel engineering semantic role labeling systems tree kernel engineering semantic role labeling systems 
paper describes approach learning concept definitions operates fully parsed text subcorpus dutch version wikipedia searched sentences syntactic properties definitions next experimented various text classification techniques distinguish actual definitions sentences maximum entropy classifier incorporates features referring position sentence document well various syntactic features gives best results learning identify definitions using syntactic features learning identify definitions using syntactic features learning identify definitions using syntactic features 
tools hierarchical annotation typed dialogue myroslava dzikovska charles callaway elaine farrow human communication research centre university edinburgh buccleuch place edinburgh eh lw united kingdom mdzikovs ccallawa efarrow inf ed ac uk tools hierarchical annotation typed dialogue tools hierarchical annotation typed dialogue tools hierarchical annotation typed dialogue 
present method recognizing semantic role arguments using kernel weighted marked ordered labeled trees wmolt kernel extend kernels marked ordered labeled trees kazama torisawa mark weighted according importance improve accuracy giving weights subtrees contain predicate argument nodes ability although kazama torisawa presented fast training tree kernels slow classification runtime remained solved paper give solution uses efficient dp updating procedure applicable argument recognition demonstrate wmolt kernel improves accuracy method makes recognition times faster naive classification semantic role recognition using kernels weighted marked ordered labeled trees semantic role recognition using kernels weighted marked ordered labeled trees semantic role recognition using kernels weighted marked ordered labeled trees 
recent work semantic role labeling srl shown achieve high accuracy joint inference whole predicate argument structure applied paper used syntactic subtrees span potential argument structures target predicate tree kernel functions allows support vector machines discern correct incorrect predicate structures based joint probability arguments experiments propbank data show classification based tree kernels improve srl systems semantic role labeling via tree kernel joint inference semantic role labeling via tree kernel joint inference semantic role labeling via tree kernel joint inference 
propose generalization supervised dop model unsupervised learning new model call initially assigns possible unlabeled binary trees set sentences next uses subtrees large subset binary trees compute probable parse trees show implemented technique report competitive results english wsj german negra chinese ctb data best knowledge first paper accurately bootstraps structure wall street journal sentences words obtaining roughly accuracy binarized supervised pcfg show previous approaches unsupervised parsing shortcomings either constrain lexical structural context unsupervised parsing u-dop unsupervised parsing u-dop unsupervised parsing u-dop 
describe online learning dependency parser shared task based projective algorithm eisner experiment large feature set models tokens involved dependencies immediate context surfacetext distance tokens syntactic context dominated dependency experiments treatment multilingual information totally blind projective dependency parsing perceptron projective dependency parsing perceptron projective dependency parsing perceptron 
paper presents deterministic parsing algorithm projective dependency grammar way algorithm finds local optimum dynamically constraint procedure made use structure information algorithm parses sentences linear time labeling integrated parsing parser achieves labeled attachment score average conllx shared task dependency parsing based dynamic local optimization dependency parsing based dynamic local optimization dependency parsing based dynamic local optimization 
present multilingual dependency parser evaluate diverse languages first stage based unlabeled dependency parsing models described mcdonald pereira augmented morphological features subset languages second stage takes output first labels edges dependency graph appropriate syntactic categories using globally trained sequence classifier components graph report results shared task buchholz et al data sets present error analysis multilingual dependency analysis two-stage discriminative parser multilingual dependency analysis two-stage discriminative parser multilingual dependency analysis two-stage discriminative parser 
unlexicalized probabilistic parsing general flexible approach sometimes reaches competitive results multilingual dependency parsing even minimum information supplied furthermore integrating parser results good long dependencies tagger results good short range dependencies easily adaptable treebank peculiarities gives competitive results languages language independent probabilistic context-free parsing bolstered machine learning language independent probabilistic context-free parsing bolstered machine learning language independent probabilistic context-free parsing bolstered machine learning 
following mcdonald et al present application maximum spanning tree algorithm directed graph labeled dependency parsing using variant voted perceptron collins collins roark crammer singer discriminatively trained parser fashion one epoch training generally able attain average results conll shared task maximum spanning tree algorithm non-projective labeled dependency parsing maximum spanning tree algorithm non-projective labeled dependency parsing maximum spanning tree algorithm non-projective labeled dependency parsing 
paper propose multilingual dependency parser generalizes efficient parsing algorithm first phase root parser postprocessor second third stages main focus work provide efficient parser practical use combining lexical features toward language independent parsing experimental results show method outperforms maltparser languages expect efficient model applicable languages exploration deterministic efficient dependency parsing exploration deterministic efficient dependency parsing exploration deterministic efficient dependency parsing 
paper describes new methodology enhancing quality relevance suggestions provided users interactive systems show using conditional random fields combine relevance feedback gathered users along information derived discourse structure coherence accurately identify irrelevant suggestions nearly enhanced interactive question-answering conditional random fields enhanced interactive question-answering conditional random fields enhanced interactive question-answering conditional random fields 
evaluation machine translation output important difficult task last years variety automatic evaluation measures studied like word error rate wer position independent word error rate per bleu nist scores become widely used tools comparing different systems well evaluating improvements within one system however measures give details nature translation errors therefore analysis generated output needed order identify main problems focus research efforts hand human evaluation time consuming expensive task paper investigate methods using information automatic evaluation standard error measures wer per calculated distinct word classes forms order get better idea nature translation errors possibilities improvements morpho-syntactic information automatic error analysis statistical machine translation output morpho-syntactic information automatic error analysis statistical machine translation output morpho-syntactic information automatic error analysis statistical machine translation output 
paper describes sentiment detection system participated subtask task sentiment analysis twitter system uses supervised approach learn features training data classify expressions new tweets positive negative neutral proposed approach helps understand relevant features contribute classification task kea: expression-level sentiment analysis twitter data kea: expression-level sentiment analysis twitter data kea: expression-level sentiment analysis twitter data 
state art statistical machine translation currently represented phrasebased models typically incorporate large number probabilities word work investigate data compression methods efficiently encoding probabilities usually encoded floating point numbers measured impact compression translation quality decoder trained two distinct tasks translation european parliament speeches spanish english translation news agencies chinese english show simple quantization scheme probabilities encoded bits relative loss bleu score two tasks respectively many bits needed store probabilities phrase-based translation? many bits needed store probabilities phrase-based translation? many bits needed store probabilities phrase-based translation? 
paper reports translation results exploiting parallel texts statistical machine translation workshop parallel texts studied different techniques improve standard translation system mainly introduce two reordering approaches add morphological information talp phrase-based statistical translation system european language pairs talp phrase-based statistical translation system european language pairs talp phrase-based statistical translation system european language pairs 
paper describes statistical machine translation decoder phramer paper also presents utd hltri system build wmt shared task goal improve translation quality enhancing translation table preprocessing source language text phramer - open source statistical phrase-based translator phramer - open source statistical phrase-based translator phramer - open source statistical phrase-based translator 
work presents translation results three data sets made available shared task exploiting parallel texts statistical machine translation workshop statistical machine translation results presented generated using statistical machine translation system enhanced last year evaluation tagged target language model using tags translation directions translation task baseline system allows linguistically motivated sourceside reorderings n-gram-based smt system enhanced reordering patterns n-gram-based smt system enhanced reordering patterns n-gram-based smt system enhanced reordering patterns 
within framework described rissanen de marcken goldsmith pointers used avoid repetition phonological material work familiar assumed one way items could pointed purpose paper describe compare several different methods satisfies mdl basic requirements different consequences treatment linguistic phenomena particular assess conditions different ways pointing yield compact descriptions data theoretical empirical perspective exploring variant definitions pointer length mdl exploring variant definitions pointer length mdl exploring variant definitions pointer length mdl 
current definitional question answering systems apply lexicosyntactic patterns identify definitions analyzing large set online definitions study shows semantic types definienda constrain lexical semantics lexicosyntactic patterns definientia example heart semantic type part organ organ definition heart locates lungs incorporates lexicosyntactic patterns term locates terms lung semantic type part organ organ contrast aids different semantic type definition infectious disease caused human immunodeficiency virus consists different lexicosyntactic patterns causes terms infectious disease semantic type semantic types defined widely used biomedical knowledge resource unified medical language system umls semantics definiendum constrains lexical semantics lexicosyntactic patterns definiens semantics definiendum constrains lexical semantics lexicosyntactic patterns definiens semantics definiendum constrains lexical semantics lexicosyntactic patterns definiens 
semantic textual similarity sts systems rate degree semantic equivalence graded scale similar year set two tasks core task core ii task typed core similar set semeval sts task pairs sentences sources related yet different genre set namely year included newswire headlines machine translation evaluation datasets multiple lexical resource glossed sets typed hand novel tries characterize two items deemed similar using cultural heritage items described metadata title author description several types similarity defined including similar author similar time period similar location annotation tasks leverages crowdsourcing relative high interannotator correlation ranging core task attracted participants runs typed task attracted teams runs *sem 2013 shared task: semantic textual similarity *sem 2013 shared task: semantic textual similarity *sem 2013 shared task: semantic textual similarity 
describe three semantic text similarity systems developed sem sts shared task results corresponding three runs shared word similarity feature combined lsa word similarity wordnet knowledge first achieved best mean score submitted runs used simple term alignment algorithm augmented penalty terms two runs ranked second fourth used support vector regression models combine larger sets features umbc_ebiquity-core: semantic textual similarity systems umbc_ebiquity-core: semantic textual similarity systems umbc_ebiquity-core: semantic textual similarity systems 
contrasts thus gopubmed doms schroeder clustering system retrieves abstracts using pmc search clusters according terms gene ontology go scientists face two major obstacles using ir ie technology select best keywords intended search assess validity relevance extracted information address latter problem bioki provides convenient access different degrees context allowing user view information three different formats abstract level ranked list articles provides first five lines pertinent text segment selected bioki similar snippets provided google clicking article link open new window articles available html format currently processed view article retrieved pmc left different text segments ordered relevance user selected keywords right user thus possibility assess information context text segment first original desired ranking address problem finding best keywords bioki enzymes explores different approaches research enzymology users specified standard pattern information retrieval reflected user interface enzymes proteins catalyze reactions differently different bioki:enzymes - adaptable system locate low-frequency information full-text proteomics articles bioki:enzymes - adaptable system locate low-frequency information full-text proteomics articles bioki:enzymes - adaptable system locate low-frequency information full-text proteomics articles 
william cohen machine learning department carnegie mellon university pittsburgh pa wcohen cs cmu edu graph-search framework geneid ranking graph-search framework geneid ranking graph-search framework geneid ranking 
proceedings bionlp workshop linking natural language processing biology pages new york city june association computational linguistics rapid adaptation pos tagging domain specific uses john miller michael bloodgood manabu torii computer information sciences biostatistics bioinformatics biomathematics university delaware georgetown university medical center newark de washington dc jmiller bloodgoo vijay cis udel edu mt georgetown edu rapid adaptation pos tagging domain specific uses rapid adaptation pos tagging domain specific uses rapid adaptation pos tagging domain specific uses 
paper describes ongoing work thoughts developing grammar learning system based construction grammar formalism necessary modules presented first results challenges formalizing grammar shown furthermore point major reasons chose construction grammar fitting formalism purposes approach ideas learning new linguistic phenomena ranging holophrastic constructions compositional ones presented searching grammar right searching grammar right searching grammar right 
translator first parses input parsetree recursively converts tree string model conversion extended transducer trees gives system expressive power flexibility also define direct probability model use dynamic programming algorithm search best derivation model extended general framework order rescore features like language models devise algorithm generate translations rescoring initial experimental results translation presented syntax-directed translator extended domain locality syntax-directed translator extended domain locality syntax-directed translator extended domain locality 
paper presents series efficient dp based algorithms decoding alignment computation statistical machine translation smt decoding algorithms analyzed terms shortest algorithms similarity decoding algorithms speech recognition demonstrated paper contains following original contributions decoding algorithm tillmann ney extended formal way handle phrases novel pruning strategy increased translation speed presented novel alignment algorithm presented computes phrase alignment efficiently case consistent underlying word alignment certain restrictions algorithms handle problems efficiently generally np complete knight efficient dynamic programming search algorithms phrase-based smt efficient dynamic programming search algorithms phrase-based smt efficient dynamic programming search algorithms phrase-based smt 
present word prediction model based igtree induction algorithm favorable scaling abilities functional equivalence models backoff smoothing first series experiments train reuters newswire text test either type data general fictional text demonstrate system exhibits increases prediction accuracy increasing numbers training examples trained million words newswire text prediction accuracies range fictional text newswire text second series experiments compare prediction confusable prediction task specialized predicting among limited sets words confusable prediction yields high accuracies nine example confusable sets genres text confusable approach outperforms approach data difference decreases all-word prediction ultimate confusible disambiguation all-word prediction ultimate confusible disambiguation all-word prediction ultimate confusible disambiguation 
classification techniques deploy supervised labeled instances train classifiers various classification problems however labeled instances limited expensive time consuming obtain due need experienced human annotators meanwhile large amount unlabeled data usually easy obtain learning addresses problem utilizing unlabeled data along supervised labeled data build better classifiers paper introduce approach based mutual reinforcement graphs obtain labeled data enhance classifier accuracy approach used supplement maximum entropy model training ace relation detection characterization rdc task ace rdc considered hard task information extraction due lack large amounts training data inconsistencies available data proposed approach provides relative improvement state art supervised baseline system graph based semi-supervised approach information extraction graph based semi-supervised approach information extraction graph based semi-supervised approach information extraction 
many information retrieval selection tasks valuable score much text certain entity compute much text discusses entity respect certain viewpoint paper interested giving aboutness score text input query person name want measure aboutness respect biographical data person present algorithm compare results approaches measuring aboutness entity text measuring aboutness entity text measuring aboutness entity text 
document indexing representation relations important document clustering retrieval paper combine dimensionality reduction method association measure within generalized latent semantic analysis framework evaluate glsa document clustering task graph-based generalized latent semantic analysis document representation graph-based generalized latent semantic analysis document representation graph-based generalized latent semantic analysis document representation 
introduce chinese whispers randomized algorithm number edges detailed definition algorithm discussion strengths weaknesses performance chinese whispers measured natural language processing nlp problems diverse language separation acquisition syntactic word classes word sense disambiguation fact employed property holds many graphs nlp chinese whispers - efficient graph clustering algorithm application natural language processing problems chinese whispers - efficient graph clustering algorithm application natural language processing problems chinese whispers - efficient graph clustering algorithm application natural language processing problems 
ve ronis recently proposed innovative unsupervised algorithm word sense disambiguation based graphs called hyperlex paper explores two sides algorithm first extend ve ronis work optimizing free parameters set words different target set second given empirical comparison among unsupervised systems respect supervised systems seldom made used corpora map induced senses standard lexicon wordnet publicly available gold standard senseval english lexical sample results nouns show thanks optimization parameters mapping method hyperlex obtains results close supervised systems using kind features given information loss inherent mapping step fact parameters tuned another set words interesting results evaluating optimizing parameters unsupervised graph-based wsd algorithm evaluating optimizing parameters unsupervised graph-based wsd algorithm evaluating optimizing parameters unsupervised graph-based wsd algorithm 
present machine translation framework incorporate arbitrary features input output sentences core approach novel decoder based lattice parsing quasisynchronous grammar smith eisner syntactic formalism require source target trees isomorphic using generic approximate dynamic programming techniques decoder handle features similar approximate inference techniques support efficient parameter estimation hidden variables use decoder conduct controlled experiments translation task compare lexical phrase syntax combined models measure effects various restrictions nonisomorphism feature-rich translation quasi-synchronous lattice parsing feature-rich translation quasi-synchronous lattice parsing feature-rich translation quasi-synchronous lattice parsing 
present implemented machine learning system automatic detection nonreferential spoken dialog system builds shallow features extracted dialog transcripts experiments indicate level performance makes system usable preprocessing filter coreference resolution system also report results annotation study dealing classification naive subjects automatic detection nonreferential spoken multi-party dialog automatic detection nonreferential spoken multi-party dialog automatic detection nonreferential spoken multi-party dialog 
clustering syntactic positions similar semantic requirements pablo gamallo universidade de santiago de compostela alexandre agustini pontif cia universidade cato lica rio grande sul centro de informa tica tecnologias de informaza gabriel lopescentro de informa tica tecnologias de informaza article describes unsupervised strategy acquire requirements nouns verbs adjectives partially parsed text corpora linguistic notion requirement underlying strategy based two specific assumptions first assumed two words dependency mutually required phenomenon called corequirement second also claimed set words occurring similar positions defines extensionally requirements associated positions main aim learning strategy presented article identify clusters similar positions identifying words define requirements extensionally strategy allows us learn syntactic semantic requirements words different positions information used solve attachment ambiguities results particular task evaluated end article extensive experimentation performed portuguese text corpora clustering syntactic positions similar semantic requirements clustering syntactic positions similar semantic requirements clustering syntactic positions similar semantic requirements 
sentence fusion multidocument news summarization regina barzilay massachusetts institute technology kathleen mckeown columbia university system produce informative summaries highlighting common information found many online documents help web users pinpoint information need without extensive reading article introduce sentence fusion novel generation technique synthesizing common information across documents sentence fusion involves local multisequence alignment identify phrases conveying similar information statistical generation combine common phrases sentence sentence fusion moves summarization field use purely extractive methods generation abstracts contain sentences found input documents synthesize information across sources sentence fusion multidocument news summarization sentence fusion multidocument news summarization sentence fusion multidocument news summarization 
retrieval flexible framework lexical distributional similarity julie weeds david weir university sussex techniques exploit knowledge distributional similarity words proposed many areas natural language processing example language modeling sparse data problem alleviated estimating probabilities unseen events probabilities seen similar events applications distributional similarity taken approximation semantic similarity however due wide range potential applications lack strict definition concept distributional similarity many methods calculating distributional similarity proposed adopted work flexible parameterized framework calculating distributional similarity proposed within framework problem finding distributionally similar words cast one retrieval cr precision recall measured analogy way measured document retrieval shown number popular existing measures distributional similarity simulated parameter settings within cr framework article cr framework used systematically investigate three fundamental questions concerning distributional similarity first relationship lexical similarity necessarily symmetric advantages gained considering asymmetric relationship second inherently salient others calculation distributional similarity third necessary consider difference extent word occurs type two tasks used evaluation automatic thesaurus generation possible achieve significantly better results tasks varying parameters within cr framework rather using existing distributional similarity measures also shown single unparameterized measure unlikely able better tasks due inherent asymmetry lexical substitutability therefore also lexical distributional similarity co-occurrence retrieval: flexible framework lexical distributional similarity co-occurrence retrieval: flexible framework lexical distributional similarity co-occurrence retrieval: flexible framework lexical distributional similarity 
chinese word segmentation named entity recognition pragmatic approach jianfeng gao microsoft research asia mu li microsoft research asia andi wu grapecity inc huang microsoft research asia article presents pragmatic approach chinese word segmentation differs previous approaches mainly three respects first theoretical linguists defined chinese words using various linguistic criteria chinese words study defined pragmatically segmentation units whose definition depends used processed realistic computer applications second propose pragmatic mathematical framework segmenting known words detecting unknown words different types morphologically derived words factoids named entities unlisted words performed simultaneously unified way tasks usually conducted separately systems finally assume existence universal word segmentation standard instead argue necessity multiple segmentation standards due pragmatic fact different natural language processing applications might require different granularities chinese words pragmatic approaches implemented adaptive chinese word segmenter called msrseg described detail consists two components generic segmenter based framework linear mixture models provides unified approach five fundamental features chinese language processing lexicon word processing morphological analysis factoid detection named entity recognition new word identification set output adaptors adapting output different standards evaluation five test sets different standards shows adaptive system achieves performance test sets chinese word segmentation named entity recognition: pragmatic approach chinese word segmentation named entity recognition: pragmatic approach chinese word segmentation named entity recognition: pragmatic approach 
extend blum chawla graph algorithm structured problems extension alternatively viewed joint inference method set training test instances parts instances interact prespecified associative network method efficient approximation relaxation small training data sets method achieves relative error reduction transductive structured classification constrained min-cuts transductive structured classification constrained min-cuts transductive structured classification constrained min-cuts 
difficulties involved spelling error detection correction language investigated work conceptualization spellnet weighted network words edges indicate orthographic proximity two words construct spellnets three languages bengali english hindi appropriate mathematical analysis intuitive justification interpret different topological metrics spellnet perspective issues related make many interesting observations significant among probability making real word error language propotionate average weighted degree spellnet found highest hindi followed bengali english difficult develop perfect spell-checker? cross-linguistic analysis complex network approach difficult develop perfect spell-checker? cross-linguistic analysis complex network approach difficult develop perfect spell-checker? cross-linguistic analysis complex network approach 
paper reports progress applying partially observable markov decision processes pomdps commercial dialog domain troubleshooting troubleshooting domain spoken dialog system helps user fix product failed dsl connection past work argued pomdp principled approach building spoken dialog systems simpler domain paper explains pomdps formulation extended complex troubleshooting domain results dialog simulation verify pomdp outperforms handcrafted baseline applying pomdps dialog systems troubleshooting domain applying pomdps dialog systems troubleshooting domain applying pomdps dialog systems troubleshooting domain 
paper describe sourceside reordering method based syntactic chunks statistical machine translation first shallow parse source language sentences reordering rules automatically learned chunks word alignments translation rules used generate reordering lattice sentence experimental results reported task showing improvement bleu score absolute various test sets better computational efficiency reordering decoding experiments also show reordering performs better chunk-level reordering source language sentences automatically learned rules statistical machine translation chunk-level reordering source language sentences automatically learned rules statistical machine translation chunk-level reordering source language sentences automatically learned rules statistical machine translation 
present phrasal inversion transduction grammar alternative joint phrasal translation models syntactic model similar flatstring phrasal predecessors admits algorithms viterbi alignment em training demonstrate consistency constraints allow flat phrasal models scale also help itg algorithms producing faster algorithm also show phrasal translation tables produced itg superior flat joint phrasal model producing point improvement bleu score finally explore first time utility joint phrasal translation model word alignment method inversion transduction grammar joint phrasal translation modeling inversion transduction grammar joint phrasal translation modeling inversion transduction grammar joint phrasal translation modeling 
factoring synchronous grammar equivalent grammar smaller number nonterminals rule enables synchronous parsing algorithms lower complexity problem formalized searching given permutation minimal branching factor paper modifying algorithm uno yagiura closely related problem finding common intervals two permutations achieve linear time algorithm permutation factorization problem also use algorithm analyze maximum scfg rule length needed cover data various language pairs factorization synchronous context-free grammars linear time factorization synchronous context-free grammars linear time factorization synchronous context-free grammars linear time 
present main ideas behind new machine translation system based reducing machine translation task task tree labeling reduced sequence decisions four varieties discriminatively trained optimal tree labeling translation found simple search early system founded ideas shown competitive pharaoh trained small subsection europarl corpus motivation statistical machine translation dominated translation paradigm och ney paradigm sentences translated source language target language repeated substitution contiguous word sequences phrases source language word sequences target language training phrase translation model builds top standard statistical word alignment training corpus identifying corresponding word blocks assuming linguistic analysis source target language decoding systems typically rely language models simple statistical reordering models shuffle phrases order coherent target language limits approach ultimately achieve machine translation based deeper analysis syntactic structure sentence long identified desirable objective principle consider wu yamada knight however attempts retrofit syntactic information paradigm met enormous success koehn et al och et al purely machine translation systems continue outperform syntax hybrids work try make fresh start machine translation discarding paradigm designing machine translation system ground using syntax central guiding star evaluation bleu detailed manual error analysis nascent system show new approach might well potential finally realize promises syntax problem formulation want build system learn translate sentences source language destination language first step assume system learning corpus consisting triples machine translation tree labeling machine translation tree labeling machine translation tree labeling 
present novel method evaluating output machine translation mt based comparing dependency structures translation reference rather surface string forms method uses widecoverage probabilistic grammar lfg parser produce set structural dependencies sentence pair calculates precision recall dependencies dependencybased evaluation contrast popular evaluation metrics unfairly penalize perfectly valid syntactic variations translation addition allowing legitimate syntactic differences use paraphrases evaluation process account lexical variation comparison metrics sentences newswire text method reaches high correlation human scores experiment two translations sentences europarl shows contrast metrics method display high bias towards statistical models translation dependency-based automatic evaluation machine translation dependency-based automatic evaluation machine translation dependency-based automatic evaluation machine translation 
paper describes new method compare reordering constraints statistical machine translation investigate best possible oracle bleu score achievable different reordering constraints using dynamic programming efficiently find reordering approximates highest attainable bleu score given reference set reordering constraints present empirical evaluation popular reordering constraints local constraints ibm constraints inversion transduction grammar itg constraints present results translation task show reordering itg constraints improve baseline bleu points comparing reordering constraints smt using efficient bleu oracle computation comparing reordering constraints smt using efficient bleu oracle computation comparing reordering constraints smt using efficient bleu oracle computation 
empirical data regarding syntactic complexity children speech important theories language acquisition currently much data absent annotated versions childes database perliminary study show subcategorization acquisition system preiss et al used extract largescale subcategorization frequency information child ii speech within childes database without tuning demonstrate acquired information sufficiently accurate confirm extend previously reported research findings also report qualitative results used improve parsing lexical acquisition technology child language data future shoot shopping shoot tins---automatic lexical acquisition childes database shoot shopping shoot tins---automatic lexical acquisition childes database shoot shopping shoot tins---automatic lexical acquisition childes database 
semantic networks used successfully explain access mental lexicon topological analyses networks focused acquisition generation extend work look models distinguish semantic relations find properties association networks found networks consistent studies childhood acquisition relationships find distributional models language acquisition display similar topological properties networks topology synonymy homonymy networks topology synonymy homonymy networks topology synonymy homonymy networks 
current statistical machine translation systems handle translation process transformation string symbols another string symbols normally symbols dealt words different languages sometimes additional information included like morphological data work try push approach limit working level words treating source target sentences string letters try find nearly unmodified translation system able cope problem whether capable generalize translation rules example level word suffixes translation unseen words experiments carried translation catalan spanish translate letters? translate letters? translate letters? 
evaluation error analysis machine translation output important difficult tasks work propose novel method obtaining details actual translation errors generated output introducing decomposition word error rate wer position independent word error rate per different pos classes furthermore investigate two possible aspects use decompositions automatic error analysis estimation inflectional errors distribution missing words pos classes obtained results shown correspond results human error analysis results obtained european parliament plenary session corpus spanish english give better overview nature translation errors well ideas put efforts possible improvements translation system word error rates: decomposition pos classes applications error analysis word error rates: decomposition pos classes applications error analysis word error rates: decomposition pos classes applications error analysis 
paper present bayesian learning based method train word dependent transition models hmm based word alignment present word alignment results canadian hansards corpus compared conventional hmm ibm model show method gives consistent significant alignment error rate aer reduction also conducted machine translation mt experiments europarl corpus mt results show word alignment based method used machine translation system yield absolute improvement bleu score compared conventional hmm compared ibm model based word alignment using word-dependent transition models hmm-based word alignment statistical machine translation using word-dependent transition models hmm-based word alignment statistical machine translation using word-dependent transition models hmm-based word alignment statistical machine translation 
introduce novel evaluation scheme human evaluation different machine translation systems method based direct comparison two sentences time human judges binary judgments used decide possible rankings systems advantages new method lower dependency extensive evaluation guidelines tighter focus typical evaluation task namely ranking systems furthermore argue machine translation evaluations regarded statistical processes human automatic evaluation show confidence ranges evaluation measures wer ter computed accurately efficiently without resort monte carlo estimates give example new evaluation scheme well comparison classical automatic human evaluation data recent international evaluation campaign human evaluation machine translation binary system comparisons human evaluation machine translation binary system comparisons human evaluation machine translation binary system comparisons 
describe approach adapting statistical machine translation system new domains using weights depend text distances mixture components investigate number variants approach including versus dynamic adaptation linear versus loglinear mixtures language translation model adaptation different methods assigning weights granularity source unit adapted best methods achieve gains approximately one bleu percentage point art baseline system mixture-model adaptation smt mixture-model adaptation smt mixture-model adaptation smt 
paper evaluates translation quality machine translation systems language pairs translating french german spanish czech english back carried extensive human evaluation allowed us rank different mt systems also perform analysis evaluation process measured timing agreement three types subjective evaluation measured correlation automatic evaluation metrics human judgments reveals surprising facts commonly used methodologies (meta-) evaluation machine translation (meta-) evaluation machine translation (meta-) evaluation machine translation 
one main challenge statistical machine translation smt dealing word order main idea statistical machine reordering smr approach use powerful techniques smt systems generate weighted reordering graph smt systems technique supplies reordering constraints smt system using statistical criteria paper experiment different graph pruning guarantees translation quality improvement due reordering low increase computational cost smr approach capable generalizing reorderings learned training using word classes instead words experiment statistical morphological classes order choose capture probable reorderings satisfactory results reported wmt es en task system outperforms terms bleu wmt official baseline system analysis statistical morphological classes generate weigthed reordering hypotheses statistical machine translation system analysis statistical morphological classes generate weigthed reordering hypotheses statistical machine translation system analysis statistical morphological classes generate weigthed reordering hypotheses statistical machine translation system 
investigate effect corpus size combining supervised unsupervised learning two types attachment decisions relative clause attachment prepositional phrase attachment supervised component collins parser trained wall street journal unsupervised component gathers lexical statistics unannotated corpus newswire text find combined system improves performance parser small training sets surprisingly size unannotated corpus little effect due noisiness lexical statistics acquired unsupervised learning effect corpus size combining supervised unsupervised training disambiguation effect corpus size combining supervised unsupervised training disambiguation effect corpus size combining supervised unsupervised training disambiguation 
present portage statistical machine translation system participated shared task acl second workshop statistical machine translation focus description improvements incorporated system last year include adapted language models phrase table pruning ibm decoder feature rescoring posterior probabilities nrc's portage system wmt 2007 nrc's portage system wmt 2007 nrc's portage system wmt 2007 
paper describes development statistical machine translation system based moses decoder wmt shared tasks several different translation strategies explored also use statistical language model based continuous representation words vocabulary means expect take better advantage limited amount training data finally investigated usefulness second reference translation development data building statistical machine translation system french using europarl corpus building statistical machine translation system french using europarl corpus building statistical machine translation system french using europarl corpus 
describe architecture allows combine statistical machine translation smt machine translation rbmt setup use variant standard smt technology align translations one rbmt systems source text incorporate phrases extracted alignments phrase table smt system use decoder moses find good combinations phrases smt training data phrases derived rbmt first experiments based hybrid architecture achieve promising results multi-engine machine translation open-source smt decoder multi-engine machine translation open-source smt decoder multi-engine machine translation open-source smt decoder 
paper describe interactive systems laboratories isl machine translation system used shared task machine translation european languages acl workshop statistical machine translation present results system combination isl mt system isl system combining rescoring lists two systems also investigate combination two systems translating different source languages namely spanish german common target language english isl phrase-based mt system 2007 acl workshop statistical machine translation isl phrase-based mt system 2007 acl workshop statistical machine translation isl phrase-based mt system 2007 acl workshop statistical machine translation 
wmt shared task uc berkeley team employed three techniques interest first used monolingual syntactic paraphrases provide syntactic variety source training set sentences second trained two language models small model large model finally made use results prior research shows cognate pairs improve word alignments contributed runs translating english spanish french german using various combinations techniques ucb system description wmt 2007 shared task ucb system description wmt 2007 shared task ucb system description wmt 2007 shared task 
describe syntax augmented machine translation system samt used shared task machine translation european languages acl workshop statistical machine translation following overview syntax augmented machine translation describe parameters components samt toolkit used generate translation results spanish english track shared task discuss relative performance submission syntax augmented mt (samt) system shared task 2007 acl workshop statistical machine translation syntax augmented mt (samt) system shared task 2007 acl workshop statistical machine translation syntax augmented mt (samt) system shared task 2007 acl workshop statistical machine translation 
meteor automatic metric machine translation evaluation demonstrated high levels correlation human judgments translation quality significantly outperforming commonly used bleu metric one several automatic metrics used year shared task within acl workshop paper recaps technical details underlying metric describes recent improvements metric latest release includes improved metric parameters extends metric support evaluation mt output spanish french german addition english meteor: automatic metric mt evaluation high levels correlation human judgments meteor: automatic metric mt evaluation high levels correlation human judgments meteor: automatic metric mt evaluation high levels correlation human judgments 
paper describes experiments machine translation additional annotation input output tokens multiple factors used explicitly model morphology vary translation scenario setup multiple factors amount information morphological tags experimental results demonstrate significant improvement translation quality terms bleu english-to-czech factored machine translation english-to-czech factored machine translation english-to-czech factored machine translation 
evaluation results recently reported et al koehn monz revealed certain cases bleu metric may reliable mt quality indicator happens instance systems evaluation based different paradigms therefore share lexicon reason mt quality aspects diverse bleu limits scope lexical dimension work suggest using metrics take account linguistic features abstract levels provide experimental results showing metrics based deeper linguistic information syntactic able produce reliable system rankings metrics based lexical matching alone specially systems evaluation different nature linguistic features automatic evaluation heterogenous mt systems linguistic features automatic evaluation heterogenous mt systems linguistic features automatic evaluation heterogenous mt systems 
propose new approach language modeling utilizes discriminative learning methods approach iterative one starting initial language model iteration generate sentences current model train classifier discriminate sentences training corpus extent succeeds classifier incorporated model lowering probability sentences classified false process repeated demonstrate effectiveness approach natural language corpus show provides improvement perplexity modified smoothed trigram refining generative language models using discriminative learning refining generative language models using discriminative learning refining generative language models using discriminative learning 
present paper concerned statistical parsing constituent structures german paper presents four experiments aim improving parsing performance coordinate structure reranking parses pcfg parser enriching input pcfg parser gold scopes conjunct reranking parser output possible scopes conjuncts permissible regard clause structure experiment reranks combination parses experiments experiments presented show nbest parsing combined reranking improves results large margin providing parser different scope possibilities reranking resulting parses results increase baseline similar one first experiment parsing reranking first experiment results higher recall vs third one higher precision vs combining two methods results best result parsing coordinations parsing coordinations parsing coordinations 
paper presents results first statistical dependency parser turkish turkish order language complex agglutinative inflectional derivational morphology presents interesting challenges statistical parsing general dependency relations portions words called inflectional groups explored statistical models use different representational units parsing used turkish dependency treebank train test parser limited initial exploration subset treebank sentences dependency links results indicate best accuracy terms dependency relations inflectional groups obtained use inflectional groups units parsing contexts around dependent employed statistical dependency parsing turkish statistical dependency parsing turkish statistical dependency parsing turkish 
names named entities often occur constituents larger noun phrases denote different types entity understanding structure embedding phrase enormously beneficial first step enhancing whatever processing intended follow named entity recognition first place paper examine integration general purpose linguistic processors together domain specific named entity recognition order carry task basenp detection report best task also report agreement score kappa task basenp annotation new data set basenps contain gene names: domain specificity genericity basenps contain gene names: domain specificity genericity basenps contain gene names: domain specificity genericity 
bionlp biological translational clinical language processing pages prague june association computational linguistics adaptation pos tagging multiple biomedical domains john miller manabu torii computer information sciences university delaware newark de jmiller vijay cis udel edu biostatistics bioinformatics biomathematics georgetown university medical center washington dc mt georgetown edu adaptation pos tagging multiple biomedical domains adaptation pos tagging multiple biomedical domains adaptation pos tagging multiple biomedical domains 
paper describes fully unsupervised automated method extraction multiword expressions mwes large corpora method aims capturing mwes intuition noun within mwe cannot easily replaced semantically similar noun implement intuition noun clustering automatically extracted using distributional similarity measures gives us clusters semantically related nouns next number statistical measures based selectional preferences developed formalize intuition approach tested dutch automatically evaluated using dutch lexical resources semantics-based multiword expression extraction semantics-based multiword expression extraction semantics-based multiword expression extraction 
paper present framework experimentation parse selection using syntactic semantic features results given syntactic features dependency relations use semantic classes exploiting semantic information hpsg parse selection exploiting semantic information hpsg parse selection exploiting semantic information hpsg parse selection 
paper discusses lexical resources based semantic roles framenet propbank verbnet used question answering especially web question answering two algorithms implemented end quite different characteristics discuss approaches applied resources combination give evaluation argue employing semantic roles indeed highly beneficial qa system question answering based semantic roles question answering based semantic roles question answering based semantic roles 
describe framework deep linguistic processing natural language understanding spoken dialogue systems goal create domaingeneral processing techniques shared across domains dialogue tasks combined optimization based ontology mapping generic lf application ontology framework tested six domains involve tasks interactive planning coordination operations tutoring learning deep linguistic processing spoken dialogue systems deep linguistic processing spoken dialogue systems deep linguistic processing spoken dialogue systems 
demand deep linguistic analysis huge volumes data means increasingly important time taken parse data minimized xle parsing model parsing system time spent unification searching valid dependency attributevalue matrices within space many valid phrase structure trees carried experiment determine whether pruning search space earlier stage parsing process results improvement overall time taken parse maintaining quality produced retrained probabilistic parser used input xle constraining valid space sentence evaluated parc dependency bank show possible decrease time taken parse maintaining accuracy pruning search space hand-crafted parsing system probabilistic parser pruning search space hand-crafted parsing system probabilistic parser pruning search space hand-crafted parsing system probabilistic parser 
paper presents approach partial parse selection robust deep processing work based chart parser hpsg parsing following definition partial parses kasper et al different partial parse selection methods presented evaluated basis multiple metrics syntactic semantic viewpoints application partial parsing spontaneous speech texts processing shows promising competence method partial parse selection robust deep processing partial parse selection robust deep processing partial parse selection robust deep processing 
score well rte even create good justifications entailments substantial lexical world knowledge needed mind present analysis sample rte positive entailment pairs identify kinds world knowledge needed fully identify justify entailment discuss several existing resources capacity supplying knowledge also briefly sketch path following build rte system implementation preliminary scoring time rte contribution paper thus framework discussing knowledge requirements posed rte exploration requirements met role lexical world knowledge rte3 role lexical world knowledge rte3 role lexical world knowledge rte3 
investigate way partially automate corpus annotation named entity recognition requiring binary decisions annotator approach based linear sequence model trained using mira learning algorithm ask annotator decide whether mention produced high recall tagger true mention false positive conclude approach reduce effort extending seed training corpus semi-automated named entity annotation semi-automated named entity annotation semi-automated named entity annotation 
proceedings linguistic annotation workshop pages prague june association computational linguistics panel session discourse annotation manfred stede dept linguistics university potsdam stede ling de janyce wiebe dept computer science university pittsburgh wiebe cs pitt edu eva hajic ova faculty math physics charles university hajicova ufal ms mff cuni cz brian reese dept linguistics univ texas austin bjreese mail utexas edu simone teufel computer laboratory univ cambridge sht cl cam uk bonnie webber school informatics univ edinburgh bonnie inf ed ac uk theresa wilson dept comp science univ pittsburgh twilson cs pitt edu discourse annotation working group report discourse annotation working group report discourse annotation working group report 
order automated navigation systems operate effectively route instructions produce must clear concise easily understood users order incorporate landmark within coherent sentence necessary first understand landmark conceptualised travellers whether perceived linelike paper investigates viability automatically classifying conceptualisation landmarks relative given city context use web data learn default conceptualisation landmarks crucially analysing preposition verb collocations classification landmark classification route directions landmark classification route directions landmark classification route directions 
present language independent approach categorization discrimination names basis text semantic similarity information experiments conducted languages romance spanish slavonic bulgarian language groups despite fact languages specific characteristics grammar obtained results encouraging show name entity method scalable different categories also different languages exhaustive experimental evaluation demonstrated approach yields better results compared baseline system language independent approach name categorization discrimination language independent approach name categorization discrimination language independent approach name categorization discrimination 
paper presents two techniques lemmatization polish person names first apply approach relies linguistic information heuristics investigate alternative method employs string distance measures provide evaluation adopted techniques using set newspaper texts lemmatization polish person names lemmatization polish person names lemmatization polish person names 
several hybrid disambiguation methods described combine strength disambiguation rules statistical taggers three different statistical hmm averaged perceptron taggers used tagging experiment using prague dependency treebank results hybrid systems better method tried czech tagging far best two worlds: cooperation statistical rule-based taggers czech best two worlds: cooperation statistical rule-based taggers czech best two worlds: cooperation statistical rule-based taggers czech 
made use parallel texts gather training test examples english lexical sample task two tracks organized task first track used examples gathered ldc corpus second track used examples gathered web corpus paper describe process gathering examples parallel corpora differences similar tasks previous senseval evaluations present results participating systems semeval-2007 task 11: english lexical sample task via english-chinese parallel text semeval-2007 task 11: english lexical sample task via english-chinese parallel text semeval-2007 task 11: english lexical sample task via english-chinese parallel text 
affective text task focuses classification emotions valence positive negative polarity news headlines meant exploration connection emotions lexical semantics paper describe data set used evaluation results obtained participating systems semeval-2007 task 14: affective text semeval-2007 task 14: affective text semeval-2007 task 14: affective text 
paper describes experience preparing data evaluating results three subtasks lexical sample semantic role labeling srl respectively tabulate analyze results participating systems semeval-2007 task-17: english lexical sample, srl words semeval-2007 task-17: english lexical sample, srl words semeval-2007 task-17: english lexical sample, srl words 
paper present system arabic semantic role labeling srl based svms standard features system evaluated released semeval development test data results show score argument boundary detection overall score complete semantic role labeling task using gold parse trees cunit: semantic role labeling system modern standard arabic cunit: semantic role labeling system modern standard arabic cunit: semantic role labeling system modern standard arabic 
present approach semantic relation extraction nominals combines shallow deep syntactic processing semantic information using kernel methods two information sources considered whole sentence relation appears ii wordnet synsets hypernymy relations candidate nominals source information represented kernel functions particular five basic kernel functions linearly combined weighted different conditions experiments carried using support vector machines classifier system achieves overall classification semantic relations nominals task fbk-irst: kernel methods semantic relation extraction fbk-irst: kernel methods semantic relation extraction fbk-irst: kernel methods semantic relation extraction 
word sense disambiguation wsd system developed english lexical sample task task semeval information retrieval lab harbin institute technology system based supervised method using svm classifier including words surrounding context neighboring words collocations syntactic relations used final raw score achieves test set best one among participating runs hit-ir-wsd: wsd system english lexical sample task hit-ir-wsd: wsd system english lexical sample task hit-ir-wsd: wsd system english lexical sample task 
paper describes hit system participation english lexical substitution task two main steps included method candidate substitute extraction candidate scoring first step candidate substitutes target word given sentence extracted wordnet second step extracted candidates scored ranked using scoring method substitute ranked first selected best substitute multiword subtask simple approach employed hit: web based scoring method english lexical substitution hit: web based scoring method english lexical substitution hit: web based scoring method english lexical substitution 
paper present semantic role labeling system submitted task multilevel semantic annotation catalan spanish context semeval core system memory based classifier makes use full syntactic information building standard features train two classifiers predict separately semantic class verb semantic roles ilk2: semantic role labeling catalan spanish using timbl ilk2: semantic role labeling catalan spanish using timbl ilk2: semantic role labeling catalan spanish using timbl 
participated english task english task used supervised learning approach svm learning algorithm knowledge sources used include local collocations surrounding words gathered training examples parallel corpora semcor dso corpus sense inventory wordnet used train system employed english task system employed english task trained sense inventory released task organizers scores recall precision english task english task respectively scores put systems first place english task second place english task nus-pt: exploiting parallel texts word sense disambiguation english all-words tasks nus-pt: exploiting parallel texts word sense disambiguation english all-words tasks nus-pt: exploiting parallel texts word sense disambiguation english all-words tasks 
optimal ensembling oe word sense disambiguation wsd method using training factors average positive vs negative training per sense posex negex predict best system classifier algorithm applicable feature set given target word official entry oe task english lexical sample task contained many design flaws thus failed show whole potential method finishing behind top system gain best base system fixed system oe finished behind net gain systems used official training data average training examples per sense also show official evaluation measure tends favor systems well words oe: wsd using optimal ensembling (oe) method oe: wsd using optimal ensembling (oe) method oe: wsd using optimal ensembling (oe) method 
present simple supervised strategy identification classification thematic roles natural language texts employ external source information automatic parse trees input sentences use features tree kernel functions applied specialized structured features resulting system semeval closed task semantic role labeling rtv: tree kernels thematic role classification rtv: tree kernels thematic role classification rtv: tree kernels thematic role classification 
proceedings th international workshop semantic evaluations pages prague june association computational linguistics sussx wsd using automatically acquired predominant senses rob koeling diana mccarthy department informatics university sussex brighton bn qj uk robk dianam sussex ac uk sussx: wsd using automatically acquired predominant senses sussx: wsd using automatically acquired predominant senses sussx: wsd using automatically acquired predominant senses 
paper describes approach word sense disambiguation followed system underlying disambiguation method uses wordnet external resource use training data results obtained english task task english subtask task presented tkb-uo: using sense clustering wsd tkb-uo: using sense clustering wsd tkb-uo: using sense clustering wsd 
syntactic knowledge important pronoun resolution traditionally syntactic information pronoun resolution represented terms features selected defined heuristically paper propose method automatically mine syntactic information parse trees pronoun resolution specifically utilize parse trees directly structured feature apply kernel functions feature well normal features learn resolution classifier way approach avoids efforts decoding parse trees set flat syntactic features experimental results show approach bring significant performance improvement reliably effective pronoun resolution task kernel-based pronoun resolution structured syntactic knowledge kernel-based pronoun resolution structured syntactic knowledge kernel-based pronoun resolution structured syntactic knowledge 
paper describe created two svm classifiers one detect sentiment messages tweets sms task one detect sentiment term within message task among submissions teams competition submissions stood first tasks tweets obtaining task task implemented variety semantic sentiment features also generated two large word sentiment association lexicons one tweets hashtags one tweets emoticons task features provided gain points others systems replicated using freely available resources nrc-canada: building state-of-the-art sentiment analysis tweets nrc-canada: building state-of-the-art sentiment analysis tweets nrc-canada: building state-of-the-art sentiment analysis tweets 
paper outcome ongoing research presents unsupervised method automatic word sense induction wsi disambiguation wsd induction algorithm based modeling cooccurrences two words using hypergraphs wsi takes place detecting components cooccurrence hypergraphs wsd assigns induced cluster score equal sum weights hyperedges found local context target word system participates word sense induction discrimination task uoy: hypergraph model word sense induction \& disambiguation uoy: hypergraph model word sense induction \& disambiguation uoy: hypergraph model word sense induction \& disambiguation 
one main challenges applications text summarization question answering information retrieval etc natural language processing determine several senses word used given context problem phrased word sense disambiguation wsd nlp community paper presents dictionary based disambiguation technique adopts assumption one sense per discourse context task english uofl: word sense disambiguation using lexical cohesion uofl: word sense disambiguation using lexical cohesion uofl: word sense disambiguation using lexical cohesion 
compare accuracy statistical parse ranking model trained portion susanne treebank one trained unlabeled sentences derived treebank penn treebank demonstrate techniques similar outperform expectation maximization constrained partial bracketing methods based training data outperform fully supervised technique principle applied statistical parser whose output consistent also explore tuning model different domain effect data training processes semi-supervised training statistical parser unlabeled partially-bracketed data semi-supervised training statistical parser unlabeled partially-bracketed data semi-supervised training statistical parser unlabeled partially-bracketed data 
ccg parser highly efficient linguistically motivated parser efficiency achieved using supertagger assigns ccg lexical categories words sentence integration allows parser request categories cannot find spanning analysis present several enhancements cky chart parsing algorithm used parser first proposal chart repair allows chart efficiently updated adding lexical categories individually evaluate several strategies adding categories second proposal add constraints chart require certain spans constituents finally propose partial beam search reduce search space overall parsing speed improved negligible loss accuracy coverage improving efficiency wide-coverage ccg parser improving efficiency wide-coverage ccg parser improving efficiency wide-coverage ccg parser 
try improve deterministic dependency parsing two ways introducing better search method based nbest algorithm devising series linguistically richer models experimentally shown conll shared task results system higher performance still keeping simple enough efficient implementation nbest dependency parsing linguistically rich models nbest dependency parsing linguistically rich models nbest dependency parsing linguistically rich models 
despite popularity stochastic parsers symbolic parsing still advantages practical without effective mechanism selecting among alternative analyses paper describes symbolic preference system hybrid parser combines shallow parser overlay parser builds chunks hybrid currently equals exceeds stochastic parsers speed approaching accuracy preference system novel using simple scoring method assigning preferences constituents viewed context containing constituents approach addresses problems associated earlier preference systems considerably facilitated development ultimately based viewing preference scoring engineering mechanism indirectly related cognitive principles frequencies symbolic preference using simple scoring symbolic preference using simple scoring symbolic preference using simple scoring 
paper investigate several nonprojective parsing algorithms dependency parsing providing novel polynomial time solutions assumption dependency decision independent others called model also investigate algorithms parsing account nonlocal information present several hardness results suggests unlikely exact dependency parsing tractable model richer model complexity non-projective data-driven dependency parsing complexity non-projective data-driven dependency parsing complexity non-projective data-driven dependency parsing 
propose generative dependency parsing model uses binary latent variables induce conditioning features define model use recently proposed class bayesian networks structured prediction incremental sigmoid belief networks demonstrate proposed model achieves results three different languages also demonstrate features induced isbn latent variables crucial success show proposed model particularly good long dependencies latent variable model generative dependency parsing latent variable model generative dependency parsing latent variable model generative dependency parsing 
conference computational natural language learning features shared task participants train test learning systems data sets shared task devoted dependency parsing year multilingual track domain adaptation track paper summarize main findings shared task try identify major challenges parsing community based findings data-driven dependency parsing across languages domains: perspectives conll-2007 shared task data-driven dependency parsing across languages domains: perspectives conll-2007 shared task data-driven dependency parsing across languages domains: perspectives conll-2007 shared task 
shallow semantic parsing automatic identification labeling sentential constituents recently received much attention work examines whether semantic role information beneficial question answering introduce general framework answer extraction exploits semantic role annotations framenet paradigm view semantic role assignment optimization problem bipartite graph answer extraction instance graph matching experimental results trec datasets demonstrate improvements models using semantic roles improve question answering using semantic roles improve question answering using semantic roles improve question answering 
paper unitor system participating sentiment analysis twitter task presented polarity detection tweet modeled classification task tackled multiple kernel approach allows combine contribution complex kernel functions latent semantic kernel smoothed partial tree kernel implicitly integrate syntactic lexical information annotated examples challenge unitor system achieves good results even considering manual feature engineering performed manually coded resources employed kernels embed distributional models lexical semantics determine expressive generalization tweets unitor: combining syntactic semantic kernels twitter sentiment analysis unitor: combining syntactic semantic kernels twitter sentiment analysis unitor: combining syntactic semantic kernels twitter sentiment analysis 
describe approach improve statistical machine translation smt performance using parallel corpora several bridge languages approach consists simple method utilizing bridge language create word alignment system procedure combining word alignment systems multiple bridge languages final translation obtained consensus decoding combines hypotheses obtained using bridge language word alignments present experiments showing multilingual parallel text spanish french russian chinese utilized framework improve translation performance task improving word alignment bridge languages improving word alignment bridge languages improving word alignment bridge languages 
present comparative error analysis two dominant approaches datadriven dependency parsing global exhaustive models local greedy models show spite similar performance overall two models produce different types errors way explained theoretical properties two models analysis leads new directions parser development characterizing errors data-driven dependency parsing models characterizing errors data-driven dependency parsing models characterizing errors data-driven dependency parsing models 
notable gap research statistical dependency parsing proper conditional probability distribution nonprojective dependency trees given sentence exploit matrix tree theorem tutte derive algorithm efficiently sums scores nonprojective trees sentence permitting definition conditional model trees discriminative methods presented mcdonald et al obtain high accuracy standard dependency parsing tasks trained applied without marginalization summing trees permits alternative techniques interest using summing algorithm present competitive experimental results four nonprojective languages maximum conditional likelihood estimation minimum parsing hidden variable training probabilistic models nonprojective dependency trees probabilistic models nonprojective dependency trees probabilistic models nonprojective dependency trees 
paper provides algorithmic framework learning statistical models involving directed spanning trees equivalently dependency structures show partition functions marginals directed spanning trees computed adaptation kirchhoff theorem demonstrate application method perform experiments use algorithm training dependency parsers new training methods give improvements accuracy models structured prediction models via matrix-tree theorem structured prediction models via matrix-tree theorem structured prediction models via matrix-tree theorem 
traditional research spelling correction natural language processing information retrieval literature mostly relies lexicons detect spelling errors method work well web query spelling correction lexicon cover vast amount terms occurring across web recent work showed using search query logs helps solve problem extent however approaches cannot deal query terms well due data sparseness problem paper novel method proposed use web search results improve existing query spelling correction models solely based query logs leveraging rich information web related query candidate experiments performed based realworld queries randomly sampled search engine daily logs results show new method achieve relative improvement overall error rate reduction comparison baseline method improving query spelling correction using web search results improving query spelling correction using web search results improving query spelling correction using web search results 
paper proposes new bootstrapping approach unsupervised induction comparison previous bootstrapping algorithms developed problem approach aims improve quality seed clusters employing seed words distributionally morphologically reliable particular present novel method combining morphological distributional information seed selection experimental results demonstrate approach works well english bengali thus providing suggestive evidence applicable morphologically impoverished languages highly inflectional languages unsupervised part-of-speech acquisition resource-scarce languages unsupervised part-of-speech acquisition resource-scarce languages unsupervised part-of-speech acquisition resource-scarce languages 
describe discriminatively trained sequence alignment model based averaged perceptron common approaches sequence modeling using perceptrons contrast comparable generative models model permits transparently exploits arbitrary features input strings simplicity perceptron training lends versatility comparable approaches allowing model applied variety problem types learned edit model might useful enumerate problem types describe training procedure evaluate model performance several problems show proposed model performs least well approach based statistical machine translation two problems name transliteration provide evidence combination two approaches promises improvement sequence alignment model based averaged perceptron sequence alignment model based averaged perceptron sequence alignment model based averaged perceptron 
given multiple translations source sentence combine produce translation better single system output propose hierarchical system combination framework machine translation framework integrates multiple mt systems output levels boosting common word phrase translation pairs pruning unused phrases exploring decoding paths adopted mt systems framework achieves better translation quality much less redecoding time full sentence translation hypotheses multiple systems additionally selected based language models trained word mixed stream improves translation quality consistently observed significant improvements several test sets multiple languages covering different genres hierarchical system combination machine translation hierarchical system combination machine translation hierarchical system combination machine translation 
paper investigates hmms estimated em produce poor results pos taggers find hmms estimated em generally assign roughly equal number word tokens hidden state empirical distribution tokens pos tags highly skewed motivates bayesian approach using sparse prior bias estimator toward skewed distribution investigate gibbs sampling gs variational bayes vb estimators show vb converges faster gs task vb significantly improves tagging accuracy em also show em nearly well vb number hidden hmm states dramatically reduced also point high variance estimators require many iterations approach convergence usually thought doesn't em find good hmm pos-taggers? doesn't em find good hmm pos-taggers? doesn't em find good hmm pos-taggers? 
cannot use features current major methods sequence labeling crfs due concerns complexity propose new perceptron algorithm use features algorithm allows use types features whose values determined sequence labels weights local features learned together training process guaranteed convergence present experimental results conll named entity recognition ner task demonstrate performance proposed algorithm new perceptron algorithm sequence labeling non-local features new perceptron algorithm sequence labeling non-local features new perceptron algorithm sequence labeling non-local features 
paper explore use selectional preferences detecting noncompositional combinations characterise arguments given grammatical relationship experiment three models selectional preference two use wordnet one uses entries distributional thesaurus classes representation previous work selectional preference acquisition classes used representation selected according coverage argument tokens rather selected according coverage argument types distributional thesaurus models one methods using wordnet select classes representing preferences virtue number argument types cover tokens classes representative argument head data used estimate probability distribution selectional preference model demonstrate highly significant correlation measures use typebased selectional preferences compositionality judgements data set used previous research models perform better models use tokens selecting classes furthermore models use automatically acquired thesaurus entries produced best results correlation thesaurus models stronger individual features used previous research dataset detecting compositionality verb-object combinations using selectional preferences detecting compositionality verb-object combinations using selectional preferences detecting compositionality verb-object combinations using selectional preferences 
paper consider computational modelling human plausibility judgements triples task equivalent computation selectional preferences models applications psycholinguistics computational linguistics extending recent model obtain completely model task achieves significant correlations human judgements rivals exceeds deeper models exhibiting higher coverage moreover show model combined deeper models obtain better predictions either model alone flexible, corpus-based modelling human plausibility judgements flexible, corpus-based modelling human plausibility judgements flexible, corpus-based modelling human plausibility judgements 
bloom filter bf randomised data structure set membership queries space requirements fall significantly lossless lower bounds produces false positives quantifiable probability present general framework deriving smoothed language model probabilities bfs investigate bf containing statistics used direct replacement conventional model recent work demonstrated corpus statistics stored efficiently within bf consider smoothed language model probabilities derived efficiently randomised representation proposal takes advantage error guarantees bf simple inequalities hold related statistics order reduce bf storage requirements error rate derived probabilities use models replacements conventional language model machine translation experiments smoothed bloom filter language models: tera-scale lms cheap smoothed bloom filter language models: tera-scale lms cheap smoothed bloom filter language models: tera-scale lms cheap 
address problem training free parameters statistical machine translation system show significant improvements minimum error rate training baseline large chineseenglish translation task present novel training criteria based maximum likelihood estimation expected loss computation additionally compare maximum decision rule minimum bayes risk decision rule show theoretical point view also terms translation quality minimum bayes risk decision rule preferable systematic comparison training criteria statistical machine translation systematic comparison training criteria statistical machine translation systematic comparison training criteria statistical machine translation 
reordering model important statistical machine translation smt current smt technologies good capturing local reordering global reordering paper introduces syntactic knowledge improve global reordering capability smt system syntactic knowledge boundary words pos information dependencies used guide phrase reordering constraints syntax tree proposed avoid reordering errors also modification syntax tree made strengthen capability capturing phrase reordering furthermore combination parse trees compensate reordering errors caused single parse tree finally experimental results show performance system superior smt system phrase reordering model integrating syntactic knowledge smt phrase reordering model integrating syntactic knowledge smt phrase reordering model integrating syntactic knowledge smt 
paper explores parsimonious approach parsing allowing principle possible subtrees trees treebank productive elements approach aims finding manageable subset trees accurately describe empirical distributions trees proposed algorithm leads computationally much tracktable parsers well linguistically informative grammars parser evaluated ovis wsj corpora shows improvements efficiency parse accuracy testset likelihood parsing parsing dop framework statistical parsing language modeling originally proposed scha innovations although radical time widely accepted use fragments trees annotated corpus symbolic grammar known treebank grammars charniak inclusion statistical dependencies nodes trees disambiguation allsubtrees approach collins duffy best known instantiations dopframework due bod using probabilistic tree substitution grammar ptsg formalism bod advocated maximalist approach dop inducing grammars contain subtrees parse trees treebank using parse unknown sentences subtrees potentially contribute probable parse although bod empirical results excellent maximalism poses important computational challenges although necessarily unsolvable threaten scalability larger treebanks cognitive plausibility models paper explore different approach dop call parsimonious parsing approach remains true scha original program allowing principle possible subtrees trees treebank productive elements unlike bod approach aims finding succinct subset elementary trees chosen still accurately describe observed distributions phrasestructure trees demonstrate leads computationally tracktable parsers well linguistically informative grammars moreover formulated enrichment treebank probabilistic grammar pcfg allows much easier comparison alternative approaches statistical parsing collins charniak johnson klein manning petrov et al independence assumptions parsimonious data-oriented parsing parsimonious data-oriented parsing parsimonious data-oriented parsing 
present idea estimating semantic distance one possibly language using knowledge source another possibly language creating distributional profiles concepts using bilingual lexicon bootstrapping algorithm without use data corpora measures semantic distance evaluated two tasks estimating semantic distance words ranking word pairs according semantic distance solving reader digest word power problems task measures superior conventional monolingual measures based wordnet task measures able solve problems correctly despite scores affected many tied answers overall performance better best monolingual measures cross-lingual distributional profiles concepts measuring semantic distance cross-lingual distributional profiles concepts measuring semantic distance cross-lingual distributional profiles concepts measuring semantic distance 
paper proposes use lexicalized grammar ltag formalism important additional source features semantic role labeling srl task using set support vector machines svms evaluate features experiments show features improve srl accuracy significantly compared best known set features used state art srl systems obtain improvement experimental evaluation ltag-based features semantic role labeling experimental evaluation ltag-based features semantic role labeling experimental evaluation ltag-based features semantic role labeling 
propose based method detecting disambiguating coordinate conjunctions method averaged perceptron learning used adapt substitution matrix training data drawn target language domain reduce cost training data construction method accepts training examples complete alignment labels missing instead boundaries coordinated conjuncts marked report promising empirical results detecting disambiguating coordinated noun phrases genia corpus despite relatively small number training examples minimal features employed discriminative learning model coordinate conjunctions discriminative learning model coordinate conjunctions discriminative learning model coordinate conjunctions 
paper describe new algorithm recovering empty nodes approach combines set patterns together probabilistic model patterns heavily utilize regular expressions pertinent tree structures covered using limited number patterns probabilistic model essentially probabilistic grammar pcfg approach patterns acting terminals production rules evaluate algorithm performance gold trees parser output using three different metrics method compares favorably algorithms recover recovery empty nodes parse structures recovery empty nodes parse structures recovery empty nodes parse structures 
show phrase structures penn treebank style parses optimal syntaxbased machine translation exploit series binarization methods restructure penn treebank style trees syntactified phrases smaller penn treebank constituents acquired exploited translation find employing em algorithm determining binarization parse tree among set alternative binarizations gives us best translation result binarizing syntax trees improve syntax-based machine translation accuracy binarizing syntax trees improve syntax-based machine translation accuracy binarizing syntax trees improve syntax-based machine translation accuracy 
paper analyze effect resampling techniques including undersampling used active learning word sense disambiguation wsd experimental results show causes negative effects active learning relatively good choice alleviate withinclass imbalance problem propose oversampling bootos method works better ordinary active learning wsd finally investigate stop active learning adopt two strategies stopping conditions active learning according experimental results suggest prediction solution considering upper bound lower bound stopping conditions active learning word sense disambiguation methods addressing class imbalance problem active learning word sense disambiguation methods addressing class imbalance problem active learning word sense disambiguation methods addressing class imbalance problem 
unknown words hindrance natural language applications particular drastically impact machine translation quality easy way commercial translation systems usually offer users possibility add unknown words translations dedicated lexicon recently stroppa yvon shown analogical learning alone deals nicely morphology different languages study show analogical learning offers well elegant effective solution problem identifying potential translations unknown words translating unknown words analogical learning translating unknown words analogical learning translating unknown words analogical learning 
deterministic dependency parsers use parsing actions construct dependencies parsers compute probability whole dependency tree determine parsing actions stepwisely trained classifier globally model parsing actions steps taken input sentence propose two kinds probabilistic parsing action models compute probability whole dependency tree tree maximal probability outputted experiments carried languages results show probabilistic parsing action models outperform original deterministic dependency parser probabilistic parsing action models multi-lingual dependency parsing probabilistic parsing action models multi-lingual dependency parsing probabilistic parsing action models multi-lingual dependency parsing 
use generative model predict likely derivation dependency parse probabilistic model based incremental sigmoid belief networks recently proposed class latent variable models structure prediction ability automatically induce features results multilingual parsing robust enough achieve accuracy well average individual language multilingual track shared task robustness led third best overall average labeled attachment score task despite using discriminative methods also demonstrate parser quite fast provide even faster parsing times without much loss accuracy fast robust multilingual dependency parsing generative latent variable model fast robust multilingual dependency parsing generative latent variable model fast robust multilingual dependency parsing generative latent variable model 
present experiments dependency parsing model defined rich factors model represents dependency trees factors include three types relations tokens dependency children extend projective parsing algorithm eisner case train models using averaged perceptron experiments show considering information yields significant improvements parsing accuracy comes high cost terms time memory consumption multilingual exercise shared task nivre et al system obtains best accuracy english second best accuracies basque czech experiments higher-order projective dependency parser experiments higher-order projective dependency parser experiments higher-order projective dependency parser 
paper presents empirical study different selections input translation systems affect translation quality system combination give empirical evidence systems combined similar quality need almost uncorrelated order beneficial system combination experimental results presented composite translations computed large numbers different research systems well set translation systems derived one bestranked machine translation engines nist machine translation evaluation empirical study computing consensus translations multiple machine translation systems empirical study computing consensus translations multiple machine translation systems empirical study computing consensus translations multiple machine translation systems 
widely observed different nlp applications require different sense granularities order best exploit word sense distinctions many applications wordnet senses contrast previously proposed automatic methods sense clustering formulate sense merging supervised learning problem exploiting sense clusterings training data train discriminative classifier wide variety features derived wordnet structure evidence evidence lexical resources learned similarity measure outperforms previously proposed automatic methods sense clustering task predicting human sense merging judgments yielding absolute improvement nouns verbs adjectives finally propose model clustering sense taxonomies using outputs classifier make available several automatically wordnets various sense granularities learning merge word senses learning merge word senses learning merge word senses 
paper presents novel approach exploiting global context task word sense disambiguation wsd done using topic features constructed using latent dirichlet alocation lda algorithm unlabeled data features incorporated modified na ve bayes network alongside features neighboring words single words surrounding context local collocations syntactic patterns english task english lexical sample task method achieved significant improvement simple na ve bayes classifier higher accuracy best official scores task improving word sense disambiguation using topic features improving word sense disambiguation using topic features improving word sense disambiguation using topic features 
present variant lr algorithm dependency parsing extend search probabilistic generalized lr dependency parsing parser actions determined classifier based features represent current state parser apply parsing framework tracks conll shared task case taking advantage multiple models trained different learners multilingual track train three lr models ten languages combine analyses obtained individual model maximum spanning tree voting scheme domain adaptation track use two models parse unlabeled data target domain supplement labeled training set scheme similar one iteration dependency parsing domain adaptation lr models parser ensembles dependency parsing domain adaptation lr models parser ensembles dependency parsing domain adaptation lr models parser ensembles 
paper discusses automatic determination case arabic task major source errors full diacritization arabic use syntactic tree obtain error rate machine learning based system outperforming system using rules careful error analysis suggests account annotation errors gold standard error rate drops rules outperforming machine system determining case arabic: learning complex linguistic behavior requires complex linguistic features determining case arabic: learning complex linguistic behavior requires complex linguistic features determining case arabic: learning complex linguistic behavior requires complex linguistic features 
describe experiments using desr parser multilingual domain adaptation tracks conll shared task desr implements incremental deterministic shift reduce parsing algorithm using specific rules handle dependencies multilingual track adopted second order averaged perceptron performed feature selection tune feature model language domain adaptation track applied tree revision method learns correct mistakes made base parser adaptation domain multilingual dependency parsing domain adaptation using desr multilingual dependency parsing domain adaptation using desr multilingual dependency parsing domain adaptation using desr 
present adaptation constraint satisfaction inference canisius et al predicting dependency trees three different classifiers trained predict weighted parts complex output constraints standard weighted constraint satisfaction problem formed solution valid dependency tree constraint satisfaction approach dependency parsing constraint satisfaction approach dependency parsing constraint satisfaction approach dependency parsing 
present multilingual dependency parsing system submitted multilingual track parser first identifies dependencies using deterministic parsing method labels dependencies sequence labeling problem describe features used stage four languages different values root design special features root labeler present evaluation results error analyses focusing chinese two-stage parser multilingual dependency parsing two-stage parser multilingual dependency parsing two-stage parser multilingual dependency parsing 
describe incremental parser trained minimize cost sentences rather individual parsing actions attempt use advantages two systems shared task evaluation present performance parser multilingual task well evaluation contribution bidirectional parsing beam search parsing performance incremental dependency parsing using online learning incremental dependency parsing using online learning incremental dependency parsing using online learning 
deterministic parsing emerged effective alternative complex parsing algorithms search entire search space get best probable parse tree paper present online large margin based training framework deterministic parsing using nivre parsing algorithm online training facilitates use high dimensional features without creating memory bottlenecks unlike popular svms participated conll shared evaluated system ten languages got average multilingual labeled attachment score average highest average multilingual unlabeled attachment score average highest online learning deterministic dependency parsing online learning deterministic dependency parsing online learning deterministic dependency parsing 
paper report empirical study initiative conflicts conversation examined conflicts two corpora dialogues results show conversants try avoid initiative conflicts conflicts occur efficiently resolved linguistic devices volume avoiding resolving initiative conflicts dialogue avoiding resolving initiative conflicts dialogue avoiding resolving initiative conflicts dialogue 
quality sentence translated machine translation mt system difficult evaluate propose method automatically evaluating quality translation general translating given sentence one conditions satisfied maintain high translation quality englishjapanese translation example prepositions infinitives must appropriately translated show several procedures enable evaluating quality translated sentence appropriately using conventional methods first procedure constructing test set conditions assigned sentence form yes questions second procedure developing system determines answer question third procedure combining measure based questions conventional measures also present method automatically generating form yes questions estimating rate accomplishment promising results shown automatic evaluation machine translation based rate accomplishment sub-goals automatic evaluation machine translation based rate accomplishment sub-goals automatic evaluation machine translation based rate accomplishment sub-goals 
conditional random fields crfs shown great success problems involving structured output variables however many nlp applications exact training intractable computing global normalization factor even approximately extremely hard addition optimizing likelihood often correlate maximizing evaluation measures paper present novel training procedure structured local training maximizes likelihood exploiting benefits global inference training hidden variables used capture interactions local inference global inference furthermore introduce biased potential functions empirically drive crfs towards performance improvements preferred evaluation measure learning task report promising experimental results two coreference data sets using two evaluation measures structured local training biased potential functions conditional random fields application coreference resolution structured local training biased potential functions conditional random fields application coreference resolution structured local training biased potential functions conditional random fields application coreference resolution 
introduce novel ranking algorithm called grasshopper ranks items emphasis diversity top items different order broad coverage whole item set many natural language processing tasks benefit diversity ranking algorithm based random walks absorbing markov chain turn ranked items absorbing states effectively prevents redundant items receiving high rank demonstrate grasshopper effectiveness extractive text summarization algorithm ranks st nd systems duc task social network analysis task identifies movie stars world improving diversity ranking using absorbing random walks improving diversity ranking using absorbing random walks improving diversity ranking using absorbing random walks 
paper describes method generating data using wikipedia source sense annotations word sense disambiguation experiments show sense annotations reliable used construct accurate sense classifiers using wikipedia automatic word sense disambiguation using wikipedia automatic word sense disambiguation using wikipedia automatic word sense disambiguation 
information retrieval systems frequently required handle long queries simply using terms query relying underlying retrieval model appropriately weight terms often leads ineffective retrieval show rewriting query version comprises small subset appropriate terms original query greatly improves effectiveness targeting demonstrated potential improvement almost difficult trec queries associated collections develop suite automatic techniques queries study characteristics show shortcomings automatic methods ameliorated simple user interaction report results average better baseline case shorter queries, helping users create case shorter queries, helping users create case shorter queries, helping users create 
proceedings naacl hlt pages rochester ny april association computational linguistics combining outputs multiple machine translation systems rosti combining outputs multiple machine translation systems combining outputs multiple machine translation systems combining outputs multiple machine translation systems 
propose new framework supervised machine learning goal learn smaller amounts supervised training data collecting richer kind training data annotations rationales annotating example human teacher also highlight evidence supporting annotation thereby teaching machine learner example belongs category provide data present learning method exploits rationales training boost performance significantly sample task namely sentiment classification movie reviews hypothesize situations providing rationales fruitful use annotator time annotating examples using ``annotator rationales'' improve machine learning text categorization using ``annotator rationales'' improve machine learning text categorization using ``annotator rationales'' improve machine learning text categorization 
propose method extracting semantic orientations phrases pairs adjective noun positive negative neutral given adjective semantic orientation classification phrases reduced classification words construct lexical network connecting similar related words network node one three orientation values neighboring nodes tend value adopt potts model probability model lexical network adjective estimate states nodes indicate semantic orientations pairs unlike existing methods phrase classification proposed method classify phrases consisting unseen words also propose use unlabeled data seed set probability computation empirical evaluation shows effectiveness proposed method extracting semantic orientations phrases dictionary extracting semantic orientations phrases dictionary extracting semantic orientations phrases dictionary 
address problem analyzing multiple related opinions text instance restaurant review opinions may include food ambience service formulate task multiple aspect ranking problem goal produce set numerical scores one aspect present algorithm jointly learns ranking models individual aspects modeling dependencies assigned ranks algorithm guides prediction individual rankers analyzing opinions agreement contrast prove agreementbased joint model expressive individual ranking models empirical results confirm strength model algorithm provides significant improvement individual rankers joint ranking model multiple aspect ranking using good grief algorithm multiple aspect ranking using good grief algorithm multiple aspect ranking using good grief algorithm 
measuring semantic similarity words vital various applications natural language processing language modeling information retrieval document clustering propose method utilizes information available web measure semantic similarity pair words entities integrate page counts word pair patterns occur among top ranking snippets query using support vector machines experimental results millercharles benchmark data set show proposed measure outperforms existing web based semantic similarity measures wide margin achieving correlation coefficient moreover proposed semantic similarity measure significantly improves accuracy measure named entity clustering task proving capability proposed measure capture semantic similarity using web content integrated approach measuring semantic similarity words using information available web integrated approach measuring semantic similarity words using information available web integrated approach measuring semantic similarity words using information available web 
present revision learning model improving accuracy dependency parser revision stage corrects output base parser means revision rules learned mistakes base parser revision learning performed discriminative classifier revision stage linear complexity preserves efficiency base parser present empirical evaluations treebanks two languages show effectiveness relative error reduction state art accuracy tree revision learning dependency parsing tree revision learning dependency parsing tree revision learning dependency parsing 
open issue dependency parsing handle dependencies seem required linguistically adequate representations pose problems parsing respect accuracy efficiency using data five different languages evaluate incremental deterministic parser derives dependency structures time supported svm classifiers predicting next parser action experiments show unrestricted parsing gives significant improvement accuracy compared strictly projective baseline error reduction leading results given data sets moreover restricting class permissible structures limited degrees parsing time reduced without significant decrease accuracy incremental non-projective dependency parsing incremental non-projective dependency parsing incremental non-projective dependency parsing 
present novel method creating estimates structured search problems approach project complex model onto multiple simpler models exact inference efficient use optimization framework estimate parameters projections way bounds true costs similar klein manning combine completion estimates simpler models guide search original complex model apply approach bitext parsing lexicalized parsing demonstrating effectiveness domains approximate factoring a* search approximate factoring a* search approximate factoring a* search 
new architecture identifying interpreting temporal expressions introduced large set complex rules standard systems task replaced series machine learned classifiers much smaller set semantic composition rules experiments tern data set demonstrate overall system performance comparable normalization performance particularly good cascaded machine learning approach interpreting temporal expressions cascaded machine learning approach interpreting temporal expressions cascaded machine learning approach interpreting temporal expressions 
compare two pivot strategies statistical machine translation smt namely phrase translation sentence translation phrase translation strategy means directly construct phrase translation table source target language pair two one constructed source language english one constructed english target language use smt system sentence translation strategy means first translate source language sentence english sentences translate sentences target language sentences separately select highest scoring sentence target sentences conducted controlled experiments using europarl corpus evaluate performance pivot strategies compared directly trained smt systems phrase translation strategy significantly outperformed sentence translation strategy relative performance compared directly trained smt systems comparison pivot methods phrase-based statistical machine translation comparison pivot methods phrase-based statistical machine translation comparison pivot methods phrase-based statistical machine translation 
propose use statistical phrasebased machine translation system task system takes input raw machine translation output commercial mt system produces text report experiments performed data collected precisely setting pairs raw mt output manually versions evaluation output automatic ape system better quality mt terms bleu ter metrics also better output mt system used standalone translation mode results indicate automatic constitutes simple efficient way combining statistical mt technologies statistical phrase-based post-editing statistical phrase-based post-editing statistical phrase-based post-editing 
proceedings naacl hlt pages rochester ny april association computational linguistics automatic answer typing christopher pinchak shane bergsma department computing science university alberta edmonton alberta canada automatic answer typing how-questions automatic answer typing how-questions automatic answer typing how-questions 
research semantic role labeling srl focused training evaluating corpus order develop technology strategy appropriate initiating research lead particular corpus work presented paper focuses analyzing robustness srl system trained one genre data used label different genre semantic role labeling system performing well wsj test data shows significant performance degradation applied data brown corpus present series experiments designed investigate source lack portability experiments based comparisons performance using propbanked wsj data propbanked brown corpus data results indicate syntactic parses argument identification port relatively well new genre argument classification analysis reasons presented generally point nature lexical semantic features dominating classification task general structural features dominating argument identification task towards robust semantic role labeling towards robust semantic role labeling towards robust semantic role labeling 
paper explores problem computing text similarity verb phrases describing skilled human behavior purpose finding approximate matches four parsers evaluated large corpus skill statements extracted expertise taxonomy similarity measure utilizing common semantic role features extracted parse trees found superior measure similarity comparable level human agreement computing semantic similarity skill statements approximate matching computing semantic similarity skill statements approximate matching computing semantic similarity skill statements approximate matching 
algorithms deterministic incremental dependency parsing joakim nivre va xjo university uppsala university parsing algorithms process input left right construct single derivation often considered inadequate natural language parsing massive ambiguity typically found natural language grammars nevertheless shown algorithms combined classifiers used build highly accurate disambiguating parsers particular syntactic representations article first present general framework describing analyzing algorithms deterministic incremental dependency parsing formalized transition systems describe analyze two families algorithms algorithms former family restricted projective dependency structures describe variant latter family present projective nonprojective variant four algorithms give proofs correctness complexity addition perform experimental evaluation algorithms combination svm classifiers predicting next parsing action using data thirteen languages show four algorithms give competitive accuracy although algorithm generally outperforms projective algorithms languages proportion constructions however projective algorithms often produce comparable results combined technique known parsing linear time complexity algorithms gives advantage respect efficiency learning parsing projective algorithm turns equally efficient practice moreover projective algorithms used implement parsing sometimes become less efficient parsing learning algorithm although algorithms partially described literature first comprehensive analysis evaluation algorithms within unified framework algorithms deterministic incremental dependency parsing algorithms deterministic incremental dependency parsing algorithms deterministic incremental dependency parsing 
describe new pruning approach remove phrase pairs translation models statistical machine translation systems approach applies original translation system large amount text calculates usage statistics phrase pairs using statistics relevance phrase pair estimated approach tested strong baseline based previous work shows significant improvements translation model pruning via usage statistics statistical machine translation translation model pruning via usage statistics statistical machine translation translation model pruning via usage statistics statistical machine translation 
present approach using multiple preprocessing schemes improve statistical word alignments show relative reduction alignment error rate combination statistical word alignments based multiple preprocessing schemes combination statistical word alignments based multiple preprocessing schemes combination statistical word alignments based multiple preprocessing schemes 
ability distinguish statistically different populations speakers writers important asset many nlp applications paper describe method using document similarity measures describe differences behavior native speakers english writing task document similarity measures distinguish native vs.\ non-native essay writers document similarity measures distinguish native vs.\ non-native essay writers document similarity measures distinguish native vs.\ non-native essay writers 
dependency analysis natural language gives rise structures constraint dependency trees recently shown give good fit empirical linguistic data present reformulation constraint using properties nonprojective edges show formal relationship level types edges also derive simple algorithm checking relationship non-projective edges, level types, well-nestedness relationship non-projective edges, level types, well-nestedness relationship non-projective edges, level types, well-nestedness 
framework project analyze propose combination two statistical machine translation systems one exhaustive analysis includes comparison translation models terms efficiency number translation units used search computational time examination errors system output additionally combine systems showing accuracy improvements analysis system combination phrase- n-gram-based statistical machine translation systems analysis system combination phrase- n-gram-based statistical machine translation systems analysis system combination phrase- n-gram-based statistical machine translation systems 
present joint language model jmllm use statistical machine translation smt language pairs one languages morphologically rich proposed jmllm takes advantage rich morphology reduce oov rate keeping predictive power whole words also allows incorporation additional available semantic syntactic linguistic information morphemes words language model preliminary experiments english smt system demonstrate improved translation performance trigram based baseline language model joint morphological-lexical language modeling machine translation joint morphological-lexical language modeling machine translation joint morphological-lexical language modeling machine translation 
customization specific domains discourse user requirements one greatest challenges today information extraction ie systems demonstrably effective supervised machine learning approaches ie customization pose high burden user semisupervised learning approaches may principle offer resource effective solution still insufficiently accurate grant realistic application demonstrate limitation overcome integrating learning techniques within semisupervised ie approach without increasing resource requirements high accuracy method semi-supervised information extraction high accuracy method semi-supervised information extraction high accuracy method semi-supervised information extraction 
present novel machine translation framework based kernel regression techniques model translation task viewed mapping regression type learning employed source target sentences embedded kernel induced feature spaces report experiments translation task showing encouraging results kernel regression based machine translation kernel regression based machine translation kernel regression based machine translation 
propose variation algorithm japanese use weblog opinion mining unsupervised approach proposed turney shown work well english first used algorithm japanese way similar turney original idea result trial leaned heavily toward positive opinions expanded reference words sets words tried introduce balancing factor detect neutral expressions modifications achieved wellbalanced result positive negative accuracy exceeded shows proposed approach adapted japanese also modified analyze japanese opinions effectively modifying so-pmi japanese weblog opinion mining using balancing factor detecting neutral expressions modifying so-pmi japanese weblog opinion mining using balancing factor detecting neutral expressions modifying so-pmi japanese weblog opinion mining using balancing factor detecting neutral expressions 
statistical machine translation systems depend heavily knowledge represented phrase translation tables however phrase pairs included tables typically selected using simple heuristics potentially leave much room improvement paper present technique selecting phrase pairs include phrase translation tables based estimated quality according translation model method reduces size phrase translation table also improves translation quality measured bleu metric selective phrase pair extraction improved statistical machine translation selective phrase pair extraction improved statistical machine translation selective phrase pair extraction improved statistical machine translation 
posslt korean english spoken language translation slt system like slt systems automatic speech recognition asr machine translation mt tts coupled cascading manner posslt however several novel techniques applied improve overall translation quality speed models used posslt trained travel domain conversational corpus posslt: korean english spoken language translation system posslt: korean english spoken language translation system posslt: korean english spoken language translation system 
paper describes novel text comparison environment facilities text comparison administered assessing aggregating information nuggets automatically created extracted texts question goal designing tool enable improve automatic nugget creation present application evaluations various natural language processing tasks demonstration hlt new users able experience first hand text analysis fun enjoyable interesting using nuggets text comparison using machine-generated nuggets text comparison using machine-generated nuggets text comparison using machine-generated nuggets 
present global discriminative statistical word order model machine translation model combines syntactic movement surface movement information discriminatively trained choose among possible word orders show combining discriminative training features detect two different kinds movement phenomena leads substantial improvements word ordering performance strong baselines integrating word order model baseline mt system results points improvement bleu english japanese translation discriminative syntactic word order model machine translation discriminative syntactic word order model machine translation discriminative syntactic word order model machine translation 
statistical machine translation systems usually trained large amounts bilingual text monolingual text target language paper explore use transductive methods effective use monolingual data source language order improve translation quality propose several algorithms aim present strengths weaknesses one present detailed experimental evaluations french english europarl data set data nist chinese english largedata track show significant improvement translation quality tasks transductive learning statistical machine translation transductive learning statistical machine translation transductive learning statistical machine translation 
present novel approach word sense disambiguation problem makes use evidence combined background knowledge employing inductive logic programming algorithm approach generates expressive disambiguation rules exploit several knowledge sources also model relations approach evaluated two tasks identification correct translation set highly ambiguous verbs englishportuguese translation disambiguation verbs lexical sample task average accuracy obtained multilingual task outperforms machine learning techniques investigated monolingual task approach performs well systems reported results set verbs learning expressive models word sense disambiguation learning expressive models word sense disambiguation learning expressive models word sense disambiguation 
proceedings th annual meeting association computational linguistics pages prague czech republic june association computational linguistics discriminative language model samples daisuke okanohara discriminative language model pseudo-negative samples discriminative language model pseudo-negative samples discriminative language model pseudo-negative samples 
words foreign origin referred borrowed words loanwords loanword usually imported chinese phonetic transliteration translation easily available semantic transliteration seen good tradition introducing foreign words chinese preserve word sounds source language also carries forward word original semantic attributes paper attempts automate semantic transliteration process first time conduct inquiry feasibility semantic transliteration propose probabilistic model transliterating personal names latin script chinese results show semantic transliteration substantially consistently improves accuracy phonetic transliteration experiments semantic transliteration personal names semantic transliteration personal names semantic transliteration personal names 
representations natural language syntax require fine balance structural flexibility computational complexity previous work several constraints proposed identify classes dependency structures wellbalanced sense also restrictive projectivity constraints formulated fully specified structures makes hard integrate models structures composed lexical information paper show two empirically relevant relaxations projectivity lexicalized combining resulting lexicons regular means syntactic composition gives rise hierarchy mildly dependency languages mildly context-sensitive dependency languages mildly context-sensitive dependency languages mildly context-sensitive dependency languages 
examine problem choosing word order set dependency trees minimize total dependency length present algorithm computing optimal layout single tree well numerical method optimizing grammar orderings set dependency types grammar generated minimizing dependency length unordered trees penn treebank found agree surprisingly well english word order suggesting dependency length minimization influenced evolution english optimizing grammars minimum dependency length optimizing grammars minimum dependency length optimizing grammars minimum dependency length 
convolution tree kernel shown promising results semantic role classification however carries hard matching may lead less accurate similarity measure remove constraint paper proposes grammardriven convolution tree kernel semantic role classification introducing linguistic knowledge standard tree kernel proposed tree kernel displays two advantages previous one approximate substructure matching grammardriven approximate tree node matching two improvements enable grammardriven tree kernel explore linguistically motivated structure features previous one experiments srl shared task show grammardriven tree kernel significantly outperforms previous one srl moreover present composite kernel integrate tree methods experimental results show composite kernel outperforms previously methods grammar-driven convolution tree kernel semantic role classification grammar-driven convolution tree kernel semantic role classification grammar-driven convolution tree kernel semantic role classification 
proceedings th annual meeting association computational linguistics pages prague czech republic june association computational linguistics adding noun phrase structure penn treebank david vadas james curran school information technologies university sydney nsw australia adding noun phrase structure penn treebank adding noun phrase structure penn treebank adding noun phrase structure penn treebank 
last years two main research directions machine learning natural language processing study learning algorithms way train classifiers labeled data scarce study ways exploit knowledge global information structured learning tasks paper suggest method incorporating domain knowledge learning algorithms novel framework unifies exploit several kinds task speci constraints experimental results presented information extraction domain demonstrate applying constraints helps model generate better feedback learning hence framework allows high performance learning significantly less training data possible tasks guiding semi-supervision constraint-driven learning guiding semi-supervision constraint-driven learning guiding semi-supervision constraint-driven learning 
quite recently extending statistical machine translation pbsmt syntactic structure caused system performance deteriorate work show incorporating lexical syntactic descriptions form supertags yield significantly better pbsmt systems describe novel pbsmt model integrates supertags target language model target side translation model two kinds supertags employed lexicalized grammar combinatory categorial grammar despite differences two approaches supertaggers give similar improvements addition supertagging also explore utility surface global grammaticality measure based combinatory operators perform various experiments arabic english nist test set addressing issues sparseness scalability utility system subcomponents best result bleu improves relative pbsmt model compares favourably leading systems nist task supertagged phrase-based statistical machine translation supertagged phrase-based statistical machine translation supertagged phrase-based statistical machine translation 
many automatic evaluation metrics machine translation mt rely making comparisons human translations resource may always available present method developing mt evaluation metrics directly rely human reference translations metrics developed using regression learning based set weaker indicators fluency adequacy pseudo references experimental results suggest rival standard metrics terms correlations human judgments new test instances regression sentence-level mt evaluation pseudo references regression sentence-level mt evaluation pseudo references regression sentence-level mt evaluation pseudo references 
introduce simple method pack words statistical word alignment goal simplify task automatic word alignment packing several consecutive words together believe correspond single word opposite language done using word aligner bootstrapping output evaluate performance approach machine translation task report relative increase bleu score art phrasebased smt system bootstrapping word alignment via word packing bootstrapping word alignment via word packing bootstrapping word alignment via word packing 
proceedings th annual meeting association computational linguistics pages prague czech republic june association computational linguistics improved system combination machine translation rosti spyros matsoukas richard schwartz bbn technologies moulton street cambridge ma improved word-level system combination machine translation improved word-level system combination machine translation improved word-level system combination machine translation 
evaluating output language technology applications mt natural language generation summarisation automatic evaluation techniques generally conflate measurement faithfulness source content fluency resulting text paper develop automatic evaluation metric estimate fluency alone examining use parser outputs metrics show correlate human judgements generated text fluency develop machine learner based show performs better individual parser metrics approaching lower bound human performance finally look different language models generating sentences show individual parser metrics fooled depending generation method machine learner provides consistent estimator fluency gleu: automatic evaluation sentence-level fluency gleu: automatic evaluation sentence-level fluency gleu: automatic evaluation sentence-level fluency 
present method paraphrases given sentence first generating candidate paraphrases ranking classifying candidates generated applying existing paraphrasing rules extracted parallel corpora ranking component considers overall quality rules produced candidate also extent preserve grammaticality meaning particular context input sentence well degree candidate differs input experimented maximum entropy classifier svr ranker experimental results show incorporating features existing paraphrase recognizer ranking component improves performance overall method compares well state art paraphrase generator paraphrasing rules apply input sentences also propose new methodology evaluate ranking components paraphrase generators evaluates across different combinations weights grammaticality meaning preservation diversity paper accompanied paraphrasing dataset constructed evaluations kind generate rank approach sentence paraphrasing generate rank approach sentence paraphrasing generate rank approach sentence paraphrasing 
paper introduces maximum entropy dependency parser based efficient kbest maximum spanning tree mst algorithm although recent work suggests constraints mst algorithm significantly inhibit parsing accuracy show generating parses according model oracle performance well performance best dependency parsers motivates parsing approach based reranking kbest parses generated model oracle parse accuracy results presented model results reranker eight languages seven english k-best spanning tree parsing k-best spanning tree parsing k-best spanning tree parsing 
average performance statistical parsers gradually improves still attach many sentences annotations rather low quality number sentences grows training test data taken different domains case major web applications information retrieval question answering paper present sample ensemble parse assessment sepa algorithm detecting parse quality use function agreement among several copies parser trained different sample training data assess parse quality experimented generative reranking parsers collins charniak johnson respectively show superior results several baselines training test data domain different domains test setting used previous work show error reduction opposed ensemble method selection high quality parses ensemble method selection high quality parses ensemble method selection high quality parses 
present approach query expansion answer retrieval uses statistical machine translation smt techniques bridge lexical gap questions answers query expansion done using paraphraser introduce synonyms context entire query ii translating query terms answer terms using smt model trained pairs evaluate global query expansion techniques tfidf retrieval million pairs extracted faq pages experimental results show smtbased expansion improves retrieval performance local expansion retrieval without expansion statistical machine translation query expansion answer retrieval statistical machine translation query expansion answer retrieval statistical machine translation query expansion answer retrieval 
paper proposes boosting approach improve statistical word alignment limited labeled data large amounts unlabeled data proposed approach modifies supervised boosting algorithm semisupervised learning algorithm incorporating unlabeled data algorithm build word aligner using labeled data unlabeled data build pseudo reference set unlabeled data calculate error rate word aligner using labeled data based semisupervised boosting algorithm investigate two boosting methods word alignment addition improve word alignment results combining results two boosting methods experimental results word alignment indicate semisupervised boosting achieves relative error reductions compared supervised boosting unsupervised boosting respectively boosting statistical word alignment using labeled unlabeled data boosting statistical word alignment using labeled unlabeled data boosting statistical word alignment using labeled unlabeled data 
propose novel approach crosslingual language model lm adaptation based bilingual latent semantic analysis blsa blsa model introduced enables latent topic distributions efficiently transferred across languages enforcing topic correspondence training using proposed blsa framework crosslingual lm adaptation performed first inferring topic posterior distribution source text applying inferred distribution target language lm via marginal adaptation proposed framework also enables rapid bootstrapping lsa models new languages based source lsa model another language chinese english speech text translation proposed blsa framework successfully reduced word perplexity english lm unigram lm lm furthermore proposed approach consistently improved machine translation quality speech text based adaptation bilingual-lsa based lm adaptation spoken language translation bilingual-lsa based lm adaptation spoken language translation bilingual-lsa based lm adaptation spoken language translation 
though document summarization keyword extraction aim extract concise representations documents two tasks usually investigated independently paper proposes novel iterative reinforcement approach simultaneously extracting summary keywords single document assumption summary keywords document mutually boosted approach naturally make full use reinforcement sentences keywords fusing three kinds relationships sentences words either homogeneous heterogeneous experimental results show effectiveness proposed approach tasks approach validated work almost well approach computing word semantics towards iterative reinforcement approach simultaneous document summarization keyword extraction towards iterative reinforcement approach simultaneous document summarization keyword extraction towards iterative reinforcement approach simultaneous document summarization keyword extraction 
creating large amounts annotated data train statistical pcfg parsers expensive performance parsers declines training test data taken different domains paper use selftraining order improve quality parser adapt different domain using small amounts manually annotated seed data report significant improvement seed test data domain adaptation scenario particular achieve reduction annotation cost case yielding improvement previous work reduction domain adaptation case first time small labeled datasets applied successfully tasks also able formulate characterization selftraining valuable self-training enhancement domain adaptation statistical parsers trained small datasets self-training enhancement domain adaptation statistical parsers trained small datasets self-training enhancement domain adaptation statistical parsers trained small datasets 
present novel framework combines strengths surface syntactic parsing deep syntactic parsing increase deep parsing accuracy specifically combining dependency hpsg parsing show using surface dependencies constrain application hpsg rules benefit number parsing techniques designed highaccuracy dependency parsing actually performing deep syntactic analysis framework results absolute improvement approach wide coverage hpsg parsing hpsg parsing shallow dependency constraints hpsg parsing shallow dependency constraints hpsg parsing shallow dependency constraints 
current machine transliteration systems employ corpus known sourcetarget word pairs train system typically evaluate systems similar corpus paper explore performance transliteration systems corpora varied controlled way particular control number prior language knowledge human transliterators used construct corpora origin source words make corpora find word accuracy automated transliteration systems vary absolute terms depending corpus run conclude least four human transliterators used construct corpora evaluating automated transliteration systems although absolute word accuracy metrics may translate across corpora relative rankings system performance remains stable across differing corpora corpus effects evaluation automated transliteration systems corpus effects evaluation automated transliteration systems corpus effects evaluation automated transliteration systems 
paper propose rules enhance expressive power translation models rule capable capturing nonsyntactic phrase pairs describing correspondence multiple parse trees one string integrate rules translation models auxiliary rules introduced provide generalization level experimental results show nist test set model augmented rules achieves relative improvement terms bleu score original model allows rules forest-to-string statistical translation rules forest-to-string statistical translation rules forest-to-string statistical translation rules 
inspired previous preprocessing approaches smt paper proposes novel probabilistic approach reordering combines merits syntax smt given source sentence parse tree method generates tree operations list reordered inputs fed standard decoder produce optimal translation experiments show nist task translation proposal leads bleu improvement probabilistic approach syntax-based reordering statistical machine translation probabilistic approach syntax-based reordering statistical machine translation probabilistic approach syntax-based reordering statistical machine translation 
describe new loss function due jeon lin estimating structured models arbitrary features loss function seen generative alternative maximum likelihood estimation interesting interpretation statistically consistent substantially faster maximum conditional likelihood estimation conditional random fields lafferty et al order magnitude compare performance training time hmm crf memm pseudolikelihood shallow parsing task experiments help tease apart contributions rich features discriminative training shown additive computationally efficient m-estimation log-linear structure models computationally efficient m-estimation log-linear structure models computationally efficient m-estimation log-linear structure models 
paper propose guided learning new learning framework bidirectional sequence classification tasks learning order inference training local classifier dynamically incorporated single perceptron like learning algorithm apply novel learning algorithm pos tagging obtains error rate standard ptb test set represents relative error reduction previous best result data set using fewer features guided learning bidirectional sequence classification guided learning bidirectional sequence classification guided learning bidirectional sequence classification 
standard approaches chinese word segmentation treat problem tagging task assigning labels characters sequence indicating whether character marks word boundary discriminatively trained models based local character features used make tagging decisions viterbi decoding finding highest scoring segmentation paper propose alternative segmentor uses features based complete words word sequences generalized perceptron algorithm used discriminative training use beamsearch decoder closed tests first second sighan bakeoffs show system competitive best literature achieving highest reported number corpora chinese segmentation word-based perceptron algorithm chinese segmentation word-based perceptron algorithm chinese segmentation word-based perceptron algorithm 
recent studies suggest machine learning applied develop good automatic evaluation metrics machine translated sentences paper analyzes aspects learning impact performance argue previously proposed approaches training humanlikeness classifier well correlated human judgments translation quality learning produces reliable metrics demonstrate feasibility metrics empirical analysis learning curves generalization studies show achieve higher correlations human judgments standard automatic metrics re-examination machine learning approaches sentence-level mt evaluation re-examination machine learning approaches sentence-level mt evaluation re-examination machine learning approaches sentence-level mt evaluation 
paper presents pipeline iteration approach uses output later stages pipeline constrain earlier stages pipeline demonstrate significant improvements pcfg parsing pipeline using constraints derived either later stages parsing pipeline finitestate shallow parser best performance achieved reranking union unconstrained parses relatively heavilyconstrained parses pipeline iteration pipeline iteration pipeline iteration 
previous studies dependency parsing shown tree transformations improve parsing accuracy specific parsers data sets investigate extent generalized across languages treebanks parsers focusing parsing way capturing dependencies transformations used facilitate parsing coordinate structures verb groups results indicate beneficial effect parsing independent parsing strategy sensitive language treebank specific properties contrast construction specific transformations appear sensitive parsing strategy constant positive effect several languages generalizing tree transformations inductive dependency parsing generalizing tree transformations inductive dependency parsing generalizing tree transformations inductive dependency parsing 
bilingual word alignment forms foundation approaches statistical machine translation current word alignment methods predominantly based generative models paper demonstrate discriminative approach training simple word alignment models comparable accuracy complex generative models normally used models advantages easy add features allow fast optimization model parameters using small amounts annotated data motivation bilingual word alignment first step current approaches statistical machine translation although best performing systems phrasebased och ney possible phrase translations normally first extracted wordaligned bilingual text segments standard approach word alignment makes use various combinations five generative models developed ibm brown et al sometimes augmented model och ney model och ney best combinations models produce high accuracy alignments least trained large corpus fairly direct translations related languages standard models less ideal however number ways two address paper first although standard models theoretically trained without supervision practice various parameters introduced optimized using annotated data example och ney suggest supervised optimization number parameters including probablity jumping empty word hmm model well smoothing parameters distortion probabilities fertility probabilities complex models since values parameters affect values translation alignment fertility probabilities trained em effective way optimize run training procedure particular combination values evaluate accuracy resulting alignments since evaluating combination parameter values way take hours days large training corpus seems safe say parameters rarely ever truly jointly optimized particular alignment discriminative framework bilingual word alignment discriminative framework bilingual word alignment discriminative framework bilingual word alignment 
proceedings acl demo poster sessions pages prague june association computational linguistics linguistically motivated nlp boxer james curran school information technologies university sydney nsw australia james usyd edu au stephen clark computing laboratory oxford university wolfson building parks road oxford ox qd uk stephen clark comlab ox ac uk johan bos dipartimento di informatica universita di roma la sapienza via salaria roma italy bos di uniroma linguistically motivated large-scale nlp c\&c boxer linguistically motivated large-scale nlp c\&c boxer linguistically motivated large-scale nlp c\&c boxer 
gorman curran argue thesaurus generation billion corpora problematic full computation takes many days present algorithm computation takes two hours created made publicly available thesauruses based large corpora time writing seven major world languages development implemented sketch engine kilgarriff et al another innovative development tool presentation grammatical behaviour word background words word class behave thus english noun constraint occurs plural salient lexical fact form judgement need know distribution nouns use histograms present distribution way easy grasp thesaurus creation last ten years interest growing distributional thesauruses hereafter simply thesauruses following initial work spa rck jones grefenstette early online distributional thesaurus presented lin widely used cited numerous authors since explored thesaurus properties parameters see survey component weeds weir thesaurus created taking corpus identifying contexts word identifying words share contexts word words share contexts according statistic also takes account frequency nearest neighbours thesauruses generally improve accuracy corpus size larger corpus clearly signal similar words distinguished noise words happen share contexts lin based around words curran used billion direct approach thesaurus computation looks word compares word checking contexts see shared thus complexity number types size context vector number types increases corpus size ravichandran et al propose heuristics thesaurus building without undertaking complete calculation line reasoning explored gorman curran argue complete calculation realistic given large efficient algorithm building distributional thesaurus (and sketch engine developments) efficient algorithm building distributional thesaurus (and sketch engine developments) efficient algorithm building distributional thesaurus (and sketch engine developments) 
paper presents use support vector machines svm detect relevant information included queryfocused summary several svms trained using information pyramids summary content units performance compared best performing systems using rouge autopan automatic scoring method pyramid evaluation support vector machines query-focused summarization trained evaluated pyramid data support vector machines query-focused summarization trained evaluated pyramid data support vector machines query-focused summarization trained evaluated pyramid data 
kernel methods support vector machines svms attracted great deal popularity machine learning natural language processing nlp communities polynomial kernel svms showed competitive accuracy many nlp problems like tagging chunking however methods usually inefficient applied large dataset real time purpose paper propose approximate method analogy polynomial kernel efficient data mining approaches prevent testing time complexity also present new method speeding svm classifying independent polynomial degree experimental results showed method times faster traditional polynomial kernel terms training testing respectively approximate approach training polynomial kernel svms linear time approximate approach training polynomial kernel svms linear time approximate approach training polynomial kernel svms linear time 
text categorization task compare effectiveness feature based approach use sequential learning technique proven successful tasks email act classification evaluation demonstrates three separate dimensions well established annotation scheme novel thread based features greater consistent impact classification performance feature based approach leveraging context classifying newsgroup style discussion segments feature based approach leveraging context classifying newsgroup style discussion segments feature based approach leveraging context classifying newsgroup style discussion segments 
opinion analysis important research topic recent years however common methods create evaluation corpora paper introduces method developing opinion corpora involving multiple annotators characteristics created corpus discussed methodologies select consistent testing collections corresponding gold standards proposed gold standards opinion extraction system evaluated experiment results show interesting phenomena test collection selection gold standard generation multiply-annotated opinion corpus test collection selection gold standard generation multiply-annotated opinion corpus test collection selection gold standard generation multiply-annotated opinion corpus 
present minimum bayes risk mbr decoder statistical machine translation approach aims minimize expected loss translation errors regard bleu score show mbr decoding lists leads improvement translation quality report performance mbr decoder four different tasks tcstar epps task nist task gale task absolute improvement bleu score tcstar task gale chineseenglish task minimum bayes risk decoding bleu minimum bayes risk decoding bleu minimum bayes risk decoding bleu 
ability detect similarity conjunct heads potentially useful tool helping disambiguate coordination structures difficult task parsers propose distributional measure similarity designed task compare several different measures word similarity testing whether empirically detect similarity head nouns noun phrase conjuncts wall street journal wsj treebank demonstrate several measures word similarity successfully detect conjunct head similarity suggest measure proposed paper appropriate task empirical measurements lexical similarity noun phrase conjuncts empirical measurements lexical similarity noun phrase conjuncts empirical measurements lexical similarity noun phrase conjuncts 
summarization extracts organizes summary sentences terms events sentences describe work focus semantic relations among event terms connecting terms relations build event term graph upon relevant terms grouped clusters assume cluster represents topic documents two summarization strategies investigated selecting one term representative topic cover topics selecting terms one significant topic highlight relevant information related topic selected terms responsible pick appropriate sentences describing evaluation summarization duc document sets shows encouraging improvement summarization extractive summarization based event term clustering extractive summarization based event term clustering extractive summarization based event term clustering 
present approach mt turkic languages present results implementation mt system turkmen turkish approach relies ambiguous lexical morphological transfer augmented target side repairs rescoring statistical language models machine translation turkic languages machine translation turkic languages machine translation turkic languages 
dependency structures information phrase categories phrase structure grammar thus dependency parsing relies heavily lexical information words paper discusses investigation effectiveness lexicalization dependency parsing specifically restricting degree lexicalization training phase parser examine change accuracy dependency relations experimental results indicate minimal low lexicalization sufficient parsing accuracy minimally lexicalized dependency parsing minimally lexicalized dependency parsing minimally lexicalized dependency parsing 
paper investigates use machine learning algorithms label compounds semantic relation attributes used input learning algorithms web frequencies phrases containing modifier noun prepositional joining term compare evaluate different algorithms different joining phrases nastase szpakowicz dataset compounds find using support vector machine classifier obtain better performance dataset current system even relatively small set prepositional joining terms semantic classification noun phrases using web counts learning algorithms semantic classification noun phrases using web counts learning algorithms semantic classification noun phrases using web counts learning algorithms 
propose automatic machine translation mt evaluation metric calculates similarity score based precision recall pair sentences unlike metrics compute similarity score items across two sentences find maximum weight matching items item one sentence mapped one item sentence general framework allows us use arbitrary similarity functions items incorporate different information comparison dependency relations etc evaluated data mt workshop proposed metric achieves higher correlation human judgements automatic mt evaluation metrics evaluated workshop maxsim: maximum similarity metric machine translation evaluation maxsim: maximum similarity metric machine translation evaluation maxsim: maximum similarity metric machine translation evaluation 
work problem extracting phrase translation formulated information retrieval process implemented model aiming balanced precision recall present generic phrase training algorithm parameterized feature functions optimized jointly translation engine directly maximize system performance multiple feature functions proposed capture quality confidence phrases phrase pairs experimental results demonstrate consistent significant improvement widely used method based word alignment matrix phrase table training precision recall: makes good phrase good phrase pair? phrase table training precision recall: makes good phrase good phrase pair? phrase table training precision recall: makes good phrase good phrase pair? 
propose language model based precise linguistically motivated grammar phrase structure grammar statistical model estimating probability parse tree language model applied means rescoring step allows directly measure performance gains relative baseline system without rescoring demonstrate approach feasible beneficial speech recognition tasks applied simplified german transcription task report significant reduction word error rate compared baseline system applying grammar-based language model simplified broadcast-news transcription task applying grammar-based language model simplified broadcast-news transcription task applying grammar-based language model simplified broadcast-news transcription task 
written documents created dictation differ significantly true verbatim transcript recorded speech poses obstacle automatic dictation systems speech recognition output needs undergo fair amount editing order turn document complies customary standards present approach attempts perform edit recognized words final document automatically learning appropriate transformations example documents addresses number problems integrated way far studied independently particular automatic punctuation text segmentation error correction disfluency repair study two different learning methods one based rule induction one based probabilistic sequence model quantitative evaluation shows probabilistic method performs accurately automatic editing back-end speech-to-text system automatic editing back-end speech-to-text system automatic editing back-end speech-to-text system 
query expansion word alterations alternative forms word often used web search replace word stemming allows users specify particular word forms query however many alterations added query traffic greatly increased paper propose methods select useful word alterations query expansion selection made according appropriateness alteration query context using bigram language model according expected impact retrieval effectiveness using regression model experiments two trec collections show methods select expansion terms retrieval effectiveness improved significantly selecting query term alternations web search exploiting query contexts selecting query term alternations web search exploiting query contexts selecting query term alternations web search exploiting query contexts 
paper proposes method correct english verb form errors made speakers basic approach template matching parse trees proposed method improves approach two ways improve recall irregularities parse trees caused verb form errors taken account improve precision counts utilized filter proposed corrections evaluation corpora representing two genres mother tongues shows promising results correcting misuse verb forms correcting misuse verb forms correcting misuse verb forms 
among translation models approach takes input parse tree source sentence promising direction faster simpler counterpart however current systems suffer major drawback use parse direct translation potentially introduces translation mistakes due parsing errors propose approach translates packed forest exponentially many parses encodes many alternatives standard lists experiments show absolute improvement bleu points baseline result also points higher decoding parses takes even less time forest-based translation forest-based translation forest-based translation 
paper proposes framework representing meaning phrases sentences vector space central approach vector composition operationalize terms additive multiplicative functions framework introduce wide range composition models evaluate empirically sentence similarity task experimental results demonstrate multiplicative models superior additive alternatives compared human judgments vector-based models semantic composition vector-based models semantic composition vector-based models semantic composition 
study presents novel approach problem system portability across different domains sentiment annotation system integrates classifier trained small set annotated data system trained wordnet paper explores challenges system portability across domains text genres movie reviews news blogs product reviews highlights factors affecting system performance smallset data presents new system consisting ensemble two classifiers vote weighting provides significant gains accuracy recall classifier system taken individually specialists generalists work together: overcoming domain dependence sentiment tagging specialists generalists work together: overcoming domain dependence sentiment tagging specialists generalists work together: overcoming domain dependence sentiment tagging 
propose using clustering dependency relations verbs multiword nouns mns construct gazetteer named entity recognition ner since dependency relations capture semantics mns well mn clusters constructed using dependency relations serve good gazetteer however high level computational cost prevented use clustering constructing gazetteers parallelized clustering algorithm based expectationmaximization em thus enabled construction mn clusters demonstrated irex dataset japanese ner using constructed clusters gazetteer cluster gazetteer effective way improving accuracy ner moreover demonstrate combination cluster gazetteer gazetteer extracted wikipedia also useful ner improve accuracy several cases inducing gazetteers named entity recognition large-scale clustering dependency relations inducing gazetteers named entity recognition large-scale clustering dependency relations inducing gazetteers named entity recognition large-scale clustering dependency relations 
statistical machine learning methods employed train named entity recognizer annotated data methods like maximum entropy conditional random fields make use features training purpose methods tend overfit available training corpus limited especially number features large number values feature large overcome proposed two techniques feature reduction based word clustering selection number word similarity measures proposed clustering words named entity recognition task corpus based statistical measures used important word selection feature reduction techniques lead substantial performance improvement baseline maximum entropy technique word clustering word selection based feature reduction maxent based hindi ner word clustering word selection based feature reduction maxent based hindi ner word clustering word selection based feature reduction maxent based hindi ner 
propose succinct randomized language model employs perfect hash function encode fingerprints associated probabilities backoff weights parameters scheme represent standard model easily combined existing model reduction techniques demonstrate scheme via machine translation experiments within distributed language modeling framework randomized language models via perfect hash functions randomized language models via perfect hash functions randomized language models via perfect hash functions 
present novel training algorithm learning dependency parsers combining supervised large margin loss unsupervised least squares loss discriminative convex learning algorithm obtained applicable problems demonstrate benefits approach apply technique learning dependency parsers combined labeled unlabeled corpora using stochastic gradient descent algorithm parsing model efficiently learned data significantly outperforms corresponding supervised methods semi-supervised convex training dependency parsing semi-supervised convex training dependency parsing semi-supervised convex training dependency parsing 
paper presents empirical study robustness generalization two alternative role sets semantic role labeling propbank numbered roles verbnet thematic roles testing state art srl system two alternative role annotations show propbank role set robust lack verb specific semantic information generalizes better infrequent unseen predicates keeping mind thematic roles better application needs also tested best way generate verbnet annotation conclude tagging first propbank roles mapping verbnet roles effective training tagging directly verbnet robust domain shifts robustness generalization role sets: propbank vs. verbnet robustness generalization role sets: propbank vs. verbnet robustness generalization role sets: propbank vs. verbnet 
previous studies evaluate simulated dialog corpora using evaluation measures automatically extracted dialog systems logs however validity automatic measures fully proven study first recruit human judges assess quality three simulated dialog corpora use human judgments gold standard validate conclusions drawn automatic measures observe hard human judges reach good agreement asked rate quality dialogs given perspectives however human ratings give consistent ranking quality simulated corpora generated different simulation models building prediction models human judgments using previously proposed automatic measures find cannot reliably predict human ratings using regression model predict human rankings ranking model assessing dialog system user simulation evaluation measures using human judges assessing dialog system user simulation evaluation measures using human judges assessing dialog system user simulation evaluation measures using human judges 
paper provides evidence use unlabeled data learning improve performance natural language processing nlp tasks tagging syntactic chunking named entity recognition first propose simple yet powerful discriminative model appropriate handling large scale unlabeled data describe experiments performed widely used test collections namely ptb iii data conll shared task data three nlp tasks respectively incorporate one billion tokens unlabeled data largest amount unlabeled data ever used tasks investigate performance improvement addition results superior best reported results test collections semi-supervised sequential labeling segmentation using giga-word scale unlabeled data semi-supervised sequential labeling segmentation using giga-word scale unlabeled data semi-supervised sequential labeling segmentation using giga-word scale unlabeled data 
validity semantic inferences depends contexts applied propose generic framework handling contextual considerations within applied inference termed contextual preferences framework defines various components needed inference relationships contextual preferences extend generalize previous notions selectional preferences experiments show extended framework allows improving inference quality real application data contextual preferences contextual preferences contextual preferences 
work describes answer ranking engine questions built using large online collection yahoo answers show collections may used effectively set large supervised learning experiments furthermore investigate wide range feature types exploiting nlp processors demonstrate using combination leads considerable improvements accuracy learning rank answers large online qa collections learning rank answers large online qa collections learning rank answers large online qa collections 
widely held belief natural language computational linguistics communities semantic role labeling srl significant step toward improving important applications question answering information extraction paper present srl system modern standard arabic exploits many aspects rich morphological features language experiments pilot arabic propbank data show system based support vector machines kernel methods yields global srl score improves current arabic srl semantic role labeling systems arabic using kernel methods semantic role labeling systems arabic using kernel methods semantic role labeling systems arabic using kernel methods 
extend classical active learning al approach active learning mtal paradigm select examples several annotation tasks rather single one usually done context al introduce two mtal metaprotocols alternating selection rank combination propose method implement practice experiment twotask annotation scenario includes named entity syntactic parse tree annotations three different corpora mtal outperforms random selection stronger baseline onesided example selection one task pursued using al selected examples provided also task multi-task active learning linguistic annotations multi-task active learning linguistic annotations multi-task active learning linguistic annotations 
previous studies dependency parsing shown distribution parsing errors correlated theoretical properties models used learning inference paper show results exploited improve parsing accuracy integrating model letting one model generate features consistently improve accuracy models resulting significant improvement state art evaluated data sets shared task integrating graph-based transition-based dependency parsers integrating graph-based transition-based dependency parsers integrating graph-based transition-based dependency parsers 
define new formalism based sikkel parsing schemata constituency parsers used describe analyze compare dependency parsing algorithms abstraction allows us establish clear relations several existing projective dependency parsers prove correctness deductive approach dependency parsing deductive approach dependency parsing deductive approach dependency parsing 
automatic word alignment key step training statistical machine translation systems despite much recent work word alignment methods alignment accuracy increases often produce little improvements machine translation quality work analyze recently proposed em algorithm unsupervised alignment models attempt tease apart effects simple effective modification alignment precision recall rare common words affected across several language pairs propose extensively evaluate simple method using alignment models produce alignments mt systems show significant gains measured bleu score translation systems six languages pairs used recent mt competitions better alignments = better translations? better alignments = better translations? better alignments = better translations? 
adding syntax statistical mt tradeoff taking advantage linguistic analysis versus allowing model exploit linguistically unmotivated mappings learned parallel training data number previous efforts tackled tradeoff starting commitment linguistically motivated analyses finding appropriate ways soften commitment present approach explores tradeoff direction starting translation model learned directly aligned parallel text adding soft constraints based parses source language obtain substantial improvements performance translation chinese arabic english soft syntactic constraints hierarchical phrased-based translation soft syntactic constraints hierarchical phrased-based translation soft syntactic constraints hierarchical phrased-based translation 
word lattice decoding proven useful spoken language translation argue provides compelling model translation text genres well show prior work translating lattices using finite state techniques naturally extended expressive synchronous grammarbased models additionally resolve significant complication word lattice inputs introduce reordering models experiments evaluating approach demonstrate substantial gains chineseenglish translation generalizing word lattice translation generalizing word lattice translation generalizing word lattice translation 
paper studies impact written language variations way affects capitalization task time discriminative approach based maximum entropy models proposed perform capitalization taking language changes consideration proposed method makes possible use large corpora training evaluation performed newspaper corpora using different testing periods achieved results reveal strong relation capitalization performance elapsed time training testing data periods language dynamics capitalization using maximum entropy language dynamics capitalization using maximum entropy language dynamics capitalization using maximum entropy 
paper describes extractive summarizer educational science content called cogent cogent extends mead based strategies elicited empirical study domain instructional experts cogent implements hybrid approach integrating domain independent sentence scoring features features initial evaluation results indicate cogent outperforms existing summarizers generates summaries closely resemble generated human experts extractive summaries educational science content extractive summaries educational science content extractive summaries educational science content 
many phrase alignment models operate combinatorial space bijective phrase alignments prove finding optimal alignment space computing alignment expectations hand show problem finding optimal alignment cast integer linear program provides simple declarative approach viterbi inference phrase alignment models empirically quite efficient complexity phrase alignment problems complexity phrase alignment problems complexity phrase alignment problems 
current algorithms machine translation rely models potential problem underfitting training data present boostedmert novel boosting algorithm uses minimum error rate training mert weak learner builds far expressive models boostedmert easy implement inherits efficient optimization properties mert quickly boost bleu score tasks paper describe general algorithm present preliminary results iwslt task beyond log-linear models: boosted minimum error rate training n-best re-ranking beyond log-linear models: boosted minimum error rate training n-best re-ranking beyond log-linear models: boosted minimum error rate training n-best re-ranking 
present four techniques online handling words phrasebased statistical machine translation techniques use spelling expansion morphological expansion dictionary term expansion proper name transliteration reuse extend phrase table compare performance techniques combine results show consistent improvement baseline terms bleu manual error analysis four techniques online handling out-of-vocabulary words arabic-english statistical machine translation four techniques online handling out-of-vocabulary words arabic-english statistical machine translation four techniques online handling out-of-vocabulary words arabic-english statistical machine translation 
paper describe recent improvements components methods used statistical machine translation system chineseenglish used january gale evaluation main improvements results consistent data processing larger statistical models word reordering approach recent improvements cmu large scale chinese-english smt system recent improvements cmu large scale chinese-english smt system recent improvements cmu large scale chinese-english smt system 
song sentiment classification seeks assign songs appropriate sentiment labels four problems render vector space model vsm text classification approach ineffective many words within song lyrics actually contribute little sentiment nouns verbs used express sentiment ambiguous negations modifiers around sentiment keywords make particular contributions sentiment song lyric usually short address problems sentiment vector space model proposed represent song lyric document preliminary experiments prove svsm model outperforms vsm model song sentiment classification task lyric-based song sentiment classification sentiment vector space model lyric-based song sentiment classification sentiment vector space model lyric-based song sentiment classification sentiment vector space model 
limitation research supervised sentence compression dearth available training data propose new bountiful resource training data obtain mining revision history wikipedia sentence compressions expansions using fraction available wikipedia data collected training corpus sentence pairs two orders magnitude larger standardly used corpus using newfound data propose novel lexicalized noisy channel model sentence compression achieving improved results grammaticality compression rate criteria slight decrease importance mining wikipedia revision histories improving sentence compression mining wikipedia revision histories improving sentence compression mining wikipedia revision histories improving sentence compression 
paper propose linguistically annotated reordering model statistical machine translation model incorporates linguistic knowledge predict orders syntactic phrases linguistic knowledge automatically learned parse trees annotation algorithm empirically demonstrate proposed model leads significant improvement bleu score baseline reordering model nist translation task linguistically annotated reordering model btg-based statistical machine translation linguistically annotated reordering model btg-based statistical machine translation linguistically annotated reordering model btg-based statistical machine translation 
paper report set initial results statistical machine translation smt show morphological decomposition arabic source beneficial especially corpora investigate different recombination techniques also report use factored translation models translation segmentation english-to-arabic statistical machine translation segmentation english-to-arabic statistical machine translation segmentation english-to-arabic statistical machine translation 
word posterior probabilities estimated hypotheses used improve performance statistical machine translation smt rescoring framework paper extend idea estimate posterior probabilities hypotheses translation target language source word reorderings smt system posterior knowledge learned nbest hypotheses framework experiments nist task show performance improvements strategies moreover combination three strategies achieves improvements outperforms baseline bleu score set nist set respectively exploiting n-best hypotheses smt self-enhancement exploiting n-best hypotheses smt self-enhancement exploiting n-best hypotheses smt self-enhancement 
automatic extraction collocations large corpora focus many research efforts approaches concentrate improving combining known lexical association measures paper describe genetic programming approach evolving new association measures limited specific language corpus type collocation preliminary experimental results show evolved measures outperform three known association measures evolving new lexical association measures using genetic programming evolving new lexical association measures using genetic programming evolving new lexical association measures using genetic programming 
show sentence fusion better defined task generic sentence fusion fusions shorter display less variety length yield identical results higher normalized rouge scores moreover show qa setting participants strongly prefer fusions generic ones preference union intersection fusions query-based sentence fusion better defined leads preferred results generic sentence fusion query-based sentence fusion better defined leads preferred results generic sentence fusion query-based sentence fusion better defined leads preferred results generic sentence fusion 
paper present research apply kind intrinsic evaluation metrics characteristic current comparative hlt evaluation ii extrinsic human evaluations keeping nlg traditions systems implementing language generation task analyse evaluation results find significant correlations intrinsic extrinsic evaluation measures task intrinsic vs. extrinsic evaluation measures referring expression generation intrinsic vs. extrinsic evaluation measures referring expression generation intrinsic vs. extrinsic evaluation measures referring expression generation 
present fast summarizer called fastsum based solely features clusters documents topics summary sentences ranked regression svm summarizer use expensive nlp techniques parsing tagging names even part speech information still achieved accuracy comparable best systems presented recent academic competitions document understanding conference duc detailed feature analysis using least angle regression lars fastsum rely minimal set features leading fast processing times news documents seconds fastsum: fast accurate query-based multi-document summarization fastsum: fast accurate query-based multi-document summarization fastsum: fast accurate query-based multi-document summarization 
paper addresses new task sentiment classification called sentiment classification aims improve performance fusing training data multiple domains achieve propose two approaches fusion use training data multiple domains simultaneously experimental studies show sentiment classification using approach performs much better single domain classification using training data individually multi-domain sentiment classification multi-domain sentiment classification multi-domain sentiment classification 
distributional similarity widely used capture semantic relatedness words many nlp tasks however various parameters similarity measures must handtuned make work effectively instead propose novel approach synonym identification based supervised learning distributional features correspond commonality individual context types shared word pairs considering integration features built compared five synonym classifiers evaluation experiment shown dramatic performance increase measure basis compared conventional classification hand features appeared almost redundant supervised learning approach automatic synonym identification based distributional features supervised learning approach automatic synonym identification based distributional features supervised learning approach automatic synonym identification based distributional features 
demo introduce side summarization integrated development environment infrastructure facilitates construction summaries tailored needs user aims address issue thing perfect summary purposes rather quality summary subjective task dependent possibly specific user side framework allows users flexibility determining find useful summary terms structure content educational tool successfully user tested class students graduate course summarization personal information management side: summarization integrated development environment side: summarization integrated development environment side: summarization integrated development environment 
system combination method machine translation mt combination using confusion networks one crucial steps confusion network decoding alignment different hypotheses building network paper present new methods improve alignment hypotheses using word synonyms alignment strategy demonstrate combination new alignment technique yields bleu point improvement best input system bleu point improvement combination method two different language pairs improving alignments better confusion networks combining machine translation systems improving alignments better confusion networks combining machine translation systems improving alignments better confusion networks combining machine translation systems 
present automatic method senselabeling text unsupervised manner method makes use distributionally similar words derive automatically labeled training set used train standard supervised classifier distinguishing word senses experimental results datasets show approach yields significant improvements unsupervised methods competitive supervised ones eliminating annotation cost good neighbors make good senses: exploiting distributional similarity unsupervised wsd good neighbors make good senses: exploiting distributional similarity unsupervised wsd good neighbors make good senses: exploiting distributional similarity unsupervised wsd 
paper studies three techniques improve quality hypotheses additional regeneration process unlike consensus approach multiple translation systems used improvement achieved expansion nbest hypotheses single system explore three different methods implement regeneration process redecoding expansion confusion regeneration experiments nist iwslt tasks show three methods obtain consistent improvements moreover combination three strategies achieves improvements outperforms baseline iwslt nist nist test set respectively regenerating hypotheses statistical machine translation regenerating hypotheses statistical machine translation regenerating hypotheses statistical machine translation 
paper focus adaptation problem large labeled data source domain large unlabeled data target domain aim learn reliable information unlabeled target domain data dependency parsing adaptation current statistical parsers perform much better shorter dependencies longer ones thus propose adaptation approach learning reliable information shorter dependencies unlabeled target data help parse longer distance words unlabeled data parsed dependency parser trained labeled source domain data experimental results indicate proposed approach outperforms baseline system better current adaptation techniques learning reliable information dependency parsing adaptation learning reliable information dependency parsing adaptation learning reliable information dependency parsing adaptation 
present novel approach word reordering successfully integrates syntactic structural knowledge smt done constructing lattice alternatives based automatically learned probabilistic syntactic rules decoding alternatives scored based output word order order input unlike previous approaches makes possible successfully integrate syntactic reordering smt task achieve absolute improvement translation quality bleu manual evaluation supports claim present approach significantly superior previous approaches syntactic reordering integrated phrase-based smt syntactic reordering integrated phrase-based smt syntactic reordering integrated phrase-based smt 
paper proposes novel lexicalized approach rule selection statistical machine translation smt build maximum entropy maxent models combine rich context information selecting translation rules decoding successfully integrate rule selection models smt model experiments show lexicalized approach rule selection achieves statistically significant improvements smt system improving statistical machine translation using lexicalized rule selection improving statistical machine translation using lexicalized rule selection improving statistical machine translation using lexicalized rule selection 
paper describe new reranking strategy named word lattice reranking task joint chinese word segmentation pos tagging derivation forest reranking parsing huang strategy reranks pruned word lattice potentially contains much candidates using less storage compared traditional list reranking perceptron classifier trained local features baseline word lattice reranking performs reranking features easily incorporated perceptron baseline experimental results show strategy achieves improvement segmentation pos tagging perceptron baseline list reranking word lattice reranking chinese word segmentation part-of-speech tagging word lattice reranking chinese word segmentation part-of-speech tagging word lattice reranking chinese word segmentation part-of-speech tagging 
almost automatic semantic role labeling srl systems rely preliminary parsing step derives syntactic structure sentence analyzed makes choice syntactic representation essential design decision paper study influence syntactic representation performance srl systems specifically compare dependencybased representations srl english framenet paradigm contrary previous claims results demonstrate systems based dependencies perform roughly well based constituents argument classification task dependencybased systems perform slightly higher average opposite holds argument identification task remarkable dependency parsers still infancy constituent parsing mature furthermore results show semantic role classifiers rely less lexicalized features makes robust domain changes makes learn efficiently respect amount training data effect syntactic representation semantic role labeling effect syntactic representation semantic role labeling effect syntactic representation semantic role labeling 
active learning proven method reducing cost creating training sets necessary statistical nlp however little work stopping criteria active learning operational stopping criterion necessary able use active learning nlp applications investigate three different stopping criteria active learning named entity recognition ner show one stopping reliably stops active learning ii achieves nearoptimal ner performance iii needs much training data exhaustive labeling stopping criteria active learning named entity recognition stopping criteria active learning named entity recognition stopping criteria active learning named entity recognition 
paper describes incremental approach parsing transcribed spontaneous speech containing disfluencies hierarchical hidden markov model hhmm model makes use transform shown increase parsing accuracy transcribed spontaneous speech miller schuler using trees transformed manner train hhmm parser representations used model align structure speech repairs timeseries model directly integrated conventional speech recognition systems run continuous streams audio system implementing model evaluated standard task parsing switchboard corpus achieves improvement standard baseline probabilistic cyk parser syntactic time-series model parsing fluent disfluent speech syntactic time-series model parsing fluent disfluent speech syntactic time-series model parsing fluent disfluent speech 
och minimum error rate training mert procedure commonly used method training feature weights statistical machine translation smt models use multiple randomized starting points mert practice although seems published systematic study benefits compare several ways performing random restarts mert find random restart methods outperform mert without random restarts develop refinements random restarts superior common approach regard resulting model quality training time random restarts minimum error rate training statistical machine translation random restarts minimum error rate training statistical machine translation random restarts minimum error rate training statistical machine translation 
paper proposes new approach dynamically determine tree span tree semantic relation extraction exploits constituent dependencies keep nodes head children along path connecting two entities removing noisy information syntactic parse tree eventually leading dynamic syntactic parse tree paper also explores entity features combined features unified parse semantic tree integrates structured syntactic parse information semantic information evaluation ace rdc corpus shows dynamic syntactic parse tree outperforms previous tree spans composite kernel combining tree kernel linear kernel achieves far best performance exploiting constituent dependencies tree kernel-based semantic relation extraction exploiting constituent dependencies tree kernel-based semantic relation extraction exploiting constituent dependencies tree kernel-based semantic relation extraction 
paper consider classifying word positions whether either start end constituents provides mechanism closing chart cells inference demonstrated improve efficiency accuracy used constrain wellknown charniak parser additionally present method closing sufficient number chart cells ensure quadratic complexity inference empirical results show bound achieved without impacting parsing accuracy classifying chart cells quadratic complexity context-free inference classifying chart cells quadratic complexity context-free inference classifying chart cells quadratic complexity context-free inference 
dependency parsing approaches assume sentence structure represented trees although trees several desirable properties computational linguistic perspectives structure linguistic phenomena goes beyond shallow syntax often cannot fully captured tree representations present parsing approach nearly simple current dependency parsing frameworks outputs directed acyclic graphs dags demonstrate benefits dag parsing two experiments advantages dependency tree parsing clearly observed analysis english syntactic analysis danish representation includes dependencies anaphoric reference links shift-reduce dependency dag parsing shift-reduce dependency dag parsing shift-reduce dependency dag parsing 
machine learning whether one build accurate classifier using unlabeled data learning important issue although number methods proposed effectiveness nlp tasks always clear paper presents novel method employs learning paradigm call structural learning idea find good classifiers like learning thousands automatically generated auxiliary classification problems unlabeled data common predictive structure shared multiple classification problems discovered used improve performance target problem method produces performance higher previous best results conll syntactic chunking conll named entity chunking english german high-performance semi-supervised learning method text chunking high-performance semi-supervised learning method text chunking high-performance semi-supervised learning method text chunking 
semantic role labeling srl arguments usually limited syntax subtree reasonable label arguments locally rather whole tree identify active region arguments paper models maximal projection mp concept dstructure projection principle principle parameters theory paper makes new definition mp sstructure proposes two methods predict anchor group approach single anchor approach anchor group approach achieves accuracy single anchor approach achieves experimental results also indicate prediction mp improves semantic role labeling prediction maximal projection semantic role labeling prediction maximal projection semantic role labeling prediction maximal projection semantic role labeling 
describe automatic word sense disambiguation wsd system disambiguates verb senses using syntactic semantic features encode information predicate arguments semantic classes system performs best published accuracy english verbs also experiment using predicateargument labels propbank disambiguating wordnet senses propbank framesets show disambiguation verb senses improved better extraction semantic roles role semantic roles disambiguating verb senses role semantic roles disambiguating verb senses role semantic roles disambiguating verb senses 
proceedings rd annual meeting acl pages ann arbor june association computational linguistics towards developing generation algorithms applications radu soricut daniel marcu information sciences institute university southern california admiralty way suite marina del rey ca towards developing generation algorithms text-to-text applications towards developing generation algorithms text-to-text applications towards developing generation algorithms text-to-text applications 
order realize full potential syntactic parsing desirable allow dependency structures show datadriven deterministic dependency parser restricted projective structures combined graph transformation techniques produce structures experiments using data prague dependency treebank show combined system handle nonprojective constructions precision sufficient yield significant improvement overall parsing accuracy leads best reported performance robust parsing czech pseudo-projective dependency parsing pseudo-projective dependency parsing pseudo-projective dependency parsing 
paper suggests refinements distributional similarity hypothesis proposed hypotheses relate distributional behavior pairs words lexical entailment tighter notion semantic similarity required many nlp applications automatically explore validity defined hypotheses developed inclusion testing algorithm characteristic features two words incorporates corpus feature sampling overcome data sparseness degree hypotheses validity empirically tested manually analyzed respect word sense level addition testing algorithm exploited improve lexical entailment acquisition distributional inclusion hypotheses lexical entailment distributional inclusion hypotheses lexical entailment distributional inclusion hypotheses lexical entailment 
paper extension dimensionality reduction algorithm called nonnegative matrix factorization presented combines bag words data syntactic data order find semantic dimensions according words syntactic relations classified use three way data allows one determine dimension responsible certain sense word adapt corresponding feature vector accordingly subtracting one sense discover another one intuition syntactic features approach disambiguated semantic dimensions found bag words approach novel approach embedded clustering algorithms make fully automatic approach carried dutch evaluated eurowordnet using three way data word sense discrimination using three way data word sense discrimination using three way data word sense discrimination 
propose method extracting semantic orientations words desirable undesirable regarding semantic orientations spins electrons use mean field approximation compute approximate probability function system instead intractable actual probability function also propose criterion parameter selection basis magnetization given small number seed words proposed method extracts semantic orientations high accuracy experiments english lexicon result comparable best value ever reported extracting semantic orientations words using spin model extracting semantic orientations words using spin model extracting semantic orientations words using spin model 
paper introduces new application boosting parse reranking several parsers proposed utilize representation tree kernel data oriented parsing paper argues representation extremely redundant comparable accuracy achieved using small set subtrees show boosting algorithm applied representation selects small relevant feature set efficiently two experiments parse reranking show method achieves comparable even better performance kernel methods also improves testing efficiency boosting-based parse reranking subtree features boosting-based parse reranking subtree features boosting-based parse reranking subtree features 
bracketing transduction grammar btg natural choice effective integration desired linguistic knowledge statistical machine translation smt paper propose linguistically annotated btg labtg smt conveys linguistic knowledge syntax structures btg hierarchical structures linguistic annotation linguistically annotated data learn annotated btg rules train linguistically motivated phrase translation model reordering model also present annotation algorithm captures syntactic information btg nodes experiments show labtg approach significantly outperforms baseline btgbased system phrasebased system translation task moreover empirically demonstrate proposed method achieves better translation selection phrase reordering linguistically annotated btg statistical machine translation linguistically annotated btg statistical machine translation linguistically annotated btg statistical machine translation 
words chinese text naturally separated delimiters poses challenge standard machine translation mt systems mt widely used approach apply chinese word segmenter trained manually annotated data using fixed lexicon word segmentation necessarily optimal translation propose bayesian chinese word segmentation model uses monolingual bilingual information derive segmentation suitable mt experiments show method improves mt system small large data environment bayesian semi-supervised chinese word segmentation statistical machine translation bayesian semi-supervised chinese word segmentation statistical machine translation bayesian semi-supervised chinese word segmentation statistical machine translation 
describe evaluate new method automatic seed word selection unsupervised sentiment classification product reviews chinese whole method unsupervised require annotated training data requires information commonly occurring negations adverbials unsupervised techniques promising task since avoid problems typically associated supervised methods results obtained close supervised classifiers sometimes better automatic seed word selection unsupervised sentiment classification chinese text automatic seed word selection unsupervised sentiment classification chinese text automatic seed word selection unsupervised sentiment classification chinese text 
paper presents probabilistic framework qarla evaluation text summarisation systems input framework set manual reference summaries set baseline automatic summaries set similarity metrics summaries provides measure evaluate quality set similarity metrics ii measure evaluate quality summary using optimal set similarity metrics iii measure evaluate whether set baseline summaries reliable may produce biased results compared previous approaches framework able combine different metrics evaluate quality set metrics without weighting relative importance provide quantitative evidence effectiveness approach improve automatic evaluation text summarisation systems combining several similarity metrics qarla: framework evaluation text summarization systems qarla: framework evaluation text summarization systems qarla: framework evaluation text summarization systems 
paper describes summarization system technical chats emails linux kernel reflect complexity sophistication discussions clustered according subtopic structure level immediate responding pairs identified machine learning methods resulting summary consists one subtopic discussion digesting virtual "geek" culture: summarization technical internet relay chats digesting virtual "geek" culture: summarization technical internet relay chats digesting virtual "geek" culture: summarization technical internet relay chats 
paper address issue deciding stop active learning building labeled training corpus firstly paper presents new stopping criterion considers potential ability unlabeled example changing decision boundaries secondly combination strategy proposed solve problem predefining appropriate threshold stopping criterion overalluncertainty finally examine effectiveness stopping criteria uncertainty sampling heterogeneous uncertainty sampling active learning experimental results show stopping criteria work well evaluation data sets combination strategies outperform individual criteria multi-criteria-based strategy stop active learning data annotation multi-criteria-based strategy stop active learning data annotation multi-criteria-based strategy stop active learning data annotation 
paper addresses two issues active learning firstly solve problem uncertainty sampling often fails selecting outliers paper presents new selective sampling technique sampling uncertainty density sud density measure adopted determine whether unlabeled example outlier secondly technique sampling clustering sbc applied build representative initial training data set active learning finally implement new algorithm active learning sud sbc techniques experimental results three data sets show method outperforms competing methods particularly early stages active learning active learning sampling uncertainty density word sense disambiguation text classification active learning sampling uncertainty density word sense disambiguation text classification active learning sampling uncertainty density word sense disambiguation text classification 
applicability many current information extraction techniques severely limited need supervised training data demonstrate certain field structured extraction tasks classified advertisements bibliographic citations small amounts prior knowledge used learn effective models primarily unsupervised fashion although hidden markov models hmms provide suitable generative model field structured text general unsupervised hmm learning fails learn useful structure either domains however one dramatically improve quality learned structure exploiting simple prior knowledge desired solutions domains found unsupervised methods attain accuracies unlabeled examples comparable attained supervised methods labeled examples methods make good use small amounts labeled data unsupervised learning field segmentation models information extraction unsupervised learning field segmentation models information extraction unsupervised learning field segmentation models information extraction 
shortage manually data obstacle supervised word sense disambiguation methods paper investigate label propagation based semisupervised learning algorithm wsd combines labeled unlabeled data learning process fully realize global consistency assumption similar examples similar labels experimental results benchmark corpora indicate consistently outperforms svm labeled examples available performance also better monolingual bootstrapping comparable bilingual bootstrapping word sense disambiguation using label propagation based semi-supervised learning word sense disambiguation using label propagation based semi-supervised learning word sense disambiguation using label propagation based semi-supervised learning 
present smmr scalable sentence scoring method update summarization sentences scored thanks criterion combining query relevance dissimilarity already read documents history amount data history increases prioritized show smmr achieves promising results duc update corpus scalable mmr approach sentence scoring multi-document update summarization scalable mmr approach sentence scoring multi-document update summarization scalable mmr approach sentence scoring multi-document update summarization 
propose method obtain subsentential alignments several languages simultaneously method handles several languages avoids complexity explosion due usual processing used different units characters morphemes words chunks evaluation word alignments trilingual machine translation corpus conducted comparison results obtained state art alignment software reported multilingual alignments monolingual string differences multilingual alignments monolingual string differences multilingual alignments monolingual string differences 
paper proposes alignment adaptation approach improve word alignment basic idea alignment adaptation use corpus improve word alignment results paper first train two statistical word alignment models corpus corpus respectively interpolate two models improve word alignment experimental results show approach improves word alignment terms precision recall achieving relative error rate reduction compared technologies alignment model adaptation domain-specific word alignment alignment model adaptation domain-specific word alignment alignment model adaptation domain-specific word alignment 
present version inversion transduction grammar rule probabilities lexicalized throughout synchronous parse tree along pruning techniques efficient training alignment results improve unlexicalized itg short sentences full em feasible pruning seems negative impact longer sentences stochastic lexicalized inversion transduction grammar alignment stochastic lexicalized inversion transduction grammar alignment stochastic lexicalized inversion transduction grammar alignment 
proceedings rd annual meeting acl pages ann arbor june association computational linguistics localized prediction model statistical machine translation christoph tillmann tong zhang ibm watson research center yorktown heights ny usa localized prediction model statistical machine translation localized prediction model statistical machine translation localized prediction model statistical machine translation 
learning based shift reduce parsing algorithms emerged dependency parsing shown excellent performance many treebanks paper investigate extension methods considerably improved runtime training time efficiency via svms also present several properties constraints enhance parser completeness runtime integrate syntactic information using sequential taggers experimental results show positive effect features improve parser labeled attachment scores modified yamada nivre method respectively chinese treebank comparison parsers maltparser mstparser methods produce better accuracy also drastically reduced testing time respectively robust efficient chinese word dependency analysis linear kernel support vector machines robust efficient chinese word dependency analysis linear kernel support vector machines robust efficient chinese word dependency analysis linear kernel support vector machines 
semantic role labeling process annotating structure text semantic labels paper present baseline semantic role labeling system based support vector machine classifiers show improvements system adding new features including features extracted dependency parses ii performing feature selection calibration iii combining parses obtained semantic parsers trained using different syntactic views error analysis baseline system showed approximately half argument identification errors resulted parse errors syntactic constituent aligned correct argument order address problem combined semantic parses minipar syntactic parse chunked syntactic representation original baseline system based charniak parses reported techniques resulted performance improvements semantic role labeling using different syntactic views semantic role labeling using different syntactic views semantic role labeling using different syntactic views 
despite much recent progress accurate semantic role labeling previous work largely used independent classifiers possibly combined separate label sequence models via viterbi decoding stands stark contrast linguistic observation core argument frame joint structure strong dependencies arguments show build joint model argument frames incorporating novel features model interactions discriminative loglinear models system achieves error reduction arguments core arguments art independent classifier goldstandard parse trees propbank joint learning improves semantic role labeling joint learning improves semantic role labeling joint learning improves semantic role labeling 
paper explore power randomized algorithm address challenge working large amounts data apply algorithms generate noun similarity lists million pages reduce running time quadratic practically linear number elements computed randomized algorithms nlp: using locality sensitive hash functions high speed noun clustering randomized algorithms nlp: using locality sensitive hash functions high speed noun clustering randomized algorithms nlp: using locality sensitive hash functions high speed noun clustering 
paper presents status quo ongoing research study collocations essential linguistic phenomenon wide spectrum applications field natural language processing core work empirical evaluation comprehensive list automatic collocation extraction methods using measures proposal new approach integrating multiple basic methods statistical classification demonstrate combining multiple independent techniques leads significant performance improvement comparisonwith individualbasic methods extensive empirical study collocation extraction methods extensive empirical study collocation extraction methods extensive empirical study collocation extraction methods 
semantic role labeling srl proved valuable tool performing automatic analysis natural language texts currently however systems rely large training set manually annotated effort needs repeated whenever different languages different set semantic roles used certain application possible solution problem learning small set training examples automatically expanded using unlabeled texts present latent words language model language model learns word similarities unlabeled texts use similarities different srl methods additional features automatically expand small training set evaluate methods propbank dataset find small training sizes best performing system achieves error reduction compared supervised baseline semi-supervised semantic role labeling using latent words language model semi-supervised semantic role labeling using latent words language model semi-supervised semantic role labeling using latent words language model 
many statistical translation models regarded weighted logical deduction paradigm use weights expectation semiring eisner compute statistics expected hypothesis length feature counts packed forests translations lattices hypergraphs introduce novel expectation semiring computes statistics variance hypothesis length gradient entropy semiring essential many interesting training paradigms minimum risk deterministic annealing active learning learning gradient descent optimization requires computing gradient entropy risk use semirings machine translation toolkit joshua enabling training benefit bleu point first- second-order expectation semirings applications minimum-risk training translation forests first- second-order expectation semirings applications minimum-risk training translation forests first- second-order expectation semirings applications minimum-risk training translation forests 
minimum error rate training mert involves choosing parameter values machine translation mt system maximize performance tuning set measured automatic evaluation metric bleu method best system eventually evaluated using metric reality mt evaluations component although performing mert metric seems like daunting task describe new metric rypt takes human judgments account requires human input build database reused hence eliminating need human input tuning time investigative study analyze diversity lack thereof candidates produced mert describe redundancy used advantage show rypt better predictor translation quality bleu feasibility human-in-the-loop minimum error rate training feasibility human-in-the-loop minimum error rate training feasibility human-in-the-loop minimum error rate training 
sentiment classification seeks identify piece text according author general feeling toward subject positive negative traditional machine learning techniques applied problem reasonable success shown work well good match training test data respect topic paper demonstrates match respect domain time also important presents preliminary experiments training data labeled emoticons potential independent domain topic time using emoticons reduce dependency machine learning techniques sentiment classification using emoticons reduce dependency machine learning techniques sentiment classification using emoticons reduce dependency machine learning techniques sentiment classification 
present framework extract important features tree fragments tree kernel tk space according importance target kernelbased machine support vector machines svms particular mining algorithm selects relevant features based svm estimated weights uses information automatically infer explicit representation input data explicit features improve knowledge target problem domain make learning practical improving training test time yielding accuracy line traditional tk classifiers experiments semantic role labeling question classification illustrate claims reverse engineering tree kernel feature spaces reverse engineering tree kernel feature spaces reverse engineering tree kernel feature spaces 
instant messaging chat sessions realtime conversations analyzed using models describe statistical approach modelling detecting dialogue acts instant messaging dialogue involved collection small set dialogues annotating revised tag set dealt segmentation synchronisation issues arise spoken dialogue model developed combines naive bayes obtain better accuracy tagging experiment dialogue act tagging instant messaging chat sessions dialogue act tagging instant messaging chat sessions dialogue act tagging instant messaging chat sessions 
present statistical machine translation system performs translation dependency structures bilingual resource required parallel corpus resources monolingual also refer evaluation method plan compare system output benchmark system dependency-based statistical machine translation dependency-based statistical machine translation dependency-based statistical machine translation 
paper presents paradigm assess degrees sentiment product reviews sentiment identification well studied however previous work provides binary polarities positive negative polarity sentiment simply reversed negation detected extraction lexical features unigram bigram also complicates sentiment classification task linguistic structure implicit dependency often disregarded paper propose approach extracting phrases based clause structure obtained parsing sentences hierarchical representation also propose robust general solution modeling contribution adverbials negation score degree sentiment application involving extracting pros cons restaurant reviews obtained relative improvement recall use parsing methods also improving precision review sentiment scoring via parse-and-paraphrase paradigm review sentiment scoring via parse-and-paraphrase paradigm review sentiment scoring via parse-and-paraphrase paradigm 
paper investigates new task subjectivity word sense disambiguation swsd automatically determine word instances corpus used subjective senses used objective senses provide empirical evidence swsd feasible full word sense disambiguation exploited improve performance contextual subjectivity sentiment analysis systems subjectivity word sense disambiguation subjectivity word sense disambiguation subjectivity word sense disambiguation 
paper describes adaptations unsupervised word sense discrimination techniques problem name discrimination methods cluster contexts containing ambiguous name cluster refers unique underlying person place also present new techniques assign meaningful labels discovered clusters unsupervised discrimination labeling ambiguous names unsupervised discrimination labeling ambiguous names unsupervised discrimination labeling ambiguous names 
present method align words bitext combines elements traditional statistical approach linguistic knowledge demonstrate approach using alignment lexicon produced statistical word aligner well linguistic resources ranging english parser heuristic alignment rules function words linguistic heuristics generalized development corpus parallel sentences aligner ualign outperforms commonly used giza aligner leaf aligner produces superior scores statistical machine translation bleu points giza leaf improved word alignment statistics linguistic heuristics improved word alignment statistics linguistic heuristics improved word alignment statistics linguistic heuristics 
combining information extraction systems yields significantly higher quality resources system isolation paper generalize mixing sources features framework called ensemble semantics show large gains entity extraction combining distributional patternbased systems large set features webcrawl query logs wikipedia experimental results webscale extraction actors athletes musicians show significantly higher mean average precision scores gain compared current state art entity extraction via ensemble semantics entity extraction via ensemble semantics entity extraction via ensemble semantics 
machine involvement potential speed language documentation assess potential timed annotation experiments consider annotator expertise example selection methods suggestions machine classifier find better example selection label suggestions improve efficiency effectiveness depends strongly annotator expertise expert performed best uncertainty selection gained little suggestions performed best random selection suggestions results underscore importance measuring annotation cost reductions respect time need learning methods adapt annotators well active learning <i>actually work? time-based</i> evaluation cost-reduction strategies language documentation. well active learning <i>actually work? time-based</i> evaluation cost-reduction strategies language documentation. well active learning <i>actually work? time-based</i> evaluation cost-reduction strategies language documentation. 
demonstrate textrank system unsupervised extractive summarization relies application iterative graphbased ranking algorithms graphs encoding cohesive structure text important characteristic system rely knowledge resources manually constructed training data thus highly portable new languages domains language independent extractive summarization language independent extractive summarization language independent extractive summarization 
report empirical study role syntactic features building semisupervised named entity ne tagger study addresses two questions types syntactic features suitable extracting potential nes train classifier setting good resulting ne classifier testing instances dissimilar training data study shows constituency dependency parsing constraints suitable features extract nes train classifier moreover classifier showed significant accuracy improvement constituency features combined new dependency feature furthermore degradation accuracy unfamiliar test cases low suggesting trained classifier generalizes well syntax-based semi-supervised named entity tagging syntax-based semi-supervised named entity tagging syntax-based semi-supervised named entity tagging 
previously introduced method word sense disambiguation computes intended sense target word using measures semantic relatedness patwardhan et al senserelate targetword perl package implements algorithm disambiguation process carried selecting sense target word related context words relatedness word senses measured using wordnet similarity perl modules senserelate::targetword - generalized framework word sense disambiguation senserelate::targetword - generalized framework word sense disambiguation senserelate::targetword - generalized framework word sense disambiguation 
problem induction text involves two aspects firstly set word classes derived automatically secondly word vocabulary assigned one several word classes paper present method solves problems good accuracy approach adopts mixture statistical methods successfully applied word sense induction main advantage previous attempts reduces syntactic space important dimensions thereby almost eliminating otherwise omnipresent problem data sparseness practical solution problem automatic part-of-speech induction text practical solution problem automatic part-of-speech induction text practical solution problem automatic part-of-speech induction text 
paper propose novel statistical language model capture semantic dependencies specifically apply concept semantic composition problem constructing predictive history representations upcoming words also examine influence underlying semantic space composition task comparing spatial semantic representations ones composition models yield reductions perplexity combined standard language model model alone also obtain perplexity reductions integrating models structured language model language models based semantic composition language models based semantic composition language models based semantic composition 
paper describes method interactively visualizing directing process translating sentence method allows user explore model statistical machine translation mt understand model strengths weaknesses compare mt systems using visualization method find address conceptual practical problems mt system demonstration acl new users tool drive syntaxbased decoder interactively exploring machine translation model interactively exploring machine translation model interactively exploring machine translation model 
describe new approach synthetically combining output several different machine translation mt engines operating input goal produce synthetic combination surpasses original systems translation quality approach uses individual mt engines black boxes require explicit cooperation original mt systems decoding algorithm uses explicit word matches conjunction confidence estimates various engines trigram language model order score rank collection sentence hypotheses synthetic combinations words various original engines highest scoring sentence hypothesis selected final output system experiments using several systems similar quality show substantial improvement quality translation output multi-engine machine translation guided explicit word matching multi-engine machine translation guided explicit word matching multi-engine machine translation guided explicit word matching 
senseclusters freely available system identifies similar contexts text relies lexical features build first second order representations contexts clustered using unsupervised methods originally developed discriminate among contexts centered around given target word applied generally also supports methods create descriptive discriminating labels discovered clusters senseclusters: unsupervised clustering labeling similar contexts senseclusters: unsupervised clustering labeling similar contexts senseclusters: unsupervised clustering labeling similar contexts 
recently introduced online cw learning algorithm binary classification performs well many binary nlp tasks however problems cw learning updates inference cannot computed analytically solved convex optimization problems binary case derive learning algorithms cw setting provide extensive evaluation using nine nlp datasets including three derived recently released new york times corpus best algorithm outperforms online batch methods eight nine tasks also show confidence information maintained learning yields useful probabilistic information test time multi-class confidence weighted algorithms multi-class confidence weighted algorithms multi-class confidence weighted algorithms 
statistical machine translation quite robust comes choice input representation requires consistency training testing result wide range possible preprocessing choices data used statistical machine translation even morphologically rich languages arabic paper study effect different preprocessing schemes arabic quality statistical machine translation also present evaluate different methods combining preprocessing schemes resulting improved translation quality combination arabic preprocessing schemes statistical machine translation combination arabic preprocessing schemes statistical machine translation combination arabic preprocessing schemes statistical machine translation 
paper presents extensive evaluation five different alignments investigates impact corresponding mt system output introduce new measures intrinsic evaluations examine distribution phrases untranslated words decoding identify characteristics different alignments affect translation show alignments yield better mt output translating words using longer phrases recalloriented alignments going beyond aer: extensive analysis word alignments impact mt going beyond aer: extensive analysis word alignments impact mt going beyond aer: extensive analysis word alignments impact mt 
present inexact search algorithm problem predicting dependency graph algorithm based version standard cubictime search algorithm projective dependency parsing used backbone beam search procedure allows us handle complex nonlocal feature dependencies occurring bistratal parsing model interdependency two layers apply algorithm syntactic semantic dependency parsing task shared task obtain competitive result equal highest published system jointly learns syntactic semantic structure statistical bistratal dependency parsing statistical bistratal dependency parsing statistical bistratal dependency parsing 
polarity lexicons valuable resource sentiment analysis opinion mining number lexical resources available often suboptimal use general purpose lexical resources reflect lexical usage paper propose novel method based integer linear programming adapt existing lexicon new one reflect characteristics data directly particular method collectively considers relations among words opinion expressions derive likely polarity lexical item positive neutral negative negator given domain experimental results show lexicon adaptation technique improves performance polarity classification adapting polarity lexicon using integer linear programming domain-specific sentiment classification adapting polarity lexicon using integer linear programming domain-specific sentiment classification adapting polarity lexicon using integer linear programming domain-specific sentiment classification 
mitchell et al demonstrated models semantic knowledge predict neural activation patterns recorded using fmri could powerful technique evaluating conceptual models extracted corpora however fmri expensive imposes strong constraints data collection following experiments demonstrated eeg activation patterns encode enough information discriminate broad conceptual categories show semantic representations predict eeg activation patterns significant accuracy evaluate relative performance different task eeg responds conceptual stimuli corpus semantics eeg responds conceptual stimuli corpus semantics eeg responds conceptual stimuli corpus semantics 
windowless word assocation measures recently appeared nlp literature performance compared existing windowed measures largely unknown conduct largescale empirical comparison variety measures reproduction syntagmatic human assocation norms overall results show improvement predictive power windowless windowed measures provides support previously published theoretical advantages makes windowless approaches promising avenue explore study also serves first comparison windowed methods across numerous human association datasets comparison also introduce novel variations measures perform well better human association norm task established measures comparison windowless window-based computational association measures predictors syntagmatic human associations comparison windowless window-based computational association measures predictors syntagmatic human associations comparison windowless window-based computational association measures predictors syntagmatic human associations 
inspired success english research speech synthesis many researchers proposed transliteration models however approaches severely suffered errors chinese conversion address issue propose new transliteration model make systematic comparisons conventional models proposed model relies joint use chinese phonemes corresponding english graphemes phonemes experiments showed chinese phonemes proposed model contribute performance improvement transliteration chinese phonemes improve machine transliteration?: comparative study english-to-chinese transliteration models chinese phonemes improve machine transliteration?: comparative study english-to-chinese transliteration models chinese phonemes improve machine transliteration?: comparative study english-to-chinese transliteration models 
shortage manually labeled data obstacle supervised relation extraction methods paper investigate graph based learning algorithm label propagation lp algorithm relation extraction represents labeled unlabeled examples distances nodes weights edges graph tries obtain labeling function satisfy two constraints fixed labeled nodes smooth whole graph experiment results ace corpus showed lp algorithm achieves better performance svm labeled examples available also performs better bootstrapping relation extraction task relation extraction using label propagation based semi-supervised learning relation extraction using label propagation based semi-supervised learning relation extraction using label propagation based semi-supervised learning 
tree adjoining grammars advantages typically considered difficult practical systems demonstrate done right adjoining improves translation quality without becoming computationally intractable using adjoining model optionality allows general translation patterns learned without clutter endless variations optional material appropriate modifiers later spliced needed paper describe novel method learning type synchronous tree adjoining grammar associated probabilities aligned tree string training data introduce method converting grammars weakly equivalent tree transducer decoding finally show adjoining results improvement bleu baseline statistical mtmodel arabic englishmt task synchronous tree adjoining machine translation synchronous tree adjoining machine translation synchronous tree adjoining machine translation 
paper describes model parsing transcribed speech containing disfluencies model differs previous parsers explicit modeling buffer recent words allows recognize repairs easily due frequent overlap words errors repairs parser implementing model evaluated standard switchboard transcribed speech parsing task overall parsing accuracy edited word detection word buffering models improved speech repair parsing word buffering models improved speech repair parsing word buffering models improved speech repair parsing 
recent availability large corpora training language models shown utility models higher order trigrams paper investigate methods control increase model size resulting applying standard methods higher orders introduce selection reduces model size also improves perplexity several smoothing methods including katz backoff absolute discounting also show combined new smoothing method novel variant pruning selection method performs better model size perplexity best pruning method found modified smoothing less more: significance-based n-gram selection smaller, better language models less more: significance-based n-gram selection smaller, better language models less more: significance-based n-gram selection smaller, better language models 
semantic similarity central concept extends across numerous fields artificial intelligence natural language processing cognitive science psychology accurate measurement semantic similarity words essential various tasks document clustering information retrieval synonym extraction propose novel model semantic similarity using semantic relations exist among words given two words first represent semantic relations hold words using automatically extracted lexical pattern clusters next semantic similarity two words computed using mahalanobis distance measure compare proposed similarity measure previously proposed semantic similarity measures benchmark dataset wordsimilarity collection proposed method outperforms existing semantic similarity measures achieving pearson correlation coefficient dataset relational model semantic similarity words using automatically extracted lexical pattern clusters web relational model semantic similarity words using automatically extracted lexical pattern clusters web relational model semantic similarity words using automatically extracted lexical pattern clusters web 
paper introduces new parser evaluation corpus containing around sentences annotated unbounded dependencies seven different grammatical constructions run series parsers corpus evaluate well parsing technology able recover dependencies overall results range accuracy low scores call question validity using parseval scores general measure parsing capability discuss importance parsers able recover unbounded dependencies given relatively low frequency corpora also analyse various errors made constructions one successful parsers unbounded dependency recovery parser evaluation unbounded dependency recovery parser evaluation unbounded dependency recovery parser evaluation 
transforming syntactic representations order improve parsing accuracy exploited successfully statistical parsing systems using representations paper show similar transformations give substantial improvements also dependency parsing experiments prague dependency treebank show systematic transformations coordinate structures verb groups result error reduction deterministic dependency parser combining transformations previously proposed techniques recovering nonprojective dependencies leads accuracy given data set graph transformations data-driven dependency parsing graph transformations data-driven dependency parsing graph transformations data-driven dependency parsing 
investigate utility supertag information guiding existing dependency parser german using weighted constraints integrate additionally available information decision process parser influenced changing preferences without excluding alternative structural interpretations considered paper reports series experiments using varying models supertags significantly increase parsing accuracy addition upper bound accuracy achieved perfect supertags estimated guiding constraint dependency parser supertags guiding constraint dependency parser supertags guiding constraint dependency parser supertags 
computing pairwise semantic similarity words web computationally challenging task parallelization optimizations necessary propose highly scalable implementation based distributional similarity implemented mapreduce framework deployed billion word crawl web pairwise similarity million terms computed hours using nodes apply learned similarity matrix task automatic set expansion present large empirical study quantify effect expansion performance corpus size corpus quality seed composition seed size make public experimental testbed set expansion analysis includes large collection diverse entity sets extracted wikipedia web-scale distributional similarity entity set expansion web-scale distributional similarity entity set expansion web-scale distributional similarity entity set expansion 
ordering information difficult important task applications generating text present approach arranging sentences extracted summarization capture association order two textual segments eg sentences define four criteria chronology precedence succession criteria integrated criterion supervised learning approach repeatedly concatenate two textual segments one segment based criterion obtain overall segment sentences arranged experimental results show significant improvement existing sentence ordering strategies bottom-up approach sentence ordering multi-document summarization bottom-up approach sentence ordering multi-document summarization bottom-up approach sentence ordering multi-document summarization 
apply machine learning linear ordering problem order learn reordering models machine translation demonstrate even models used mere preprocessing step translation significantly outperform moses integrated lexicalized reordering model models trained automatically aligned bitext form simple novel assess based features input sentence strongly pair input word tokens would like reverse relative order combining pairwise preferences find best global reordering however present algorithm based chart parsing least finds best reordering within certain exponentially large neighborhood show iterate reordering process within local search algorithm use training learning linear ordering problems better translation learning linear ordering problems better translation learning linear ordering problems better translation 
paper investigates conceptually empirically novel sense matching task requires recognize whether senses two synonymous words match context suggest direct approaches problem avoid intermediate step explicit word sense disambiguation demonstrate appealing advantages stimulating potential future research direct word sense matching lexical substitution direct word sense matching lexical substitution direct word sense matching lexical substitution 
present discriminative substring decoder transliteration decoder extends recent approaches discriminative character transduction allowing list known words important resource transliteration approach improves upon sherif kondrak decoder creating relative improvement transliteration accuracy japanese task also conduct controlled comparison two feature paradigms discriminative training indicators hybrid generative features surprisingly generative hybrid outperforms purely discriminative counterpart despite losing access rich features finally show machine transliterations positive impact machine translation quality improving human judgments scale discriminative substring decoding transliteration discriminative substring decoding transliteration discriminative substring decoding transliteration 
current system combination methods usually use confusion networks find consensus translations among different systems requiring mappings words candidate translations confusion networks difficulty handling general situations several words connected another several words instead propose system combination model allows phrase alignments uses lattices encode candidate translations experiments show approach achieves significant improvements baseline system translation test sets lattice-based system combination statistical machine translation lattice-based system combination statistical machine translation lattice-based system combination statistical machine translation 
paper investigates effect direction statistial machine translation decoding compare typical machine translation decoder using decoding strategy decoder also investigate effectiveness bidirectional decoding strategy integrates approaches aim reducing effects due language specificity experimental evaluation extensive based different language pairs gave surprising result language pairs better decode expected relative performance strategies proved highly language dependent bidirectional approach outperformed strategy strategy showing consistent improvements appeared unrelated specific languages used translation bidirectional decoding gave rise improvement performance decoding strategy terms bleu score experiments bidirectional phrase-based statistical machine translation bidirectional phrase-based statistical machine translation bidirectional phrase-based statistical machine translation 
many years statistical machine translation relied generative models provide bilingual word alignments several independent efforts showed discriminative models could used enhance replace standard generative approach building work demonstrate substantial improvement accuracy partly though improved training methods predominantly selection better features best model produces lowest alignment error rate yet reported canadian hansards bilingual data improved discriminative bilingual word alignment improved discriminative bilingual word alignment improved discriminative bilingual word alignment 
propose novel reordering model statistical machine translation smt uses maximum entropy maxent model predicate reorderings neighbor blocks phrase pairs model provides hierarchical phrasal reordering generalization based features automatically learned bitext present algorithm extract reordering events neighbor blocks bilingual data experiments translation reordering model obtains significant improvements bleu score nist tasks maximum entropy based phrase reordering model statistical machine translation maximum entropy based phrase reordering model statistical machine translation maximum entropy based phrase reordering model statistical machine translation 
system combination emerged powerful method machine translation mt paper pursues joint optimization strategy combining outputs multiple mt systems word alignment ordering lexical selection decisions made jointly according set feature functions combined single model decoding algorithm described detail set new features support joint decoding approach proposed approach evaluated comparison system combination methods using equivalent features shown outperform significantly joint optimization machine translation system combination joint optimization machine translation system combination joint optimization machine translation system combination 
jointly parsing two languages shown improve accuracies either sides however search space much bigger monolingual case forcing existing approaches employ complicated modeling crude approximations propose much simpler alternative monolingual parsing parser learns exploit reorderings additional observation bothering build tree well show specifically enhance dependency parser alignment features resolve conflicts experiments bilingual portion chinese treebank show bilingual features improve parsing accuracies absolute english chinese baseline negligible efficiency overhead thus much faster biparsing bilingually-constrained (monolingual) shift-reduce parsing bilingually-constrained (monolingual) shift-reduce parsing bilingually-constrained (monolingual) shift-reduce parsing 
paper explores chinese semantic role labeling srl nominal predicates besides widely used features verbal srl various nominal features first included improve performance nominal srl integrating useful features derived verbal srl system finally address issue automatic predicate recognition essential nominal srl system evaluation chinese nombank shows research integrating various features derived verbal srl significantly improves performance also shows nominal srl system much outperforms ones improving nominal srl chinese language verbal srl information automatic predicate recognition improving nominal srl chinese language verbal srl information automatic predicate recognition improving nominal srl chinese language verbal srl information automatic predicate recognition 
present method noun phrase chunking hebrew show traditional definition nonrecursive noun phrases apply hebrew propose alternative definition simple nps review syntactic properties hebrew related noun phrases indicate task hebrew simplenp chunking harder chunking english confirmation apply methods known work well english hebrew data methods give low results hebrew discuss method applies svm induction lexical morphological features morphological features improve average precision recall resulting system average performance precision recall fmeasure noun phrase chunking hebrew: influence lexical morphological features noun phrase chunking hebrew: influence lexical morphological features noun phrase chunking hebrew: influence lexical morphological features 
propose novel approach improving statistical machine translation languages exploiting similarity ones precisely improve translation resourcepoor source language resourcerich language given containing limited number parallel sentences larger language closely related evaluation indonesian english using malay spanish english using portuguese pretending spanish shows absolute gain bleu points respectively improvement rivaling approaches using much less additional data improved statistical machine translation resource-poor languages using related resource-rich languages improved statistical machine translation resource-poor languages using related resource-rich languages improved statistical machine translation resource-poor languages using related resource-rich languages 
propose novel objective function discriminatively tuning machine translation models objective explicitly optimizes bleu score expected counts quantities arise forestbased consensus minimum bayes risk decoding methods continuous objective optimized using simple gradient ascent however computing critical quantities gradient necessitates novel dynamic program also present assuming bleu evaluation measure objective function two principle advantages standard max bleu tuning first specifically optimizes model weights downstream consensus decoding procedures unexpected second benefit reduces overfitting improve test set bleu scores using standard viterbi decoding consensus training consensus decoding machine translation consensus training consensus decoding machine translation consensus training consensus decoding machine translation 
present discriminative approach machine translation large feature sets exploited unlike discriminative reranking approaches system take advantage learned features stages decoding first discuss several challenges discriminative approaches particular explore different ways updating parameters given training example find making frequent smaller updates preferable making fewer larger updates discuss array features show quantitatively increase bleu score qualitatively interact specific examples one particular feature investigate novel way introduce learning initial phrase extraction process previously entirely heuristic end-to-end discriminative approach machine translation end-to-end discriminative approach machine translation end-to-end discriminative approach machine translation 
paper presents new approach selecting initial seed set using stratified sampling strategy learning semantic relation classification first training data partitioned several strata according relation types subtypes relation instances randomly sampled stratum form initial seed set also investigate different augmentation strategies iteratively adding reliable instances labeled set find bootstrapping procedure may stop reasonable point significantly decrease training time without degrading much performance experiments ace rdc corpora show stratified sampling strategy contributes bootstrapping procedure suggests proper sampling strategy critical learning semi-supervised learning semantic relation classification using stratified sampling strategy semi-supervised learning semantic relation classification using stratified sampling strategy semi-supervised learning semantic relation classification using stratified sampling strategy 
past years number lexical association measures studied help extract new scientific terminology collocations implicit assumption research newly designed term measures involving sophisticated statistical criteria would outperform simple counts cooccurrence frequencies explicitly test assumption way four qualitative criteria show purely measures reveal virtually difference compared frequency occurrence counts linguistically informed metrics reveal marked difference can't beat frequency (unless use linguistic knowledge) - qualitative evaluation association measures collocation term extraction can't beat frequency (unless use linguistic knowledge) - qualitative evaluation association measures collocation term extraction can't beat frequency (unless use linguistic knowledge) - qualitative evaluation association measures collocation term extraction 
paper proposes novel composite kernel relation extraction composite kernel consists two individual kernels entity kernel allows features convolution parse tree kernel models syntactic information relation examples motivation method fully utilize nice properties kernel methods explore diverse knowledge relation extraction study illustrates composite kernel effectively capture flat structured features without need extensive feature engineering also easily scale include features evaluation ace corpus shows method outperforms previous methods significantly outperforms previous two dependency tree kernels relation extraction composite kernel extract relations entities flat structured features composite kernel extract relations entities flat structured features composite kernel extract relations entities flat structured features 
bootstrapping process improving performance trained classifier iteratively adding data labeled classifier training set retraining classifier often used situations labeled training data scarce unlabeled data abundant paper consider problem domain adaptation situation training data may scarce belongs different domain target application domain distribution unlabeled data different training data standard bootstrapping often difficulty selecting informative data add training set propose effective domain adaptive bootstrapping algorithm selects unlabeled target domain data informative target domain easy automatically label correctly call instances bridges used bridge source domain target domain show method outperforms supervised transductive bootstrapping algorithms named entity recognition task domain adaptive bootstrapping named entity recognition domain adaptive bootstrapping named entity recognition domain adaptive bootstrapping named entity recognition 
paper investigate novel method detect asymmetric entailment relations verbs starting point idea verb selectional preferences carry relevant semantic information experiments using wordnet gold standard show promising results applicable method used combination approaches significantly increases performance entailment detection combined approach including model improves aroc absolute points respect standard models discovering asymmetric entailment relations verbs using selectional preferences discovering asymmetric entailment relations verbs using selectional preferences discovering asymmetric entailment relations verbs using selectional preferences 
present work advances accuracy training speed discriminative parsing discriminative parsing method generative component yet surpasses generative baseline constituent parsing minimal linguistic cleverness model incorporate arbitrary features input parse state performs feature selection incrementally exponential feature space training demonstrate flexibility approach testing several parsing strategies various feature sets implementation freely available http nlp cs nyu edu parser advances discriminative parsing advances discriminative parsing advances discriminative parsing 
paper discusses computational compositional semantics perspective grammar engineering light experience use minimal recursion semantics grammars relationship argument indexation semantic role labelling explored semantic dependency notation dmrs introduced <b>invited talk:</b> slacker semantics: superficiality, dependency avoidance commitment right way go <b>invited talk:</b> slacker semantics: superficiality, dependency avoidance commitment right way go <b>invited talk:</b> slacker semantics: superficiality, dependency avoidance commitment right way go 
proceedings st international conference computational linguistics th annual meeting acl pages sydney july association computational linguistics question answering lexical chains propagating verb arguments adrian novischi dan moldovan language computer corp collins blvd richardson tx question answering lexical chains propagating verb arguments question answering lexical chains propagating verb arguments question answering lexical chains propagating verb arguments 
investigate unsupervised detection cue phrases paper proposes novel approach unseen text basis handful seed cue phrases desired semantics problem contrast bootstrapping approaches question answering information extraction hard find constraining context occurrences cue phrases method uses components cue phrase rather external context bootstrap successfully excludes phrases different target semantics look superficially similar method achieves accuracy outperforming standard bootstrapping approaches bootstrapping approach unsupervised detection cue phrase variants bootstrapping approach unsupervised detection cue phrase variants bootstrapping approach unsupervised detection cue phrase variants 
propose system builds manner resource aims helping ner system annotate named entities system based distributional approach uses syntactic dependencies measuring similarities named entities specificity presented method however combine approach clustering technique amounts soft clustering method experiments show resource constructed using cliquebased clustering system allows improve different ner systems clique-based clustering improving named entity recognition systems clique-based clustering improving named entity recognition systems clique-based clustering improving named entity recognition systems 
web search double checking model proposed explore web live corpus five association measures including variants dice overlap ratio jaccard cosine well cooccurrence double check codc presented experiments benchmark data set codc measure achieves correlation coefficient competes performance model using wordnet experiments link detection named entities using strategies direct association association matrix scalar association matrix verify frequencies reliable study named entity clustering shows five measures quite useful particular codc measure stable wordword experiments application codc measure expand community chains personal name disambiguation achieves increase compared system without community expansion experiments illustrate novel model web search double checking feasible mining associations web novel association measures using web search double checking novel association measures using web search double checking novel association measures using web search double checking 
present algorithm pronounanaphora english uses expectation maximization em learn virtually parameters unsupervised fashion em frequently fails find good models tasks set case works quite well compared several systems available web found far program significantly outperforms algorithm fast robust made publically available downloading em works pronoun anaphora resolution em works pronoun anaphora resolution em works pronoun anaphora resolution 
subjectivity meaning important properties language paper explores interaction brings empirical evidence support hypotheses subjectivity property associated word senses word sense disambiguation directly benefit subjectivity annotations word sense subjectivity word sense subjectivity word sense subjectivity 
large scale annotated corpora prerequisite developing semantic role labeling systems unfortunately corpora expensive produce limited size may representative work aims reduce annotation effort involved creating resources semantic role labeling via learning algorithm augments small number manually labeled instances unlabeled examples whose roles inferred automatically via annotation projection formulate projection task generalization linear assignment problem seek find role assignment unlabeled data argument similarity labeled unlabeled instances maximized experimental results semantic role labeling show automatic annotations produced method improve performance using instances alone semi-supervised semantic role labeling semi-supervised semantic role labeling semi-supervised semantic role labeling 
paper shows simple approach handle dependencies named entity recognition ner outperform existing approaches handle dependencies much computationally efficient ner systems typically use sequence models tractable inference makes unable capture long distance structure present text use conditional random field crf based ner system using local features make predictions train another crf uses local information features extracted output first crf using features capturing dependencies document approach yields relative error reduction score ner systems using alone compared relative error reduction offered best systems exploit information approach also makes easy incorporate information documents test corpus gives us error reduction ner systems using alone additionally running time inference inference time two sequential crfs much less complicated approaches directly model dependencies approximate inference effective two-stage model exploiting non-local dependencies named entity recognition effective two-stage model exploiting non-local dependencies named entity recognition effective two-stage model exploiting non-local dependencies named entity recognition 
present parsing algorithms various mildly dependency formalisms particular algorithms presented structures gap degree complexity best existing parsers constituency formalisms equivalent generative power structures gap degree bounded constant new class structures gap degree includes structures third case includes gap degree structures number dependency treebanks parsing mildly non-projective dependency structures parsing mildly non-projective dependency structures parsing mildly non-projective dependency structures 
introduce cube summing technique permits dynamic programming algorithms summing structures like forward inside algorithms extended features violate classical structural independence assumptions inspired cube pruning chiang huang chiang computation features dynamically using scored lists also maintains additional residual quantities used calculating approximate marginals restricted local features cube summing reduces novel semiring residual generalizes many semirings goodman features included cube summing reduce semiring compatible generic techniques solving dynamic programming equations cube summing, approximate inference non-local features, dynamic programming without semirings cube summing, approximate inference non-local features, dynamic programming without semirings cube summing, approximate inference non-local features, dynamic programming without semirings 
named entity recognition morphologically rich languages including majority semitic languages iranian languages indian languages inherently difficult english counterpart worse still progress machine learning approaches named entity recognition many languages currently hampered scarcity annotated data lack accurate tagger possible rely gazetteers combat data scarcity approach potential weakness creating irreproducible results since name lists publicly available general motivated part concern present named entity recognizer rely gazetteers using bengali representative morphologicallyrich language recognizer achieves relative improvement fmeasure baseline recognizer improvements arise using induced affixes extracting information online lexical databases jointly modeling tagging named entity recognition learning-based named entity recognition morphologically-rich, resource-scarce languages learning-based named entity recognition morphologically-rich, resource-scarce languages learning-based named entity recognition morphologically-rich, resource-scarce languages 
extend factored translation model koehn hoang allow translations longer phrases composed factors pos morphological tags act templates selection reordering surface phrase translation also reintroduce use alignment information within decoder forms integral part decoding alignment template system och decoding results show increase translation performance bleu french english translation also show method compares relates lexicalized reordering improving mid-range re-ordering using templates factors improving mid-range re-ordering using templates factors improving mid-range re-ordering using templates factors 
hybrid convolution tree kernel proposed paper effectively model syntactic structures semantic role labeling srl hybrid kernel consists two individual convolution kernels path kernel captures predicateargument link features constituent structure kernel captures syntactic structure features arguments evaluation datasets conll srl shared task shows novel hybrid convolution tree kernel outperforms previous tree kernels also combine new hybrid tree kernel based method standard rich flat feature based method experimental results show combinational method get better performance individually hybrid convolution tree kernel semantic role labeling hybrid convolution tree kernel semantic role labeling hybrid convolution tree kernel semantic role labeling 
paper compare contrast two approaches machine translation mt syntax augmented machine translation system samt statistical machine translation smt samt hierarchical translation system underlain model target part parse tree smt translation process based bilingual units related alignment statistical modeling bilingual context following maximumentropy framework provide comparison systems report results terms automatic evaluation metrics required computational resources smaller translation task tokens training corpus human error analysis clarifies advantages disadvantages systems consideration finally combine output systems yield significant improvements translation quality n-gram-based statistical machine translation versus syntax augmented machine translation: comparison system combination n-gram-based statistical machine translation versus syntax augmented machine translation: comparison system combination n-gram-based statistical machine translation versus syntax augmented machine translation: comparison system combination 
paper explores techniques take advantage fundamental difference structure hidden markov models hmm hierarchical hidden markov models hhmm hhmm structure allows repeated parts model merged together merged model takes advantage recurring patterns within hierarchy clusters exist sequences observations order increase extraction accuracy paper also presents new technique reconstructing grammar rules automatically work builds idea combining phrase extraction method hhmm expose patterns within english text reconstruction used simplify complex structure hhmm models discussed evaluated applying natural language tasks based lancaster treebank keywords information extraction natural language hidden markov models techniques incorporate benefits hierarchy modified hidden markov model techniques incorporate benefits hierarchy modified hidden markov model techniques incorporate benefits hierarchy modified hidden markov model 
open problem dependency parsing accurate efficient treatment structures propose attack problem using algorithms developed mildly contextsensitive grammar formalisms paper provide two key tools approach first show reduce nonprojective dependency parsing parsing linear rewriting systems lcfrs presenting technique extracting lcfrs dependency treebanks efficient parsing extracted grammars need transformed order minimize number nonterminal symbols per production second contribution algorithm computes transformation large empirically relevant class grammars treebank grammar techniques non-projective dependency parsing treebank grammar techniques non-projective dependency parsing treebank grammar techniques non-projective dependency parsing 
consider problem producing summary given collection documents since successful methods summarization still largely extractive paper explore well extractive method perform introduce oracle score based probability distribution unigrams human summaries demonstrate oracle score generate extracts score average better human summaries evaluated rouge addition introduce approximation oracle score produces system best known performance document understanding conference duc evaluation topic-focused multi-document summarization using approximate oracle score topic-focused multi-document summarization using approximate oracle score topic-focused multi-document summarization using approximate oracle score 
present unified view many translation algorithms synthesizes work deductive parsing semiring parsing efficient approximate search algorithms gives rise clean analyses compact descriptions serve basis modular implementations illustrate several examples showing build search spaces several disparate search strategies integrate features devise novel models although framework drawn parsing applied translation applicable many dynamic programming problems arising natural language processing areas translation weighted deduction translation weighted deduction translation weighted deduction 
paper studies enrichment spanish wordnet synset glosses automatically obtained english wordnet glosses using statistical machine translation system construct translation system parallel corpus proceedings european parliament study adapt statistical models domain dictionary definitions build specialized language translation models small set parallel definitions experiment robust manners combine statistically significant increase performance obtained best system finally used generate definition spanish synsets currently ready manual revision complementary issue analyze impact amount data needed improve system trained entirely data low-cost enrichment spanish wordnet automatically translated glosses: combining general specialized models low-cost enrichment spanish wordnet automatically translated glosses: combining general specialized models low-cost enrichment spanish wordnet automatically translated glosses: combining general specialized models 
parsing computationally intensive task due combinatorial explosion seen chart parsing algorithms explore possible parse trees paper propose method limit combinatorial explosion restricting cyk chart parsing algorithm based output chunk parser tested three parsers presented collins observed approximate three fold speedup average decrease precision recall speeding full syntactic parsing leveraging partial parsing decisions speeding full syntactic parsing leveraging partial parsing decisions speeding full syntactic parsing leveraging partial parsing decisions 
current approaches prediction associations rely one type information generally taking form either word space models collocation measures moment open question approaches compare one another paper investigate performance two types models new approach based compounding best single predictor ratio followed closely word space model show however ensemble method combines two best approaches compounding algorithm achieves increase performance almost current state art predicting strong associations basis corpus data predicting strong associations basis corpus data predicting strong associations basis corpus data 
paper introduce notion frame relatedness relatedness among prototypical situations represented framenet database first demonstrate cognitive plausibility notion annotation experiment propose different types computational measures automatically assess relatedness results show measures provide good performance task ranking pairs frames measuring frame relatedness measuring frame relatedness measuring frame relatedness 
deterministic parsing guided treebankinduced classifiers emerged simple efficient alternative complex models parsing present systematic comparison learning mbl support vector machines svm inducing classifiers deterministic dependency parsing using data chinese english swedish together variety different feature models comparison shows svm gives higher accuracy richly articulated feature models across languages albeit considerably longer training times results also confirm deterministic parsing achieve parsing accuracy close best results reported complex parsing models discriminative classifiers deterministic dependency parsing discriminative classifiers deterministic dependency parsing discriminative classifiers deterministic dependency parsing 
various kinds scored dependency graphs proposed packed shared data structures combination optimum dependency tree search algorithms paper classifies scored dependency graphs discusses specific features dependency forest df packed shared data structure adopted preference dependency grammar pdg proposes graph branch algorithm computing optimum dependency tree df paper also reports experiment showing computational amount behavior graph branch algorithm graph branch algorithm: optimum tree search method scored dependency graph arc co-occurrence constraints graph branch algorithm: optimum tree search method scored dependency graph arc co-occurrence constraints graph branch algorithm: optimum tree search method scored dependency graph arc co-occurrence constraints 
revisit idea parsing present parsing framework strives simple general flexible also provide decoder probability model optimal anytime parser based framework evaluated section penn treebank compares favorably approaches terms accuracy speed exploring potential intractable parsers exploring potential intractable parsers exploring potential intractable parsers 
propose unsupervised method distinguishing literal usages idiomatic expressions method determines well literal interpretation linked overall cohesive structure discourse strong links found expression classified literal otherwise idiomatic show method help tell apart literal usages even idioms occur canonical form unsupervised recognition literal non-literal use idiomatic expressions unsupervised recognition literal non-literal use idiomatic expressions unsupervised recognition literal non-literal use idiomatic expressions 
paper describes pos tagging experiments training extension supervised averaged perceptron algorithm first introduced task collins experiments iterative training supervised manually annotated dataset tokens combined relatively modest order tokens unsupervised plain data fashion showed significant improvement pos classification task typologically different languages yielding better results english czech relative error reduction respectively absolute accuracies semi-supervised training averaged perceptron pos tagger semi-supervised training averaged perceptron pos tagger semi-supervised training averaged perceptron pos tagger 
latent conditional models become popular recently natural language processing vision processing communities however establishing effective efficient inference method latent conditional models remains question paper describe inference ldi able produce optimal label sequence latent conditional models using efficient search strategy dynamic programming furthermore describe straightforward solution approximating ldi show approximated ldi performs well exact ldi speed much faster experiments demonstrate proposed inference algorithm outperforms existing inference methods variety natural language processing tasks sequential labeling latent variables: exact inference algorithm efficient approximation sequential labeling latent variables: exact inference algorithm efficient approximation sequential labeling latent variables: exact inference algorithm efficient approximation 
discuss text summarization terms maximum coverage problem variant explore decoding algorithms including ones never used summarization formulation greedy algorithm performance guarantee randomized algorithm method basis results comparative experiments also augment summarization model takes account relevance document cluster experiments showed augmented model superior method duc without stopwords text summarization model based maximum coverage problem variant text summarization model based maximum coverage problem variant text summarization model based maximum coverage problem variant 
paper presents discriminative approach full parsing convert task full parsing series chunking tasks apply conditional random field crf model level chunking probability entire parse tree computed product probabilities individual chunking results parsing performed manner best derivation efficiently obtained using depthfirst search algorithm experimental results demonstrate simple parsing framework produces fast reasonably accurate parser fast full parsing linear-chain conditional random fields fast full parsing linear-chain conditional random fields fast full parsing linear-chain conditional random fields 
paper presents new model thematic fit contrast previous models approximate thematic fit argument plausibility fit verb selectional preferences directly semantic role plausibility pair similaritybased generalization previously seen pairs makes model robust data sparsity argue model easily extensible model semantic role ambiguity resolution online sentence comprehension model evaluated human semantic role plausibility judgments predictions correlate significantly human judgments rivals two models thematic fit exceeds performance previously unseen lowfrequency items robust extensible exemplar-based model thematic fit robust extensible exemplar-based model thematic fit robust extensible exemplar-based model thematic fit 
syntactic parsing requires fine balance expressivity complexity naturally occurring structures accurately parsed without compromising efficiency parsing several constraints proposed restrict class permissible structures projectivity planarity gap degree edge degree projectivity generally taken restrictive natural language syntax clear proposals strikes best balance expressivity complexity paper review compare different constraints theoretically provide experimental evaluation using data two treebanks investigating large proportion structures found treebanks permitted different constraints results indicate combination constraint parametric constraint discontinuity gives good fit linguistic data mildly non-projective dependency structures mildly non-projective dependency structures mildly non-projective dependency structures 
investigate connection part speech pos distribution content language define pos blocks groups parts speech hypothesise exists directly proportional relation frequency pos blocks content salience also hypothesise class membership parts speech within blocks reflects content load blocks basis open class parts speech closed class parts speech test hypotheses context information retrieval syntactically representing queries removing blocks line aforementioned hypotheses first hypothesis induce pos distribution information corpus approximate probability occurrence pos blocks per two statistical estimators separately second hypothesis use simple heuristics estimate content load within pos blocks use text retrieval conference trec queries retrieve documents wt wt test collections five different retrieval strategies experimental outcomes confirm hypotheses hold context information retrieval examining content load part speech blocks information retrieval examining content load part speech blocks information retrieval examining content load part speech blocks information retrieval 
number metrics automatic evaluation machine translation proposed recent years metrics focusing measuring adequacy mt output metrics focusing fluency metrics bleu measure overlap mt outputs references represent information contrast metrics compute longest common subsequences ignore words aligned lcs propose metric based stochastic iterative string alignment sia aims combine strengths approaches compare sia existing metrics find outperforms overall evaluation works specially well fluency evaluation stochastic iterative alignment machine translation evaluation stochastic iterative alignment machine translation evaluation stochastic iterative alignment machine translation evaluation 
paper deals task finding generally applicable substitutions given input term show output distributional similarity system baseline filtered obtain terms simply similar frequently substitutable filter relies fact two terms common entailment relation possible substitute one frequent surface contexts using google corpus find characteristic contexts show given task filter improves precision distributional similarity system test set comprising common transitive verbs finding word substitutions using distributional similarity baseline immediate context overlap finding word substitutions using distributional similarity baseline immediate context overlap finding word substitutions using distributional similarity baseline immediate context overlap 
article compound processing translation german factored statistical mt system investigated compounds handled splitting prior training merging parts translation explored eight merging strategies using different combinations external knowledge sources word lists internal sources carried translation process symbols show merging successful internal knowledge source needed also show extra sequence model useful order improve order compound parts output best merging results achieved matching scheme tags comparison merging strategies translation german compounds comparison merging strategies translation german compounds comparison merging strategies translation german compounds 
paper examines two problems sentiment analysis determining whether given document review classifying polarity review positive negative first demonstrate review identification performed high accuracy using unigrams features examine role four types simple linguistic knowledge sources polarity classification system examining role linguistic knowledge sources automatic identification classification reviews examining role linguistic knowledge sources automatic identification classification reviews examining role linguistic knowledge sources automatic identification classification reviews 
paper proposes method incrementally translating english spoken language japanese realize simultaneous translation languages different word order english japanese method utilizes feature word order target language flexible resolve problem generating grammatically incorrect sentence method uses dependency structures japanese dependency constraints determine word order translation moreover considering fact inversion predicate expressions occurs frequently japanese spoken language method takes advantage predicate inversion resolve problem japanese predicate end sentence furthermore method includes function canceling inversion restating predicate translation incomprehensible due inversion implement prototype translation system conduct experiment sentences atis corpus results indicate improvements comparison two methods simultaneous english-japanese spoken language translation based incremental dependency parsing transfer simultaneous english-japanese spoken language translation based incremental dependency parsing transfer simultaneous english-japanese spoken language translation based incremental dependency parsing transfer 
recently proposed deterministic classifierbased parsers nivre scholz sagae lavie yamada matsumoto offer attractive alternatives generative statistical parsers deterministic parsers fast efficient simple implement generally less accurate optimal nearly optimal statistical parsers present statistical parser bridges gap deterministic probabilistic parsers parsing model essentially one previously used deterministic parsing parser performs search instead greedy search using standard sections wsj corpus penn treebank training testing parser precision recall using automatically assigned tags perhaps interestingly parsing model significantly different generative models used wellknown accurate parsers allowing simple combination produces precision recall respectively best-first probabilistic shift-reduce parser best-first probabilistic shift-reduce parser best-first probabilistic shift-reduce parser 
dependency parsing turkish gu ls en eryig istanbul technical university joakim nivre va xjo university uppsala university kemal oflazer sabanc university suitability different parsing methods different languages important topic syntactic parsing especially languages typologically different languages methods originally developed pose interesting challenges respect article presents investigation dependency parsing turkish agglutinative free constituent order language seen representative wider class languages similar type investigations show morphological structure plays essential role finding syntactic relations language particular show employing sublexical units called inflectional groups rather word forms basic parsing units improves parsing accuracy test claim two different parsing methods one based probabilistic model beam search based discriminative classifiers deterministic parsing strategy show usefulness sublexical units holds regardless parsing method examine impact morphological lexical information detail show properly used kind information improve parsing accuracy substantially applying techniques presented article achieve highest reported accuracy parsing turkish treebank dependency parsing turkish dependency parsing turkish dependency parsing turkish 
paper present tool uses comparable corpora find appropriate translation equivalents expressions considered translators difficult phrase source language tool identifies range possible expressions used similar contexts target language corpora presents translator list suggestions paper discuss method present results human evaluation performance tool highlight usefulness dictionary solutions lacking using comparable corpora solve problems difficult human translators using comparable corpora solve problems difficult human translators using comparable corpora solve problems difficult human translators 
statistical approaches translation sergio barrachina universitat jaume oliver bender rwth aachen francisco casacuberta universitat polite cnica de vale ncia jorge civera universitat polite cnica de vale ncia elsa cubel universitat polite cnica de vale ncia shahram khadivi rwth aachen antonio lagarda universitat polite cnica de vale ncia hermann ney rwth aachen jesu toma universitat polite cnica de vale ncia enrique vidal universitat polite cnica de vale ncia vilar universitat jaume current machine translation mt systems still perfect practice output systems needs edited correct errors way increasing productivity whole translation process mt plus human work incorporate human correction activities within translation process thereby shifting mt paradigm translation model entails iterative process human translator activity included loop iteration prefix translation validated accepted amended human system computes best translation suffix hypothesis complete prefix successful framework mt statistical pattern recognition framework interestingly within framework adaptation mt systems interactive scenario affects mainly search process allowing great reuse successful techniques models article alignment templates models stochastic transducers used develop translation systems systems assessed european project transtype two real tasks translation printer manuals manuals translation bulletin european union task following three pairs languages involved translation directions english spanish english german english french departament enginyeria cie ncies dels computadors universitat jaume castello de la plana spain lehrstuhl fu informatik vi rwth aachen university technology aachen germany institut tecnolo gic informa tica departament de sistemes informa tics computacio universitat polite cnica de vale ncia vale ncia spain institut tecnolo gic informa tica departament de comunicacions universitat polite cnica de statistical approaches computer-assisted translation statistical approaches computer-assisted translation statistical approaches computer-assisted translation 
training parameters natural language system one would prefer minimize loss error evaluation set since error surface many natural language problems piecewise constant riddled local minima many systems instead optimize conveniently differentiable convex propose training instead minimize expected loss risk define expectation using probability distribution hypotheses gradually sharpen anneal focus hypothesis besides linear loss functions used previous work also describe techniques optimizing nonlinear functions precision bleu metric present experiments training combinations models dependency parsing machine translation machine translation annealed minimum risk training achieves significant improvements bleu standard minimum error training also show improvements labeled dependency parsing direct minimization error researchers empirical natural language processing expended substantial ink effort developing metrics evaluate systems automatically corpora ongoing evaluation literature perhaps obvious machine translation community efforts better bleu papineni et al despite research parsing machine translation systems often trained using much simpler harsher metric maximum likelihood one reason supervised training objective function generally convex meaning single global maximum easily found indeed supervised generative models parameters maximum may even solution contrast likelihood surface error surface discrete structured prediction riddled local minima piecewise constant work supported nsf graduate research fellowship first author nsf itr grant iis onr grant views expressed necessarily endorsed sponsors thank sanjeev khudanpur noah smith markus dreyer reviewers helpful discussions comments everywhere differentiable minimum risk annealing training log-linear models minimum risk annealing training log-linear models minimum risk annealing training log-linear models 
obtaining machine translations still long way postediting phase required improve output machine translation system alternative called computerassisted translation framework human translator interacts system order obtain translations statistical approach translation described article new decoder algorithm interactive search also presented combines monotone nonmonotone search system assessed project translation several printer manuals english spanish german french statistical phrase-based models interactive computer-assisted translation statistical phrase-based models interactive computer-assisted translation statistical phrase-based models interactive computer-assisted translation 
sentence compression task creating short grammatical sentence removing extraneous words phrases original sentence preserving meaning existing methods learn statistics trimming grammar cfg rules however methods sometimes eliminate original meaning incorrectly removing important parts sentences trimming probabilities depend parents daughters applied cfg rules apply maximum entropy model method method easily include various features example parts parse tree words sentences contain evaluated method using manually compressed sentences human judgments found method produced grammatical informative compressed sentences methods trimming cfg parse trees sentence compression using machine learning approaches trimming cfg parse trees sentence compression using machine learning approaches trimming cfg parse trees sentence compression using machine learning approaches 
paper examines kind similarity words represented kind word vectors vector space model two experiments three methods constructing word vectors methods compared terms ability represent two kinds similarity taxonomic similarity associative similarity result comparison word vectors better reflect taxonomic similarity lsabased word vectors better reflect associative similarity word vectors two kinds similarity word vectors two kinds similarity word vectors two kinds similarity 
many proposals extract semantically related words using measures distributional similarity typically able distinguish synonyms types semantically related words antonyms co hyponyms hypernyms present method based automatic word alignment parallel corpora consisting documents translated multiple languages compare method monolingual method approach uses aligned multilingual data extract synonyms shows much higher precision recall scores task synonym extraction monolingual approach finding synonyms using automatic word alignment measures distributional similarity finding synonyms using automatic word alignment measures distributional similarity finding synonyms using automatic word alignment measures distributional similarity 
bootstrapping distributional feature vector quality maayan university ido dagan university article presents novel bootstrapping approach improving quality feature vector weighting distributional word similarity method motivated attempts utilize distributional similarity identifying concrete semantic relationship lexical entailment analysis revealed major reason rather loose semantic similarity obtained distributional similarity methods insufficient quality word feature vectors caused deficient feature weighting observation led definition bootstrapping scheme yields improved feature weights hence higher quality feature vectors underlying idea approach features common similar words also characteristic meanings thus promoted idea realized via bootstrapping step applied initial standard approximation similarity space superior performance bootstrapping method assessed two different experiments one based direct human annotation based automatically created disambiguation dataset results supported applying novel quantitative measurement quality feature weighting functions improved feature weighting also allows massive feature reduction indicates characteristic features word indeed concentrated top ranks vector finally experiments three prominent similarity measures two feature weighting functions showed bootstrapping scheme robust independent original functions applied articles: bootstrapping distributional feature vector quality articles: bootstrapping distributional feature vector quality articles: bootstrapping distributional feature vector quality 
supplement wordnet entries information subjectivity word senses supervised classifiers operate word sense definitions way text classifiers operate web newspaper texts need large amounts training data resulting data sparseness problem aggravated fact dictionary definitions short propose minimum cut framework makes use wordnet definitions relation structure experimental results show outperforms supervised minimum cut well standard supervised classification reducing error rate addition approach achieves results supervised framework less training data subjectivity recognition word senses via semi-supervised mincuts subjectivity recognition word senses via semi-supervised mincuts subjectivity recognition word senses via semi-supervised mincuts 
paper presents compares wordnetbased distributional similarity approaches strengths weaknesses approach regarding similarity relatedness tasks discussed combination presented methods independently provide best results class rg wordsim datasets supervised combination yields best published results datasets finally pioneer similarity showing methods easily adapted task minor losses study similarity relatedness using distributional wordnet-based approaches study similarity relatedness using distributional wordnet-based approaches study similarity relatedness using distributional wordnet-based approaches 
word sense disambiguation process determining sense word used given context due importance understanding semantics natural languages word sense disambiguation extensively studied computational linguistics however existing methods either brittle narrowly focus specific topics words provide mediocre performance settings broad coverage disambiguation quality critical word sense disambiguation system paper present fully unsupervised word sense disambiguation method requires dictionary unannotated text input automatic approach overcomes problem brittleness suffered many existing methods makes word sense disambiguation feasible practice evaluated approach using semeval task english task system significantly outperformed best unsupervised system participating semeval achieved performance approaching supervised systems although method tested sense disambiguation directly applied sense disambiguation fully unsupervised word sense disambiguation method using dependency knowledge fully unsupervised word sense disambiguation method using dependency knowledge fully unsupervised word sense disambiguation method using dependency knowledge 
paper designs novel lexical hub disambiguate word sense using syntagmatic paradigmatic relations words employs semantic network wordnet calculate word similarity edinburgh association thesaurus eat transform contextual space computing syntagmatic domain relations target word without policy result english lexical sample shows lexical cohesion based techniques good way unsupervisedly disambiguating senses word sense disambiguation using lexical cohesion context word sense disambiguation using lexical cohesion context word sense disambiguation using lexical cohesion context 
investigate independent relevant extractive summarization approaches paper events defined event terms associated event elements independent approach identify important contents frequency events relevant approach identify important contents pagerank algorithm event map constructed documents experimental results encouraging investigations event-based summarization investigations event-based summarization investigations event-based summarization 
propose principled probabilisitc framework uses trees vocabulary capture similarities among terms information retrieval setting allows retrieval documents based occurrences specific query terms also similarities terms effect similar query expansion additionally principled generative model exhibits effect similar inverse document frequency give encouraging experimental evidence superiority hierarchical dirichlet tree compared standard baselines hierarchical dirichlet trees information retrieval hierarchical dirichlet trees information retrieval hierarchical dirichlet trees information retrieval 
paper introduces new approach ranking speech utterances system confidence contain spoken word multiple alternate pronunciations degradations query word phoneme sequence hypothesized incorporated ranking function consider two methods hypothesizing degradations best constructed using factored phrasebased statistical machine translation show approach able significantly improve upon baseline technique evaluation speech evaluate systems using three different methods indexing speech utterances using phoneme phoneme multigram word recognition find degradation modeling shows particular promise locating words underlying indexing system constructed standard speech recognition phrase-based query degradation modeling vocabulary-independent ranked utterance retrieval phrase-based query degradation modeling vocabulary-independent ranked utterance retrieval phrase-based query degradation modeling vocabulary-independent ranked utterance retrieval 
propose unified approach web search query alterations japanese limited particular character types orthographic similarity query alteration candidate model based previous work english query correction makes crucial improvements augment list include orthographically dissimilar semantically similar pairs use lexical semantic similarity avoid problem data sparseness computing querycandidate similarity also propose efficient method generating pairs model training testing show proposed method achieves accuracy query alteration task improving previously proposed methods use semantic similarity japanese query alteration based lexical semantic similarity japanese query alteration based lexical semantic similarity japanese query alteration based lexical semantic similarity 
use margin infused relaxed algorithm crammer et al add large number new features two machine translation systems hiero hierarchical phrasebased translation system translation system chineseenglish translation task obtain statistically significant improvements respectively analyze impact new features performance learning algorithm 11,001 new features statistical machine translation 11,001 new features statistical machine translation 11,001 new features statistical machine translation 
introduce novel precedence reordering approach based dependency parser statistical machine translation systems similar preprocessing reordering approaches method efficiently incorporate linguistic knowledge smt systems without increasing complexity decoding set five sov order languages show significant improvements bleu scores translating english compared reordering approaches smt systems using dependency parser improve smt subject-object-verb languages using dependency parser improve smt subject-object-verb languages using dependency parser improve smt subject-object-verb languages 
interactive presentation chinese named entity relation identification system demonstrated domainspecific system pipeline architecture includes word segmentation pos tagging named entity recognition named entity relation identitfication experimental results shown average word segmentation pos tagging correcting errors achieves separately moreover overall average kinds name entities kinds named entity relations respectively chinese named entity relation identification system chinese named entity relation identification system chinese named entity relation identification system 
many language technology applications question answering overall system runs several independent processors data named entity recognizer coreference system parser easily results inconsistent annotations harmful performance aggregate system begin address problem joint model parsing named entity recognition based discriminative constituency parser model produces consistent output named entity spans conflict phrasal spans parse tree joint representation also allows information type annotation improve performance experiments ontonotes corpus found improvements absolute parsing named entity recognition joint parsing named entity recognition joint parsing named entity recognition joint parsing named entity recognition 
extent organization natural language grammars reflects drive minimize dependency length remains little explored present first algorithm sentence length obtaining linearization dependency tree subject constraints mild context sensitivity minimally contextsensitive case dependency trees prove several properties minimallength linearizations allow us improve efficiency algorithm point used naturallyoccurring sentences use algorithm compare optimal observed random sentence dependency length surface deep dependencies english german find languages analyses surface deep dependencies yield highly similar results mild contextsensitivity affords little reduction minimal dependency length fully projective linearizations observed linearizations german much closer random farther linearizations english minimal-length linearizations mildly context-sensitive dependency trees minimal-length linearizations mildly context-sensitive dependency trees minimal-length linearizations mildly context-sensitive dependency trees 
statistical parsing models recently proposed employ bounded stack timeseries recognition using rightcorner transform defined training trees minimize stack use schuler et al corpus results shown vast majority sentences parsed way using small stack bound three four elements suggests standard cky algorithm implicitly assumes unbounded stack may wasting probability mass trees whose complexity beyond human recognition generation capacity paper first describes version rightcorner transform defined entire probabilistic grammars cast infinite sets generable trees order ensure fair comparison unbounded pcfg parsing using common underlying model presents experimental results show parser using transformed version grammar significantly outperforms unboundedstack cky parser using original grammar positive results parsing bounded stack using model-based right-corner transform positive results parsing bounded stack using model-based right-corner transform positive results parsing bounded stack using model-based right-corner transform 
statistical machine translation smt models need large bilingual corpora training unavailable language pairs paper provides first serious experimental study active learning smt use active learning improve quality smt system show significant improvements translation compared random sentence selection baseline test training data taken different domains experimental results shown simulated setting using three language pairs realistic situation language pair limited translation resources active learning statistical phrase-based machine translation active learning statistical phrase-based machine translation active learning statistical phrase-based machine translation 
paper describes decoder hierarchical translation decoder implemented standard wfst operations alternative cube pruning procedure find use wfsts rather lists requires less pruning translation search resulting fewer search errors direct generation translation lattices target language better parameter optimization improved translation performance rescoring language models mbr decoding report translation experiments nist translation tasks contrast wfstbased hierarchical decoder hierarchical translation cube pruning hierarchical phrase-based translation weighted finite state transducers hierarchical phrase-based translation weighted finite state transducers hierarchical phrase-based translation weighted finite state transducers 
chen show variety language models belonging exponential family test set model accurately predicted training set parameter values work show relationship used motivate two heuristics shrinking size language model improve performance use first heuristic develop novel language model outperforms baseline word trigram model perplexity absolute speech recognition rate wall street journal data use second heuristic motivate regularized version minimum discrimination information models show method outperforms techniques domain adaptation shrinking exponential language models shrinking exponential language models shrinking exponential language models 
address problem automatic detection online reviews without using human labels propose efficient method combines two basic ideas building classifier large number noisy examples using structure website enhance performance classifier experiments suggest method competitive supervised learning methods mandate expensive human effort dollars less: identifying review pages sans human labels dollars less: identifying review pages sans human labels dollars less: identifying review pages sans human labels 
tree substitution grammars tsgs compelling alternative grammars modelling syntax however many popular techniques estimating weighted tsgs moniker data oriented parsing suffer problems inconsistency present theoretically principled model solves problems using bayesian formulation model learns compact simple grammars uncovering latent linguistic structures verb subcategorisation far standard pcfg inducing compact accurate tree-substitution grammars inducing compact accurate tree-substitution grammars inducing compact accurate tree-substitution grammars 
batch em algorithm plays important role unsupervised induction sometimes suffers slow convergence paper show online variants provide significant speedups even find better solutions found batch em support findings four unsupervised tasks tagging document classification word segmentation word alignment online em unsupervised models online em unsupervised models online em unsupervised models 
paper extend methods roark hollingshead reducing complexity parsing pipeline via hard constraints derived tagging methods previous paper achieved quadratic complexity prove alternate methods choosing constraints achieve either linear oro log complexity bounds processing demonstrated achieved without reducing parsing accuracy fact cases improving accuracy new methods achieve observed performance comparable previously published quadratic complexity method finally demonstrate improved performance combining complexity bounding methods additional high precision constraints linear complexity context-free parsing pipelines via chart constraints linear complexity context-free parsing pipelines via chart constraints linear complexity context-free parsing pipelines via chart constraints 
paper introduces three new syntactic models representing speech repairs models developed test intuition erroneous parts speech repairs reparanda generated recognized occurring corrected thus designed minimize differences grammar rule applications fluent disfluent speech containing similar structure three models considered paper also designed isolate mechanism impact systematically exploring different variables improved syntactic models parsing speech repairs improved syntactic models parsing speech repairs improved syntactic models parsing speech repairs 
cohesive constraints allow decoder employ arbitrary phrases encourage translate phrases order respects source dependency tree structure present extensions cohesive constraints exhaustive interruption count rich interruption check show decoder significantly outperforms standard phrasebased decoder english spanish improvements bleu point obtained english iraqi system cohesive constraints beam search phrase-based decoder cohesive constraints beam search phrase-based decoder cohesive constraints beam search phrase-based decoder 
paper revisits optimal decoding statistical machine translation using ibm model show exact optimal inference using integer linear programming practical previously suggested used conjunction algorithm experiments see exact inference provide gain one bleu point sentences length tokens revisiting optimal decoding machine translation ibm model 4 revisiting optimal decoding machine translation ibm model 4 revisiting optimal decoding machine translation ibm model 4 
show integration extended lexicon model decoder improve translation performance model based lexical triggers capture dependencies sentence level results compared variants model applied reranking lists present combined application models search rescoring gives promising results experiments reported gale task improvements bleu ter absolute competitive baseline comparison extended lexicon models search rescoring smt comparison extended lexicon models search rescoring smt comparison extended lexicon models search rescoring smt 
propose variation algorithm specifically customized optimizing parameters statistical machine translation smt decoder better automatic evaluation metric scores translations versions bleu ter mixtures traditional simplexdownhill advantage computations objective functions yet still gives satisfactory searching directions scenarios suitable optimizing translation metrics differentiable nature hand armijo algorithm usually performs line search efficiently given searching direction deep hidden fact efficient line search method change iterations simplex hence searching trajectories propose embed armijo inexact line search within simplexdownhill algorithm show experiments proposed algorithm improves widelyapplied minimum error rate training algorithm optimizing machine translation parameters simplex armijo downhill algorithm optimizing statistical machine translation decoding parameters simplex armijo downhill algorithm optimizing statistical machine translation decoding parameters simplex armijo downhill algorithm optimizing statistical machine translation decoding parameters 
investigate natural language understanding partial speech recognition results equip dialogue system incremental language processing capabilities realistic conversations show relatively high accuracy achieved understanding spontaneous utterances utterances completed towards natural language understanding partial speech recognition results dialogue systems towards natural language understanding partial speech recognition results dialogue systems towards natural language understanding partial speech recognition results dialogue systems 
investigate important challenging problem summary generation evolutionary summarization etts generates news timelines massive data internet etts greatly facilitates fast news browsing knowledge comprehension hence necessity given collection web documents related evolving news etts aims return news evolution along timeline consisting individual correlated summaries date existing summarization algorithms fail utilize characteristics among component summaries propose model correlations among component summaries timelines using sentence dependencies present novel combination develop experimental systems compare rival algorithms instinctively different datasets amount documents evaluation results rouge metrics indicate effectiveness proposed approach based information timeline generation evolutionary trans-temporal summarization timeline generation evolutionary trans-temporal summarization timeline generation evolutionary trans-temporal summarization 
mt systems proven effective models compelling show good room improvement however decoding involves slow search present new method obtains significant speedups strong baseline loss bleu faster mt decoding pervasive laziness faster mt decoding pervasive laziness faster mt decoding pervasive laziness 
recent years structural correspondence learning scl becoming one promising techniques learning however scl model treats feature well instance strategy address two issues effectively proposed weighted scl model weights features well instances specifically assigns smaller weight hfds features assigns larger weight instances label involved pivot feature experimental results indicate proposed model could overcome adverse influence hfds features leverage knowledge labels instances pivot features improving scl model sentiment-transfer learning improving scl model sentiment-transfer learning improving scl model sentiment-transfer learning 
conventional confusion network based system combination machine translation mt heavily relies features based measure agreement words different translation hypotheses paper presents two new features consider agreement different hypotheses improve performance system combination first one based sentence specific online language model second one based voting experiments large scale mt task show features yield significant improvements translation performance combination produces even better translation results using n-gram based features machine translation system combination using n-gram based features machine translation system combination using n-gram based features machine translation system combination 
automatic ape systems aim correcting output machine translation systems produce better quality translations produce translations manually postedited increase productivity work present ape system uses statistical models enhance commercial rulebased machine translation rbmt system addition procedure effortless human evaluation established tested ape system two corpora different complexity parliament corpus show ape system significantly complements improves rbmt system results protocols corpus although less conclusive promising well finally several possible sources errors identified help develop future system enhancements statistical post-editing rule-based machine translation system statistical post-editing rule-based machine translation system statistical post-editing rule-based machine translation system 
compare two approaches dependency tree linearization task arises many nlp applications first one widely used overgenerate rank approach relies exclusively trigram language model lm second one combines language modeling maximum entropy classifier trained range linguistic features results provide strong support combined method show trigram lms appropriate phrase linearization clause level richer representation necessary achieve comparable performance tree linearization english: improving language model based approaches tree linearization english: improving language model based approaches tree linearization english: improving language model based approaches 
word sense distributions usually skewed predicting extent skew help word sense disambiguation wsd system determine whether consider evidence local context apply simple yet effective heuristic using first frequent sense paper propose method estimate entropy sense distribution boost precision first sense heuristic restricting application words lower entropy show two standard datasets automatic prediction entropy increase performance automatic first sense heuristic estimating exploiting entropy sense distributions estimating exploiting entropy sense distributions estimating exploiting entropy sense distributions 
combining output multiple parsers via parse selection parse hybridization improves best individual parser henderson brill sagae lavie propose three ways improve upon existing methods parser combination first propose method parse hybridization recombines productions instead constituents thereby preserving structure output individual parsers greater extent second propose efficient lineartime algorithm computing expected using minimum bayes risk parse selection third extend parser combination methods multiple outputs multiple outputs present results wsj section also english side parallel corpus combining constituent parsers combining constituent parsers combining constituent parsers 
proceedings naacl hlt short papers pages boulder colorado june association computational linguistics reverse revision linear tree combination dependency parsing giuseppe attardi dipartimento di informatica universita di pisa pisa italy attardi di unipi felice dell orletta dipartimento di informatica universita di pisa pisa italy felice dellorletta di unipi reverse revision linear tree combination dependency parsing reverse revision linear tree combination dependency parsing reverse revision linear tree combination dependency parsing 
demonstrate supervised annotation learning approach using structured features derived tokens prior annotations performs better bag words approach present general graph representation automatically deriving features labeled data automatic feature selection based class association scores requires large amount labeled data direct voting difficult structured features even language specialists show highlighted rationales user used indirect feature voting performance achieved less labeled data present results two annotation learning tasks opinion mining product movie reviews interactive annotation learning indirect feature voting interactive annotation learning indirect feature voting interactive annotation learning indirect feature voting 
mi vvim vt elt diai gt derospod vodvmt ri dpbavgodti gl rvvopwti gol pi vli mta ri vvimpvt elt diai pgodti aods vt aodsb emi pi dvo rodel oei ei dci dvri vvim vt elt diai gt oeemt vli et romelmopi topi nmodp vi pb nli mi pl rvp mi dvpgri omrs ciat dpvmovi vlovpl glvi gl god ti pi rs tmri vvim vt elt diai gt db mmipl rvp pltw od tkimorr dv xbkp tkimvli topi odc omi gtaeomotri vt vli pvovi vli omvb orpt emtet pi oai opl mi vt vli gl rvs riki rt mydvopw tmo rodel oei modeling letter-to-phoneme conversion phrase based statistical machine translation problem minimum error rate training modeling letter-to-phoneme conversion phrase based statistical machine translation problem minimum error rate training modeling letter-to-phoneme conversion phrase based statistical machine translation problem minimum error rate training 
wordnet senserelate allwords freely available open source perl package assigns sense every content word known wordnet text finds sense word related senses surrounding words based measures found wordnet similarity method shown competitive results recent evaluations including wordnet::senserelate::allwords - broad coverage word sense tagger maximizes semantic relatedness wordnet::senserelate::allwords - broad coverage word sense tagger maximizes semantic relatedness wordnet::senserelate::allwords - broad coverage word sense tagger maximizes semantic relatedness 
number studies presented approaches semantic role labeling availability corpora framenet propbank corpora define semantic roles predicates frame independently thus crucial approach generalize semantic roles across different frames increase size training instances paper explores several criteria generalizing semantic roles framenet role hierarchy descriptors roles semantic types filler phrases mappings framenet roles thematic roles verbnet also propose feature functions naturally combine weight criteria based training data experimental result role classification shows improvements error reduction rate score respectively also provide analyses proposed criteria comparative study generalization semantic roles framenet comparative study generalization semantic roles framenet comparative study generalization semantic roles framenet 
paper describe system participated semeval task disambiguating sentiment ambiguous adjectives chinese system uses text messages twitter popular microblogging platform building dataset emotional texts using built dataset system classifies meaning adjectives positive negative sentiment polarity according given context approach fully automatic require additional language resources language independent twitter based system: using twitter disambiguating sentiment ambiguous adjectives twitter based system: using twitter disambiguating sentiment ambiguous adjectives twitter based system: using twitter disambiguating sentiment ambiguous adjectives 
paper revisits pivot language approach machine translation first investigate three different methods pivot translation employ hybrid method combining rbmt smt systems fill data gap pivot translation sourcepivot corpora independent experimental results spoken language translation show hybrid method significantly improves translation quality outperforms method using corpus size addition propose system combination approach select better translations produced various pivot translation methods method regards system combination translation evaluation problem formalizes regression learning model experimental results indicate method achieves consistent significant improvement individual translation outputs revisiting pivot language approach machine translation revisiting pivot language approach machine translation revisiting pivot language approach machine translation 
minimum error rate training mert minimum mbr decoding used current statistical machine translation smt systems algorithms originally developed work lists translations recently extended lattices encode many hypotheses typical lists extend mert mbr algorithms work hypergraphs encode vast number translations produced mt systems based synchronous context free grammars algorithms efficient versions presented earlier show mert employed optimize parameters mbr decoding experiments show speedups mert mbr well performance improvements mbr decoding several language pairs efficient minimum error rate training minimum bayes-risk decoding translation hypergraphs lattices efficient minimum error rate training minimum bayes-risk decoding translation hypergraphs lattices efficient minimum error rate training minimum bayes-risk decoding translation hypergraphs lattices 
statistical machine translation smt models require bilingual corpora training corpora often multilingual parallel text multiple languages simultaneously introduce active learning task adding new language existing multilingual set parallel text constructing high quality mt systems language collection new target language show adding new language using active learning europarl corpus provides significant improvement compared random sentence selection baseline also provide new highly effective sentence selection methods improve al smt multilingual single language pair setting active learning multilingual statistical machine translation active learning multilingual statistical machine translation active learning multilingual statistical machine translation 
computational story telling sparked great interest artificial intelligence partly relevance educational gaming applications traditionally story generators rely large repository background knowledge containing information story plot characters information detailed usually hand crafted paper propose approach generating short children stories require extensive manual involvement create system realizes various components generation pipeline stochastically system follows approach space multiple candidate stories pruned considering whether plausible interesting coherent learning tell tales: data-driven approach story generation learning tell tales: data-driven approach story generation learning tell tales: data-driven approach story generation 
lack chinese sentiment corpora limits research progress chinese sentiment classification however many freely available english sentiment corpora web paper focuses problem sentiment classification leverages available english corpus chinese sentiment classification using english corpus training data machine translation services used eliminating language gap training set test set english features chinese features considered two independent views classification problem propose cotraining approach making use unlabeled chinese data experimental results show effectiveness proposed approach outperform standard inductive classifiers transductive classifiers co-training cross-lingual sentiment classification co-training cross-lingual sentiment classification co-training cross-lingual sentiment classification 
sentiment classification refers task automatically identifying whether given piece text expresses positive negative opinion towards subject hand proliferation web content blogs discussion forums online review sites made possible perform mining public opinion sentiment modeling thus becoming critical component market intelligence social media technologies aim tap collective wisdom crowds paper consider problem learning sentiment models minimal manual supervision propose novel approach learn lexical prior knowledge form sentimentladen terms conjunction domaindependent unlabeled data labeled documents model based constrained matrix implemented using simple update rules extensive experimental studies demonstrate effectiveness approach variety sentiment prediction tasks non-negative matrix tri-factorization approach sentiment classification lexical prior knowledge non-negative matrix tri-factorization approach sentiment classification lexical prior knowledge non-negative matrix tri-factorization approach sentiment classification lexical prior knowledge 
existing evaluation metrics machine translation lack crucial robustness correlations human quality judgments vary considerably across languages genres believe main reason inability properly capture meaning good translation candidate means thing reference translation regardless formulation propose metric evaluates mt output based rich set features motivated textual entailment compatibility argument structure overlap compare metric combination metric four scores bleu nist ter meteor two different settings combination metric outperforms individual scores bested metric combining entailment traditional features yields improvements robust machine translation evaluation entailment features robust machine translation evaluation entailment features robust machine translation evaluation entailment features 
efficient decoding algorithm crucial element statistical machine translation system researchers noted certain similarities smt decoding famous traveling salesman problem particular knight shown tsp instance mapped smt model demonstrating decoding task paper focus reverse mapping showing smt decoding problem directly reformulated tsp transformation natural deepens understanding decoding problem allows direct use powerful existing tsp solvers smt decoding test approach three datasets compare decoder popular algorithm cases method provides competitive better performance phrase-based statistical machine translation traveling salesman problem phrase-based statistical machine translation traveling salesman problem phrase-based statistical machine translation traveling salesman problem 
present novel transition system dependency parsing constructs arcs adjacent words parse arbitrary trees swapping order words input adding swapping operation changes time complexity deterministic parsing linear quadratic worst case empirical estimates based treebank data show expected running time fact linear range data attested corpora evaluation data five languages shows accuracy especially good results labeled exact match score non-projective dependency parsing expected linear time non-projective dependency parsing expected linear time non-projective dependency parsing expected linear time 
pure statistical parsing systems achieves high accuracy performs poorly paper propose two different approaches produce syntactic dependency structures using hpsg grammar dependency backbone hpsg analysis used provide general linguistic insights combined statistical dependency parsing models achieves performance improvements tests cross-domain dependency parsing using deep linguistic grammar cross-domain dependency parsing using deep linguistic grammar cross-domain dependency parsing using deep linguistic grammar 
stochastic gradient descent sgd uses approximate gradients estimated subsets training data updates parameters online fashion learning framework attractive often requires much less training time practice batch training algorithms however becoming popular natural language processing ability produce compact models cannot efficiently applied sgd training due large dimensions feature vectors fluctuations approximate gradients present simple method solve problems penalizing weights according cumulative values penalty evaluate effectiveness method three applications text chunking named entity recognition tagging experimental results demonstrate method produce compact accurate models much quickly quasinewton method loglinear models stochastic gradient descent training l1-regularized log-linear models cumulative penalty stochastic gradient descent training l1-regularized log-linear models cumulative penalty stochastic gradient descent training l1-regularized log-linear models cumulative penalty 
minimum bayes risk mbr decoding objective improves bleu scores machine translation output relative standard viterbi objective maximizing model score however mbr targeting bleu prohibitively slow optimize lists large paper introduce analyze alternative mbr equally effective improving performance yet asymptotically faster running times faster mbr experiments lists furthermore fast decoding procedure select output sentences based distributions entire forests translations addition lists evaluate procedure translation forests two hierarchical machine translation systems decoding objective consistently outperforms list mbr giving improvements bleu fast consensus decoding translation forests fast consensus decoding translation forests fast consensus decoding translation forests 
current smt systems usually decode single translation models cannot benefit strengths models decoding phase instead propose joint decoding method combines multiple translation models one decoder joint decoder draws connections among multiple models integrating translation hypergraphs produce individually therefore one model share translations even derivations models comparable system combination technique joint decoding achieves absolute improvement bleu points individual decoding joint decoding multiple translation models joint decoding multiple translation models joint decoding multiple translation models 
paper presents collaborative decoding new method improve machine translation accuracy leveraging translation consensus multiple machine translation decoders different system combination mbr decoding postprocess lists word lattice machine translation decoders method multiple machine translation decoders collaborate exchanging partial translation results using iterative decoding approach agreement statistics translations multiple decoders employed full partial hypothesis explored decoding experimental results data sets nist machine translation task show method bring significant improvements baseline decoders outputs used improve result system combination collaborative decoding: partial hypothesis re-ranking using translation consensus decoders collaborative decoding: partial hypothesis re-ranking using translation consensus decoders collaborative decoding: partial hypothesis re-ranking using translation consensus decoders 
statistical models machine translation exhibit spurious ambiguity probability output string split among many distinct derivations trees segmentations principle goodness string measured total probability many derivations however finding best string decoding computationally intractable therefore systems use simple viterbi approximation measures goodness string using probable derivation instead develop variational approximation considers derivations still allows tractable decoding particular variational distributions parameterized models also analytically show interpolating models different similar minimumrisk decoding bleu tromble et al experiments show approach improves state art variational decoding statistical machine translation variational decoding statistical machine translation variational decoding statistical machine translation 
present new approach learning semantic parser system maps natural language sentences logical form unlike previous methods exploits existing syntactic parser produce disambiguated parse trees drive compositional semantic interpretation resulting system produces improved results standard corpora natural language interfaces database querying simulated robot control learning compositional semantic parser using existing syntactic parser learning compositional semantic parser using existing syntactic parser learning compositional semantic parser using existing syntactic parser 
paper presents set bayesian methods automatically extending wordnet ontology new concepts annotating existing concepts generic property fields attributes base approach latent dirichlet allocation evaluate along two dimensions precision ranked lists attributes quality attribute assignments wordnet concepts cases find principled approaches outperform previously proposed heuristic methods greatly improving specificity attributes concept latent variable models concept-attribute attachment latent variable models concept-attribute attachment latent variable models concept-attribute attachment 
recent advances functional magnetic resonance imaging fmri offer significant new approach studying semantic representations humans making possible directly observe brain activity people comprehend words sentences study investigate humans comprehend phrases strong dog neural activity recorded classification analysis shows distributed pattern neural activity contains sufficient signal decode differences among phrases furthermore semantic models explain significant portion systematic variance observed neural activity multiplicative composition models phrase outperform additive models consistent assumption people use adjectives modify meaning noun rather conjoining meaning adjective noun quantitative modeling neural representation adjective-noun phrases account fmri activation quantitative modeling neural representation adjective-noun phrases account fmri activation quantitative modeling neural representation adjective-noun phrases account fmri activation 
text categorization feature selection fs strategy aims making text classifiers efficient accurate however dealing new task still difficult quickly select suitable one various fs methods provided many previous studies paper propose theoretic framework fs methods based two basic measurements frequency measurement ratio measurement six popular fs methods detail discussed framework moreover guidance theoretical analysis propose novel method called weighed frequency odds wfo combines two measurements trained weights experimental results data sets sentiment classification tasks show new method robust across different tasks numbers selected features framework feature selection methods text categorization framework feature selection methods text categorization framework feature selection methods text categorization 
present learning qa task ranking candidate sentences using textual entailment analysis obtain entailment scores natural language question posed user candidate sentences returned search engine textual entailment two sentences assessed via features representing attributes entailment problem sentence structure matching matching based etc implement learning ssl approach demonstrate utilization unlabeled data points improve task qa create graph labeled unlabeled data using textual entailment features similarity weights data points apply summarization method graph make computations feasible large datasets new representation ssl qa datasets using handful features limited amounts labeled data show improvement generalization performance qa models graph-based semi-supervised learning question-answering graph-based semi-supervised learning question-answering graph-based semi-supervised learning question-answering 
demonstrate learning used correct noisy speech recognition transcripts lecture domain average word error rate reduction method distinguished earlier related work robustness small amounts training data resulting efficiency spite use true word error rate computations rule scoring function improving automatic speech recognition lectures transformation-based rules learned minimal data improving automatic speech recognition lectures transformation-based rules learned minimal data improving automatic speech recognition lectures transformation-based rules learned minimal data 
efficiency prime concern syntactic mt decoding yet significant developments statistical parsing respect asymptotic efficiency haven yet explored mt recently mcdonald et al formalized dependency parsing maximum spanning tree mst problem solved quadratic time relative length sentence show mst parsing almost accurate dependency parsing case english accurate free word order languages paper applies mst parsing mt describes integrated decoder compute dependency language model scores results show augmenting system dependency language model leads significant improvements ter bleu scores five nist evaluation test sets quadratic-time dependency parsing machine translation quadratic-time dependency parsing machine translation quadratic-time dependency parsing machine translation 
paper describes models sentence realizer based dependency structures unlike traditional realizers using grammar rules method realizes sentences linearizing dependency relations directly two steps first relative order head dependent determined dependency relation best linearizations compatible relative order selected models models incorporate three types feature functions including dependency relations surface words headwords approach sentence realization provides simplicity efficiency competitive accuracy trained dependency structures chinese dependency treebank realizer achieves bleu score dependency based chinese sentence realization dependency based chinese sentence realization dependency based chinese sentence realization 
conventional sentence compression methods employ syntactic parser compress sentence without changing meaning however reference compressions made humans always retain syntactic structures original sentences moreover goal ondemand sentence compression time spent parsing stage negligible alternative syntactic parsing propose novel term weighting technique based positional information within original sentence novel language model combines statistics original sentence general corpus experiments involve human subjective evaluations automatic evaluations show method outperforms hori method conventional technique method use syntactic parser times faster hori method syntax-free approach japanese sentence compression syntax-free approach japanese sentence compression syntax-free approach japanese sentence compression 
paraphrase generation pg important plenty nlp applications however research pg far enough paper propose novel method statistical paraphrase generation spg achieve various applications based uniform statistical model naturally combine multiple resources enhance pg performance experiments use proposed method generate paraphrases three different applications results show method easily transformed one application another generate valuable interesting paraphrases application-driven statistical paraphrase generation application-driven statistical paraphrase generation application-driven statistical paraphrase generation 
present dialogue system enables robot work together human user build wooden construction toys describe study na ve subjects interacted system range conditions completed questionnaire results study provide wide range subjective objective measures quality interactions assess aspects interaction greatest impact users opinions system used method based paradise evaluation framework walker et al derive performance function data major contributors user satisfaction number repetition requests negative effect satisfaction dialogue length users recall system instructions contributed positively comparing objective subjective measures usability human-robot dialogue system comparing objective subjective measures usability human-robot dialogue system comparing objective subjective measures usability human-robot dialogue system 
tree sequence based translation model allows violation syntactic boundaries rule capture phrases tree sequence contiguous sequence subtrees paper goes present translation model based tree sequence alignment tree sequence sequence gaps compared contiguous tree sequencebased model proposed model well handle phrases large gaps means tree sequence alignment algorithm targeting noncontiguous constituent decoding also proposed experimental results nist translation task show proposed model statistically significantly outperforms baseline systems non-contiguous tree sequence alignment-based model statistical machine translation non-contiguous tree sequence alignment-based model statistical machine translation non-contiguous tree sequence alignment-based model statistical machine translation 
paper present confidence measure word alignment based posterior probability alignment links introduce sentence alignment confidence measure alignment link confidence measure based measures improve alignment quality selecting high confidence sentence alignments alignment links multiple word alignments sentence pair additionally remove low confidence alignment links word alignment bilingual training corpus increases alignment improves translation quality significantly reduces phrase translation table size confidence measure word alignment confidence measure word alignment confidence measure word alignment 
recently confusion network decoding shows best performance combining outputs multiple machine translation mt systems however overcoming different word orders presented multiple mt systems hypothesis alignment still remains biggest challenge confusion mt system combination paper compare four commonly used word alignment methods namely giza ter cla ihmm hypothesis alignment propose method build confusion network intersection word alignment utilizes direct inverse word alignment backbone hypothesis improve reliability hypothesis alignment experimental results demonstrate intersection word alignment yields consistent performance improvement four word alignment methods spoken written language tasks comparative study hypothesis alignment improvement machine translation system combination comparative study hypothesis alignment improvement machine translation system combination comparative study hypothesis alignment improvement machine translation system combination 
parsing makes search efficient suppressing unlikely items existing kbest extraction methods efficiently search top derivations exhaustive pass present unified algorithm parsing preserves efficiency extraction giving methods algorithm produces optimal parses conditions required optimality parser empirically optimal lists extracted significantly faster approaches range grammar types k-best a* parsing k-best a* parsing k-best a* parsing 
modern models relation extraction tasks like ace based supervised learning relations small corpora investigate alternative paradigm require labeled corpora avoiding domain dependence acestyle algorithms allowing use corpora size experiments use freebase large semantic database several thousand relations provide distant supervision pair entities appears freebase relation find sentences containing entities large unlabeled corpus extract textual features train relation classifier algorithm combines advantages supervised ie combining noisy pattern features probabilistic classifier unsupervised ie extracting large numbers relations large corpora domain model able extract instances relations precision also analyze feature performance showing syntactic parse features particularly helpful relations ambiguous lexically distant expression distant supervision relation extraction without labeled data distant supervision relation extraction without labeled data distant supervision relation extraction without labeled data 
active learning al already shown markedly reduce annotation efforts many sequence labeling tasks compared random selection al remains unconcerned internal structure selected sequences typically sentences propose semisupervised al approach sequence labeling highly uncertain subsequences presented human annotators others selected sequences automatically labeled task entity recognition experiments reveal approach reduces annotation efforts terms manually labeled tokens compared standard fully supervised al scheme semi-supervised active learning sequence labeling semi-supervised active learning sequence labeling semi-supervised active learning sequence labeling 
variational em become popular technique probabilistic nlp hidden variables commonly computational tractability make strong independence assumptions meanfield assumption approximating posterior distributions hidden variables show looser restriction approximate posterior requiring mixture help inject prior knowledge exploit soft constraints variational variational inference grammar induction prior knowledge variational inference grammar induction prior knowledge variational inference grammar induction prior knowledge 
nlp applications work assumption user input thus word segmentation ws written languages use word boundary markers wbms spaces regarded trivial issue however noisy texts blogs sms may contain spacing errors require correction processing may take place korean language many researchers adopted traditional ws approach eliminates spaces user input proper word boundaries unfortunately approach often exacerbates word spacing quality user input spacing errors case perfect ws model exist paper propose novel ws method takes consideration initial word spacing information user input method generates better output original user input even user input spacing errors moreover proposed method significantly outperforms korean ws model user input initially contains less spacing errors performs comparably cases containing spacing errors believe proposed method practical module novel word segmentation approach written languages word boundary markers novel word segmentation approach written languages word boundary markers novel word segmentation approach written languages word boundary markers 
investigate effect text summarisation problem task associating numerical rating opinionated document comparison framework study effect different summarisation algorithms various compression rates task compare classification accuracy summaries documents associating documents classes make use svm algorithms associate numerical ratings opinionated documents algorithms informed linguistic features computed full documents summaries preliminary results show types summaries could effective better full documents problem experiments summary-based opinion classification experiments summary-based opinion classification experiments summary-based opinion classification 
distributional word similarity commonly perceived symmetric relation yet one major applications lexical expansion generally asymmetric paper investigates nature directional asymmetric similarity measures aim quantify distributional feature inclusion identify desired properties measures specify particular one based averaged precision demonstrate empirical benefit directional measures expansion directional distributional similarity lexical expansion directional distributional similarity lexical expansion directional distributional similarity lexical expansion 
paper introduces novel hierarchical summarization approach automatic multidocument summarization creating hierarchical representation words input document set proposed approach able incorporate various objectives multidocument summarization integrated framework evaluation conducted duc data set integrated multi-document summarization approach based word hierarchical representation integrated multi-document summarization approach based word hierarchical representation integrated multi-document summarization approach based word hierarchical representation 
paper presents effective approach discard entries rule table statistical machine translation rule table filtered monolingual key phrases extracted source text using technique based term extraction experiments show rule table reduced without worsening translation performance cases approach results measurable improvements bleu score reducing smt rule table monolingual key phrase reducing smt rule table monolingual key phrase reducing smt rule table monolingual key phrase 
recently various synchronous grammars proposed machine translation synchronous grammar synchronous tree sequence substitution grammar either purely formal linguistically motivated aiming combining strengths different grammars describes synthetic synchronous grammar ssg tentatively paper integrates synchronous grammar scfg synchronous tree sequence substitution grammar stssg statistical machine translation experimental results nist mt test set show ssg based translation system achieves significant improvement three baseline systems statistical machine translation model based synthetic synchronous grammar statistical machine translation model based synthetic synchronous grammar statistical machine translation model based synthetic synchronous grammar 
automatic tools machine translation mt evaluation bleu well established drawbacks well sentence level presuppose manually translated reference texts assuming mt system evaluated deal directions language pair research suggest conduct automatic mt evaluation determining orthographic similarity original source text way eliminate need human translated reference texts correlating bleu scores human could shown score gives improved sentence level backtranslation score: automatic mt evalution sentence level without reference translations backtranslation score: automatic mt evalution sentence level without reference translations backtranslation score: automatic mt evalution sentence level without reference translations 
often statistical machine translation smt english korean suffers null alignment previous studies attempted resolve problem removing unnecessary function words reordering source sentences however removal function words cause serious loss information paper present possible method bridging gap englishkorean smt particular proposed method tries transform source sentence inserting pseudo words reordering sentence way sentences similar length word order proposed method achieves increase bleu score baseline system bridging morpho-syntactic gap source target sentences english-korean statistical machine translation bridging morpho-syntactic gap source target sentences english-korean statistical machine translation bridging morpho-syntactic gap source target sentences english-korean statistical machine translation 
investigate use fisher exact significance test pruning translation table hierarchical statistical machine translation system addition significance values computed fisher exact test introduce compositional properties classify phrase pairs significance values also examine impact using significance values feature translation models experimental results show bleu improvements achieved along substantial model size reduction iraqi english translation task toward smaller, faster, better hierarchical phrase-based smt toward smaller, faster, better hierarchical phrase-based smt toward smaller, faster, better hierarchical phrase-based smt 
semantic role labeling srl reasonable globally assign semantic roles due strong dependencies among arguments relations arguments significantly characterize structural information argument structure paper concentrate thematic hierarchy rank relation restricting syntactic realization arguments loglinear model proposed accurately identify thematic rank two arguments import structural information employ technique incorporate thematic rank relations local semantic role classification results experimental results show automatic prediction thematic hierarchy help semantic role classification prediction thematic rank structured semantic role labeling prediction thematic rank structured semantic role labeling prediction thematic rank structured semantic role labeling 
paper describes parsing model speech repairs makes clear separation linguistically meaningful symbols grammar operations specific speech repair operation parser system builds model unfinished constituents speech repairs likely finish finishes probabilistically placeholder structure modified repair constituents restarted replacement constituent recognized together way two coordinated phrases type recognized parsing speech repair without specialized grammar symbols parsing speech repair without specialized grammar symbols parsing speech repair without specialized grammar symbols 
existing summarization methods decompose documents sentences work directly sentence space using matrix however knowledge document side topics embedded documents help context understanding guide sentence selection summarization procedure paper propose new bayesian topic model summarization making use associations efficient variational bayesian algorithm derived model parameter estimation experimental results benchmark data sets show effectiveness proposed model summarization task multi-document summarization using sentence-based topic models multi-document summarization using sentence-based topic models multi-document summarization using sentence-based topic models 
aim deal problem proposed novel approach integrates sentiment orientations documents algorithm apply algorithm using accurate labels documents well pseudo labels documents experimental results show proposed algorithm could improve performance baseline methods dramatically sentiment transfer graph ranking sentiment transfer graph ranking sentiment transfer graph ranking sentiment transfer 
dependency parsers show syntactic relations words using directed graph comparing dependency parsers difficult differences theoretical models describe system convert dependency models structural grammar used grammar education highlights features potentially overlooked dependency graph well exposing potential weaknesses limitations parsing models system performs automated analysis dependency relations uses populate data structure designed emulate sentence diagrams done mapping dependency relations words relative positions words sentence diagram using original metric judging accuracy sentence diagrams achieve precision multiple causes errors presented potential areas improvement dependency parsers dependency parsing dependencies generally considered strong metric accuracy parse trees described lin dependency parse words connected relations head word governor modified dependent word converting parse trees dependency representations judging accuracy detailed syntactic information discovered recently however number dependency parsers developed different theories correct model dependencies dependency parsers define syntactic relations words sentence done either spanning tree search mcdonald et al computationally expensive analysis another modeling system phrase structure parse tree introduce errors long pipeline best knowledge first use dependency relations evaluation tool parse trees lin described process determining heads phrase structures assigning modifiers heads appropriately different ways describe relations negations conjunctions grammatical structures immediately clear comparing different models would difficult research area evaluation produced several new dependency parsers using different theories constitutes correct parse addition attempts model multiple parse trees single dependency relation system often stymied problems differences tokenization systems sentence diagram generation using dependency parsing sentence diagram generation using dependency parsing sentence diagram generation using dependency parsing 
remarkable relationship persists computational linguists cl part general linguistics comprising mainstream mit tg theoretical syntax lines still open represents something tribute cl practitioners tolerance triumph hope goodwill experience abuse tg community shown considerable hostility toward cl everything stands past fifty years offer brief historical notes hint prospects better basis collaboration future computational linguistics generative linguistics: triumph hope experience computational linguistics generative linguistics: triumph hope experience computational linguistics generative linguistics: triumph hope experience 
present results clustering experiments number different evaluation sets using dependency based word spaces contrary previous results found clear advantage using parsed corpus word spaces constructed help simple patterns achieve considerable gains performance spaces ranging absolute terms cluster purity unsupervised classification dependency based word spaces unsupervised classification dependency based word spaces unsupervised classification dependency based word spaces 
paper discusses new convolution tree kernel introducing local alignments main idea new kernel allow syntactic alternations match subtrees paper give algorithm calculate composite kernel experiment results show promising improvements two tasks semantic role labeling question classification study convolution tree kernel local alignment study convolution tree kernel local alignment study convolution tree kernel local alignment 
appropriateness paraphrases words depends often context grab replace catch catch ball catch cold structured vector space svs erk pad model computes word meaning context order assess appropriateness paraphrases paper investigates parameter settings svs presents method obtain large datasets paraphrase assessment corpora wsd annotation paraphrase assessment structured vector space: exploring parameters datasets paraphrase assessment structured vector space: exploring parameters datasets paraphrase assessment structured vector space: exploring parameters datasets 
paper propose novel way include unsupervised feature selection methods probabilistic taxonomy learning models leverage computation logistic regression exploit unsupervised feature selection singular value decomposition svd experiments show way using svd feature selection positively affects performances svd feature selection probabilistic taxonomy learning svd feature selection probabilistic taxonomy learning svd feature selection probabilistic taxonomy learning 
distributional similarity methods proven valuable tool induction semantic similarity till algorithms use cooccurrence data compute meaning words frequencies however need pairwise one easily imagine situations desirable investigate frequencies three modes beyond paper investigate tensor factorization method called tensor factorization build model cooccurrences approach applied problem selectional preference induction automatically evaluated task results show tensor factorization promising tool nlp non-negative tensor factorization model selectional preference induction non-negative tensor factorization model selectional preference induction non-negative tensor factorization model selectional preference induction 
paper presents results wmt shared tasks included translation task system combination task evaluation task conducted manual evaluation machine translation systems system combination entries used ranking systems measure strongly automatic metrics correlate human judgments translation quality metrics present new evaluation technique whereby system output edited judged correctness findings 2009 workshop statistical machine translation findings 2009 workshop statistical machine translation findings 2009 workshop statistical machine translation 
explored novel automatic evaluation measures machine translation output oriented syntactic structure sentence bleu score detailed pos tags well precision recall obtained pos also introduced fmeasure based word pos ngrams correlations new metrics human judgments calculated data first second third shared task statistical machine translation workshop machine translation outputs four different european languages taken account english spanish french german results show new measures correlate well human judgements competitive widely used bleu meteor ter metrics syntax-oriented evaluation measures machine translation output syntax-oriented evaluation measures machine translation output syntax-oriented evaluation measures machine translation output 
paper describes simple evaluation metric mt attempts overcome deficits standard bleu metric slightly different angle employes levenshtein edit distance establishing alignment mt output reference translation order reflect morphological properties highly inflected languages also incorporates simple measure expressing differences word order paper also includes evaluation data previous smt workshop several language pairs simple automatic mt evaluation metric simple automatic mt evaluation metric simple automatic mt evaluation metric 
present simple method generating translations moses toolkit koehn et al existing hypotheses produced translation engines structures underlying translation engines known evaluationbased strategy applied select systems combination experiments show promising improvements terms bleu combining multi-engine translations moses combining multi-engine translations moses combining multi-engine translations moses 
rwth participated system combination task fourth workshop statistical machine translation wmt hypotheses german english mt systems combined consensus translation consensus translation scored better bleu better ter abs best single system addition output french german spanish english systems combined consensus translation gave improvement bleu ter abs best single system rwth system combination system wmt 2009 rwth system combination system wmt 2009 rwth system combination system wmt 2009 
describe synthetic method combining machine translations produced different systems given input outputs explicitly aligned remove duplicate words hypotheses follow system outputs sentence order switching systems produce combined output experiments wmt tuning data showed improvement bleu meteor point best hungarianenglish system constrained data provided contest system submitted wmt shared system combination task machine translation system combination flexible word ordering machine translation system combination flexible word ordering machine translation system combination flexible word ordering 
rwth participated shared translation task fourth workshop statistical machine translation wmt pair translation direction submissions generated using hierarchical statistical machine translation systems appropriate enhancements reorderings source language systems splitting german compounds systems applied tasks system combination used generate final hypothesis additional english hypothesis produced combining three final systems translation english rwth machine translation system wmt 2009 rwth machine translation system wmt 2009 rwth machine translation system wmt 2009 
present word substitution approach combine output different machine translation systems using part speech information candidate words determined among possible translation options turn estimated precomputed word alignment automatic substitution guided several decision factors including part speech local context language model probabilities combination factors defined careful manual analysis respective impact approach tested language pair germanenglish however general technique language independent translation combination using factored word substitution translation combination using factored word substitution translation combination using factored word substitution 
describe system developed team national university singapore english spanish machine translation news commentary text wmt shared translation task approach based domain adaptation combining small news commentary large one europarl corpus built combined two separate phrase tables combined two language models experimented cognates improved tokenization recasing achieving highest lowercased nist score second best lowercased bleu score training without using additional external data translation shared task nus wmt09: domain adaptation experiments english-spanish machine translation news commentary text nus wmt09: domain adaptation experiments english-spanish machine translation news commentary text nus wmt09: domain adaptation experiments english-spanish machine translation news commentary text 
paper describe statistical machine translation system universita karlsruhe developed translation task fourth workshop statistical machine translation smt system augmented alternative word reordering alignment mechanisms well optional phrase table modifications participate constrained condition well constrained condition universit&auml;t karlsruhe translation system eacl-wmt 2009 universit&auml;t karlsruhe translation system eacl-wmt 2009 universit&auml;t karlsruhe translation system eacl-wmt 2009 
study presents submission eacl fourth worskhop statistical machine translation evaluation campaign outlines architecture configuration statistical machine translation smt system putting emphasis major novelty year combination smt systems implementing different word reordering algorithms traditionally concentrated news commentary translation tasks talp-upc phrase-based translation system eacl-wmt 2009 talp-upc phrase-based translation system eacl-wmt 2009 talp-upc phrase-based translation system eacl-wmt 2009 
paper describe machine translation system evaluation campaign fourth workshop statistical machine translation eacl describe modular design mt system particular focus components used participation participated translation task following translation directions french english english french employed architecture translate also participated system combination task carried mbr decoder confusion network decoder report results provided development test sets matrex: dcu mt system wmt 2009 matrex: dcu mt system wmt 2009 matrex: dcu mt system wmt 2009 
paper describes statistical machine translation systems wmt en fr shared task evaluation developed four systems using two different mt toolkits primary submission directions based moses boosted contextual information phrases contrasted conventional system additional contrasts based ncode toolkit one uses part english french gigaword parallel corpus limsi's statistical translation systems wmt'09 limsi's statistical translation systems wmt'09 limsi's statistical translation systems wmt'09 
paper describes nict statistical machine translation smt system used wmt shared task wmt evaluation participated translation task focus year participation investigate model adaptation transliteration techniques order improve translation quality baseline phrasebased smt system nict@wmt09: model adaptation transliteration spanish-english smt nict@wmt09: model adaptation transliteration spanish-english smt nict@wmt09: model adaptation transliteration spanish-english smt 
describe liu systems englishgerman translation wmt shared task focus two methods improve word alignment applying giza second phase reordered training corpus reordering based alignments first phase ii adding lexical data obtained highprecision alignments different word aligner methods studied context system uses compound processing morphological sequence model german sequence model english methods gave improvements translation quality measured bleu meteor scores though consistently systems used data mixed corpus better scores baseline configuration improving alignment smt reordering augmenting training corpus improving alignment smt reordering augmenting training corpus improving alignment smt reordering augmenting training corpus 
describe two systems machine translation took part wmt translation task one systems tuned system one based linguistically motivated approach english-czech mt 2008 english-czech mt 2008 english-czech mt 2008 
paper describes development several machine translation systems wmt shared task evaluation consider translation french english describe statistical system based moses decoder statistical system using systran system also investigated techniques automatically extract additional bilingual texts comparable corpora smt spe machine translation systems wmt'09 smt spe machine translation systems wmt'09 smt spe machine translation systems wmt'09 
paper presents carnegie mellon university statistical transfer mt system submitted wmt shared task translation describe approach incorporates syntactic phrase pairs addition syntactic grammar reporting development test results conduct preliminary analysis coverage effectiveness system components improved statistical transfer system french-english machine translation improved statistical transfer system french-english machine translation improved statistical transfer system french-english machine translation 
paper describes techniques explored improve translation news text tracks wmt shared translation task beginning convention hierarchical system found benefits using word segmentation lattices input explicit generation beginning end sentence markers minimum bayes risk decoding incorporation feature scoring alignment function words hypothesized translation also explored use monolingual paraphrases improve coverage well improve quality segmentation lattices used lead improvements university maryland statistical machine translation system fourth workshop machine translation university maryland statistical machine translation system fourth workshop machine translation university maryland statistical machine translation system fourth workshop machine translation 
describe system used submission translation task use moses phrasebased statistical machine translation system two simple modications decoding input strategy based morphology analyze impact translation quality toward using morphology french-english phrase-based smt toward using morphology french-english phrase-based smt toward using morphology french-english phrase-based smt 
article describe machine translation systems used create morphologic submissions wmt shared hungarian english english hungarian shared translation tasks used rule based metamorpho system generate primary submission addition created hybrid system moses decoder used rank translations assemble partial translations created metamorpho third system purely statistical morpheme based system hungarian english task morphologic's submission wmt 2009 shared task morphologic's submission wmt 2009 shared task morphologic's submission wmt 2009 shared task 
edinburgh university participated wmt shared task using moses statistical machine translation decoder building systems language pairs system configuration identical language pairs additional components germanenglish language pairs paper describes configuration systems plus novel contributions moses including truecasing efficient decoding methods framework specify reordering constraints edinburgh's submission tracks wmt 2009 shared task reordering speed improvements moses edinburgh's submission tracks wmt 2009 shared task reordering speed improvements moses edinburgh's submission tracks wmt 2009 shared task reordering speed improvements moses 
present comparison two approaches machine translation using english pivot language sentence pivoting pivoting results show using english pivot either approach outperforms direct translation arabic chinese best result system scores higher direct translation bleu points error analysis best system shows successfully handle many complex syntactic variations improving arabic-chinese statistical machine translation using english pivot language improving arabic-chinese statistical machine translation using english pivot language improving arabic-chinese statistical machine translation using english pivot language 
paper describe new approach model word reorderings statistical machine translation smt smt approaches able model local reorderings even word order related languages like german english different recent years approaches reorder source sentence preprocessing step better match target sentences according pos rules applied successfully enhance approach model reorderings introducing discontinuous rules tested new approach germanenglish translation task could significantly improve translation quality bleu points compared system already uses continuous posbased rules model reorderings pos-based model long-range reorderings smt pos-based model long-range reorderings smt pos-based model long-range reorderings smt 
linking constructions involving de ubiquitous chinese translated english many different ways major source machine translation error even syntaxsensitive translation models used paper explores getting information syntactic semantic discourse context uses de facilitate producing appropriate english translation strategy describe finergrained classification de constructions chinese nps construct corpus annotated examples train classifier contains linguistically inspired features use de classifier preprocess mt data explicitly labeling de constructions well reordering phrases show approach provides significant bleu point gains mt mt mt phrasedbased system improvement persists hierarchical reordering model applied disambiguating "de" chinese-english machine translation disambiguating "de" chinese-english machine translation disambiguating "de" chinese-english machine translation 
automatic machine translation mt evaluation metrics traditionally evaluated correlation scores assign mt output human judgments translation performance different types human judgments fluency adequacy hter measure varying aspects mt performance captured automatic mt metrics explore differences use new tunable mt metric extends translation edit rate evaluation metric tunable parameters incorporation morphology synonymy paraphrases shown one top metrics nist metrics matr challenge highest average rank terms pearson spearman correlation optimizing different types human judgments yields significantly improved correlations meaningful changes weight different types edits demonstrating significant differences types human judgments fluency, adequacy, hter? exploring different human judgments tunable mt metric fluency, adequacy, hter? exploring different human judgments tunable mt metric fluency, adequacy, hter? exploring different human judgments tunable mt metric 
generation systems tend manually built limits reusability makes time create maintain methods automating part system building process exist methods risk loss output quality paper investigate cost quality generation system building compare four new systems created predominantly automatic techniques six existing systems domain created predominantly manual techniques evaluate ten systems using intrinsic automatic metrics human quality ratings find increasing degree system building automated necessarily result reduction output quality find furthermore standard automatic evaluation metrics underestimate quality handcrafted systems quality automatically created systems system building cost vs. output quality data-to-text generation system building cost vs. output quality data-to-text generation system building cost vs. output quality data-to-text generation 
developing text rewriting algorithm paraphrasing essential monolingual corpus aligned paraphrased sentences news article headlines rich source paraphrases tend describe event various different ways easily obtained web compare two methods aligning headlines construct aligned corpus paraphrases one based clustering pairwise matching show latter performs best task aligning paraphrastic headlines clustering matching headlines automatic paraphrase acquisition clustering matching headlines automatic paraphrase acquisition clustering matching headlines automatic paraphrase acquisition 
challenge one evaluation competitions generation challenges tunareg used data tuna corpus paired representations entities referring expressions shared task create systems generate referring expressions entities given representations sets entities properties four teams submitted six systems tunareg evaluated six systems two sets referring expressions using several automatic intrinsic measures intrinsic evaluation human task performance experiment report describes tunareg task evaluation methods used presents evaluation results tuna-reg challenge 2009: overview evaluation results tuna-reg challenge 2009: overview evaluation results tuna-reg challenge 2009: overview evaluation results 
investigate syntactic reordering within english arabic translation task extend syntactic reordering approach developed close language pair distant language pair achieve significant improvements translation quality related approaches measured manual well automatic evaluations results prove viability approach distant languages syntactic reordering english-arabic phrase-based machine translation syntactic reordering english-arabic phrase-based machine translation syntactic reordering english-arabic phrase-based machine translation 
problem identifying correcting confusibles spelling errors text typically tackled using specifically trained machine learning classifiers different set confusibles specific classifier trained tuned research investigate generic approach confusible correction instead using specific classifiers use one generic classifier based language model measures likelihood sentences different possible solutions confusible place advantage approach confusible sets handled single model preliminary results show performance generic classifier approach slightly worse specific classifier approach language models contextual error detection correction language models contextual error detection correction language models contextual error detection correction 
present simple effective approach identifying data noisy data sets structured problems like parsing greedily exploiting partial structures analyze approach annotation projection framework dependency trees show dependency parsers two different paradigms trained resulting tree fragments train parsers dutch evaluate method investigate degree transitionbased parsers benefit incomplete training data find partial correspondence projection gives rise parsers outperform parsers trained aggressively filtered data sets achieve unlabeled attachment scores behind average uas dutch shared task supervised parsing buchholz marsi data-driven dependency parsing new languages using incomplete noisy training data data-driven dependency parsing new languages using incomplete noisy training data data-driven dependency parsing new languages using incomplete noisy training data 
combination support vector machines high dimensional kernels string tree kernels suffers two major drawbacks first implicit representation feature spaces allow us understand features actually triggered generalization second resulting computational burden may cases render unfeasible use large data sets training propose approach based feature space reverse engineering tackle problems experiments tree kernels semantic role labeling data set show proposed approach drastically reduce computational footprint yielding almost unaffected accuracy efficient linearization tree kernel functions efficient linearization tree kernel functions efficient linearization tree kernel functions 
vector space models word meaning typically represent meaning word vector computed summing corpus occurrences words close point space assumed similar meaning far around point region similar meaning extend paper discuss two models represent word meaning regions vector space representations computed traditional point representations vector space find models perform token classification task representing words regions vector space representing words regions vector space representing words regions vector space 
recent advances statistical machine translation used beam search approximate inference within probabilistic translation models present alternative approach sampling posterior distribution defined translation model define novel gibbs sampler sampling translations given source sentence show effectively explores posterior distribution overcome limitations heuristic beam search obtain theoretically sound solutions inference problems finding maximum probability translation minimum expected risk training decoding monte carlo inference maximization phrase-based translation monte carlo inference maximization phrase-based translation monte carlo inference maximization phrase-based translation 
supervised machine learning methods increasingly used language technology need annotated language data becomes imminent active learning al means alleviate burden annotation paper addresses problem knowing stop al process without human annotator make explicit decision matter propose evaluate intrinsic criterion al named entity recognizers intrinsic stopping criterion committee-based active learning intrinsic stopping criterion committee-based active learning intrinsic stopping criterion committee-based active learning 
analyze fundamental design challenges misconceptions underlie development efficient robust ner system particular address issues representation text chunks inference approach needed combine local ner decisions sources prior knowledge use within ner system process comparing several solutions challenges reach surprising conclusions well develop ner system achieves score ner shared task best reported result dataset design challenges misconceptions named entity recognition design challenges misconceptions named entity recognition design challenges misconceptions named entity recognition 
th straight year conference computational natural language learning accompanied shared task whose purpose promote natural language processing applications evaluate standard setting shared task dedicated joint parsing syntactic semantic dependencies multiple languages shared task combines shared tasks previous five years unique formalism similar task paper define shared task describe data sets created show quantitative properties report results summarize approaches participating systems conll-2009 shared task: syntactic semantic dependencies multiple languages conll-2009 shared task: syntactic semantic dependencies multiple languages conll-2009 shared task: syntactic semantic dependencies multiple languages 
propose system carry joint parsing syntactic semantic dependencies multiple languages participation shared task present iterative approach dependency parsing semantic role labeling participated closed challenge system achieves labeled macro complete problem labeled attachment score syntactic dependencies labeled semantic dependencies current experimental results show method effectively improves system performance iterative approach joint dependency parsing semantic role labeling iterative approach joint dependency parsing semantic role labeling iterative approach joint dependency parsing semantic role labeling 
motivated large number languages seven short development time two months conll shared task exploited latent variables avoid costly process feature engineering allowing latent variables induce features data took generative latent variable model joint syntacticsemantic dependency parsing developed english applied six new languages minimal adjustments parser robustness across languages indicates parser general feature set parser high performance indicates latent variables succeeded inducing effective features system ranked third overall macro averaged score worse best system latent variable model synchronous syntactic-semantic parsing multiple languages latent variable model synchronous syntactic-semantic parsing multiple languages latent variable model synchronous syntactic-semantic parsing multiple languages 
paper describe system conll shared task joint parsing syntactic semantic dependency structures multiple languages system combines implements efficient parsing techniques get high accuracy well good parsing training time applications syntactic semantic parsing parsing time memory footprint important think also development systems profit since one perform experiments given time subtask syntactic dependency parsing could reach second place accuracy average points behind first ranked system task system highest accuracy english german data average semantic role labeler works well parser reached therefore fourth place ranked macro score joint task syntactic semantic dependency parsing efficient parsing syntactic semantic dependency structures efficient parsing syntactic semantic dependency structures efficient parsing syntactic semantic dependency structures 
paper presents design implementation bionlp shared task reports final results analysis shared task consists three addresses event extraction different level specificity data developed based genia event corpus shared task run weeks drawing initial interest teams teams submitted final results evaluation results encouraging indicating performance approaching practically applicable level revealing remaining challenges overview bionlp&rsquo;09 shared task event extraction overview bionlp&rsquo;09 shared task event extraction overview bionlp&rsquo;09 shared task event extraction 
describe biological event detection method implemented bionlp shared task method relies entirely chunk syntactic dependency relations provided general nlp pipeline adapted way purposes shared task method maps syntactic relations event structures guided probabilities syntactic features events automatically learned training data method achieved recall precision official test run strict equality events uzurich bionlp 2009 shared task uzurich bionlp 2009 shared task uzurich bionlp 2009 shared task 
present tightly packed tries tpts compact implementation compressed trie structures fast paging short load times demonstrate benefits tpts storing language models phrase tables statistical machine translation encoded tpts databases require less space flat text file representations data compressed gzip utility time mapped memory quickly searched directly time linear length key without need decompress entire file overhead local decompression search marginal tightly packed tries: fit large models memory, make load fast, tightly packed tries: fit large models memory, make load fast, tightly packed tries: fit large models memory, make load fast, 
dependency parsers almost ubiquitously evaluated accuracy scores scores say nothing complexity usefulness resulting structures structures may complexity due coordination structure attachment rules dependency parses basic structures systems built upon would seem reasonable judge parsers nlp pipeline show results individual parsers including dependency constituent parsers ensemble parsing techniques overall effect machine translation system treex english czech translation show parsers uas scores correlated nist evaluation metric bleu metric however see increases metrics improvements syntax-based machine translation using ensemble dependency parsers improvements syntax-based machine translation using ensemble dependency parsers improvements syntax-based machine translation using ensemble dependency parsers 
paper present new statistical approach opinion detection evaluation english chinese japanese corpora besides proposed method compared three baselines namely na ve bayes classifier language model approach based significant collocations models language independent improved use technique example english corpus show method almost always gives better performance compared considered baselines investigation statistical language-independent approaches opinion detection english, chinese japanese investigation statistical language-independent approaches opinion detection english, chinese japanese investigation statistical language-independent approaches opinion detection english, chinese japanese 
paper describe sentence position based summarizer built based sentence position policy created evaluation testbed recent summarization tasks document understanding conferences duc show summarizer thus built able outperform systems participating task focused summarization evaluations text analysis conferences tac experiments also show method would perform better producing short summaries upto words longer summaries discuss baselines traditionally used summarization evaluation suggest revival old baseline suit current summarization task tac update summarization task sentence position revisited: robust light-weight update summarization baseline algorithm sentence position revisited: robust light-weight update summarization baseline algorithm sentence position revisited: robust light-weight update summarization baseline algorithm 
paper framework acquiring common sense knowledge web presented common sense knowledge includes information world humans use everyday lives acquire knowledge relationships nouns retrieved using search phrases automatically filled constituents empirical analysis acquired nouns wordnet probabilities produced relationships concept word rather two words specific goal acquisition method acquire knowledge successfully applied nlp problems test validity acquired knowledge means application problem word sense disambiguation results show knowledge used improve accuracy state art unsupervised disambiguation system acquiring applicable common sense knowledge web acquiring applicable common sense knowledge web acquiring applicable common sense knowledge web 
task automatically acquiring semantically related words led people study distributional similarity distributional hypothesis states words similar share similar contexts paper present technique aims improving performance distributional method augmenting original input system syntactic output system nearest neighbours technique based idea transitivity similarity combining syntactic co-occurrences nearest neighbours distributional methods remedy data sparseness. combining syntactic co-occurrences nearest neighbours distributional methods remedy data sparseness. combining syntactic co-occurrences nearest neighbours distributional methods remedy data sparseness. 
develop new objective function word alignment measures size bilingual dictionary induced alignment word alignment results small dictionary preferred one results large dictionary order search alignment minimizes objective cast problem integer linear program extend objective function align corpora level demonstrate small corpus new objective function word alignment new objective function word alignment new objective function word alignment 
faced task building machine learning nlp models often worthwhile turn active learning obtain human annotations minimal costs traditional active learning schemes query human labels intelligently chosen examples however human effort also expended collecting alternative forms annotations example one may attempt learn text classifier labeling words instead addition documents learning two different kinds supervision brings new unexplored dimension problem active learning paper demonstrate value active dual supervision context sentiment analysis show interleaving queries documents words significantly reduces human effort possible traditional active learning passive combinations supervisory inputs active dual supervision: reducing cost annotating examples features active dual supervision: reducing cost annotating examples features active dual supervision: reducing cost annotating examples features 
building machine translation mt many minority languages world serious challenge many minor languages little machine readable text knowledgeable linguists little money available mt development reasons becomes important mt system make best use resources labeled unlabeled building quality system paper argue traditional active learning setup may right fit seeking annotations required building syntax based mt system minority languages posit relatively new variant active learning proactive learning suitable task proactive learning building machine translation systems minority languages proactive learning building machine translation systems minority languages proactive learning building machine translation systems minority languages 
present innovative application discourse processing concepts educational technology corpus analysis peer learning dialogues found initiative initiative shifts indicative learning episodes incorporating finding peer learning agent developing promote learning encouraging shifts task initiative ksc-pal: peer learning agent encourages students take initiative ksc-pal: peer learning agent encourages students take initiative ksc-pal: peer learning agent encourages students take initiative 
consider learning information extraction methods especially extracting instances noun categories athlete team relations playsforteam athlete team semisupervised approaches using small number labeled examples together many unlabeled examples often unreliable frequently produce internally consistent nevertheless incorrect set extractions propose problem overcome simultaneously learning classifiers many different categories relations presence ontology defining constraints couple training classifiers experimental results show simultaneously learning coupled collection classifiers categories relations results much accurate extractions training classifiers individually coupling semi-supervised learning categories relations coupling semi-supervised learning categories relations coupling semi-supervised learning categories relations 
present simple learning algorithm named entity recognition ner using conditional random fields crfs algorithm based exploiting evidence independent features used classifier provides labels unlabeled data independent evidence used automatically extract highaccuracy data leading much improved classifier next iteration show algorithm achieves average improvement recall precision compared supervised algorithm also show algorithm achieves high accuracy training test sets different domains simple semi-supervised algorithm named entity recognition simple semi-supervised algorithm named entity recognition simple semi-supervised algorithm named entity recognition 
key concern building machine translation systems improve coverage incorporating traditional smt phrase pairs correspond syntactic constituents time desirable include much syntactic information system possible order carry linguistically motivated reordering example apply extended modified version approach tinsley et al extracting phrase pairs large parallel parsed corpus combining pbsmt phrases performing joint decoding mt framework without loss translation quality effectively addresses low coverage purely syntactic mt without discarding syntactic information show potential improved translation results inclusion syntactic grammar also introduce new syntaxprioritized technique combining syntactic phrases reduces overall phrase table size decoding time minimal drop automatic translation metric scores decoding syntactic non-syntactic phrases syntax-based machine translation system decoding syntactic non-syntactic phrases syntax-based machine translation system decoding syntactic non-syntactic phrases syntax-based machine translation system 
alignment problem synchronous grammars unrestricted form whether grammar string pair grammar induces alignment two strings reduces universal recognition problem restrictions may imposed alignment sought alignments may sorted complexities restricted alignment problems two different synchronous grammar formalisms machine translation inversion transduction grammars itgs wu restricted form range concatenation grammars gaard investigated universal recognition problems therefore also unrestricted alignment problems formalisms solved time complexities restricted alignment problems differ significantly however complexity alignment problems two synchronous grammar formalisms complexity alignment problems two synchronous grammar formalisms complexity alignment problems two synchronous grammar formalisms 
paper start existing idea taking reordering rules automatically derived syntactic representations applying preprocessing step translation make source sentence structurally like target propose new approach hierarchically extracting rules evaluate combined decoding show improvements distortion models coupling hierarchical word reordering decoding phrase-based statistical machine translation coupling hierarchical word reordering decoding phrase-based statistical machine translation coupling hierarchical word reordering decoding phrase-based statistical machine translation 
refine frequent sense baseline word sense disambiguation using number novel word sense disambiguation techniques evaluating english words task combined system focuses improving every stage word sense disambiguation starting lemmatization part speech tags used accuracy frequent sense baseline highly targeted individual systems supervised systems include ranking algorithm wikipedia similarity measure refining frequent sense baseline refining frequent sense baseline refining frequent sense baseline 
paper describe shared task linking events participants discourse task variant classical semantic role labelling task novel aspect focus linking local semantic argument structures across sentence boundaries specifically task aims linking locally uninstantiated roles coreferents wider discourse context exist task potentially beneficial number nlp applications hope attract researchers semantic role labelling community also resolution information extraction semeval-2010 task 10: linking events participants discourse semeval-2010 task 10: linking events participants discourse semeval-2010 task 10: linking events participants discourse 
novel variant traditional lexicalized tree adjoining grammar ltag introduced shen treebank shen et al combines elementary trees extracted penn treebank propbank annotation paper present semantic role labeling srl system based new resource provide experimental comparison ccgbank srl system based treebank trees deep linguistic information predicateargument relationships either implicit absent original penn treebank made explicit accessible treebank show useful resource semantic role labeling exploration ltag-spinal formalism treebank semantic role labeling exploration ltag-spinal formalism treebank semantic role labeling exploration ltag-spinal formalism treebank semantic role labeling 
grammar extraction deep formalisms received remarkable attention recent years recognise value try create grammar core grammar learning lexical types lexical items treebank study performed focused german used tiger treebank resource completely grammar framework hpsg forms inspiration core grammar also frame reference evaluation construction german hpsg grammar detailed treebank construction german hpsg grammar detailed treebank construction german hpsg grammar detailed treebank 
introduce content selection method opinion summarization based formal mathematical model clustering problem facility location theory method replaces series local myopic steps content selection global solution designed allow content realization decisions naturally integrated evaluate compare method existing method content selection using human selections gold standard find algorithms perform similarly suggesting content selection method robust enough support integration aspects summarization optimization-based content selection opinion summarization optimization-based content selection opinion summarization optimization-based content selection opinion summarization 
evaluation automatic summaries necessary employ multiple topics models order assessment stable reliable however providing multiple topics models costly paper examines relation number available models topics correlations human judgment obtained automatic metrics rouge well manual pyramid method testing methods data set taken tac summarization track allows us compare contrast methods different conditions evaluation automatic summaries: metrics varying data conditions evaluation automatic summaries: metrics varying data conditions evaluation automatic summaries: metrics varying data conditions 
paper presents experiments combine datadriven parser show conversion lfg output dependency representation allows technique parser stacking whereby output parser supplies features dependency parser evaluate english german show significant improvements stemming proposed dependency structure well various deep linguistic features derived respective grammars improving data-driven dependency parsing using large-scale lfg grammars improving data-driven dependency parsing using large-scale lfg grammars improving data-driven dependency parsing using large-scale lfg grammars 
confidence estimation machine translation nicola ueffing rwth aachen university hermann ney rwth aachen university article introduces evaluates several different confidence measures machine translation measures provide method labeling word automatically generated translation correct incorrect approaches confidence estimation presented based word posterior probabilities different concepts word posterior probabilities well different ways calculating introduced compared divided two categories methods explore knowledge provided translation system generated translations direct methods independent translation system techniques make use system output word graphs lists word posterior probability determined summing probabilities sentences translation hypothesis space contains target word direct confidence measures take knowledge sources word phrase lexica account applied output nonstatistical machine translation systems well experimental assessment different confidence measures various translation tasks several language pairs presented moreover application confidence measures rescoring translation hypotheses investigated word-level confidence estimation machine translation word-level confidence estimation machine translation word-level confidence estimation machine translation 
construction semantic space models sebastian pad saarland university mirella lapata university edinburgh traditionally semantic space models use word counts large corpora represent lexical meaning article present novel framework constructing semantic spaces takes syntactic relations account introduce formalization class models allows linguistic knowledge guide construction process evaluate framework range tasks relevant cognitive science natural language processing semantic priming synonymy detection word sense disambiguation cases framework obtains results comparable superior state art dependency-based construction semantic space models dependency-based construction semantic space models dependency-based construction semantic space models 
sketch algorithm estimating associations ping li stanford university kenneth church microsoft corporation look entire corpus web know two words strongly associated one often obtain estimates associations small sample develop algorithm constructs contingency table sample one estimate contingency table entire population using straightforward scaling however one better taking advantage margins also known document frequencies proposed method cuts errors roughly half broder sketches sketch algorithm estimating two-way multi-way associations sketch algorithm estimating two-way multi-way associations sketch algorithm estimating two-way multi-way associations 
paper evaluate five distinct systems labelled grammatical dependency kind input require semantic interpretation particular deep semantic interpreter underlying tutorial dialogue system focus following linguistic phenomena passive control raising noun modifiers meaningful vs prepositions conclude one system provides features require although feature contained within least one competing systems &lsquo;deep' grammatical relations semantic interpretation &lsquo;deep' grammatical relations semantic interpretation &lsquo;deep' grammatical relations semantic interpretation 
summarization systems usually take input output automatic speech recognition asr system affected issues like speech recognition errors disfluencies difficulties accurate identification sentence boundaries propose inclusion related solid background information cope difficulties summarizing spoken language use summarization techniques single document summarization work explore possibilities offered phonetic information select background information conduct perceptual evaluation better assess relevance inclusion information results show summaries generated using approach considerably better produced latent semantic analysis lsa summarization method suggest humans prefer summaries restricted information conveyed input source mixed-source multi-document speech-to-text summarization mixed-source multi-document speech-to-text summarization mixed-source multi-document speech-to-text summarization 
concept classifier used translation unit translation systems however sparsity training data bottle neck effectiveness new method based using statistical machine translation system introduced mitigate effects data sparsity training classifiers also effects background model necessary compensate problem investigated experimental evaluation context crosslingual interaction application show superiority proposed method mitigation data sparsity classifier-based translation mitigation data sparsity classifier-based translation mitigation data sparsity classifier-based translation 
paper present method greatly reducing parse times lfg parsing time maintaining parse accuracy evaluate methodology data english german norwegian show patterns hold across languages achieve speedup english data german data small amount data norwegian achieve speedup although training data expect figure increase speeding lfg parsing using c-structure pruning speeding lfg parsing using c-structure pruning speeding lfg parsing using c-structure pruning 
corpora various corpus query tools long recognized essential language resources value word association norms language resources largely overlooked paper conducts initial comparisons lexical relationships observed within japanese collocation data extracted large corpus using japanese language version sketch engine ske tool srdanovi et al relationships found within japanese word association sets taken japanese word association database jwad ongoing construction joyce comparison results indicate relationships common linguistic resources many lexical relationships observed one resource findings suggest resources necessary order adequately cover diverse range lexical relationships finally paper reflects briefly implementation strategies electronic dictionaries proposed zock bilac zock comparing lexical relationships observed within japanese collocation data japanese word association norms comparing lexical relationships observed within japanese collocation data japanese word association norms comparing lexical relationships observed within japanese collocation data japanese word association norms 
shown behaviour test observed association simulated statistically basis common occurrences words large text corpora thereby law association well known learning theory particular focus work prediction word associations obtained subjects presentation multiword stimuli results presented diverse crossword puzzle identification word based texts computation associative responses multiword stimuli computation associative responses multiword stimuli computation associative responses multiword stimuli 
paper presents method semantic classi cation onomatopoetic words like hum clip clop exist every language especially japanese rich onomatopoetic words used clustering algorithm called newman clustering algorithm calculates simple quality function test whether particular division meaningful quality function calculated based weights edges nodes combined two different similarity measures distributional similarity orthographic similarity calculate weights results obtained using web data showed improvement baseline single distributional similarity measure graph-based clustering semantic classification onomatopoetic words graph-based clustering semantic classification onomatopoetic words graph-based clustering semantic classification onomatopoetic words 
several language processing tasks inherently represented weighted graph weights interpreted measure relatedness two vertices measuring similarity arbitary pairs vertices essential solving several language processing problems datasets random walk based measures perform better path based measures like evaluate several random walk measures propose new measure based commute time use psuedo inverse laplacian derive estimates commute times graphs show pseudo inverse based measure could improved discarding least significant eigenvectors corresponding noise graph construction process using singular value decomposition affinity measures based graph laplacian affinity measures based graph laplacian affinity measures based graph laplacian 
one main problems research automatic summarization inaccurate semantic interpretation source using specific domain knowledge considerably alleviate problem paper introduce extractive method summarization based mapping text concepts representing document sentences graphs applied approach summarize biomedical literature taking advantages free resources umls preliminary empirical results presented pending problems identified concept-graph based biomedical automatic summarization using ontologies concept-graph based biomedical automatic summarization using ontologies concept-graph based biomedical automatic summarization using ontologies 
paper report experiments explore learning syntactic semantic representations first extend statistical parser produce richly annotated tree identifies labels nodes semantic role labels well syntactic labels secondly explore learning techniques extract structures enriched output learning method competitive previous proposals semantic role labelling yields best reported precision produces rich output combination high recall systems yields semantic parsing high-precision semantic role labelling semantic parsing high-precision semantic role labelling semantic parsing high-precision semantic role labelling 
article investigates effect set linguistically motivated features argument disambiguation dependency parsing swedish present results experiments gold standard features animacy definiteness finiteness well corresponding experiments features acquired automatically show significant improvements overall parse results analysis specific argument relations subjects objects predicatives linguistic features data-driven dependency parsing linguistic features data-driven dependency parsing linguistic features data-driven dependency parsing 
though smt achieved high translation quality still lacks generalization ability capture word order differences languages paper describe general method phrasebased smt study syntactic transformation incorporated smt effectiveness design syntactic transformation models using unlexicalized form synchronous grammars models learned sourceparsed bitext system naturally make use constituent phrasal translations decoding phase considered various levels syntactic analysis ranging chunking full parsing experimental results translation showed significant improvement two baseline smt systems tree-to-string phrase-based model statistical machine translation tree-to-string phrase-based model statistical machine translation tree-to-string phrase-based model statistical machine translation 
conference computational natural language learning accompanied every year shared task whose purpose promote natural language processing applications evaluate standard setting shared task dedicated joint parsing syntactic semantic dependencies shared task unifies shared tasks previous four years unique formalism also extends significantly year syntactic dependencies include information boundaries semantic dependencies model roles verbal nominal predicates paper define shared task describe data sets created furthermore report analyze results describe approaches participating systems conll 2008 shared task joint parsing syntactic semantic dependencies conll 2008 shared task joint parsing syntactic semantic dependencies conll 2008 shared task joint parsing syntactic semantic dependencies 
paper presents contribution closed track conll shared task surdeanu et al tackle problem joint syntactic semantic analysis system relies syntactic semantic subcomponent syntactic model projective parser using transformations semantic model uses global inference mechanisms top pipeline classifiers complete syntactic semantic output selected candidate pool generated subsystems system achieved top score closed challenge labeled syntactic accuracy labeled semantic labeled macro dependency-based syntactic&#x2013;semantic analysis propbank nombank dependency-based syntactic&#x2013;semantic analysis propbank nombank dependency-based syntactic&#x2013;semantic analysis propbank nombank 
maximum entropy model based system discriminative learning syntactic semantic dependencies submitted shared task surdeanu et al presented paper system converts dependency learning task classification issues reconstructs dependent relations based classification results finally scores obtained syntactic dependencies semantic dependencies whole system respectively closed challenge open challenge corresponding scores discriminative learning syntactic semantic dependencies discriminative learning syntactic semantic dependencies discriminative learning syntactic semantic dependencies 
paper describes two algorithms developed conll shared task joint learning syntactic semantic dependencies algorithms start parsing sentence using syntactic parser first algorithm uses machine learning methods identify semantic dependencies four stages identification labeling predicates identification labeling arguments second algorithm uses generative probabilistic model choosing semantic dependencies maximize probability respect model hybrid algorithm combining best stages two algorithms attains labeled syntactic attachment accuracy labeled semantic dependency labeled macro score combined wsj brown test sets discriminative vs. generative approaches semantic role labeling discriminative vs. generative approaches semantic role labeling discriminative vs. generative approaches semantic role labeling 
paper proposes dependency treebased srl system proper pruning extensive feature engineering official evaluation conll shared task shows system achieves labeled macro overall task labeled attachment score syntactic dependencies labeled semantic dependencies combined test set using standalone maltparser besides paper also presents unofficial system applying new effective pruning algorithm including additional features adopting better dependency parser mstparser unofficial evaluation shared task shows system achieves labeled macro labeled attachment score labeled using mstparser combined test set suggests proper pruning extensive feature engineering contributes much dependency srl dependency tree-based srl proper pruning extensive feature engineering dependency tree-based srl proper pruning extensive feature engineering dependency tree-based srl proper pruning extensive feature engineering 
fall introduced new course called applied natural language processing students acquire understanding text analysis techniques currently feasible practical applications class intended interdisciplinary students somewhat technical background paper describes topics covered programming exercises emphasizing aspects successful problematic makes recommendations future versions course teaching applied natural language processing: triumphs tribulations teaching applied natural language processing: triumphs tribulations teaching applied natural language processing: triumphs tribulations 
one big challenges understanding text constructing overall coherent representation text much information needed representation unstated implicit thus order fill gaps create overall representation language processing systems need large amount world knowledge creating knowledge resources remains fundamental challenge current work seeking augment wordnet knowledge resource language understanding several ways adding formal versions word sense definitions glosses classifying morphosemantic links nouns verbs encoding small number core theories wordnet commonly used terms adding simple representations scripts although still work progress describe experiences far hope significantly improved resource deep understanding language clark fellbaum hobbs harrison murray thompson augmenting wordnet deep understanding text augmenting wordnet deep understanding text augmenting wordnet deep understanding text 
recent work automatically predicting predominant sense word proven promising mccarthy et al applied first sense heuristic word sense disambiguation wsd tasks without needing expensive data sets due big skew sense distribution many words yarowsky florian first sense heuristic wsd often hard beat however local context ambiguous word give important clues senses intended sense ranking method proposed mccarthy et al uses distributional similarity thesaurus nearest neighbours thesaurus used establish predominant sense word paper report first investigation use grammatical relations target word involved order select subset neighbours automatically created thesaurus take local context account unsupervised method quantitatively evaluated semcor found slight improvement precision using predicted first sense finally discuss strengths weaknesses method suggest ways improve results future koeling mccarthy predicting predominant senses local context word sense disambiguation predicting predominant senses local context word sense disambiguation predicting predominant senses local context word sense disambiguation 
information graphics bar charts line graphs play important role multimodal documents paper presents novel approach producing brief textual summary simple bar chart outlines approach augmenting core message graphic produce brief summary method simultaneously constructs discourse sentence structures textual summary using approach result realized natural language evaluation study validates generation methodology generating textual summaries bar charts generating textual summaries bar charts generating textual summaries bar charts 
present novel unsupervised method sentence compression relies dependency tree representation shortens sentences removing subtrees automatic evaluation shows method obtains result comparable superior state art demonstrate choice parser affects performance system also apply method german report results evaluation humans dependency tree based sentence compression dependency tree based sentence compression dependency tree based sentence compression 
evaluating generation system corpus target outputs available common simple strategy compare system output corpus contents however metrics test whether system makes exactly choices corpus item recently shown correlate well human judgements quality alternative evaluation strategy compute intrinsic properties generated output requires metrics often produce better assessment output paper range metrics using techniques used evaluate three methods selecting facial displays embodied conversational agent predictions metrics compared human judgements generated output metrics show relationship human judgements intrinsic metrics capture number variety facial displays show significant correlation preferences human users automated metrics agree human judgements generated output embodied conversational agent automated metrics agree human judgements generated output embodied conversational agent automated metrics agree human judgements generated output embodied conversational agent 
tuna challenge set three shared tasks reg used data tuna corpus three tasks covered attribute selection referring expressions realisation referring expression generation tunareg teams submitted total systems three tasks additional submission open track evaluation used range automatically computed measures addition evaluation experiment carried using peer outputs tunareg task report describes task evaluation methods used presents evaluation results tuna challenge 2008: overview evaluation results tuna challenge 2008: overview evaluation results tuna challenge 2008: overview evaluation results 
design new based word association measure incorporating concept significant cooccurrence popular word association measure pointwise mutual information pmi extensive experiments large number publicly available datasets show newly introduced measure performs better based measures despite compares well best known distributional similarity knowledge based word association measures investigate source performance improvement find two types significant concept corpus level significance combined use document counts place word counts responsible performance gains observed concept document level significance helpful pmi adaptation improving pointwise mutual information (pmi) incorporating significant co-occurrence improving pointwise mutual information (pmi) incorporating significant co-occurrence improving pointwise mutual information (pmi) incorporating significant co-occurrence 
paper presents chinese lexical analysis systems developed natural language processing laboratory dalian university technology evaluated th international chinese language processing bakeoff hmm crf hybrid model combines model model directed graph adopted system developing closed open tracks regarding chinese word segmentation pos tagging chinese named entity recognition involved systems evaluation good performance achieved especially open track chinese word segmentation sxu system ranks st hmm crf based hybrid model chinese lexical analysis hmm crf based hybrid model chinese lexical analysis hmm crf based hybrid model chinese lexical analysis 
nrc portage system participated translation tasks acl wmt evaluation notable improvement earlier versions portage efficient implementation lattice mert portage typically performed well chinese english mt evaluations recently nist evaluation participation wmt revealed interesting differences translation alerted us certain weak spots system paper discusses problems found system ways fixing learned several lessons think general interest lessons nrc&rsquo;s portage system wmt 2010 lessons nrc&rsquo;s portage system wmt 2010 lessons nrc&rsquo;s portage system wmt 2010 
fourth sighan bakeoff took part closed tracks word segmentation part speech pos tagging named entity recognition ner tasks particularly evaluated word segmentation model corpora namely academia sinica ckip city university hong kong cityu university colorado ctb state language commission ncc shanxi university sxu pos tagging ner tasks models evaluated cityu corpus models evaulation based maximum entropy approach concentrated word segmentation task bakeoff best official results corpora task cityu ckip ctb ncc sxu chinese tagging based maximum entropy model chinese tagging based maximum entropy model chinese tagging based maximum entropy model 
previous incremental parsers used monotonic state transitions however transitions made revise previous decisions quite naturally based information show simple adjustment transition system relax monotonicity constraints improve accuracy long training data includes examples mistakes nonmonotonic transitions repair evaluate change context system obtain statistically significant improvement english evaluation conll languages non-monotonic arc-eager transition system dependency parsing non-monotonic arc-eager transition system dependency parsing non-monotonic arc-eager transition system dependency parsing 
describe experiments hierarchical machine translation wmt shared task provide detailed description configuration data results replicable translation experiment several datasets various sizes various preprocessing sequences translation directions present baseline results hierarchical phrase-based mt charles university wmt 2010 shared task hierarchical phrase-based mt charles university wmt 2010 shared task hierarchical phrase-based mt charles university wmt 2010 shared task 
taxonomies important resource variety natural language processing nlp applications despite current methods taxonomy learning disregarded word polysemy effect developing taxonomies conflate word senses paper present unsupervised method builds taxonomy senses learned automatically unlabelled corpus evaluation two taxonomies shows learned taxonomies capture higher number correct taxonomic relations compared produced traditional distributional similarity approaches merge senses grouping features word single vector taxonomy learning using word sense induction taxonomy learning using word sense induction taxonomy learning using word sense induction 
paper introduces novel task topic coherence evaluation whereby set words generated topic model rated coherence interpretability apply range topic scoring models evaluation task drawing wordnet wikipedia google search engine existing research lexical similarity relatedness comparison human scores set learned topics two distinct datasets show simple measure based pointwise mutual information wikipedia data able achieve results task nearing level correlation lexical relatedness methods also achieve strong results google produces strong less consistent results results wordnet patchy best automatic evaluation topic coherence automatic evaluation topic coherence automatic evaluation topic coherence 
current models lexical semantics create single prototype vector represent meaning word however due lexical ambiguity encoding word meaning single vector problematic paper presents method uses clustering produce multiple vectors word approach provides vector representation word meaning naturally accommodates homonymy polysemy experimental comparisons human judgements semantic similarity isolated words well words sentential contexts demonstrate superiority approach prototype exemplar based models multi-prototype vector-space models word meaning multi-prototype vector-space models word meaning multi-prototype vector-space models word meaning 
constrained decoding great importance speed also translation quality previous efforts explore soft syntactic constraints based constituent boundaries deduced parse trees source language present new framework establish soft constraints based natural alternative translation boundary rather constituent boundary propose simple classifiers learn translation boundaries source sentences classifiers trained directly corpus without using additional resources report accuracy translation boundary classifiers show using constraints based translation boundaries predicted classifiers achieves significant improvements baseline translation experiments new constraints also significantly outperform constituent boundary based syntactic constrains learning translation boundaries phrase-based decoding learning translation boundaries phrase-based decoding learning translation boundaries phrase-based decoding 
paper describes efficient sampler synchronous grammar induction nonparametric bayesian prior inspired ideas slice sampling sampler able draw samples posterior distributions models standard dynamic programing based sampler proves intractable corpora compare sampler previously proposed gibbs sampler demonstrate strong improvements terms training performance translation evaluation inducing synchronous grammars slice sampling inducing synchronous grammars slice sampling inducing synchronous grammars slice sampling 
semantic role labeling srl needs lexical syntactic information also needs word sense information however lack corpus annotated word senses semantic roles research using word sense srl release ontonotes provides opportunity us study use word sense srl paper present novel word sense features srl find improve performance significantly improving semantic role labeling word sense improving semantic role labeling word sense improving semantic role labeling word sense 
paper presents extended version meteor metric designed high correlation postediting measures machine translation quality describe changes made metric sentence aligner scoring scheme well method tuning metric parameters optimize correlation humantargeted translation edit rate hter show improves correlation hter baseline metrics including earlier versions meteor approaches correlation level metric terp extending meteor machine translation evaluation metric phrase level extending meteor machine translation evaluation metric phrase level extending meteor machine translation evaluation metric phrase level 
describe synchronous parsing algorithm based two successive monolingual parses input sentence pair although complexity algorithm must binary scfgs far better demonstrate number common synchronous parsing problems algorithm substantially outperforms alternative synchronous parsing strategies making efficient enough utilized without resorting pruned search two monolingual parses better one (synchronous parse) two monolingual parses better one (synchronous parse) two monolingual parses better one (synchronous parse) 
investigate methods generating additional bilingual phrase pairs phrasebased decoder translating short sequences source text translation task constrained use model employs linguistically rich features traditional decoder implemented example approach experimental results suggest phrase pairs produced method useful decoder lead improved sentence translations improving phrase-based translation prototypes short phrases improving phrase-based translation prototypes short phrases improving phrase-based translation prototypes short phrases 
paper examine different linguistic features sentimental polarity classification perform comparative study task blog review data found results blog much worse reviews investigated two methods improve performance blogs first explored information retrieval based topic analysis extract relevant sentences given topics polarity classification second adopted adaptive method train classifiers review data incorporate hypothesis features methods yielded performance gain polarity classification blog data improving blog polarity classification via topic analysis adaptive methods improving blog polarity classification via topic analysis adaptive methods improving blog polarity classification via topic analysis adaptive methods 
class linear inversion transduction grammars litgs introduced used induce word alignment parallel corpus show alignment via stochastic bracketing litgs considerably faster stochastic bracketing itgs still yielding alignments superior widelyused heuristic intersecting bidirectional ibm alignments performance measured translation quality machine translation system built upon word alignments improvement bleu points baseline noted french english word alignment stochastic bracketing linear inversion transduction grammar word alignment stochastic bracketing linear inversion transduction grammar word alignment stochastic bracketing linear inversion transduction grammar 
field machine translation automatic metrics proven quite valuable system development tracking progress measuring impact incremental changes however human judgment still plays large role context evaluating mt systems example gale project uses humantargeted translation edit rate hter wherein mt output scored version opposed scored existing human reference poses problem mt researchers since hter easy metric calculate would require hiring training human annotators perform editing task work explore soliciting edits untrained human annotators via online service amazon mechanical turk show collected data allows us predict documents significantly higher level ranking obtained using automatic metrics predicting human-targeted translation edit rate via untrained human annotators predicting human-targeted translation edit rate via untrained human annotators predicting human-targeted translation edit rate via untrained human annotators 
paper investigates impact misspelled words statistical machine translation proposes extension translation engine handling misspellings enhanced system decodes confusion network representing spelling variations input text present extensive experimental results two translation tasks increasing complexity show misspellings different types affect performance statistical machine translation decoder extent enhanced system able recover errors statistical machine translation texts misspelled words statistical machine translation texts misspelled words statistical machine translation texts misspelled words 
carried study monolingual translators knowledge source language aided display translation options using standard test data current statistical machine translation systems monolingual translators able translate arabic chinese sentences correctly average participants coming close professional bilingual performance documents machine translation systems advanced greatly last decade nobody seriously expects performance time soon except constraint settings todays systems good enough enable monolingual speakers target language without knowledge source language generate correct translations type assistance machine translation helpful translators carried study involved monolingual translators knowledge chinese arabic translate documents nist test sets assisted statistical machine translation systems trained data created gale research program study shows monolingual translators able translate arabic chinese sentences strict standard correctness scored professional bilingual translations correct arabic chinese respectively found also large variability among participants documents http www itl nist gov iad mig tests mt http www darpa mil ipto programs gale gale asp study indicating importance general language skills domain knowledge results suggest skilled monolingual translator compete bilingual translator using todays machine translation systems related work use human translators combination machine translation old emergence first effective machine translation systems typically takes form human translator postediting machine translation output rarely human translator guiding decisions machine translation system recent examples using postediting machine translation tools translation tools google translator toolkit galvez bhansali enabling monolingual translators: post-editing vs. options enabling monolingual translators: post-editing vs. options enabling monolingual translators: post-editing vs. options 
translation systems generally trained optimize bleu many alternative metrics available explore optimizing toward various automatic evaluation metrics bleu meteor nist ter affects resulting model train mt system using mert many parameterizations metric evaluate resulting models metrics also using human judges accordance popular wisdom find important train metric used testing however also find training newer metric useful extent mt model structure features allow take advantage metric contrasting ter good correlation human judgments show people tend prefer bleu nist trained models trained edit distance based metrics like ter wer human preferences meteor trained models varies depending source language since using bleu nist produces models robust evaluation metrics perform well human judgments conclude still best choice training best lexical metric phrase-based statistical mt system optimization best lexical metric phrase-based statistical mt system optimization best lexical metric phrase-based statistical mt system optimization 
existing algorithms learning latentvariable models em existing gibbs samplers meaning update variables associated one sentence time incremental nature methods makes susceptible local optima slow mixing paper introduce sampler updates block variables identified type spans multiple sentences show improvements induction word segmentation learning grammars type-based mcmc type-based mcmc type-based mcmc 
paper describes use phrasebased statistical machine translation pbsmt automatic correction errors learner text submission conll shared task grammatical error correction since limited training data provided task insufficient training effective smt system also explored alternative ways generating pairs incorrect correct sentences automatically existing learner corpora approach yield particularly high performance reveals many problems require careful attention building smt systems error correction constrained grammatical error correction using statistical machine translation constrained grammatical error correction using statistical machine translation constrained grammatical error correction using statistical machine translation 
stochastic inversion transduction grammars constitute powerful formalism machine translation efficient dynamic programming parsing algorithm exists work review parsing algorithm propose important modifications enlarge search space modifications allow parsing algorithm search better solutions enlarged search space sitg parsing enlarged search space sitg parsing enlarged search space sitg parsing 
paper describes data driven dependency parsing approach uses clausal information sentence improve parser performance clausal information added automatically parsing process demonstrate experiments hindi language relatively rich case marking system experiments done using modified version mstparser experiments icon parsing contest data achieved improvement unlabeled attachment labeled attachment accuracies respectively baseline parsing accuracies improving data driven dependency parsing using clausal information improving data driven dependency parsing using clausal information improving data driven dependency parsing using clausal information 
recent work proposed use extracted tree grammar basis treebank analysis search queries queries stated elementary trees small chunks syntactic structure however work lacking two crucial ways first allow including lexical properties tokens search second allow using derivation tree search describing elementary trees connected together work describe implementation overcomes problems treebank query system based extracted tree grammar treebank query system based extracted tree grammar treebank query system based extracted tree grammar 
brown berkeley parsers two generative parsers since parsers produce lists possible apply reranking techniques output parsers union note standard reranker feature set distributed brown parser well berkeley parser propose extended set better ablation experiment shows different parsers benefit different reranker features reranking berkeley brown parsers reranking berkeley brown parsers reranking berkeley brown parsers 
describe method incorporating taskspecific cost functions standard conditional cll training linear structured prediction models recently introduced speech recognition community describe method generally structured models highlight connections cll learning structured prediction taskar et al show method optimizes bound risk approach simple efficient easy implement requiring little change existing cll implementation present experimental results comparing several methods training structured predictors recognition softmax-margin crfs: training log-linear models cost functions softmax-margin crfs: training log-linear models cost functions softmax-margin crfs: training log-linear models cost functions 
present novel deterministic dependency parsing algorithm attempts create easiest arcs dependency structure first manner traditional deterministic parsing algorithms based framework traverse sentence step perform one possible set actions complete tree built drawback approach extremely local decisions based complex structures left look words right contrast algorithm builds dependency tree iteratively selecting best pair neighbours connect parsing step allows incorporation features already built structures left right attachment point parser learns attachment preferences order performed result deterministic nlogn parser significantly accurate transition based parsers nears performance globally optimized parsing models efficient algorithm easy-first non-directional dependency parsing efficient algorithm easy-first non-directional dependency parsing efficient algorithm easy-first non-directional dependency parsing 
present three approaches unsupervised grammar induction sensitive data complexity apply klein manning dependency model valence first baby steps bootstraps via iterated learning increasingly longer sentences requires initialization method substantially exceeds klein manning published scores achieves accuracy section sentences wall street journal corpus second less uses subset available data sentences length focusing fewer simpler examples trades quantity ambiguity attains accuracy using standard linguisticallyinformed prior batch training beating leapfrog third heuristic combines less baby steps mixing models shorter sentences rapidly ramping exposure full training set driving accuracy trends generalize brown corpus awareness data complexity may improve parsing models unsupervised algorithms baby steps leapfrog: &#x201c;less more&#x201d; unsupervised dependency parsing baby steps leapfrog: &#x201c;less more&#x201d; unsupervised dependency parsing baby steps leapfrog: &#x201c;less more&#x201d; unsupervised dependency parsing 
recently relaxation approaches successfully used map inference nlp problems work show extend relaxation approach marginal inference used conditional likelihood training posterior decoding confidence estimation tasks evaluate approach case dependency parsing observe tenfold increase parsing speed loss accuracy performing inference small subset full factor graph also contribute bound error marginal probabilities respect full graph finally evaluated bp paper approach general enough applied marginal inference method inner loop relaxed marginal inference application dependency parsing relaxed marginal inference application dependency parsing relaxed marginal inference application dependency parsing 
paper present dependency treebased method sentiment classification japanese english subjective sentences using conditional random fields hidden variables subjective sentences often contain words reverse sentiment polarities words therefore interactions words need considered sentiment classification difficult handled simple approaches syntactic dependency structures subjective sentences exploited method method sentiment polarity dependency subtree sentence observable training data represented hidden variable polarity whole sentence calculated consideration interactions hidden variables belief propagation used inference experimental results sentiment classification japanese english subjective sentences showed method performs better methods based dependency tree-based sentiment classification using crfs hidden variables dependency tree-based sentiment classification using crfs hidden variables dependency tree-based sentiment classification using crfs hidden variables 
paper presents direct word reordering model novel features statistical machine translation reordering models address problem reordering source language word order target language ibm models reordering components use surface word information little context information determine traversal order source sentence since late machine translation solves much local reorderings using phrasal translations problem longdistance reordering become central research topic modeling distortions present syntax driven maximum entropy reordering model directly predicts source traversal order able model arbitrarily long distance word movement show model significantly improves machine translation quality direct syntax-driven reordering model phrase-based machine translation direct syntax-driven reordering model phrase-based machine translation direct syntax-driven reordering model phrase-based machine translation 
distortion cost function used mosesstyle machine translation systems two flaws first estimate future cost known required moves thus increasing search errors second distortion penalized linearly even appropriate reorderings performed cost function effectively constrain search translation quality decreases higher distortion limits often needed translating languages different typologies arabic english address problems introduce method estimating future linear distortion cost new discriminative distortion model predicts word movement translation combination extensions give statistically significant improvement baseline distortion parameterization triple distortion limit model achieves bleu average gain moses improved models distortion cost statistical machine translation improved models distortion cost statistical machine translation improved models distortion cost statistical machine translation 
synchronous tree substitution grammars translation model used machine translation investigated formal setting compared competitor least expressive competitor extended multi tree transducer analogue one essential additional feature model investigated theoretical computer science seems widely unknown natural language processing two models compared respect standard algorithms binarization regular restriction composition application particular attention paid complexity algorithms synchronous tree substitution grammars? synchronous tree substitution grammars? synchronous tree substitution grammars? 
describe method induction selectional preferences resourcepoor languages accurate monolingual models available method uses bilingual vector spaces translate foreign language structures language like english prerequisite constructing bilingual vector space large unparsed corpus language although model profit even noisy syntactic knowledge experiments show predictions correlate well human ratings clearly outperforming monolingual baseline models cross-lingual induction selectional preferences bilingual vector spaces cross-lingual induction selectional preferences bilingual vector spaces cross-lingual induction selectional preferences bilingual vector spaces 
paper presents efficient algorithms expected similarity maximization coincides minimum bayes decoding loss function algorithms designed similarity functions sequence kernels general class positive definite symmetric kernels discuss general algorithm efficient algorithm applicable common unambiguous scenario also describe application algorithms machine translation report results experiments several translation data sets demonstrate substantial particular results show two orders magnitude respect original method tromble et al factor even respect approximate algorithm specifically designed task results open path exploration appropriate optimal kernels specific tasks considered expected sequence similarity maximization expected sequence similarity maximization expected sequence similarity maximization 
principal weakness conventional statistical machine translation exploit continuous phrases paper extend decoding allow source target phrasal discontinuities provide better generalization unseen data yield significant improvements standard system moses interestingly discontinuous phrasebased system also outperforms hierarchical system joshua significant margin bleu average five chineseenglish nist test sets even though joshua system support discontinuous phrases since key difference two systems hierarchical system uses decoder instead cky imposes hard hierarchical reordering constraints training decoding paper sets challenge commonly held belief parameterization systems hiero joshua crucial good performance moses accurate non-hierarchical phrase-based translation accurate non-hierarchical phrase-based translation accurate non-hierarchical phrase-based translation 
machine translation benefits two types decoding techniques consensus decoding multiple hypotheses single model system combination hypotheses different models present model combination method integrates consensus decoding system combination unified technique approach makes assumptions underlying component models enabling us combine systems heterogenous structure unlike system combination techniques reuse search space component models entirely avoids need align translation hypotheses despite relative simplicity model combination improves translation quality pipelined approach first applying consensus decoding individual systems applying system combination output demonstrate bleu improvements across data sets language pairs experiments model combination machine translation model combination machine translation model combination machine translation 
dialogue systems typically follow rigid pace interaction system waits user finished speaking producing response interpreting user utterances completed allows system display sophisticated conversational behavior rapid appropriate use backchannels interruptions demonstrate natural language understanding approach partial utterances use virtual human dialogue system often complete user utterances real time interpretation partial utterances virtual human dialogue systems interpretation partial utterances virtual human dialogue systems interpretation partial utterances virtual human dialogue systems 
progressive summary helps user monitor changes evolving news topics period time detecting novel information essential part progressive summarization differentiates normal multi document summarization work explore possibility detecting novelty various stages summarization new scoring features criterions filtering strategies proposed identify relevant novel information compare techniques using automated evaluation framework rouge determine best overall summarizer able perform par existing prime methods progressive summarization detecting novelty context progressive summarization detecting novelty context progressive summarization detecting novelty context progressive summarization 
distributional models semantics proven useful adequate variety natural language processing tasks however lack least one key requirement order serve adequate representation natural language namely sensitivity structural information word order propose novel approach offers potential integrating word contexts completely unsupervised manner assigning words characteristic distributional matrices proposed model applied task free associations end first results well directions future work discussed towards matrix-based distributional model meaning towards matrix-based distributional model meaning towards matrix-based distributional model meaning 
present algorithms dependency parsing sense evaluate substructures containing three dependencies efficient sense require time importantly new parsers utilize interactions evaluate parsers penn treebank prague dependency treebank achieving unlabeled attachment scores respectively efficient third-order dependency parsers efficient third-order dependency parsers efficient third-order dependency parsers 
paper presents supervised approach identifying generic noun phrases context generic statements express rulelike knowledge kinds events therefore identification important automatic construction knowledge bases particular distinction generic statements crucial correct encoding generic information generic expressions studied extensively formal semantics building work explore learning approach identifying generic nps using selections linguistically motivated features results perform well baseline existing prior work identifying generic noun phrases identifying generic noun phrases identifying generic noun phrases 
present simple yet powerful hierarchical search algorithm automatic word alignment algorithm induces forest alignments efficiently extract ranked list score given alignment within forest flexible linear discriminative model incorporating hundreds features trained relatively small amount annotated data report results word alignment translation tasks model outperforms giza baseline points yielding bleu score increase machine translation system hierarchical search word alignment hierarchical search word alignment hierarchical search word alignment 
paper present babelnet large multilingual semantic network resource automatically constructed means methodology integrates lexicographic encyclopedic knowledge wordnet wikipedia addition machine translation also applied enrich resource lexical information languages conduct experiments new existing datasets show high quality coverage resource babelnet: building large multilingual semantic network babelnet: building large multilingual semantic network babelnet: building large multilingual semantic network 
current semantic role labeling technologies based inductive algorithms trained large scale repositories annotated examples systems currently make use framenet database fail show suitable generalization capabilities scenarios paper system srl extended encapsulation distributional model semantic similarity resulting argument classification model promotes simpler feature space limits potential overfitting effects large scale empirical study discussed confirms accuracy obtained evaluations towards open-domain semantic role labeling towards open-domain semantic role labeling towards open-domain semantic role labeling 
existing word similarity measures robust data sparseness since rely point estimation words context profiles obtained limited amount data paper proposes bayesian method robust distributional word similarities method uses distribution context profiles obtained bayesian estimation takes expectation base similarity measure distribution context profiles multinomial distributions priors dirichlet base measure bhattacharyya coefficient derive analytical form allows efficient calculation task word similarity estimation using large amount web data japanese show proposed measure gives better accuracies similarity measures bayesian method robust estimation distributional similarities bayesian method robust estimation distributional similarities bayesian method robust estimation distributional similarities 
inversion transduction grammar itg regained attention recent years still suffers major obstacle speed propose discriminative itg pruning framework using minimum error rate training various features previous work itg alignment experiment results show superior existing heuristics itg pruning top pruning framework also propose discriminative itg alignment model using hierarchical phrase pairs improves bleu score baseline alignment system giza discriminative pruning discriminative itg alignment discriminative pruning discriminative itg alignment discriminative pruning discriminative itg alignment 
definition combinatory categorial grammar ccg literature varies quite bit author author however differences definitions important terms language classes ccg prove wide range ccgs strongly including ccg ccgbank parser clark curran light new results train pcfg parser petrov klein ccgbank achieve state art results supertagging accuracy parseval measures dependency accuracy accurate context-free parsing combinatory categorial grammar accurate context-free parsing combinatory categorial grammar accurate context-free parsing combinatory categorial grammar 
propose novel method parser uses lexicalised grammar supertagger focusing increasing speed parser rather accuracy idea train supertagger large amounts parser output supertagger learn supply supertags parser eventually choose part highestscoring derivation since supertagger supplies fewer supertags overall parsing speed increased demonstrate effectiveness method using ccg supertagger parser obtaining significant speed increases newspaper text loss accuracy also show method used adapt ccg parser new domains obtaining accuracy speed improvements wikipedia biomedical text faster parsing supertagger adaptation faster parsing supertagger adaptation faster parsing supertagger adaptation 
several attempts made learn phrase translation probabilities phrasebased statistical machine translation go beyond pure counting phrases training data approaches report problems overfitting describe novel approach prevent allows us train phrase models show improved translation performance wmt europarl task contrast previous work phrase models trained separately models used translation include components single word lexica reordering models training using consistent training phrase models able achieve improvements points bleu side effect phrase table size reduced training phrase translation models leaving-one-out training phrase translation models leaving-one-out training phrase translation models leaving-one-out 
viterbi algorithm conventional decoding algorithm widely adopted sequence labeling viterbi decoding however prohibitively slow label set large time complexity quadratic number labels paper proposes exact decoding algorithm overcomes problem novel property algorithm efficiently reduces labels decoded still allowing us check optimality solution experiments three tasks pos tagging joint pos tagging chunking supertagging show new algorithm several orders magnitude faster basic viterbi algorithm carpediem esposito radicioni efficient staggered decoding sequence labeling efficient staggered decoding sequence labeling efficient staggered decoding sequence labeling 
date attempts made develop validate methods automatic evaluation linguistic quality text summarization present first systematic assessment several diverse classes metrics designed capture various aspects text train test linguistic quality models consecutive years nist evaluation data order show generality results grammaticality best results come set syntactic features focus coherence referential clarity best evaluated class features measuring local coherence basis cosine similarity sentences coreference information summarization specific features best results accuracy pairwise comparisons competing systems test set several inputs ranking summaries specific input automatic evaluation linguistic quality multi-document summarization automatic evaluation linguistic quality multi-document summarization automatic evaluation linguistic quality multi-document summarization 
paper present joint content selection compression model summarization model operates representation source document obtain merging information pcfg parse trees dependency graphs using integer linear programming formulation model learns select combine phrases subject length coverage grammar constraints evaluate approach task generating story highlights small number brief sentences allow readers quickly gather information news stories experimental results show model output comparable highlights terms grammaticality content automatic generation story highlights automatic generation story highlights automatic generation story highlights 
observe given named entity ne translated either semantically phonetically depends greatly associated entity type entities within aligned pair share type also initially detected nes anchors whose information used give certainty scores selecting candidates basis integrated model thus proposed paper jointly identify align bilingual named entities chinese english adopts new mapping type ratio feature proportion ne internal tokens semantically translated enforces entity type consistency constraint utilizes additional monolingual candidate certainty factors based ne anchors experiments show novel approach substantially raised identified imperfection reduction ne alignment task jointly recognizing aligning bilingual named entities jointly recognizing aligning bilingual named entities jointly recognizing aligning bilingual named entities 
syntactic knowledge important discourse relation recognition yet heuristically selected flat paths production rules used incorporate information far paper propose using tree kernel based approach automatically mine syntactic information parse trees discourse analysis applying kernel function tree structures directly structural syntactic features together normal flat features incorporated composite kernel capture diverse knowledge simultaneous discourse identification classification explicit implicit relations experiment shows tree kernel approach able give statistical significant improvements flat syntactic path feature also illustrate tree kernel approach covers structure information production rules allows tree kernel incorporate information higher dimension space possible better discrimination besides propose leverage temporal ordering information constrain interpretation discourse relation also demonstrate statistical significant improvements discourse relation recognition pdtb explicit implicit well kernel based discourse relation recognition temporal ordering information kernel based discourse relation recognition temporal ordering information kernel based discourse relation recognition temporal ordering information 
paper present simple effective method address issue generate diversified translation systems single statistical machine translation smt engine system combination method based framework boosting first sequence weak translation systems generated baseline system iterative manner strong translation system built ensemble weak translation systems adapt boosting smt system combination several key components original boosting algorithms redesigned work evaluate method machine translation mt tasks three baseline systems including system hierarchical phrasebased system system experimental results three nist evaluation test sets show method leads significant improvements translation accuracy baseline systems boosting-based system combination machine translation boosting-based system combination machine translation boosting-based system combination machine translation 
scoring sentences documents given abstract summaries created humans important extractive summarization paper formulate extractive summarization two step learning problem building generative model pattern discovery regression model inference calculate scores sentences document clusters based latent characteristics using hierarchical topic model using scores train regression model based lexical structural characteristics sentences use model score sentences new documents form summary system advances current improving rouge scores generated summaries less redundant coherent based upon manual quality evaluations hybrid hierarchical model multi-document summarization hybrid hierarchical model multi-document summarization hybrid hierarchical model multi-document summarization 
paper proposes use monolingual collocations improve statistical machine translation smt make use collocation probabilities estimated monolingual corpora two aspects namely improving word alignment various kinds smt systems improving phrase table smt experimental results show method improves performance word alignment translation quality significantly compared baseline systems achieve absolute improvements bleu score smt system bleu score smt system improving statistical machine translation monolingual collocation improving statistical machine translation monolingual collocation improving statistical machine translation monolingual collocation 
paper systematically assess value using data supervised nlp classifiers compare classifiers include exclude features counts various counts obtained auxiliary corpus show including count features advance accuracy standard data sets adjective ordering spelling correction noun compound bracketing verb disambiguation importantly operating new domains labeled training data plentiful show using features essential achieving robust performance creating robust supervised classifiers via web-scale n-gram data creating robust supervised classifiers via web-scale n-gram data creating robust supervised classifiers via web-scale n-gram data 
paper proposes convolution forest kernel effectively explore rich structured features embedded packed parse forest opposed convolution tree kernel proposed forest kernel commit single best parse tree thus able explore large object spaces much structured features embedded forest makes proposed kernel robust parsing errors data sparseness issues convolution tree kernel paper presents formal definition convolution forest kernel also illustrates computing algorithm fast compute proposed convolution forest kernel experimental results two nlp applications relation extraction semantic role labeling show proposed forest kernel significantly outperforms baseline convolution tree kernel convolution kernel packed parse forest convolution kernel packed parse forest convolution kernel packed parse forest 
strictly piecewise sp languages subclass regular languages encode certain kinds dependencies found natural languages like classes chomsky subregular hierarchies many independently converging characterizations sp class rogers et al appear define sp distributions show efficiently estimated positive data estimating strictly piecewise distributions estimating strictly piecewise distributions estimating strictly piecewise distributions 
propose cmsms novel type generic compositional models syntactic semantic aspects natural language based matrix multiplication argue structural cognitive plausibility model show able cover combine various common compositional nlp approaches ranging statistical word space models symbolic grammar formalisms compositional matrix-space models language compositional matrix-space models language compositional matrix-space models language 
present syntactically enriched vector model supports computation contextualized semantic representations quasi compositional fashion employs systematic combination context vectors apply model two different tasks show substantially outperforms previous work paraphrase ranking task ii achieves promising results wordsense similarity task knowledge first time unsupervised method applied task contextualizing semantic representations using syntactically enriched vector models contextualizing semantic representations using syntactically enriched vector models contextualizing semantic representations using syntactically enriched vector models 
fundamental step sentence comprehension involves assigning semantic roles sentence constituents accomplish listener must parse sentence find constituents candidate arguments assign semantic roles constituents step depends prior lexical syntactic knowledge children learning first languages begin solving problem paper focus parsing argumentidentification steps precede semantic role labeling srl training combine simplified srl unsupervised hmm part speech tagger experiment psycholinguisticallymotivated ways label clusters resulting hmm used parse input srl system results show proposed shallow representations sentence structure robust reductions parsing accuracy contribution alternative representations sentence structure successful semantic role labeling varies integrity parsing argumentidentification stages starting scratch semantic role labeling starting scratch semantic role labeling starting scratch semantic role labeling 
weighted tree transducers proposed useful formal models representing syntactic natural language processing applications little description inference algorithms automata beyond formal foundations give detailed description algorithms application cascades weighted tree transducers weighted tree acceptors connecting formal theory actual practice additionally present novel variants algorithms compare performance syntax machine translation cascade based yamada knight motivation weighted transducers found recent favor models natural language mohri order make actual use systems built formalisms must first calculate set possible weighted outputs allowed transducer given input call forward application set possible weighted inputs given output call backward application application inference result determining highest weighted elements may also want divide problems manageable chunks represented transducer noted woods easier designers write several small transducers performs simple transformation rather painstakingly construct single complicated device would like know result transformation input output cascade transducers one operating see various strategies approaching problem consider offline composition bucket brigade application application application cascades weighted string transducers wsts mohri less recent interest application cascades weighted tree transducers wtts tackle application wtt cascades work presenting explicit algorithms application wtt cascades novel algorithms application wtt cascades experiments comparing performance algorithms strategies string case discuss application wtts helpful recall solution problem wst domain recall efficient inference cascades weighted tree transducers efficient inference cascades weighted tree transducers efficient inference cascades weighted tree transducers 
characterization expressive power synchronous grammars stags terms tree transducers equivalently synchronous tree substitution grammars developed essentially stag corresponds extended tree transducer uses explicit substitution input output characterization allows easy integration stag toolkits extended tree transducers moreover applicability characterization several representational algorithmic problems demonstrated tree transducer model synchronous tree-adjoining grammars tree transducer model synchronous tree-adjoining grammars tree transducer model synchronous tree-adjoining grammars 
incremental parsing techniques gained popularity thanks efficiency remains major problem search greedy explores tiny fraction whole space even beam search opposed dynamic programming show surprisingly dynamic programming fact possible many parsers merging equivalent stacks based feature values empirically algorithm yields speedup dependency parser loss accuracy better search also leads better learning final parser outperforms previously reported dependency parsers english chinese yet much faster dynamic programming linear-time incremental parsing dynamic programming linear-time incremental parsing dynamic programming linear-time incremental parsing 
languages free word order german labelling grammatical functions top constituent analyses crucial making interpretable unfortunately statistical classifiers consider local information function labelling fail capture important restrictions distribution core argument functions subject object etc namely one subject etc per clause augment statistical classifier integer linear program imposing hard linguistic constraints solution space output classifier capturing global distributional restrictions show improves labelling quality particular argument grammatical functions intrinsic evaluation importantly grammar coverage treebankbased grammar acquisition parsing extrinsic evaluation hard constraints grammatical function labelling hard constraints grammatical function labelling hard constraints grammatical function labelling 
present simple accurate parser exploits large tree fragments symbol refinement parse fragments training set contrast much recent work tree selection parsing treesubstitution grammar learning require simple deterministic grammar symbol refinement contrast recent work latent symbol refinement moreover parser requires explicit lexicon machinery instead parsing input sentences character streams despite simplicity parser achieves accuracies standard english wsj task competitive substantially complicated lexicalized parsers additional specific contributions center making implicit parsing efficient including inference scheme new graph encoding simple, accurate parsing all-fragments grammar simple, accurate parsing all-fragments grammar simple, accurate parsing all-fragments grammar 
paper explores joint syntactic semantic parsing chinese improve performance syntactic semantic parsing particular performance semantic parsing paper semantic role labeling done two levels firstly integrated parsing approach proposed integrate semantic parsing syntactic parsing process secondly semantic information generated semantic parsing incorporated syntactic parsing model better capture semantic information syntactic parsing evaluation chinese treebank chinese propbank chinese nombank shows integrated parsing approach outperforms pipeline parsing approach parse trees natural extension widely used pipeline parsing approach parse tree moreover shows incorporating semantic information syntactic parsing model significantly improves performance syntactic parsing semantic parsing best knowledge first research exploring syntactic parsing semantic role labeling verbal nominal predicates integrated way joint syntactic semantic parsing chinese joint syntactic semantic parsing chinese joint syntactic semantic parsing chinese 
previous work chinnakotla et al introduced novel framework feedback prf called multiprf given query one language called source used english assisting language improve performance prf source language mulitiprf showed remarkable improvement plain model based feedback mbf uniformly languages viz french german hungarian finnish english assisting language fact inspired us study effect pair multiprf performance set languages widely different characteristics viz dutch english finnish french german spanish carrying looked effect using two assisting languages together prf present paper report investigations results conclusions drawn therefrom performance improvement multiprf observed whatever assisting language whatever source observations mixed two assisting languages used simultaneously interestingly performance improvement pronounced source assisting languages closely related french spanish multilingual pseudo-relevance feedback: performance study assisting languages multilingual pseudo-relevance feedback: performance study assisting languages multilingual pseudo-relevance feedback: performance study assisting languages 
sentiment analysis approaches use baseline support vector machines svm classifier binary unigram weights paper explore whether sophisticated feature weighting schemes information retrieval enhance classification accuracy show variants classic tf idf scheme adapted sentiment analysis provide significant increases accuracy especially using sublinear function term frequency weights document frequency smoothing techniques tested wide selection data sets produce best accuracy knowledge study information retrieval weighting schemes sentiment analysis study information retrieval weighting schemes sentiment analysis study information retrieval weighting schemes sentiment analysis 
statistical translation models try capture recursive structure language widely adopted last years models make use varying amounts information linguistic theory use none use information grammar target language use information grammar source language progress slower translation models able learn relationship grammars source target language discuss reasons challenge review existing attempts meet challenge show old new ideas combined simple approach uses source target syntax significant improvements translation accuracy learning translate source target syntax learning translate source target syntax learning translate source target syntax 
present discriminative model directly predicts set phrasal translation rules extracted sentence pair model scores extraction sets nested collections overlapping phrase pairs consistent underlying word alignment extraction set models provide two principle advantages alignment models first incorporate features phrase pairs addition word links second optimize loss function relates directly end task generating translations model gives improvements alignment quality relative unsupervised supervised baselines well providing improvement bleu score translation experiments discriminative modeling extraction sets machine translation discriminative modeling extraction sets machine translation discriminative modeling extraction sets machine translation 
learning ssl algorithms successfully used extract pairs large unstructured structured text collections however careful comparison different ssl algorithms task lacking compare three ssl algorithms acquisition variety graphs constructed different domains find recently proposed mad algorithm effective also show extraction significantly improved adding semantic information form edges derived independently developed knowledge base code data made publicly available encourage reproducible research area experiments graph-based semi-supervised learning methods class-instance acquisition experiments graph-based semi-supervised learning methods class-instance acquisition experiments graph-based semi-supervised learning methods class-instance acquisition 
finding class structures rich enough adequate linguistic representation yet restricted enough efficient computational processing important problem dependency parsing paper present transition system dependency trees trees decomposed two planar graphs show used implement parser runs linear time outperforms parser four data sets shared task addition present efficient method determining whether arbitrary tree show trees existing treebanks transition-based parser 2-planar dependency structures transition-based parser 2-planar dependency structures transition-based parser 2-planar dependency structures 
word sense disambiguation remains one complex problems facing computational linguists date paper present system combines evidence monolingual wsd system together multilingual wsd system yield state art performance standard data sets monolingual system based modification graph based state art algorithm multilingual system improvement allwords unsupervised approach salaam salaam exploits multilingual evidence means disambiguation paper present modifications original approaches combination finally report highest results obtained date senseval standard data set using unsupervised method achieve overall measure using voting scheme combining orthogonal monolingual multilingual sources evidence words wsd combining orthogonal monolingual multilingual sources evidence words wsd combining orthogonal monolingual multilingual sources evidence words wsd 
hierarchical smt systems statistical models integrated guide hierarchical rule selection better translation performance previous work mainly focused selection either source side hierarchical rule target side hierarchical rule rather considering simultaneously paper presents joint model predict selection hierarchical rules proposed model estimated based four rich context knowledge source target sides leveraged method easily incorporated practical smt systems model framework experimental results show method yield significant improvements performance joint rule selection model hierarchical phrase-based translation joint rule selection model hierarchical phrase-based translation joint rule selection model hierarchical phrase-based translation 
lexicalized reordering models play crucial role translation systems usually learned bilingual corpus examining reordering relations adjacent phrases instead checking whether one phrase adjacent given phrase argue important take number adjacent phrases account better estimations reordering models propose use structure named reordering graph represents phrase segmentations sentence pair learn lexicalized reordering models efficiently experimental results nist test sets show approach significantly outperforms baseline method learning lexicalized reordering models reordering graphs learning lexicalized reordering models reordering graphs learning lexicalized reordering models reordering graphs 
present novel method improve word alignment quality eventually translation performance producing combining complementary word alignments languages instead focusing improvement single set word alignments generate multiple sets diversified alignments based different motivations linguistic knowledge morphology heuristics demonstrate approach translation task combining alignments obtained syntactic reordering stemming partial words combined alignment outperforms baseline alignment significantly higher better translation performance diversify combine: improving word alignment machine translation low-resource languages diversify combine: improving word alignment machine translation low-resource languages diversify combine: improving word alignment machine translation low-resource languages 
paper proposes method correcting annotation errors treebank using synchronous grammar method transforms parse trees containing annotation errors ones whose errors corrected synchronous grammar automatically induced treebank report experimental result applying method penn treebank result demonstrates method corrects syntactic annotation errors high precision correcting errors treebank based synchronous tree substitution grammar correcting errors treebank based synchronous tree substitution grammar correcting errors treebank based synchronous tree substitution grammar 
one deficiency current shallow parsing based semantic role labeling srl methods syntactic chunks small effectively group words partially resolve problem propose shallow parsing takes account syntactic structures structures also introduce several new path features improve shallow parsing based srl method experiments indicate new method obtains significant improvement best reported chinese srl result semantics-driven shallow parsing chinese semantic role labeling semantics-driven shallow parsing chinese semantic role labeling semantics-driven shallow parsing chinese semantic role labeling 
present novel framework word alignment incorporates synonym knowledge collected monolingual linguistic resources bilingual probabilistic model synonym information helpful word alignment expect synonym correspond word different language design generative model word alignment uses synonym information regularization term experimental results show proposed method significantly improves word alignment quality word alignment synonym regularization word alignment synonym regularization word alignment synonym regularization 
paper presents novel filtration criterion restrict rule extraction hierarchical translation model bilingual relaxed wellformed dependency restriction used filter bad rules furthermore new feature describes regularity source target dependency edge triggers target source word also proposed experimental results show new criteria weeds rules translation performance improvement new feature brings another improvement baseline system especially larger corpus better filtration augmentation hierarchical phrase-based translation rules better filtration augmentation hierarchical phrase-based translation rules better filtration augmentation hierarchical phrase-based translation rules 
nivre method improved enhancing deterministic dependency parsing application model model considers words necessary selection parsing actions including words form trees chooses probable head candidate among trees uses candidate select parsing action evaluation experiment using penn treebank wsj section proposed model achieved higher accuracy previous deterministic models although proposed model time complexity experimental results demonstrated average parsing time much slower tree-based deterministic dependency parsing &#x2014; application nivre&rsquo;s method &#x2014; tree-based deterministic dependency parsing &#x2014; application nivre&rsquo;s method &#x2014; tree-based deterministic dependency parsing &#x2014; application nivre&rsquo;s method &#x2014; 
propose algorithm extracting lists parser algorithm tka variant kbest ka algorithm pauls klein contrast ka performs inside outside pass performing extraction bottom tka performs inside pass extracting lists top tka maintains optimality efficiency guarantees ka simpler specify implement top-down k-best a* parsing top-down k-best a* parsing top-down k-best a* parsing 
attempts train taggers mixture labeled unlabeled data failed work stacked learning used reduce tagging classification task simplifies semisupervised training considerably prefered method combines li zhou wall street journal obtain error reduction svmtool gimenez marquez simple semi-supervised training part-of-speech taggers simple semi-supervised training part-of-speech taggers simple semi-supervised training part-of-speech taggers 
minimum description length mdl principle method model selection trades explanation data model complexity model inspired mdl principle develop objective function generative models captures description data model description model model size also develop efficient general search algorithm based framework optimize function since recent work shown minimizing model size hidden markov model pos tagging leads higher accuracies test approach applying problem search algorithm involves simple change em achieves high pos tagging accuracies english italian data sets efficient optimization mdl-inspired objective function unsupervised part-of-speech tagging efficient optimization mdl-inspired objective function unsupervised part-of-speech tagging efficient optimization mdl-inspired objective function unsupervised part-of-speech tagging 
address problem selecting language model training data build auxiliary language models use tasks machine translation approach based comparing according domainspecific language models sentence text source used produce latter language model show produces better language models trained less data random data selection two previously proposed methods intelligent selection language model training data intelligent selection language model training data intelligent selection language model training data 
propose novel algorithm sentiment summarization takes account informativeness readability simultaneously algorithm generates summary selecting ordering sentences taken multiple review texts according two scores represent informativeness readability sentence order informativeness score defined number sentiment expressions readability score learned target corpus evaluate method summarizing reviews restaurants method outperforms existing algorithm indicated rouge score human readability experiments optimizing informativeness readability sentiment summarization optimizing informativeness readability sentiment summarization optimizing informativeness readability sentiment summarization 
one central challenges sentimentbased text categorization every portion document equally informative inferring overall sentiment document previous research shown enriching sentiment labels human annotators rationales produce substantial improvements categorization performance zaidan et al explore methods automatically generate annotator rationales sentiment classification rather unexpectedly find automatically generated rationales helpful human rationales automatically generating annotator rationales improve sentiment classification automatically generating annotator rationales improve sentiment classification automatically generating annotator rationales improve sentiment classification 
hierarchical ha uses hierarchy coarse grammars speed parsing without sacrificing optimality ha prioritizes search refined grammars using viterbi outside costs computed coarser grammars present bridge hierarchical bha modified hierarchial algorithm computes novel outside cost called bridge outside cost bridge costs mix finer outside scores coarser inside scores thus constitute tighter heuristics entirely coarse scores show bha substantially outperforms ha hierarchy contains coarse grammars achieving comparable performance refined hierarchies hierarchical a* parsing bridge outside scores hierarchical a* parsing bridge outside scores hierarchical a* parsing bridge outside scores 
evaluate effect adding parse features leading model preposition usage results show significant improvement preposition selection task native speaker text modest increment precision recall esl error detection task analysis parser output indicates robust enough face noisy writing extract useful information using parse features preposition selection error detection using parse features preposition selection error detection using parse features preposition selection error detection 
word alignment aims improve accuracy automatic word alignment incorporating full partial manual alignments motivated standard active learning query sampling frameworks like sampling propose multiple query strategies alignment link selection task experiments show active selection uncertain informative links reduce overall manual effort involved elicitation alignment link data training semisupervised word aligner active learning-based elicitation semi-supervised word alignment active learning-based elicitation semi-supervised word alignment active learning-based elicitation semi-supervised word alignment 
main focus work investigate robust ways generating summaries summary representations without recurring simple sentence extraction aiming summaries motivated empirical evidence tac data showing human summaries contain average shorter sentences system summaries report encouraging preliminary results comparable attained participating systems tac wrapping summary: representation generation wrapping summary: representation generation wrapping summary: representation generation 
tree srl system semantic role labelling supervised system based algorithm simple implementation novelty system lies comparing sentences tree structures multiple relations instead extracting vectors features relation classifying system tested english shared task data set accuracy obtained edit tree distance alignments semantic role labelling edit tree distance alignments semantic role labelling edit tree distance alignments semantic role labelling 
supervised semantic role labeling srl systems trained annotated corpora recently achieved performance however creating corpora tedious costly resulting corpora sufficiently representative language paper describes part ongoing work applying bootstrapping methods srl deal problem previous work shows due complexity srl task straight forward one major difficulty propagation classification noise successive iterations address problem employing balancing preselection methods bootstrapping algorithm proposed methods could achieve improvement base line use methods adapting self-training semantic role labeling adapting self-training semantic role labeling adapting self-training semantic role labeling 
present package open source framework developing evaluating word space algorithms package implements word space algorithms lsa provides comprehensive set matrix utilities data structures extending new existing models package also includes word space benchmarks evaluation algorithms libraries designed high concurrency scalability demonstrate efficiency reference implementations also provide results six benchmarks s-space package: open source package word space models s-space package: open source package word space models s-space package: open source package word space models 
punctuation implicit annotations chinese word segmentation zhongguo li tsinghua university maosong sun tsinghua university present chinese word segmentation model learned punctuation marks perfect word delimiters learning aided manually segmented corpus method considerably effective previous methods unknown word recognition step toward addressing one toughest problems chinese word segmentation punctuation implicit annotations chinese word segmentation punctuation implicit annotations chinese word segmentation punctuation implicit annotations chinese word segmentation 
investigation validity metrics automatically evaluating natural language generation systems ehud reiter university aberdeen anja belz university brighton growing interest using automatically computed evaluation metrics evaluate natural language generation nlg systems often considerably cheaper evaluations traditionally used nlg review previous work nlg evaluation validation automatic metrics nlp present results two studies well metrics popular areas nlp notably bleu rouge correlate human judgments domain weather forecasts results suggest least domain metrics may provide useful measure language quality although evidence strong would ideally like see however provide useful measure content quality also discuss number caveats must kept mind interpreting validation studies investigation validity metrics automatically evaluating natural language generation systems investigation validity metrics automatically evaluating natural language generation systems investigation validity metrics automatically evaluating natural language generation systems 
work tackle task machine translation mt without parallel training data frame mt problem decipherment task treating foreign text cipher english present novel methods training translation models nonparallel text deciphering foreign language deciphering foreign language deciphering foreign language 
describe exact decoding algorithm statistical translation approach uses lagrangian relaxation decompose decoding problem tractable subproblems thereby avoiding exhaustive dynamic programming method recovers exact solutions certificates optimality test examples comparable speed decoders exact decoding syntactic translation models lagrangian relaxation exact decoding syntactic translation models lagrangian relaxation exact decoding syntactic translation models lagrangian relaxation 
joint jst model previously proposed detect sentiment topic simultaneously text supervision required jst model learning polarity word priors paper modify jst model incorporating word polarity priors modifying dirichlet priors study topics extracted jst show augmenting original feature space topics supervised classifiers learned augmented feature representation achieve performance movie review data average sentiment dataset furthermore using feature augmentation selection according information gain criteria sentiment classification proposed approach performs either better comparably compared previous approaches nevertheless approach much simpler require difficult parameter tuning automatically extracting polarity-bearing topics cross-domain sentiment classification automatically extracting polarity-bearing topics cross-domain sentiment classification automatically extracting polarity-bearing topics cross-domain sentiment classification 
sentiment analysis twitter data attracted much attention recently paper focus twitter sentiment classification namely given query classify sentiments tweets positive negative neutral according whether contain positive negative neutral sentiments query query serves target sentiments approaches solving problem always adopt strategy may assign irrelevant sentiments given target moreover approaches take tweet classified consideration classifying sentiment ignore context related tweets however tweets usually short ambiguous sometimes enough consider current tweet sentiment classification paper propose improve twitter sentiment classification incorporating features taking related tweets consideration according experimental results approach greatly improves performance sentiment classification target-dependent twitter sentiment classification target-dependent twitter sentiment classification target-dependent twitter sentiment classification 
demonstrate supervised discriminative machine learning techniques used automate assessment english second language esol examination scripts particular use rank preference learning explicitly model grade relationships scripts number different features extracted ablation tests used investigate contribution overall performance comparison regression rank preference models supports method experimental results first publically available dataset show system achieve levels performance close upper bound task defined agreement human examiners corpus finally using set outlier texts test validity model identify cases model scores diverge human examiner new dataset method automatically grading esol texts new dataset method automatically grading esol texts new dataset method automatically grading esol texts 
lack standard datasets evaluation metrics prevented field paraphrasing making kind rapid progress enjoyed machine translation community last years address problems presenting novel data collection framework produces highly parallel text data relatively inexpensively large scale highly parallel nature data allows us use simple comparisons measure semantic adequacy lexical dissimilarity paraphrase candidates addition simple efficient compute experiments show metrics correlate highly human judgments collecting highly parallel data paraphrase evaluation collecting highly parallel data paraphrase evaluation collecting highly parallel data paraphrase evaluation 
introduce novel metric meant assesses translation utility matching semantic role fillers producing scores correlate human judgment well hter much lower labor cost machine translation systems improve lexical choice fluency shortcomings widespread based mt evaluation metrics bleu fail properly evaluate adequacy become apparent accurate nonautomatic mt evaluation metrics like hter highly bottlenecks evaluation cycle first show using untrained monolingual readers annotate semantic roles mt output version metric hmeant achieves correlation coefficient human adequacy judgments sentence level far superior bleu equal far expensive hter replace human semantic role annotators automatic shallow semantic parsing automate evaluation metric show even semiautomated evaluation metric achieves correlation coefficient human adequacy judgment still closely correlated hter despite even lower labor cost evaluation procedure results show proposed metric significantly better correlated human judgment adequacy current widespread automatic evaluation metrics much cost effective hter meant: inexpensive, high-accuracy, semi-automatic metric evaluating translation utility based semantic roles meant: inexpensive, high-accuracy, semi-automatic metric evaluating translation utility based semantic roles meant: inexpensive, high-accuracy, semi-automatic metric evaluating translation utility based semantic roles 
language models major resource bottleneck machine translation paper present several language model implementations highly compact fast query fastest implementation fast widely used srilm requiring storage compact representation store billion associated counts google corpus bits per compact lossless representation date even compact recent lossy compression techniques also discuss techniques improving query speed decoding including simple novel language model caching technique improves query speed language models srilm faster smaller n-gram language models faster smaller n-gram language models faster smaller n-gram language models 
information retrieval ir figurative language processing flp could scarcely different treatment language meaning ir views language set mostly stable signs texts indexed retrieved focusing text potential relevance potential meaning contrast flp views language system unstable signs used talk world creative new ways another key difference ir practical scalable robust daily use millions casual users flp neither scalable robust yet practical enough migrate beyond lab paper thus presents mutually beneficial hybrid ir flp one enriches ir new operators enable retrieval creative expressions also transplants flp robust scalable framework practical applications linguistic creativity implemented creative language retrieval: robust hybrid information retrieval linguistic creativity creative language retrieval: robust hybrid information retrieval linguistic creativity creative language retrieval: robust hybrid information retrieval linguistic creativity 
propose method automatic extraction transliteration pairs parallel corpora contrast previous work method uses form supervision require linguistically informed preprocessing conduct experiments data sets news shared task transliteration mining achieve outperforming systems submitted also apply method english hindi english arabic parallel corpora compare results manually built gold standards mark transliterated word pairs finally integrate transliteration module giza word aligner evaluate two word alignment tasks achieving improvements precision recall measured gold standard word alignments algorithm unsupervised transliteration mining application word alignment algorithm unsupervised transliteration mining application word alignment algorithm unsupervised transliteration mining application word alignment 
present method computation prefix probabilities synchronous contextfree grammars framework fairly general relies combination simple novel grammar transformation standard techniques bring grammars normal forms prefix probability probabilistic synchronous context-free grammars prefix probability probabilistic synchronous context-free grammars prefix probability probabilistic synchronous context-free grammars 
design class submodular functions meant document summarization tasks functions combine two terms one encourages summary representative corpus positively rewards diversity critically functions monotone nondecreasing submodular means efficient scalable greedy optimization scheme constant factor guarantee optimality evaluated duc corpora obtain better existing results generic document summarization lastly show several methods document summarization correspond fact submodular function optimization adding evidence submodular functions natural fit document summarization class submodular functions document summarization class submodular functions document summarization class submodular functions document summarization 
recent work bilingual word sense disambiguation wsd shown resource deprived language benefit annotation work done resource rich language via parameter projection however method assumes presence sufficient annotated data one resource rich language may always possible instead focus situation two resource deprived languages small amount seed annotated data large amount untagged data use bilingual bootstrapping wherein model trained using seed annotated data used annotate untagged data vice versa using parameter projection untagged instances get annotated high confidence added seed data respective languages process repeated experiments show bilingual bootstrapping algorithm evaluated two different domains small seed sizes using hindi marathi language pair performs better monolingual bootstrapping significantly reduces annotation cost together can: bilingual bootstrapping wsd together can: bilingual bootstrapping wsd together can: bilingual bootstrapping wsd 
negation present human languages used reverse polarity part statements otherwise affirmative default negated statement often carries positive implicit meaning pinpoint positive part negative part rather difficult paper aims thoroughly representing semantics negation revealing implicit positive meaning proposed representation relies focus negation detection new annotation propbank learning algorithm proposed semantic representation negation using focus detection semantic representation negation using focus detection semantic representation negation using focus detection 
ccgs directly compatible binarybranching parsing algorithms particular cky algorithms approach dominant approach ccg method little explored paper develop ccg parser using discriminative model beam search compare strengths weaknesses parser study different errors made two parsers show parser gives competitive accuracies compared considering use small beam given high ambiguity levels grammar amount information ccg lexical categories form shift actions surprising result shift-reduce ccg parsing shift-reduce ccg parsing shift-reduce ccg parsing 
present novel approach grammatical error correction based alternating structure optimization part work introduce nus corpus learner english nucle fully annotated one million words corpus learner english available research purposes conduct extensive evaluation article preposition errors using various feature sets experiments show approach outperforms two baselines trained text learner text respectively approach also outperforms two commercial grammar checking software packages grammatical error correction alternating structure optimization grammatical error correction alternating structure optimization grammatical error correction alternating structure optimization 
linking entities knowledge base entity linking key issue bridging textual data structural knowledge base due name variation problem name ambiguity problem entity linking decisions critically depending heterogenous knowledge entities paper propose generative probabilistic model called entitymention model leverage heterogenous entity knowledge including popularity knowledge name knowledge context knowledge entity linking task model name mention linked modeled sample generated generative story entity knowledge encoded distribution entities document distribution possible names specific entity distribution possible contexts specific entity find referent entity name mention method combines evidences three distributions experimental results show method significantly outperform traditional methods generative entity-mention model linking entities knowledge base generative entity-mention model linking entities knowledge base generative entity-mention model linking entities knowledge base 
use search engine results address particularly difficult language processing task adaptation named entity recognition ner news text web queries key novelty method submit token context search engine use similar contexts search results additional information correctly classifying token achieve strong gains ner performance news web queries piggyback: using search engines robust cross-domain named entity recognition piggyback: using search engines robust cross-domain named entity recognition piggyback: using search engines robust cross-domain named entity recognition 
one major challenges facing statistical machine translation model differences word order languages although great deal research focussed problem progress hampered lack reliable metrics current metrics based matching lexical items translation reference ability measure quality word order demonstrated paper presents novel metric lrscore explicitly measures quality word order using permutation distance metrics show metric consistent human judgements metrics including bleu score also show lrscore successfully used objective function training translation model parameters training lrscore leads output preferred humans moreover translations incur penalty terms bleu scores reordering metrics mt reordering metrics mt reordering metrics mt 
paper proposes novel reordering model statistical machine translation smt means modeling translation orders source language collocations model learned bilingual corpus collocated words source sentences automatically detected decoding model employed softly constrain translation orders source language collocations constrain translation orders source phrases containing collocated words experimental results show proposed method significantly improves translation quality achieving absolute improvements bleu score baseline methods reordering source language collocations reordering source language collocations reordering source language collocations 
present novel machine translation model models translation linear sequence operations contrast model sequence includes translation also reordering operations key ideas model new reordering approach better restricts position word phrase moved able handle short long distance reorderings unified way ii joint sequence model translation reordering probabilities flexible standard mt observe statistically significant improvements bleu moses tasks comparable results task joint sequence translation model integrated reordering joint sequence translation model integrated reordering joint sequence translation model integrated reordering 
present discriminative learning method improve consistency translations statistical machine translation smt systems method inspired translation memory tm systems widely used human translators industrial settings constrain translation input sentence using similar translation example retrieved tm differently previous research used simple fuzzy match thresholds constraints imposed using discriminative learning optimise translation performance observe using method benefit smt system producing consistent translations also improved translation outputs report point improvement terms bleu score english chinese technical documents consistent translation using discriminative learning - translation memory-inspired approach consistent translation using discriminative learning - translation memory-inspired approach consistent translation using discriminative learning - translation memory-inspired approach 
system combination method machine translation mt based confusion networks constructed aligning hypotheses regard word similarities introduce novel system combination framework hypotheses encoded confusion forest packed forest representing alternative trees forest generated using syntactic consensus among parsed hypotheses first mt outputs parsed second context free grammar learned extracting set rules constitute parse trees third packed forest generated starting root symbol extracted grammar rewriting new hypothesis produced searching best derivation forest experimental results wmt system combination shared task yield comparable performance conventional confusion network based method smaller space machine translation system combination confusion forest machine translation system combination confusion forest machine translation system combination confusion forest 
paper presents hypothesis mixture decoding hm decoding new decoding scheme performs translation reconstruction using hypotheses generated multiple translation systems hm decoding involves two decoding stages first component system decodes independently explored search space kept use next step second new search space constructed composing existing hypotheses produced component systems using set rules provided hm decoder new set model independent features used seek final best translation new search space assumptions made approach underlying component systems enabling us leverage smt models based arbitrary paradigms compare approach several related techniques demonstrate significant bleu improvements translation tasks hypothesis mixture decoding statistical machine translation hypothesis mixture decoding statistical machine translation hypothesis mixture decoding statistical machine translation 
propose principled efficient alignment model useful machine translation well related natural language processing problems hidden semimarkov model translations modeled directly system agreement two directional models encourages selection parsimonious phrasal alignments avoiding overfitting commonly encountered unsupervised training units expanding state space include gappy phrases french ne pas makes alignment space symmetric thus allows agreement discontinuous alignments resulting system shows substantial improvements alignment quality translation quality hidden markov models maintaining asymptotically equivalent runtime gappy phrasal alignment agreement gappy phrasal alignment agreement gappy phrasal alignment agreement 
lots chinese characters productive form many structured words either prefixes suffixes previous research chinese word segmentation mainly focused identifying word boundaries without considering rich internal structures many words paper argue unsatisfying many ways practically theoretically instead propose word structures recovered morphological analysis elegant approach given result shown promising enough encouraging effort direction probability model trained penn chinese treebank actually able parse word phrase structures unified way parse word structures research chinese word segmentation progressed tremendously recent years state art performing around precision recall xue gao et al zhang clark li sun however virtually systems focus exclusively recognizing word boundaries giving consideration internal structures many words though standard practice many years argue paradigm inadequate theory practice least following four reasons first reason confine definition word segmentation identification word boundaries people tend divergent opinions whether linguistic unit word sproat et al led many different annotation standards chinese word segmentation even worse could cause inconsistency corpus instance vice president considered one word penn chinese treebank xue et al split two words peking university corpus sighan bakeoffs sproat emerson meanwhile vice director deputy manager segmented two words penn chinese treebank fact words composed prefix vice root word thus structure vice president represented tree figure without parsing internal structure words: new paradigm chinese word segmentation parsing internal structure words: new paradigm chinese word segmentation parsing internal structure words: new paradigm chinese word segmentation 
describe new approach disambiguating semantic frames evoked lexical predicates previously unseen lexicon annotated data approach makes use large amounts unlabeled data learning framework construct large graph vertices correspond potential predicates use label propagation learn possible semantic frames new ones graph used within parser unknown predicates results absolute improvement frame identification accuracy absolute improvement full parsing score blind test set supervised baseline semi-supervised frame-semantic parsing unknown predicates semi-supervised frame-semantic parsing unknown predicates semi-supervised frame-semantic parsing unknown predicates 
paper present unified model automatic induction word senses text subsequent disambiguation particular word instances using automatically extracted sense inventory induction step disambiguation step based principle words contexts mapped limited number topical dimensions latent semantic word space intuition particular sense associated particular topic different senses discriminated association particular topical dimensions similar vein particular instance word disambiguated determining important topical dimensions model evaluated word sense induction disambiguation task reaches results latent semantic word sense induction disambiguation latent semantic word sense induction disambiguation latent semantic word sense induction disambiguation 
recent work shown parallel corpus leveraged build syntactic parser target language projecting automatic source parse onto target sentence using word alignments projected target dependency parses always fully connected useful training traditional dependency parsers paper present greedy parsing algorithm doesn need fully connected parse learn partial parses utilizing available structural syntactic information parser achieved statistically significant improvements baseline system trains fully connected parses bulgarian spanish hindi also gave significant improvement previously reported results bulgarian set benchmark hindi partial parsing bitext projections partial parsing bitext projections partial parsing bitext projections 
bootstrapping seed set expansion selecting good seeds creating stop lists two effective ways reduce semantic drift methods generally need human supervision paper propose graphbased approach helping editors choose effective seeds stop list instances applicable pantel pennacchiotti espresso bootstrapping algorithm idea select seeds create stop list using rankings instances patterns computed kleinberg hits algorithm experimental results variation lexical sample task show effectiveness method hits-based seed selection stop list construction bootstrapping hits-based seed selection stop list construction bootstrapping hits-based seed selection stop list construction bootstrapping 
paper introduces new training set condensation technique designed mixtures labeled unlabeled data finds condensed set labeled unlabeled data points typically smaller obtained using condensed nearest neighbor labeled data improves classification accuracy evaluate algorithm semisupervised tagging present best published result wall street journal data set semi-supervised condensed nearest neighbor part-of-speech tagging semi-supervised condensed nearest neighbor part-of-speech tagging semi-supervised condensed nearest neighbor part-of-speech tagging 
work introduces semantic framework machine translation evaluation based upon framework new evaluation metric able operate without need reference translations implemented evaluated metric based concepts adequacy fluency independently assessed using latent semantic indexing approach based language model approach respectively comparative analyses conventional evaluation metrics conducted two different evaluation tasks overall quality assessment comparative ranking large collection human evaluations involving five european languages finally main pros cons proposed framework discussed along future research directions am-fm: semantic framework translation quality assessment am-fm: semantic framework translation quality assessment am-fm: semantic framework translation quality assessment 
word usually adopted smallest unit tasks chinese language processing however automatic evaluation quality chinese translation output translating languages either approach approach possible far detailed study compare correlations two approaches human assessment paper compare metrics characterlevel metrics submitted output translation systems iwslt nist ec tasks experimental results reveal metrics correlate human assessment better metrics analysis suggests several key reasons behind finding automatic evaluation chinese translation output: word-level character-level? automatic evaluation chinese translation output: word-level character-level? automatic evaluation chinese translation output: word-level character-level? 
word alignment central problem statistical machine translation smt recent years supervised alignment algorithms improve alignment accuracy mimicking human alignment attracted great deal attention objective work explore performance limit supervised alignment current smt paradigm experiments used manually aligned chineseenglish corpus words recently released linguistic data consortium ldc treated human alignment oracle supervised alignment result surprising gain human alignment state art unsupervised method giza less point bleu furthermore showed benefit improved alignment becomes smaller training data implying limit also holds large training conditions much gain supervised word alignment? much gain supervised word alignment? much gain supervised word alignment? 
cast word alignment problem maximizing submodular function matroid constraints framework able express complex interactions alignment components remaining computationally efficient thanks power generality submodular functions show submodularity naturally arises modeling word fertility experiments hansards alignment task show approach achieves lower alignment error rates compared conventional matching based approaches word alignment via submodular maximization matroids word alignment via submodular maximization matroids word alignment via submodular maximization matroids 
dependency parsers generally use heuristic decoding algorithms accommodate arbitrarily rich feature representations paper show improve accuracy parsers considering even richer feature sets employed previous systems standard penn treebank setup novel features improve attachment score form giving best results far transitionbased parsing rivaling best results overall chinese treebank give signficant improvement state art open source release parser freely available transition-based dependency parsing rich non-local features transition-based dependency parsing rich non-local features transition-based dependency parsing rich non-local features 
dependency parsing sped significantly implausible arcs eliminated parsing begins methods arc filtering use separate classifiers make pointwise decisions tree label tokens roles root leaf filter arcs accordingly classifiers overlap substantially filtering consequences propose train jointly classifier focus gaps others integrate various pointwise decisions latent variables single svm classifier novel framework allows us combine nine pointwise filters adjust sensitivity using shared threshold based arc length system filters arcs classifiers without reducing filtering speed leads faster parsing reduction accuracy joint training dependency parsing filters latent support vector machines joint training dependency parsing filters latent support vector machines joint training dependency parsing filters latent support vector machines 
paper show local features computed derivations tree substitution grammars identify particular fragments count large small fragments useful binary grammatical classification tasks features outperform features various model scores wide margin although fall short performance feature set charniak johnson developed parse tree reranking order magnitude fewer features furthermore since tsgs employed learned bayesian setting use derivations viewed automatic discovery tree patterns useful classification bllip dataset achieve accuracy discriminating grammatical text samples language model judging grammaticality tree substitution grammar derivations judging grammaticality tree substitution grammar derivations judging grammaticality tree substitution grammar derivations 
paper argue ordering prenominal modifiers typically pursued supervised modeling task particularly wellsuited approaches relying automatic parses extract noun phrases scale training data orders magnitude minimizes predominant issue data sparsity informed previous approaches compare several recent approaches find improvements additional training data across board however none outperform simple model semi-supervised modeling prenominal modifier ordering semi-supervised modeling prenominal modifier ordering semi-supervised modeling prenominal modifier ordering 
generally speaking statistical machine translation systems would able attain better performance training sets unfortunately training sets rarely available real world consequently necessary focus modifying training set obtain high accuracy smt system smt system trained translation model translation pair would low probability many variations target sentences single source sentence decreased number variations translation pair could construct superior translation model paper describes effects modification training corpus consideration given synonymous sentence groups attempt three types modification compression training set replacement source target sentences selected sentence synonymous sentence group replacement sentence one side selected sentence synonymous sentence group result achieve improved performance replacement sentences training data modification smt considering groups synonymous sentences training data modification smt considering groups synonymous sentences training data modification smt considering groups synonymous sentences 
many computational linguistic scenarios training labels subjectives making necessary acquire opinions multiple annotators experts referred wisdom crowds paper propose new approach modeling wisdom crowds based latent mixture discriminative experts lmde model automatically learn prototypical patterns hidden dynamic among different experts experiments show improvement approaches task listener backchannel prediction dyadic conversations modeling wisdom crowds using latent mixture discriminative experts modeling wisdom crowds using latent mixture discriminative experts modeling wisdom crowds using latent mixture discriminative experts 
annotated corpora essential almost nlp applications whereas expected high quality importance followup developments still contain considerable number errors work want draw attention fact additionally try estimate amount errors propose method automatic correction whereas approach able find portion errors suppose contained almost annotated corpus due nature process creation high precision thus case beneficial quality corpus applied last compare different method error detection treebanks find errors able detect mostly different approaches complementary automatic detection correction errors dependency treebanks automatic detection correction errors dependency treebanks automatic detection correction errors dependency treebanks 
number systems use reordering step prior phrasebased statistical mt early work proposing idea showed improved translation performance subsequent work mixed results speculations cause suggested parser data factors systematically investigate possible factors give initial answer question conditions use syntax help psmt clause restructuring smt absolutely helpful clause restructuring smt absolutely helpful clause restructuring smt absolutely helpful 
address parse error issue translation paper proposes decoding generation sdg solution reconstructing similar source parse trees decoding decoding time instead taking multiple source parse trees input decoding experiments translation demonstrated approach achieve significant improvement standard method little impact decoding speed practice approach easy implement applied paradigms models improving decoding generalization tree-to-string translation improving decoding generalization tree-to-string translation improving decoding generalization tree-to-string translation 
paper present novel discriminative mixture model statistical machine translation smt model feature space combination multiple mixture components component contains large set features trained maximumentropy framework features within mixture component tied share mixture weights mixture weights trained discriminatively maximize translation performance approach aims bridging gap training discriminative training smt shown feature space partitioned variety ways based feature types word alignments domains various applications proposed approach improves translation performance significantly mt task discriminative feature-tied mixture modeling statistical machine translation discriminative feature-tied mixture modeling statistical machine translation discriminative feature-tied mixture modeling statistical machine translation 
one problem statistical machine translation problem longdistance reordering translating languages different word orders paper propose method imposing reordering constraints using context documentlevel context use noun phrases significantly occur context documents containing source sentences given source sentence zones cover noun phrases used reordering constraints decoding reorderings violate zones restricted experiment results patent translation tasks show significant improvement bleu points japaneseenglish translation bleu points translation reordering constraint based document-level context reordering constraint based document-level context reordering constraint based document-level context 
statistical machine translation systems phrase rule extraction algorithm uses alignments form might contain spurious alignment points usage weighted alignment matrices encode possible alignments shown generate better phrase tables systems propose two algorithms generate well known msd reordering model using weighted alignment matrices experiments iwslt evaluation datasets two language pairs different alignment algorithms show methods produce accurate reordering models shown increase regular msd models bleu points btec french english test set bleu points dialog chinese english test set reordering modeling using weighted alignment matrices reordering modeling using weighted alignment matrices reordering modeling using weighted alignment matrices 
introduce two simple improvements lexical weighting features koehn och marcu machine translation one smooths probability translating word word simplifying english morphology one conditions kind training data new variations lead improvements bleu average improvement bleu across two language pairs two genres two translation systems two easy improvements lexical weighting two easy improvements lexical weighting two easy improvements lexical weighting 
contrary popular belief show optimal parameters ibm model unique demonstrate large class words ibm model indifferent among continuum ways allocate probability mass translations study magnitude variance optimal model parameters using linear programming approach well multiple random trials demonstrate results variance test set alignment error rate initialization matters ibm model 1: multiple optima non-strict convexity initialization matters ibm model 1: multiple optima non-strict convexity initialization matters ibm model 1: multiple optima non-strict convexity 
paraphrase generation important task received great deal interest recently proposed solutions problem ranged simple approaches make minimal use nlp tools complex approaches rely numerous resources despite attention direct empirical evaluations comparing merits different approaches paper empirically examines tradeoffs simple sophisticated paraphrase harvesting approaches help shed light strengths weaknesses evaluation reveals simple approaches fare surprisingly well number distinct advantages including strong precision good coverage low redundancy empirical evaluation data-driven paraphrase generation techniques empirical evaluation data-driven paraphrase generation techniques empirical evaluation data-driven paraphrase generation techniques 
derive two variants model sentiment analysis models leverage abundant natural supervision form review ratings well small amount manually crafted sentence labels learn sentiment classifiers proposed model fusion fully supervised structured conditional model partially supervised counterpart allows highly efficient estimation inference algorithms rich feature definitions describe two variants well component models verify experimentally variants give significantly improved results sentiment analysis compared baselines sentiment analysis paper demonstrate combining supervision benefits sentiment analysis important task field opinion classification retrieval pang lee typical supervised learning approaches sentiment analysis rely supervision supervision rarely exist naturally thus requires labor intensive manual annotation effort wiebe et al supervision naturally abundant form online review ratings supervision course less informative compared supervision however combining small amount supervision large amount supervision able substantially improve classification task work combines two strands research models sentiment analysis take document structure account models use latent variables learn unobserved phenomena observed exploiting document structure sentiment analysis attracted research attention since early work pang lee performed minimal cuts sentence graph select subjective sentences mcdonald et al later showed jointly learning sentence coarsegrained document sentiment improves predictions levels recently yessenalina et al described latent variables used improve prediction nakagawa et al used latent variables syntactic dependency trees improve prediction using labeled sentences training similar vein sauper semi-supervised latent variable models sentence-level sentiment analysis semi-supervised latent variable models sentence-level sentiment analysis semi-supervised latent variable models sentence-level sentiment analysis 
paper proposes novel approach effectively utilizing unsupervised data addition supervised data supervised learning use unsupervised data generate informative condensed feature representations original feature set used supervised nlp systems main contribution method offer dense feature spaces nlp tasks maintaining performance provided recently developed learning technique method matches results current systems features features ner data uas features dependency parsing data derived learning condensed feature representations large unsupervised data sets supervised learning learning condensed feature representations large unsupervised data sets supervised learning learning condensed feature representations large unsupervised data sets supervised learning 
present novel pruning method parsing increases efficiency disallowing unary productions cky chart cells spanning single word work orthogonal recent work closing chart cells focused constituents leaving chart cells unpruned show simple discriminative classifier learn high accuracy chart cells close unary productions eliminating unary productions search large impact downstream processing depending implementation details search apply method four parsing architectures demonstrate complementary paradigm well pruning methods agenda pruning unary constraints efficient context-free parsing unary constraints efficient context-free parsing unary constraints efficient context-free parsing 
paper suggests two ways improving dependency parsing first add transition existing parsing algorithm perform either projective parsing needed second present bootstrapping technique narrows discrepancies automatic parses used features new addition algorithm shows clear advantage parsing speed bootstrapping technique gives significant improvement parsing accuracy showing near performance respect parsing approaches evaluated data set getting transition-based dependency parsing getting transition-based dependency parsing getting transition-based dependency parsing 
paper presents improving dependency parsing semantic classes improving dependency parsing semantic classes improving dependency parsing semantic classes 
paper present new word alignment combination approach language pairs one language explicit word boundaries instead combining word alignments different models xiang et al try combine word alignments multiple monolingually motivated word segmentation approach based link confidence score defined multiple segmentations thus combined alignment robust inappropriate word segmentation combination algorithm simple efficient easy implement experiment approach effectively improved word alignment quality well translation performance segmentations simultaneously showed word alignment benefit complementary knowledge due diversity multiple monolingually motivated segmentations word alignment combination multiple word segmentation word alignment combination multiple word segmentation word alignment combination multiple word segmentation 
sentiment analysis one hot demanding research areas since last decades although formidable amount research done still existing reported solutions available systems far perfect meet satisfaction level end main issue may many conceptual rules govern sentiment even clues possibly unlimited convey concepts realization verbalization human human psychology directly relates unrevealed clues govern sentiment realization us human psychology relates many things like social psychology culture pragmatics many endless intelligent aspects civilization proper incorporation human psychology computational sentiment knowledge representation may solve problem psychosentiwordnet extension sentiwordnet holds human psychological knowledge sentiment knowledge simultaneously psychosentiwordnet psychosentiwordnet psychosentiwordnet 
text often lacks grammaticality fluency paper studies grammaticality improvement using algorithm based ccg goal search problem find optimal parse tree among constructed selection ordering input words search problem significantly harder parsing solved guided learning search standard word ordering task system gives bleu score higher previous result achieved system syntax-based grammaticality improvement using ccg guided search syntax-based grammaticality improvement using ccg guided search syntax-based grammaticality improvement using ccg guided search 
sentiment analysis one hot demanding research areas since last decades although formidable amount research done existing reported solutions available systems still far perfect meet satisfaction level end users main issue various conceptual rules govern sentiment even clues possibly unlimited convey concepts realization verbalization human human psychology directly relates unrevealed clues governs sentiment realization us human psychology relates many things like social psychology culture pragmatics many endless intelligent aspects civilization proper incorporation human psychology computational sentiment knowledge representation may solve problem present paper propose template based online interactive gaming technology called dr sentiment automatically create psychosentiwordnet involving internet population psychosentiwordnet extension sentiwordnet presently holds human psychological knowledge aspects along sentiment knowledge dr sentiment knows everything! dr sentiment knows everything! dr sentiment knows everything! 
present blast open source tool error analysis machine translation mt output believe error analysis identify classify mt errors integral part mt development since gives qualitative view obtained standard evaluation methods blast aid mt researchers users process providing graphical user interface designed flexible used mt system language pair error typology annotation task aided highlighting similarities reference translation blast: tool error analysis machine translation output blast: tool error analysis machine translation output blast: tool error analysis machine translation output 
machine translation mt systems still far perfect alternative interactive machine translation imt framework knowledge human translator combined mt system present statistical imt system able learn user feedback means application online learning techniques techniques allow mt system update parameters underlying models real time according empirical results system outperforms results conventional imt systems best knowledge online learning capability never provided previous imt systems imt system implemented javascript actionscript publicly available web interactive machine translation system online learning interactive machine translation system online learning interactive machine translation system online learning 
present wikulu system focusing supporting wiki users everyday tasks means intelligent interface wikulu implemented extensible architecture transparently integrates natural language processing nlp techniques wikis designed deployed wiki platform current prototype integrates wide range nlp algorithms keyphrase extraction link discovery text segmentation summarization text similarity additionally show wikulu applied visually analyzing results nlp algorithms educational purposes enabling semantic wikis wikulu: extensible architecture integrating natural language processing techniques wikis wikulu: extensible architecture integrating natural language processing techniques wikis wikulu: extensible architecture integrating natural language processing techniques wikis 
lexicalized dependency parses word modifiers tend fall near string show crude way use dependency length parsing feature substantially improve parsing speed accuracy english chinese mixed results german show similar improvements imposing hard bounds dependency length additionally modeling resulting sequence parse fragments simple vine grammar formalism power parameterization extra parameters stringing fragments together exhibit chart parsing algorithm low grammar constant parsing soft hard constraints dependency length parsing soft hard constraints dependency length parsing soft hard constraints dependency length 
consider problem distinguishing polysemous homonymous nouns distinction often taken granted seldom operationalized shape empirical model present first step towards model based wordnet augmented ontological classes provided corelex model provides polysemy index noun accurately distinguishes polysemy homonymy supports analysis polysemy grounded frequency meaning shifts shown nouns improves regression model predicts hypothesis fails ontology-based distinction polysemy homonymy ontology-based distinction polysemy homonymy ontology-based distinction polysemy homonymy 
distributed models semantics assume word meanings discovered company keep many approaches learn semantics large corpora document considered unstructured bags words ignoring syntax compositionality within document contrast paper proposes structured vectorial semantic framework semantic vectors defined composed syntactic context syntax semantics fully interactive composition semantic vectors necessarily produces hypothetical syntactic parse evaluations show using headwords semantic space framework improves model perplexity parsing accuracy structured composition semantic vectors structured composition semantic vectors structured composition semantic vectors 
recent work evaluativity sentiment language sciences focused contributions lexical items provide paper discuss contextual evaluativity stance inferred lexical meaning pragmatic environments focusing claims like liked clearly disliked margaret thatcher build corpus construct system employing compositional principles evaluativity calculation derive dislikes margaret thatcher resulting system dataset outperforming reasonable baselines indicating viability inferencing evaluative domain contextual evaluativity central aim contemporary research sentiment evaluative language extraction evaluative triples evaluator target evaluation date formal martin white potts computational approaches pang lee focused triples lexically encoded negative affect scoundrel dislike lexical properties key source evaluative information considerations alone miss pragmatic inferences resulting context example communicates referent bears positive stance towards referent also negative stance towards margaret thatcher liked clearly disliked margaret thatcher lexical evaluativity contextual evaluativity paper argues compositional approach contextual evaluativity similar compositional methods adopted lexical evaluativity moilanen pulman nasukawa yi heart approach treatment verbal predicates dislike evaluativity functors relate argument evaluativity evaluativity discussed utitlity model surfaces cases evaluativity known context thus new information contextual evaluativity event participants margaret thatcher inferred consequently empirical focus paper structures like second clause provides grounds sentiment encoded first hence predictable evaluation first clause evaluator describe collection annotation corpus configurations web data annotated corpus serves test bed experimental evaluation various implementations proposed compositional approach results experiments strongly support compositional approach contextual evaluativity inference simple compositional algorithm based small manually created evaluativity functor lexicon demonstrated significantly better precision extracting contextual evaluativity extracting contextual evaluativity extracting contextual evaluativity 
paper describes two contributions wmt shared task factored model using moses probabilistic treetransfer model deep syntactic layer phrase-based deep syntactic english-to-czech statistical machine translation phrase-based deep syntactic english-to-czech statistical machine translation phrase-based deep syntactic english-to-czech statistical machine translation 
describe experiments uc berkeley team improving machine translation news text part wmt shared translation task experiment domain adaptation combining small news large one europarl corpus building two separate phrase translation models two separate language models add third phrase translation model trained version news augmented monolingual sentencelevel syntactic paraphrases sourcelanguage side combine models model using minimum error rate training finally experiment different tokenization recasing rules achieving bleu score wmt news test data translating english spanish sizable improvement highest bleu score achieved dataset wmt fact system wmt english spanish news translation achieve makes team second best bleu score improving english-spanish statistical machine translation: experiments domain adaptation, sentence paraphrasing, tokenization, recasing improving english-spanish statistical machine translation: experiments domain adaptation, sentence paraphrasing, tokenization, recasing improving english-spanish statistical machine translation: experiments domain adaptation, sentence paraphrasing, tokenization, recasing 
show punctuation used improve unsupervised dependency parsing linguistic analysis confirms strong connection english punctuation phrase boundaries penn treebank however approaches naively include punctuation marks grammar words perform well klein manning dependency model valence dmv instead split sentence punctuation impose parsing restrictions fragments grammar inducer trained wall street journal wsj achieves accuracy brown sentences fewer words higher previous best results evaluation using conll sets reveals punctuation aids grammar induction languages overall average net gain improvement training half parsing induced constraints inference decoding works existing even parsing models always increased accuracy experiments punctuation: making point unsupervised dependency parsing punctuation: making point unsupervised dependency parsing punctuation: making point unsupervised dependency parsing 
present weakly supervised approach automatic ontology population text compare two unsupervised approaches experiments populate part ontology named entities considered two high level categories geographical locations person names ten category list training examples syntactically parsed corpus automatically learn syntactic model set weighted syntactic features words typically certain syntactic positions members class model used classify unknown named entities test set method weakly supervised since annotated corpus used learning process achieved promising results accuracy outperforming significantly previous unsupervised approaches weakly supervised approaches ontology population weakly supervised approaches ontology population weakly supervised approaches ontology population 
paper study set problems considerable importance statistical machine translation smt addressed satisfactorily smt research community last decade variety smt algorithms built empirically tested whereas little known computational complexity fundamental problems smt work aims providing useful insights computational complexity problems prove ibm models conceptually computationally simple computations involving higher useful models hard since unlikely exists polynomial time solution hard problems unless np results highlight justify need developing polynomial time approximations computations also discuss practical ways dealing complexity computational complexity statistical machine translation computational complexity statistical machine translation computational complexity statistical machine translation 
apply statistical transfer machine translation framework task translating french german english introduce statistical methods within framework allow principled extraction transfer rules parallel corpora given word alignments constituency parses performance evaluated test sets wmt shared task statistical transfer systems french-english german-english machine translation statistical transfer systems french-english german-english machine translation statistical transfer systems french-english german-english machine translation 
feature feedback alternative instance labeling seeking supervision human experts combination instance feature feedback shown reduce total annotation cost supervised learning however learning problems may benefit equally feature feedback well understood benefit feature feedback reduces amount training data increases show characteristics domain instance granularity feature space instance selection strategy proportion relevant text significant effect benefit feature feedback estimate maximum benefit feature feedback may provide estimate depend feedback solicited incorporated model extend complexity measures proposed literature propose new ones categorize learning problems find strong indicators benefit feature feedback assessing benefit feature feedback active learning text classification assessing benefit feature feedback active learning text classification assessing benefit feature feedback active learning text classification 
paper present ulisse unsupervised linguistically driven algorithm select reliable parses output dependency parser different experiments devised show algorithm robust enough deal output different parsers different languages well used across different domains cases ulisse appears outperform baseline algorithms ulisse: unsupervised algorithm detecting reliable dependency parses ulisse: unsupervised algorithm detecting reliable dependency parses ulisse: unsupervised algorithm detecting reliable dependency parses 
investigate series constraints dependency parsing effect expressivity whether allow naturally occurring syntactic constructions adequately represented efficiency whether reduce search space parser particular define new measure degree acyclic dependency graph obeying constraint constraints evaluated experimentally using data prague dependency treebank danish dependency treebank results indicate whereas complete linguistic coverage principle requires unrestricted dependency graphs limiting degree reduce average running time quadratic linear excluding less dependency graphs found two treebanks substantial improvement commonly used projective approximation degree excludes graphs constraints non-projective dependency parsing constraints non-projective dependency parsing constraints non-projective dependency parsing 
paper present methods automatically acquiring training examples task entity extraction experimental evidence show methods compete current heavily supervised system within absolute mean average precision model significantly outperforms supervised unsupervised baselines absolute mean average precision automatically building training examples entity extraction automatically building training examples entity extraction automatically building training examples entity extraction 
paper makes two contributions area based word alignment bilingual sentence pairs firstly integrates seemingly rather different works bodrumlu et al standard probabilistic ones single framework secondly present two algorithms optimize arising task first iterative scheme similar viterbi training able handle large tasks second based inexact solution integer program handle small corpora allows insight quality model performance iterative scheme finally present alternative way handle prior dictionary knowledge discuss connections computing viterbi alignments probabilistic word alignment $l_0$-norm probabilistic word alignment $l_0$-norm probabilistic word alignment $l_0$-norm 
degree dominance sense word proportion occurrences sense text propose four new methods accurately determine word sense dominance using raw text published thesaurus unlike mccarthy et al system methods used relatively small target texts without need auxiliary text perform extensive evaluation using artificially generated data process create word category cooccurrence matrix used unsupervised word sense disambiguation estimating distributional similarity word senses well determining word sense dominance using thesaurus determining word sense dominance using thesaurus determining word sense dominance using thesaurus 
investigate use learning ssl opinion detection sparse data situations domain adaptation show reaches best results setting small labeled data sets maximum absolute gain domain transfer show gains absolute improvement labeling accuracy blog data supervised approach target domain training data filling gap: semi-supervised learning opinion detection across domains filling gap: semi-supervised learning opinion detection across domains filling gap: semi-supervised learning opinion detection across domains 
paper novel solution automatic unsupervised word sense induction wsi introduced represents instantiation one sense per collocation observation gale et al like existing approaches utilizes clustering word approach differs approaches wsi enhances effect one sense per collocation observation using triplets words instead pairs combination clustering process using sentence features allows accurate results additionally novel likewise automatic unsupervised evaluation method inspired schu tze idea evaluation word sense disambiguation algorithms employed offering advantages like reproducability independency given biased gold standard also enables automatic parameter optimization wsi algorithm word sense induction: triplet-based clustering automatic evaluation word sense induction: triplet-based clustering automatic evaluation word sense induction: triplet-based clustering automatic evaluation 
describe word alignment platform ensures text tokenization lemmatization chunking sentence alignment required accurate word alignment platform combines two different methods producing distinct alignments basic word aligners described details individually evaluated union individual alignments subject filtering postprocessing phase two different filtering methods also presented evaluation shows combined word alignment contains less errors best individual aligner improved lexical alignment combining multiple reified alignments improved lexical alignment combining multiple reified alignments improved lexical alignment combining multiple reified alignments 
paper shows performance models significantly improved performing lookahead state space making classification decision instead simply using best action output classifier determine best action looking possible sequences future actions evaluating final states realized action sequences present parameter optimization method learning framework show convergence properties proposed framework evaluated tagging chunking named entity recognition dependency parsing using standard data sets features experimental results demonstrate models lookahead competitive globally optimized models including conditional random fields crfs structured perceptrons learning lookahead: history-based models rival globally optimized models? learning lookahead: history-based models rival globally optimized models? learning lookahead: history-based models rival globally optimized models? 
argue machine translation community overly reliant bleu machine translation evaluation metric show improved bleu score neither necessary sufficient achieving actual improvement translation quality give two significant counterexamples bleu correlation human judgments quality offers new potential research previously deemed unpromising inability improve upon bleu scores re-evaluation role bleu machine translation research re-evaluation role bleu machine translation research re-evaluation role bleu machine translation research 
faced problem annotation errors pos annotated corpora develop method automatically correcting errors building top successful error detection method first try correcting corpus using two pos taggers based idea enforce consistency find improvement discussion tagging process alter tagging model better account problematic tagging distinctions modification results significantly improved performance reducing error rate corpus detecting errors automatically correcting detecting errors automatically correcting detecting errors automatically correcting 
consider evaluation problem natural language generation nlg present results evaluating several nlg systems similar functionality including generator several statistical systems compare evaluation results systems human domain experts human several automatic evaluation metrics including nist bleu rouge find nist scores correlate best human judgments automatic metrics examined biased favour generators select basis frequency alone conclude automatic evaluation nlg systems considerable potential particular reference texts small number human evaluators available however general probably best automatic evaluations supported evaluations least studies demonstrate particular metric correlates well human judgments given domain comparing automatic human evaluation nlg systems comparing automatic human evaluation nlg systems comparing automatic human evaluation nlg systems 
paper present trofi trope finder system automatically classifying literal nonliteral usages verbs nearly unsupervised disambiguation clustering techniques trofi uses sentential context instead selectional constraint violations paths semantic hierarchies also uses literal nonliteral seed sets acquired cleaned without human supervision order bootstrap learning adapt disambiguation algorithm task augment multiple seed set learners voting schema additional features like supertags extrasentential context detailed experiments data show enhanced algorithm outperforms baseline using trofi algorithm also build trofi example base extensible resource annotated literal nonliteral examples freely available nlp research community clustering approach nearly unsupervised recognition nonliteral language clustering approach nearly unsupervised recognition nonliteral language clustering approach nearly unsupervised recognition nonliteral language 
investigate lexical syntactic flexibility class idiomatic expressions develop measures draw linguistic properties demonstrate statistical measures successfully used distinguishing idiomatic combinations ones also propose means automatically determining syntactic forms particular idiom appear hence included lexical representation automatically constructing lexicon verb phrase idiomatic combinations automatically constructing lexicon verb phrase idiomatic combinations automatically constructing lexicon verb phrase idiomatic combinations 
information graphics bar charts line graphs etc popular media generally discourse goal contributes achieving communicative intent multimodal document paper presents work abstractive summarization line graphs methodology involves hypothesizing intended message line graph using core summary graphic core augmented salient propositions elaborate intended message abstractive summarization line graphs popular media abstractive summarization line graphs popular media abstractive summarization line graphs popular media 
paper describes statistical machine translation system accessible means web page user issue translation requests arabic chinese spanish english statistical technology employed realize three supported new easily added demonstrator interface allows use translation system computer connected internet web-based demonstrator multi-lingual phrase-based translation system web-based demonstrator multi-lingual phrase-based translation system web-based demonstrator multi-lingual phrase-based translation system 
aim paper present computational model dynamic composition update verb argument expectations using distributional memory framework distributional semantics experimental results conducted psycholinguistic data sets show model able successfully predict changes patient argument thematic fit produced different types verb agents composing updating verb argument expectations: distributional semantic model composing updating verb argument expectations: distributional semantic model composing updating verb argument expectations: distributional semantic model 
paper describes unsupervised knowledge lean methodology automatically determining number senses ambiguous word used large corpus based use global criterion functions assess quality clustering solution selecting "right" number senses based clustering criterion functions selecting "right" number senses based clustering criterion functions selecting "right" number senses based clustering criterion functions 
examine sentiment analysis twitter data contributions paper introduce prior polarity features explore use tree kernel obviate need tedious feature engineering new features conjunction previously proposed features tree kernel perform approximately level outperforming baseline sentiment analysis twitter data sentiment analysis twitter data sentiment analysis twitter data 
extending machine learning based coreference resolution system feature capturing automatically generated information semantic roles improves performance semantic role labeling coreference resolution semantic role labeling coreference resolution semantic role labeling coreference resolution 
paper quantitatively investigates far local context useful disambiguate senses ambiguous word done comparing frequencies particular context words first one context word representing certain sense chosen frequencies two context words one one another sense compared expected turns context words belonging sense considerably higher frequencies words belonging different senses study sense inventory taken university south florida homograph norms counts based british national corpus exploring sense distributions homographs exploring sense distributions homographs exploring sense distributions homographs 
taking development cooccurrence techniques several languages focus aspects considered nv extraction task basque basque nv expressions considered combinations noun inflected verb erabakia hartu make decision kontuan hartu take account buruz jakin know heart basic extraction system developed evaluated two references reference includes nv entries several lexicographic works manual evaluation three experts random sample lists automatic extraction nv expressions basque: basic issues cooccurrence techniques automatic extraction nv expressions basque: basic issues cooccurrence techniques automatic extraction nv expressions basque: basic issues cooccurrence techniques 
chinese word segmentation cws necessary step statistical machine translation smt performance impact results smt however many settings involved creating cws system various specifications cws methods paper investigates effect settings smt tested dictionarybased approaches found significant difference two qualty resulting translations also found correlation cws smt bleu score weak paper also proposes two methods combining advantages different specifications simple concatenation training data feature interpolation approach types features translation models various cws schemes linearly interpolated found approaches effective improving quality translations improved statistical machine translation multiple chinese word segmentation improved statistical machine translation multiple chinese word segmentation improved statistical machine translation multiple chinese word segmentation 
expressions mwes prevalent text also average less polysemous suggests accurate mwe detection lead nontrivial improvement word sense disambiguation wsd show straightforward mwe detection strategy due arranz et al increase wsd algorithm baseline percentage points measurements consistent arranz study goes using portion semcor corpus containing mwes times approximately used arranz also show perfect mwe detection semcor nets total percentage point increase wsd therefore little room improvement results presented provide mwe detection algorithms along general detection framework free java library called jmwe expressions mwes prevalent text important classic task word sense disambiguation wsd agirre edmonds algorithm attempts assign word text appropriate entry sense inventory wsd algorithm cannot correctly detect mwes listed sense inventory miss sense assignments also spuriously assign senses mwe constituents sense entries dealing wsd performance beyond penalty mwes listed sense inventory also present opportunity wsd algorithms average less polysemous wordnet average polysemy versus monowords concrete example consider sentence broke world record wordnet lemma world nine different senses record fourteen mwe world record one wsd algorithm correctly detects mwes dramatically reduce number possible senses sentences measure us arranz number mwes fraction mwes wsd impr best baseline wsd impr baseline none wsd impr best none wsd impr perfect none table improvement wsd wsd strategy various mwe detection strategies detecting multi-word expressions improves word sense disambiguation detecting multi-word expressions improves word sense disambiguation detecting multi-word expressions improves word sense disambiguation 
paper describes system produces extractive summaries short works literary fiction ultimate purpose produced summaries defined helping reader determine whether would interested reading particular story end summary aims provide reader idea settings story characters time place without revealing plot approach presented relies heavily notion aspect preliminary results show improvement two na ve baselines lead baseline sophisticated variant although modest results suggest using aspectual information may help summarizing fiction thorough evaluation involving human judges way approach summarizing short stories approach summarizing short stories approach summarizing short stories 
current named entity recognition systems suffer lack data well degradation moving domain paper explores two aspects automatic generation gazetteer lists unlabeled data building named entity recognition system labeled unlabeled data bootstrapping named entity recognition automatically generated gazetteer lists bootstrapping named entity recognition automatically generated gazetteer lists bootstrapping named entity recognition automatically generated gazetteer lists 
ngram statistics package text nsp freely available software identifies ngrams collocations word associations text implemented perl takes advantage regular expressions provide flexible tokenization allow identification ngrams includes wide range measures association used identify collocations ngram statistics package (text::nsp) : flexible tool identifying ngrams, collocations, word associations ngram statistics package (text::nsp) : flexible tool identifying ngrams, collocations, word associations ngram statistics package (text::nsp) : flexible tool identifying ngrams, collocations, word associations 
paper suggests two ways improving semantic role labeling srl first introduce novel srl algorithm gives quite different approach srl algorithm inspired parsing brings advantages transitionbased approach srl second present clustering technique effectively improves labeling accuracy test domain better generalization statistical models cluster verb predicates comparing predicate argument structures apply clustering information final labeling decisions approaches evaluated conll english data new algorithm shows comparable results another system clustering technique improves labeling accuracy tasks transition-based semantic role labeling using predicate argument clustering transition-based semantic role labeling using predicate argument clustering transition-based semantic role labeling using predicate argument clustering 
present model inclusion semantic role annotations framework confidence estimation machine translation model several interesting properties notably requires linguistic processor generally source side translation directly rely properties translation model hence applied beyond systems features make potentially appealing system ranking translation user feedback evaluation preliminary experiments pairwise hypothesis ranking five confidence estimation benchmarks show model potential capture salient aspects translation quality automatic projection semantic structures: application pairwise translation ranking automatic projection semantic structures: application pairwise translation ranking automatic projection semantic structures: application pairwise translation ranking 
argue failing capture degree contribution semantic frame sentence explains puzzling results recent work meant family semantic mt evaluation metrics disturbingly indicated dissociating semantic roles fillers predicates actually improves correlation human adequacy judgments even though intuitively properly segregating event frames accurately reflect preservation meaning analysis finds properly structured flattened representations fail adequately account contribution semantic frame overall sentence show correlation hmeant human variant meant greatly improved introducing simple weighting scheme approximates degree contribution semantic frame overall sentence new results also show without flattening structure semantic frames weighting degree frame contribution gives hmeant higher correlations previously bestperforming flattened model well hter structured vs. flat semantic role representations machine translation evaluation structured vs. flat semantic role representations machine translation evaluation structured vs. flat semantic role representations machine translation evaluation 
facilitate application semantics statistical machine translation propose structure mapping technique using automated resources approach utilizes automatic syntactic semantic parsers generate structures system produced argument mapping propbank argument types computing argument similarity based automatic word alignment achieving numbered argument mapping arguments measuring structure similarity based argument mapping formulating structure mapping problem problem system achieved using automatic srl lower using gold standard srl mapping output covered annotated chinese predicates contains predicateadjectives often parallel annotations english annotated english predicates suggesting potential valuable resource improving word alignment reranking mt output semantic mapping using automatic word alignment semantic role labeling semantic mapping using automatic word alignment semantic role labeling semantic mapping using automatic word alignment semantic role labeling 
increase model coverage sourcelanguage paraphrases utilized boost smt system performance previous work showed word lattices constructed paraphrases able reduce words express inputs different ways better translation quality however method suffers two problems path duplications word lattices decrease capacities potential paraphrases lattice decoding smt dramatically increases search space results poor time efficiency therefore paper adopt word confusion networks input structure carry paraphrase information similar previous work use word lattices build word confusion networks merging duplicated paths faster decoding experiments carried english chinese translation tasks show compared method decoding time three tasks reduced significantly comparable translation quality obtained largescale task incorporating source-language paraphrases phrase-based smt confusion networks incorporating source-language paraphrases phrase-based smt confusion networks incorporating source-language paraphrases phrase-based smt confusion networks 
mistranslation ambiguous word large impact understandability given sentence article describe thorough evaluation translation quality ambiguous nouns three different setups compared two statistical machine translation systems one dedicated word sense disambiguation wsd system wsd system incorporates multilingual information independent external lexical resources word senses derived automatically word alignments parallel corpus show two wsd classifiers built experiments english french english dutch outperform smt system trained corpus opens perspectives integration multilingual wsd module statistical machine translation framework order improve automated translation ambiguous words consequence make translation output understandable evaluation possible improvement path current smt behavior ambiguous nouns evaluation possible improvement path current smt behavior ambiguous nouns evaluation possible improvement path current smt behavior ambiguous nouns 
paper propose several novel approaches improve phrase reordering statistical machine translation framework modeling smoothed prior probability introduced take account distortion effect priors addition propose multiple novel distortion features based syntactic parsing new metric also introduced measure effect distortion translation hypotheses show smoothed priors features help significantly improve reordering hence translation performance machine translation task improving reordering statistical machine translation smoothed priors syntactic features improving reordering statistical machine translation smoothed priors syntactic features improving reordering statistical machine translation smoothed priors syntactic features 
usually unsupervised dependency parsing tries optimize probability corpus modifying dependency model presumably used generate corpus article explore different view dependency structure among things partial order nodes terms centrality saliency assumption model partial order directly derive dependency trees order result approach unsupervised dependency parsing different standard ones requires training data sentence induces model parse read approach evaluated data different languages two scenarios considered scenario information available scenario parsing relies word forms distributional clusters approach competitive scenarios ranked words dependency trees: two-stage unsupervised non-projective dependency parsing ranked words dependency trees: two-stage unsupervised non-projective dependency parsing ranked words dependency trees: two-stage unsupervised non-projective dependency parsing 
supervised learning algorithms identifying comparable sentence pairs dominantly corpora require resources computing feature functions well training classifier paper propose active learning techniques addressing problem building comparable data languages particular propose strategies elicit two kinds annotations comparable sentence pairs class label assignment parallel segment extraction also propose active learning strategy two annotations performs significantly better sampling either annotations independently active learning multiple annotations comparable data classification task active learning multiple annotations comparable data classification task active learning multiple annotations comparable data classification task 
since two multivariate generalizations pointwise mutual information two multivariate generalizations pointwise mutual information two multivariate generalizations pointwise mutual information 
paper describes three systems university minnesota duluth participated disco shared task evaluated distributional methods measuring semantic compositionality three systems approached problem collocation identification strong collocates assumed minimally compositional duluth relies whereas rely pointwise mutual information pmi top ranked system overall coarse grained scoring category assignment pairs assigned values high medium low compositionality identifying collocations measure compositionality: shared task system description identifying collocations measure compositionality: shared task system description identifying collocations measure compositionality: shared task system description 
structural events structure clauses disfluencies spontaneous speech important components human speaking used measure language development however actively used automated speech assessment research given recent substantial progress automated structural event detection spontaneous speech investigated detection clause boundaries interruption points edit disfluencies transcriptions speech data extracted features detected events speech assessment compared features computed events features computed events show promising correlations holistic scores reflect speaking proficiency levels detecting structural events assessing non-native speech detecting structural events assessing non-native speech detecting structural events assessing non-native speech 
learning vocabulary word requires seeing multiple informative contexts describe system generate contexts given word sense rather attempt word sense disambiguation example contexts already generated selected corpus compile information word sense context generation process evaluate generated contexts compared wordnet examples three human judges chose word sense fit example blind source intended sense average one judge rated generated examples compared two judges wordnet examples although system precision half wordnet recall actually higher wordnet thanks covering many senses wordnet lacks examples generating example contexts illustrate target word sense generating example contexts illustrate target word sense generating example contexts illustrate target word sense 
paper present methodology creating concept map exercises students concept mapping common pedagogical exercise students generate graphical model domain method automatically extracts knowledge representations textbook uses generate concept maps purpose study generate evaluate concept maps according accuracy completeness pedagogy generating concept map exercises textbooks generating concept map exercises textbooks generating concept map exercises textbooks 
address problem detecting english language learner errors using discriminative sequence model unlike work method agnostic specific error types thus potentially allowing higher recall across different error types approach integrates features many sources model ranging language features linguistic analysis features evaluation results large annotated corpus learner writing indicate feasibility approach realistic noisy inherently skewed set data models consistently outperform models experiments error analysis output shows calculation precision test set represents lower bound real system performance high-order sequence modeling language learner error detection high-order sequence modeling language learner error detection high-order sequence modeling language learner error detection 
paper explore computational modelling compositionality distributional models semantics particular model semantic composition pairs adjacent english adjectives nouns british national corpus build semantic space lemmatised version bnc frequent lemma pairs treated single tokens extrapolate three different models compositionality simple additive model model partial least squares regression plsr model propose two evaluation methods implemented models study leads conclusion models compositionality generally additive multiplicative approaches also show number advantages make promising future research regression model adjective-noun compositionality distributional semantics regression model adjective-noun compositionality distributional semantics regression model adjective-noun compositionality distributional semantics 
present fast scalable online method tuning statistical machine translation models large feature sets standard tuning algorithm mert scales tens features recent discriminative algorithms accommodate sparse features produced smaller expected translation quality gains large systems method based stochastic gradient descent adaptive learning rate scales millions features tuning sets tens thousands sentences still converging epochs experiments show method produces significant translation quality gains exploiting sparse features equally important analysis suggests techniques mitigating overfitting domain mismatch applies recent discriminative methods machine translation fast adaptive online training feature-rich translation models fast adaptive online training feature-rich translation models fast adaptive online training feature-rich translation models 
present approach sentence compression tightens sentence reducing character length replacing phrases shorter paraphrases yields paraphrastic compressions short original length support task introduce novel technique paraphrases extracted bilingual corpora high compression rates paraphrastic compressions outperform deletion model oracle experiment compression deleting oracle paraphrastic compressions preserves meaning deletion alone either setting paraphrastic compression shows promise surpassing methods paraphrastic sentence compression character-based metric: tightening without deletion paraphrastic sentence compression character-based metric: tightening without deletion paraphrastic sentence compression character-based metric: tightening without deletion 
propose novel method construct semantic orientation lexicons using large data thesaurus deal large data use sketch store approximate counts word pairs bounded space gb use thesaurus like roget constrain words polarity framework easily scale language thesaurus unzipped corpus size gb billion tokens evaluate lexicons intrinsically extrinsically perform comparable compared existing lexicons generating semantic orientation lexicon using large data thesaurus generating semantic orientation lexicon using large data thesaurus generating semantic orientation lexicon using large data thesaurus 
sentiment analysis one recent highly dynamic fields natural language processing existing approaches based analysis texts able detect explicit expressions sentiment paper present approach towards automatically detecting emotions underlying components sentiment contexts clues sentiment appear based commonsense knowledge resource built towards aim emotinet knowledge base concepts associated affective value preliminary evaluations show approach appropriate task implicit emotion detection thus improving performance sentiment detection classification text detecting implicit expressions sentiment text based commonsense knowledge detecting implicit expressions sentiment text based commonsense knowledge detecting implicit expressions sentiment text based commonsense knowledge 
new trend sentiment classification use semantic features representation documents propose semantic space based wordnet senses supervised sentiment classifier show better performance sentiment classification also opens opportunities building robust sentiment classifier examine possibility using similarity metrics defined wordnet address problem finding sense training corpus using three popular similarity metrics replace unknown synsets test set similar synset training set improvement seen respect baseline using approach robust sense-based sentiment classification robust sense-based sentiment classification robust sense-based sentiment classification 
present two related tasks bionlp shared tasks bacteria gene renaming rename bacteria gene interactions gi detail objectives corpus specification evaluation metrics summarize participants results issued pubmed scientific literature abstracts rename task aims extracting gene name synonyms gi task aims extracting genic interaction events mainly gene transcriptional regulations bacteria bionlp shared task 2011 &#8211; bacteria gene interactions renaming bionlp shared task 2011 &#8211; bacteria gene interactions renaming bionlp shared task 2011 &#8211; bacteria gene interactions renaming 
paper describes system inra bibliome research group applied bacteria biotope bb task shared tasks bacteria locations host entities processed approach domain lexical resources extraction environment locations propose framework based semantic analysis ontology biotope rules dealing bacteria anaphora official results show alvis system achieves best performance systems bionlp 2011 task bacteria biotope &#8211; alvis system bionlp 2011 task bacteria biotope &#8211; alvis system bionlp 2011 task bacteria biotope &#8211; alvis system 
paper describes supporting resources provided bionlp shared task resources constructed goal alleviate burden system development participants allow focus novel aspects constructing event extraction systems availability resources also seek enable evaluation applicability specific tools representations towards improving performance event extraction systems additionally supplied evaluation software services constructed visualisation tool stav visualises event extraction results annotations resources helped participants make sure final submissions research efforts track development stages evaluate progress throughout duration shared task visualisation software also employed show differences gold annotations submitted results allowing participants better understand performance system resources evaluation tools visualisation tool provided freely research purposes found http sites google com site bionlpst bionlp shared task 2011: supporting resources bionlp shared task 2011: supporting resources bionlp shared task 2011: supporting resources 
describe system natural language processing group microsoft research bionlp shared task task focuses event extraction identifying structured potentially nested events unannotated text approach follows pipeline first decorating text syntactic information identifying trigger words complex events finally identifying arguments events resulting system depends heavily lexical syntactic features therefore explored methods maintaining ambiguities improving syntactic representations making lexical information less brittle clustering exploring novel feature combinations feature reduction system ranked th genia task rd epi task msr-nlp entry bionlp shared task 2011 msr-nlp entry bionlp shared task 2011 msr-nlp entry bionlp shared task 2011 
dependency parsers give comparable accuracies chartbased counterparts yet best shiftreduce constituent parsers still lag behind one important reason existence unary nodes phrase structure trees leads different numbers actions different outputs input turns large empirical impact framework global training beam search propose simple yet effective extension process eliminates size differences action sequences parser gives comparable accuracies chart parsers linear complexity parser order magnitude faster fastest chart parser fast accurate shift-reduce constituent parsing fast accurate shift-reduce constituent parsing fast accurate shift-reduce constituent parsing 
present dialogue collection enrichment framework designed explore learning evaluation dialogue policies simple conversational characters using textual training data facilitate learning evaluation framework enriches collection dialogues additional training data including paraphrases user utterances multiple independent judgments external referees best policy response character point case study use framework train policy limited domain tactical questioning character reaching promising performance also introduce automatic policy evaluation metric recognizes validity multiple conversational responses point dialogue use metric explore variability human opinion optimal policy decisions automatically evaluate several learned policies example domain toward learning evaluation dialogue policies text examples toward learning evaluation dialogue policies text examples toward learning evaluation dialogue policies text examples 
present new approach dialogue management based use multiple interconnected policies instead capturing complexity interaction single large policy dialogue manager operates collection small local policies combined concurrently hierarchically metacontrol policies relies activation vector updated turn multi-policy dialogue management multi-policy dialogue management multi-policy dialogue management 
paper authors present new approach sentence level sentiment analysis aim determine whether sentence expresses positive negative neutral sentiment well intensity method performs wsd words sentence order work concepts rather terms makes use knowledge affective lexicon label concepts emotional categories also deals effect negations quantifiers polarity intensity analysis extensive evaluation two different domains performed order determine method behaves classes positive negative positive negative neutral strongly negative weakly negative neutral weakly positive strongly positive classification tasks results obtained compare favorably achieved systems addressing similar evaluations hybrid approach emotional sentence polarity intensity classification hybrid approach emotional sentence polarity intensity classification hybrid approach emotional sentence polarity intensity classification 
active learning promising way sentiment classification reduce annotation cost paper focus imbalanced class distribution scenario sentiment classification wherein number positive samples quite different negative samples scenario posits new challenges active learning address challenges propose novel active learning approach named taking imbalanced class distribution issue uncertainty account specifically approach employs two feature subspace classifiers collectively select informative samples manual annotation leveraging certainty measurement uncertainty measurement meanwhile automatically label informative samples reduce humanannotation efforts extensive experiments across four domains demonstrate great potential effectiveness proposed approach active learning imbalanced sentiment classification active learning imbalanced sentiment classification active learning imbalanced sentiment classification active learning imbalanced sentiment classification 
recently discriminative word alignment methods achieved accuracies extending range information sources easily incorporated aligners chief advantage discriminative framework ability score alignments based arbitrary features matching word tokens including orthographic form predictions models lexical context however proposed bipartite matching model taskar et al despite tractable effective two important limitations first limited restriction words fertility one importantly first order correlations consecutive words cannot directly captured model work address limitations enriching model form give estimation inference algorithms enhancements best model achieves relative aer reduction basic matching formulation outperforming intersected ibm model without using overly features including predictions models features achieve aer standard hansards dataset word alignment via quadratic assignment word alignment via quadratic assignment word alignment via quadratic assignment 
develop dependency parsers arabic english chinese czech using bayes point machines training algorithm easy implement perceptron yet competitive large margin methods achieve results comparable english czech report first directed dependency parsing accuracies arabic chinese given multilingual nature experiments discuss issues regarding comparison dependency parsers different languages multilingual dependency parsing using bayes point machines multilingual dependency parsing using bayes point machines multilingual dependency parsing using bayes point machines 
present pcfg parsing algorithm uses multilevel mlctf scheme improve efficiency search best parse approach requires user specify sequence nested partitions equivalence classes pcfg nonterminals define sequence pcfgs corresponding partition nonterminals pcfg clusters nonterminals original source pcfg use results parsing coarser level grammar defined terms coarser partition prune next finer level present experiments showing algorithm work load measured total number constituents processed decreased factor ten decrease parsing accuracy compared standard cky parsing original pcfg suggest search space mlctf algorithms almost totally unexplored future work able improve significantly results multilevel coarse-to-fine pcfg parsing multilevel coarse-to-fine pcfg parsing multilevel coarse-to-fine pcfg parsing 
apply slice sampling bayesian decipherment use new decipherment framework improve machine translation compared state art algorithm approach highly scalable produces better results allows us decipher ciphertext billions tokens hundreds thousands word types high accuracy decipher large amount monolingual data improve translation achieve significant gains bleu points large scale decipherment out-of-domain machine translation large scale decipherment out-of-domain machine translation large scale decipherment out-of-domain machine translation 
tense small element sentence however error tense raise odd grammars result misunderstanding recently tense drawn attention many natural language processing applications however current statistical machine translation smt systems mainly depend translation model language model never consider make full use tense information paper propose tense models smt successfully integrate smt system via two additional features experimental results nist translation task show proposed tense models effective contributing performance improvement blue points strong baseline n-gram-based tense models statistical machine translation n-gram-based tense models statistical machine translation n-gram-based tense models statistical machine translation 
parsers use features dependencies rely decoding algorithms slow difficult generalize hand dependency parsers easily utilize features without increasing linear complexity system beyond constant paper attempt address imbalance parsing generalizing eisner algorithm handle arbitrary features higherorder dependencies generalization cost asymptotic efficiency account cube pruning decoding utilized chiang first time label tuple structural features valencies scored efficiently features parser parser achieves unlabeled accuracy labeled accuracy standard test set english faster speed reimplementation model koo et al generalized higher-order dependency parsing cube pruning generalized higher-order dependency parsing cube pruning generalized higher-order dependency parsing cube pruning 
identify problems penn treebank render imperfect syntaxbased machine translation propose methods relabeling syntax trees improve translation quality develop system incorporating handful relabeling strategies yields statistically significant improvement bleu points baseline system relabeling syntax trees improve syntax-based machine translation quality relabeling syntax trees improve syntax-based machine translation quality relabeling syntax trees improve syntax-based machine translation quality 
present approach statistical machine translation combines ideas smt traditional mt system incorporates concept translation units transfer dependency structure snippets models trains statistical components according smt systems compliant classical mt target dependency structure snippets input generator experimental evaluation shows incorporation generator smt framework provides improved grammaticality achieving quality examples suggesting possible hybrid framework grammatical machine translation grammatical machine translation grammatical machine translation 
dialog act da tags useful many applications natural language processing automatic speech recognition work introduce hidden backoff models hbms large generalized backoff model trained using embedded em procedure data partially observed use hbms word models conditioned das hidden dasegments experimental results icsi meeting recorder dialog act corpus show procedure strictly increase likelihood training data effectively reduce errors test data best case test error reduced relative baseline improvement previously reported models also use prosody also compare model show hbm competitive even without use prosody yet succeeded however combining benefits prosody hbm backoff model training using partially observed data: application dialog act tagging backoff model training using partially observed data: application dialog act tagging backoff model training using partially observed data: application dialog act tagging 
statistical machine translation minimum error rate training mert standard method tuning single weight regard given development data however due diversity uneven distribution source sentences two problems suffered method first performance highly dependent choice development set may lead unstable performance testing second translations become inconsistent sentence level since tuning performed globally document level paper propose novel local training method address two problems unlike global training method mert single weight learned used input sentences perform training testing one step learning sentencewise weight input sentence propose efficient incremental training methods put local training practice nist translation tasks local training method significantly outperforms mert maximal improvements bleu points meanwhile efficiency comparable global method locally training log-linear model smt locally training log-linear model smt locally training log-linear model smt 
present method induction concise accurate probabilistic contextfree grammars efficient use early stages parsing technique method based use statistical tests determine combination unobserved due sparse data hard syntactic constraints experimental results show using method high accuracies achieved set orders magnitude smaller typically induced probabilistic grammars leading substantial parsing approach used combination existing reranker provide competitive wsj parsing results probabilistic context-free grammar induction based structural zeros probabilistic context-free grammar induction based structural zeros probabilistic context-free grammar induction based structural zeros 
introduce gap inheritance new structural property trees provides way quantify degree intervals descendants nested based property two new classes trees derived provide closer approximation set plausible natural language dependency trees alternative classes trees unlike projective trees word descendants one interval unlike spanning trees intervals cannot nested arbitrary ways class trees exactly empirical coverage natural language sentences class mildly nonprojective trees yet optimal scoring tree found order magnitude less time trees second class property edges interval descendants come node thus algorithm uses single intervals produce trees node descendants multiple intervals dynamic programming higher order parsing gap-minding trees dynamic programming higher order parsing gap-minding trees dynamic programming higher order parsing gap-minding trees 
paper propose novel translation model tm based data selection model language model lm adaptation statistical machine translation smt word models phrase models given source sentence translation task model directly estimates probability sentence target lm training corpus similar compared traditional approaches utilize first pass translation hypotheses data selection model avoids problem noisy proliferation furthermore phrase tm based data selection model effective traditional approaches based models tm captures contextual information modeling selection phrase whole experiments conducted data sets demonstrate approach significantly outperforms approaches lm perplexity smt performance translation model based cross-lingual language model adaptation: word models phrase models translation model based cross-lingual language model adaptation: word models phrase models translation model based cross-lingual language model adaptation: word models phrase models 
paper address problem modeling compositional meaning phrases sentences using distributional methods experiment several possible combinations representation composition exhibiting varying degrees sophistication shallow others operate syntactic structure rely parameter learning require access large corpora find shallow approaches good computationally intensive alternatives regards two particular tests phrase similarity paraphrase detection sizes involved training corpora generated vectors important fit meaning representation compositional method comparison vector-based representations semantic composition comparison vector-based representations semantic composition comparison vector-based representations semantic composition 
present novel decoder grammatical error correction decoder iteratively generates new hypothesis corrections current hypotheses scores based features grammatical correctness fluency features include scores discriminative classifiers specific error categories articles prepositions unlike previous approaches method able perform correction whole sentences multiple interacting errors still taking advantage powerful existing classifier approaches decoder achieves correction score significantly higher previous published scores helping hoo shared task data set beam-search decoder grammatical error correction beam-search decoder grammatical error correction beam-search decoder grammatical error correction 
recent work semantic role labeling srl focused almost exclusively analysis structure verbs largely due lack resources types predicates serve training test data semantic role labeling systems however wellknown verbs type predicates take arguments notably nouns nominalized forms verbs relational nouns generally also considered structure paper report results srl experiments nominalized predicates chinese using newly completed corpus chinese nombank also discuss impact using publicly available manually annotated verb data improve srl accuracy nouns exploiting assumption verbs nominalizations share structure finally discuss results applying reranking techniques improve srl accuracy nominalized predicates showed insignificant improvement semantic role labeling nominalized predicates chinese semantic role labeling nominalized predicates chinese semantic role labeling nominalized predicates chinese 
paper studies impact paraphrases accuracy automatic evaluation given reference sentence sentence seek find paraphrase reference sentence closer wording machine output original reference apply paraphrasing method context machine translation evaluation experiments show use paraphrased synthetic reference refines accuracy automatic evaluation also found strong connection quality automatic paraphrases judged humans contribution automatic evaluation paraphrasing automatic evaluation paraphrasing automatic evaluation paraphrasing automatic evaluation 
proceedings human language technology conference north american chapter acl pages new york june association computational linguistics cdd cdd di ll ll cdd information-theoretic approach automatic evaluation summaries information-theoretic approach automatic evaluation summaries information-theoretic approach automatic evaluation summaries 
dependency parsers suffer sheer number higher order edges need score consider optimization show working lp relaxations large fractions edges pruned fully scored without loss optimality guarantees hence accuracy achieved iteratively parsing subset higherorder edges adding edges may improve score current solution adding edges implied current best first order edges amounts delayed column row generation lp relaxation guaranteed provide optimal lp solution second order grandparent models method considers scores second order edges full model yields eightfold parsing speedup providing empirical accuracy certificates optimality working full lp relaxation also provide tighter lp formulation grandparent models leads smaller integrality gap higher speed parse, price cut?delayed column row generation graph based parsers parse, price cut?delayed column row generation graph based parsers parse, price cut?delayed column row generation graph based parsers 
several learning methods proposed leverage unlabeled data imbalanced class distributions data set hurt performance algorithms paper adapt new approach contrast classifiers learning enables us exploit large amounts unlabeled data skewed distribution experiments speech act agreement disagreement classification problem achieve better results methods also obtain performance comparable best results reported far task outperform systems equivalent feature sets agreement/disagreement classification: exploiting unlabeled data using contrast classifiers agreement/disagreement classification: exploiting unlabeled data using contrast classifiers agreement/disagreement classification: exploiting unlabeled data using contrast classifiers 
paper evaluates benefit deleting fillers know like early parsing conversational speech readability studies shown disfluencies fillers speech repairs may deleted transcripts without compromising meaning jones et al deleting repairs prior parsing shown improve accuracy charniak johnson explore whether strategy early deletion also beneficial regard fillers reported experiments measure effect early deletion parser training conditions using parser charniak early deletion found yield modest benefit parsing significant improvement achieved adaptation suggests potentially broader role disfluency modeling adapting tools processing conversational speech early deletion fillers processing conversational speech early deletion fillers processing conversational speech early deletion fillers processing conversational speech 
goal project described paper evaluation utility latent semantic analysis lsa unsupervised word sense discrimination hypothesis lsa used compute context vectors ambiguous words clustered together cluster corresponding different sense word paper report first experimental result tightness separation purity clusters function vector space dimensionality using different distance metrics evaluation utility lsa word sense discrimination evaluation utility lsa word sense discrimination evaluation utility lsa word sense discrimination 
describe method based tweaking existing learned sequential classifier change tradeoff guided performance criterion method evaluated task recognizing personal names email newswire text proves simple effective ner systems suit user's preferences: adjusting recall-precision trade-off entity extraction ner systems suit user's preferences: adjusting recall-precision trade-off entity extraction ner systems suit user's preferences: adjusting recall-precision trade-off entity extraction 
paper use tree kernels exploit deep syntactic parsing information natural language applications study properties different kernels provide algorithms computation linear average time experiments svms task predicate argument classification provide empirical data validates methods syntactic kernels natural language learning: semantic role labeling case syntactic kernels natural language learning: semantic role labeling case syntactic kernels natural language learning: semantic role labeling case 
investigate paradigmatic representations word context domain unsupervised syntactic category acquisition paradigmatic representations word context based potential substitutes word contrast syntagmatic representations based properties neighboring words compare bigram based baseline model several paradigmatic models demonstrate significant gains accuracy best model based euclidean embedding combines paradigmatic context representation morphological orthographic features achieves accuracy word corpus learning syntactic categories using paradigmatic representations word context learning syntactic categories using paradigmatic representations word context learning syntactic categories using paradigmatic representations word context 
machine translation models shown yield better translations models since phrase pairs encode contextual information needed accurate translation however many phrase pairs encode relevant context means translation event encoded phrase pair led smaller translation events independent found smaller phrase pairs little loss translation accuracy work propose relative entropy model translation models measures likely phrase pair encodes translation event derivable using smaller translation events similar probabilities model applied phrase table pruning tests show considerable amounts phrase pairs excluded without much impact translation quality fact show better translations obtained using pruned models due compression search space decoding entropy-based pruning phrase-based machine translation entropy-based pruning phrase-based machine translation entropy-based pruning phrase-based machine translation 
trained large parallel corpora phrase table component machine translation system grows consume vast computational resources paper introduce novel pruning criterion places phrase table pruning sound theoretical foundation systematic experiments four language pairs various data conditions show principled approach superior existing ad hoc pruning methods systematic comparison phrase table pruning techniques systematic comparison phrase table pruning techniques systematic comparison phrase table pruning techniques 
present novel parser combination scheme works reparsing input sentences already parsed several different parsers apply idea dependency constituent parsing generating results surpass accuracy levels individual parsers parser combination reparsing parser combination reparsing parser combination reparsing 
word subject domains widely used improve performance word sense disambiguation algorithms however comparatively little effort devoted far disambiguation word subject domains existing approaches focused development algorithms specific word domain disambiguation paper explore alternative approach word domain disambiguation achieved via word sense disambiguation study shows approach yields strong results suggesting word domain disambiguation addressed terms word sense disambiguation need special purpose algorithms word domain disambiguation via word sense disambiguation word domain disambiguation via word sense disambiguation word domain disambiguation via word sense disambiguation 
propose subtree ranking approach parse forest reranking generalization current reranking methods training reranker extract competing local subtrees hence training instances candidate subtree sets similar used beamsearch parsing leads better parameter optimization another chief advantage framework arbitrary learning rank methods applied evaluated reranking approach german english phrase structure parsing tasks compared various reranking approaches forest reranker subtree ranking approach maximum entropy model significantly outperformed approaches forest reranking subtree ranking forest reranking subtree ranking forest reranking subtree ranking 
current work focus systems provide incremental directions monitor progress mobile users following directions directions based dynamic quantities like visibility reference points distance user intelligent navigation assistant might take advantage user mobility within setting achieve communicative goals example repositioning point description target easier produce calculating spatial variables corpus data developed study trained classifier detect contexts target object felicitously described algorithm matched human subjects precision sentence planning realtime navigational instruction sentence planning realtime navigational instruction sentence planning realtime navigational instruction 
paper proposes automatic method reading proper names multiple pronunciations first method obtains web pages include proper name pronunciation second method feeds learner classification current accuracy around open data word pronunciation disambiguation using web word pronunciation disambiguation using web word pronunciation disambiguation using web 
paper describes affinity graph based approach summarization incorporate diffusion process acquire semantic relationships sentences compute information richness sentences graph rank algorithm differentiated links links sentences greedy algorithm employed impose diversity penalty sentences sentences high information richness high information novelty chosen summary experimental results task duc task duc demonstrate proposed approach outperforms existing systems improved affinity graph based multi-document summarization improved affinity graph based multi-document summarization improved affinity graph based multi-document summarization 
present method exact optimization sampling high order hidden markov models hmms generally handled approximation techniques motivated adaptive rejection sampling heuristic search propose strategy based sequentially refining language model upper bound true model wish decode sample allows us build tractable hmms arpa format language models extended enable efficient use quantities required compute upper bound evaluate approach two problems task pos tagging experiment using models results show approach used exact optimization sampling explicitly constructing fraction total implicit exact sampling decoding high-order hidden markov models exact sampling decoding high-order hidden markov models exact sampling decoding high-order hidden markov models 
vector space models successful learning lexical information however cannot capture compositional meaning longer phrases preventing deeper understanding language introduce recursive neural network rnn model learns compositional vector representations phrases sentences arbitrary syntactic type length model assigns vector matrix every node parse tree vector captures inherent meaning constituent matrix captures changes meaning neighboring words phrases rnn learn meaning operators propositional logic natural language model obtains state art performance three different experiments predicting sentiment distributions pairs classifying sentiment labels movie reviews classifying semantic relationships nouns using syntactic path semantic compositionality recursive matrix-vector spaces semantic compositionality recursive matrix-vector spaces semantic compositionality recursive matrix-vector spaces 
paper describe hybrid approach two key nlp technologies biomedical named entity recognition system successfully integrates linguistic features crf framework addition employ web lexicons boost performance broad linguistic features nature crf system outperforms systems especially recognition protein names first construct proposition bank top popular biomedical genia treebank following propbank annotation scheme annotate structures pas thirty frequently used biomedical verbs predicates corresponding arguments second use proposition bank train biomedical srl system uses maximum entropy machinelearning model thirdly automatically generate templates used improve classification biomedical argument roles experimental results show newswire english srl system achieves newswire english domain maintain ported biomedical domain using annotated biomedical corpus increase adding automatically generated template features increases overall adjunct respectively hybrid approach biomedical named entity recognition semantic role labeling hybrid approach biomedical named entity recognition semantic role labeling hybrid approach biomedical named entity recognition semantic role labeling 
despite significant recent work purely unsupervised techniques pos tagging achieved useful accuracies required many language processing tasks use parallel text languages one source weak supervision significantly improves accuracy however parallel text always available techniques using require multiple complex algorithmic steps paper show build exceeding bilingual methods using simple hidden markov models freely available naturally growing resource wiktionary across eight languages labeled data evaluate results achieve accuracy significantly exceeds best unsupervised parallel text methods achieve highest accuracy reported several languages show approach yields better taggers trained using fully supervised penn treebank wiki-ly supervised part-of-speech tagging wiki-ly supervised part-of-speech tagging wiki-ly supervised part-of-speech tagging 
popular tradition studying semantic representation driven assumption word meaning learned linguistic environment despite ample evidence suggesting language grounded perception action paper present comparative study models represent word meaning based linguistic perceptual data linguistic information approximated naturally occurring corpora sensorimotor experience feature norms attributes native speakers consider important describing meaning word models differ terms mechanisms integrate two modalities experimental results show closer correspondence human data obtained uncovering latent information shared among textual perceptual modalities rather arriving semantic knowledge concatenating two grounded models semantic representation grounded models semantic representation grounded models semantic representation 
current dependency parsers presuppose input words morphologically disambiguated using tagger parsing begins present transitionbased system joint tagging labeled dependency parsing nonprojective trees experimental evaluation chinese czech english german shows consistent improvements tagging parsing accuracy compared pipeline system lead improved results languages transition-based system joint part-of-speech tagging labeled non-projective dependency parsing transition-based system joint part-of-speech tagging labeled non-projective dependency parsing transition-based system joint part-of-speech tagging labeled non-projective dependency parsing 
introduce two bayesian models unsupervised semantic role labeling srl task models treat srl clustering syntactic signatures arguments clusters corresponding semantic roles first model induces clusterings independently predicate exploiting chinese restaurant process crp prior refined hierarchical model inject intuition clusterings similar across different predicates even though necessarily identical intuition encoded crp distance two syntactic signatures indicating likely correspond single semantic role distances automatically induced within model shared across predicates models achieve results evaluated propbank coupled model consistently outperforming factored counterpart experimental bayesian approach unsupervised semantic role induction bayesian approach unsupervised semantic role induction bayesian approach unsupervised semantic role induction 
introduce new approach transitionbased dependency parsing parser directly construct dependency structure rather undirected graph converted directed dependency tree step alleviates error propagation since undirected parsers need observe constraint undirected parsers obtained simplifying existing parsers satisfying certain conditions apply approach obtain undirected variants planar parsers covington parser perform experiments several datasets shared task showing variants outperform original directed algorithms cases dependency parsing undirected graphs dependency parsing undirected graphs dependency parsing undirected graphs 
dependency parsers often forced make attachment decisions point partial information relevant graph configuration available paper describe model takes account complete structures become available rescore elements beam combining advantages approaches also propose efficient implementation allows use sophisticated features show completion model leads substantial increase accuracy apply new parser typologically different languages english chinese czech german report competitive labeled unlabeled attachment scores best bothworlds ?a graph-based completion model transition-based parsers best bothworlds ?a graph-based completion model transition-based parsers best bothworlds ?a graph-based completion model transition-based parsers 
nowadays large amounts data available train statistical machine translation systems however clear whether training data actually help system trained subset huge bilingual corpora might outperform use bilingual data paper studies issues analysing two training data selection techniques one based approximating probability indomain corpus another based infrequent occurrence experimental results report significant improvements random sentence selection also improvement system trained whole available data surprisingly improvements obtained small fraction data accounts less sentences afterwards show much larger room improvement exists although done conditions data always yield better translations? data always yield better translations? data always yield better translations? 
paper deal named entity recognition ner transcriptions french broadcast data two aspects make task difficult respect previous ner tasks named entities annotated used work tree structure thus task cannot tackled sequence labelling task ii data used noisy data used previous ner tasks approach task two steps involving conditional random fields probabilistic grammars integrated single parsing algorithm analyse effect using several tree representations system outperforms best system evaluation campaign significant margin tree representations probabilistic models extended named entities detection tree representations probabilistic models extended named entities detection tree representations probabilistic models extended named entities detection 
paper compare three different generalization methods opinion holder extraction simple unsupervised word clustering induction method inspired distant supervision usage lexical resources generalization methods incorporated diverse classifiers show generalization causes significant improvements impact improvement depends type classifier much training test data differ also address less common case opinion holders realized patient position suggest approaches including novel linguisticallyinformed extraction method detect opinion holders without labeled training data standard datasets contain instances type generalization methods in-domain cross-domain opinion holder extraction generalization methods in-domain cross-domain opinion holder extraction generalization methods in-domain cross-domain opinion holder extraction 
becoming clear traditional evaluation measures used computational linguistics including error rates accuracy recall precision limited value unbiased evaluation systems meaningful comparison algorithms unless dataset algorithm parameters strictly controlled skew prevalence bias use techniques originally designed purposes particular receiver operating characteristics area curve plus variants kappa proposed fill void paper aims clear confusion relating evaluation demonstrating usefulness evaluation method highly dependent assumptions made distributions dataset underlying populations behaviour number evaluation measures compared common assumptions deploying system context opposite skew validation set expected approximately negate fleiss kappa halve cohen kappa leave powers kappa unchanged performance evaluation purposes latter thus appropriate whilst comparison behaviour matthews correlation recommended problem kappa problem kappa problem kappa 
paper address statistical machine translation public conference talks modeling style genre challenging given shortage available training data investigate use hybrid lm infrequent words mapped classes hybrid lms used complement lms statistics language style talks extensive experiments comparing different settings hybrid lm reported publicly available benchmarks based ted talks arabic english english french proposed models show better exploit data conventional lms target language modeling component statistical machine translation system cutting long tail: hybrid language models translation style adaptation cutting long tail: hybrid language models translation style adaptation cutting long tail: hybrid language models translation style adaptation 
previous work treebank parsing discontinuous constituents using linear rewriting systems lcfrs limited sentences words reasons computational complexity results binarizing lcfrs manner minimizes parsing complexity present work shows parsing long sentences optimally binarized grammar remains infeasible instead introduce technique removes length restriction maintaining respectable accuracy resulting parser applied discontinuous treebank favorable results efficient parsing linear context-free rewriting systems efficient parsing linear context-free rewriting systems efficient parsing linear context-free rewriting systems 
search patent databases risky business compared search domains single document relevant overlooked patent search turn expensive proposition recent research engages specialized models algorithms improve effectiveness patent retrieval bring another aspect focus detection exploitation patent inconsistencies particular analyze spelling errors assignee field patents granted united states patent trademark office introduce technology order improve retrieval effectiveness despite presence typographical ambiguities regard quantify spelling errors terms edit distance phonological dissimilarity render error detection learning problem combines word dissimilarities patent task finding patents company approach improves recall using patent search engine precision compromised impact spelling errors patent search impact spelling errors patent search impact spelling errors patent search 
composition procedure linear nondeleting extended tree transducers presented demonstrated new procedure widely applicable existing methods general result composition extended tree transducer longer linear nondeleting number cases properties easily recovered step composing extended top-down tree transducers composing extended top-down tree transducers composing extended top-down tree transducers 
propose machine translation system allows users select news category translate related live news articles arabic czech danish farsi french german italian polish portuguese spanish turkish english system optimised news domain differs available systems four ways news items automatically categorised source side translation named entity translation optimised recognising extracting source side translation target language making use separate entity repository news titles translated separate translation system optimised specific style news titles system optimised speed order cope large volume daily news articles onts: optima news translation system onts: optima news translation system onts: optima news translation system 
work address challenge augmenting language models according prior linguistic intuitions argue family hierarchical language models attractive vehicle address problem demonstrate approach proposing model german compounds empirical evaluation model outperforms model terms perplexity achieves preliminary improvements translation hierarchical bayesian language modelling linguistically informed hierarchical bayesian language modelling linguistically informed hierarchical bayesian language modelling linguistically informed 
null subjects non overtly expressed subject pronouns found languages italian spanish study quantify compare occurrence phenomenon two languages next evaluate null subjects translation french non prodrop language use europarl corpus evaluate two mt systems performance regarding null subject translation system developed latl statistical system built using moses toolkit add preprocessor statistical translation pipeline second evaluation improved system shows average increase correct translations improving machine translation null subjects italian spanish improving machine translation null subjects italian spanish improving machine translation null subjects italian spanish 
dependency parsing schemata mildly dependency parsing carlos go guez universidade da corun spain john carroll university sussex uk david weir university sussex uk introduce dependency parsing schemata formal framework based sikkel parsing schemata constituency parsers used describe analyze compare dependency parsing algorithms use framework describe several projective dependency parsers build correctness proofs establish formal relationships use framework define new parsing algorithms various mildly dependency formalisms including structures gap degree bounded constant time new class includes gap degree structures present several natural language treebanks call mildly structures gap degree time finally illustrate parsing schema framework applied link grammar formalism dependency parsing schemata mildly non-projective dependency parsing dependency parsing schemata mildly non-projective dependency parsing dependency parsing schemata mildly non-projective dependency parsing 
framework compositionality distributional semantics daoud clarke university hertfordshire formalizing meaning context mathematically leads new algebraic theory meaning composition bilinear associative properties shared methods proposed literature including tensor product vector addition pointwise multiplication matrix multiplication entailment represented vector lattice ordering inspired strengthened form distributional hypothesis degree entailment defined form conditional probability approaches task recognizing textual entailment including use subsequence matching lexical entailment probability latent dirichlet alocation described within framework context-theoretic framework compositionality distributional semantics context-theoretic framework compositionality distributional semantics context-theoretic framework compositionality distributional semantics 
use modality negation syntactic mt kathryn baker department defense michael bloodgood university maryland bonnie dorr university maryland chris johns hopkins university nathaniel filardo johns hopkins university christine piatko johns hopkins university lori levin carnegie mellon university scott miller bbn technologies department defense savage rd suite fort meade md kathrynlb gmail com center advanced study language university maryland nd avenue college park md meb umd edu department computer science umiacs university maryland av williams building college park md bonnie umiacs umd edu center language speech processing johns hopkins university charles street hackerman hall baltimore md ccb nwf cs jhu edu applied physics laboratory johns hopkins university johns hopkins rd laurel md christine piatko jhuapl edu carnegie technologies institute carnegie mellon university pittsburgh pa lsl cs cmu edu bnn technologies moulton street cambridge ma smiller bbn com submission received march revised submission received september accepted publication november association computational linguistics computational linguistics volume number article describes efforts johns hopkins university human language technology center excellence summer camp applied language exploration semantically informed machine translation simt describe new modality negation mn annotation scheme creation publicly available mn lexicon two automated mn taggers built using annotation scheme lexicon annotation scheme isolates three components modality negation trigger word conveys modality negation target action associated modality negation holder experiencer modality describe mn lexicon produced demonstrate mn tagger results precision around depending genre tagging standard ldc data set apply mn annotation scheme statistical machine translation using syntactic framework supports inclusion semantic annotations syntactic tags enriched semantic annotations modality negation simt use modality negation semantically-informed syntactic mt modality negation simt use modality negation semantically-informed syntactic mt modality negation simt use modality negation semantically-informed syntactic mt 
empirical risk minimization probabilistic grammars sample complexity hardness learning shay cohen columbia university noah smith carnegie mellon university probabilistic grammars generative statistical models useful compositional sequential structures used ubiquitously computational linguistics present framework reminiscent structural risk minimization empirical risk minimization probabilistic grammars using derive sample complexity bounds framework apply supervised setting unsupervised setting making assumptions underlying distribution appropriate natural language scenarios able derive sample complexity bounds probabilistic grammars also give simple algorithms carrying empirical risk minimization using framework supervised unsupervised settings unsupervised case show problem minimizing empirical risk therefore suggest approximate algorithm similar minimize empirical risk empirical risk minimization probabilistic grammars: sample complexity hardness learning empirical risk minimization probabilistic grammars: sample complexity hardness learning empirical risk minimization probabilistic grammars: sample complexity hardness learning 
modeling regular polysemy study semantic classification catalan adjectives gemma boleda universitat pompeu fabra sabine schulte im walde university stuttgart toni badia universitat pompeu fabra present study automatic acquisition semantic classes catalan adjectives distributional morphological information particular emphasis polysemous adjectives aim distinguish characterize broad classes qualitative gran big relational pulmonar pulmonary adjectives well identify polysemous adjectives econo mic economic cheap specifically aim modeling regular polysemy types sense alternations shared across lemmata date semantic classes adjectives regular polysemy sparsely addressed empirical computational linguistics two main specific questions tackled article first adequate broad semantic classification adjectives provide empirical support qualitative relational classes defined theoretical work uncover one type adjective received enough attention namely class second regular polysemy best modeled computational terms present two models argue second one models regular polysemy terms simultaneous membership multiple basic classes theoretically empirically adequate first one attempts identify independent polysemous classes best classifier achieves accuracy baseline modeling regular polysemy: study semantic classification catalan adjectives modeling regular polysemy: study semantic classification catalan adjectives modeling regular polysemy: study semantic classification catalan adjectives 
chart constraints reduced complexity parsing pipelines brian roark oregon health science university kristy hollingshead university maryland nathan bodenstab oregon health science university present methods reducing complexity parsing pipeline via hard constraints derived perform predictions determine word input sentence may begin end constituent chart cells spanning two words allow constituents chart cells spanning word constraints prune search space parsing algorithm significantly decrease decoding time many cases cell population reduced zero term chart cell closing present methods closing sufficient number chart cells ensure provably quadratic even linear complexity inference addition apply high precision constraints achieve large speedups combine high precision bound constraints achieve superior performance short long strings bounds processing achieved without reducing parsing accuracy cases accuracy improves demonstrate method generalizes across multiple grammars complementary pruning techniques presenting empirical results exact approximate inference using exhaustive cky algorithm charniak parser berkeley parser also report results parsing chinese achieve best reported results individual model commonly reported data set finite-state chart constraints reduced complexity context-free parsing pipelines finite-state chart constraints reduced complexity context-free parsing pipelines finite-state chart constraints reduced complexity context-free parsing pipelines 
semantic role labeling implicit arguments nominal predicates matthew gerber university virginia joyce chai michigan state university nominal predicates often carry implicit arguments recent work semantic role labeling focused identifying arguments within local context predicate implicit arguments however systematically examined address limitation manually annotated corpus implicit arguments ten predicates nombank analysis corpus find implicit arguments add argument structures present nombank using corpus train discriminative model able identify implicit arguments score significantly outperforming informed baseline model article describes investigation explores wide variety features important task discusses future directions work implicit argument identification semantic role labeling implicit arguments nominal predicates semantic role labeling implicit arguments nominal predicates semantic role labeling implicit arguments nominal predicates 
language models machine translation original vs translated texts gennadi lembersky university haifa noam ordan university haifa shuly wintner university haifa investigate differences language models compiled original texts compiled texts manually translated target language corroborating established observations translation studies demonstrate latter significantly better predictors translated sentences former hence fit reference set better furthermore translated texts yield better language models statistical machine translation original texts language models machine translation: original vs. translated texts language models machine translation: original vs. translated texts language models machine translation: original vs. translated texts 
conditional random fields crfs popular formalism structured prediction nlp well known train crfs certain topologies admit exact inference crfs nlp phenomena however suggest crfs complex topologies models used considering make exact inference intractable stoyanov et al recently argued training parameters minimize loss whatever approximate inference decoding methods used test time apply method three nlp problems showing using complex crfs leads improved performance ii minimumrisk training learns accurate models minimum-risk training approximate crf-based nlp systems minimum-risk training approximate crf-based nlp systems minimum-risk training approximate crf-based nlp systems 
existing theory structured prediction assumes exact inference often intractable many practical problems leads routine use approximate inference beam search much theory behind based structured perceptron propose general framework perceptrons inexact search theoretical guarantee convergence new separability conditions framework subsumes justifies popular heuristic perceptron beam search collins roark also propose several new update methods within framework among method dramatically reduces training time fold compared earlyupdate tagging incremental parsing systems structured perceptron inexact search structured perceptron inexact search structured perceptron inexact search 
common knowledge translation ambiguous mapping process date community produced empirical estimates ambiguity developed annotation tool enables us create representations compactly encode exponential number correct translations sentence findings show naturally occurring sentences billions translations access large sets translations enables us develop new metric hyter translation accuracy show metric provides better estimates machine human translation accuracy alternative evaluation metrics motivation last decade automatic evaluation metrics papineni et al snover et al lavie denkowski helped researchers accelerate pace improve machine translation mt systems metrics snover et al enabled supported government sponsored programs darpa gale olive et al however metrics started show signs wear tear automatic metrics often criticized providing scores researchers explain casual users bleu score means researchers grown increasingly concerned automatic metrics strong bias towards preferring statistical translation outputs nist matr gao et al wmt et al evaluations held last five years provided ample evidence automatic metrics yield results inconsistent human evaluations comparing statistical human outputs contrast metrics deficiencies large variance across human judges bojar et al produce unstable results one evaluation another przybocki et al evaluation scores computed automatically systems developers cannot automatically tune metrics table summarizes dimensions along evaluation metrics well strengths weaknesses automatic humaninformed metrics proposed hyter: meaning-equivalent semantics translation evaluation hyter: meaning-equivalent semantics translation evaluation hyter: meaning-equivalent semantics translation evaluation 
paper seeks close gap training algorithms used statistical machine translation machine learning specifically framework empirical risk minimization review algorithms arguing optimize loss functions assumed optimize applied machine translation instead implicit connections particular forms ramp loss propose minimize ramp loss directly present training algorithm easy implement performs comparably others notably structured ramp loss minimization algorithm rampion less sensitive initialization random seeds standard approaches structured ramp loss minimization machine translation structured ramp loss minimization machine translation structured ramp loss minimization machine translation 
present online learning algorithm statistical machine translation smt based stochastic gradient descent sgd online setting rank learning loss approximated batch local loss optimizing evaluation measures cannot linearly decomposed loss bleu propose variant sgd larger batch size parameter update iteration optimized algorithm learning efficiently parallelized line search performed round merging parameters across parallel jobs experiments nist open mt task indicate significantly better translation results optimized online rank learning machine translation optimized online rank learning machine translation optimized online rank learning machine translation 
introduce method learning predict text completion given source text partial translation approach predictions offered aimed alleviating users burden lexical grammar choices improving productivity method involves learning phraseology translation equivalents source translation prefix sliced ngrams generate rank completion candidates displayed users present prototype writing assistant transahead applies method translation language learning preliminary results show method great potentials cat call significant improvement translation quality across users transahead: computer-assisted translation writing tool transahead: computer-assisted translation writing tool transahead: computer-assisted translation writing tool 
paper proposes improved approach extractive summarization spoken interaction integrated random walk performed graph constructed topical lexical relations utterance represented node graph edges weights computed topical similarity utterances evaluated using probabilistic latent semantic analysis plsa word overlap model topics partially sharing topics speaker graph paper perform experiments automatically manually generated transcripts automatic transcripts results show topic sharing integrating topical lexical relations help include important utterances intra-speaker topic modeling improved multi-party meeting summarization integrated random walk intra-speaker topic modeling improved multi-party meeting summarization integrated random walk intra-speaker topic modeling improved multi-party meeting summarization integrated random walk 
investigate language model combines morphological shape features model test large crosslingual study european languages even though model generic use architecture features languages model achieves reductions perplexity languages represented europarl corpus ranging show almost perplexity reduction achieved identifying suffixes frequency comparative investigation morphological language modeling languages european union comparative investigation morphological language modeling languages european union comparative investigation morphological language modeling languages european union 
long observed monolingual text exhibits tendency toward one sense per discourse argued related one translation per discourse constraint operative bilingual contexts well paper introduce novel method using forced decoding confirm validity constraint demonstrate exploited order improve machine translation quality three ways incorporating preference hierarchical mt model proposed approach three combined yields greatest improvements chineseenglish translation experiments encouraging consistent translation choices encouraging consistent translation choices encouraging consistent translation choices 
proliferation recent work smt tuning algorithms capable handling larger feature sets traditional mert approach analyze number algorithms terms sentencelevel loss functions motivates several new approaches including structured svm perform empirical comparisons eight different tuning strategies including mert variety settings among results find simple efficient batch version mira performs least well training online consistently outperforms options batch tuning strategies statistical machine translation batch tuning strategies statistical machine translation batch tuning strategies statistical machine translation 
conventional telephone conversation two speakers language interaction speakers process information stream incrementally work address problem incremental translation enables communication two remote participants telephone investigate problem novel session initiation protocol sip based framework speech translation performed incrementally based generation partial hypotheses speech recognition describe statistical models comprising system sip architecture enabling dialog present dialog experiments performed framework study tradeoff accuracy versus latency incremental speech translation experimental results demonstrate high quality translations generated incremental approach approximately half latency associated nonincremental approach real-time incremental speech-to-speech translation dialogs real-time incremental speech-to-speech translation dialogs real-time incremental speech-to-speech translation dialogs 
negated statements often carry positive implicit meaning regardless semantic representation one adopts pinpointing positive concepts within negated statement needed order encode statement meaning paper novel ideas reveal positive implicit meaning using focus negation presented concept granularity focus introduced justified new annotation features detect focus discussed results reported fine-grained focus pinpointing positive implicit meaning negated statements fine-grained focus pinpointing positive implicit meaning negated statements fine-grained focus pinpointing positive implicit meaning negated statements 
paper presents novel approach inducing lexical taxonomies automatically text recast learning problem inferring hierarchy graph whose nodes represent taxonomic terms edges degree relatedness model takes graph representation input fits taxonomy via combination maximum likelihood approach monte carlo sampling algorithm essentially method works sampling hierarchical structures probability proportional likelihood produce input graph use model infer taxonomy nouns show outperforms popular flat hierarchical clustering algorithms taxonomy induction using hierarchical random graphs taxonomy induction using hierarchical random graphs taxonomy induction using hierarchical random graphs 
introduce lightly supervised learning dependency parsing paradigm algorithm initiated parser one built based limited amount fully annotated training data algorithm iterates unlabeled sentences asks single bit feedback rather full parse tree specifically given example algorithm outputs two possible parse trees receives single bit indicating two alternatives correct edges direct information correctness edge show dependency parsing tasks languages fully labeled data remaining training data algorithm achieves average lower performance training fully annotated training set also evaluate algorithm different feedback settings show robustness noise training dependency parser using light feedback training dependency parser using light feedback training dependency parser using light feedback 
inference shown robust approximate method improving efficiency structured prediction models preserving accuracy propose architecture dependency parsing using vine pruning structured prediction cascades models achieve accuracies comparable unpruned counterparts exploring fraction search space observe two orders magnitude compared exhaustive search pruned model twice fast unpruned model also compares favorably parser multiple languages vine pruning efficient multi-pass dependency parsing vine pruning efficient multi-pass dependency parsing vine pruning efficient multi-pass dependency parsing 
area machine translation mt system combination previous work generating input hypotheses focused varying core aspect mt system decoding algorithm alignment algorithm paper propose new method generating diverse hypotheses single mt system using traits traits simple properties mt output average output length average rule length method designed select hypotheses vary trait value significantly degrade bleu score hypotheses combined using standard system combination techniques produce bleu gain nist mt mt translation task trait-based hypothesis selection machine translation trait-based hypothesis selection machine translation trait-based hypothesis selection machine translation 
grammars de gispert et al introduced reduce hiero translation model chiang resulting much faster decoding restricting reordering desired level specific language pairs however grammars require parameters cannot directly optimized using minimum tuning decoder paper introduces novel improvements translation model grammars introduce two rules reordering glue rule simpler monotonic concatenation rule use separate features new rules loglinear model allowing decoder directly optimize feature weights show formulation hierarchical phrasebased translation comparable translation quality full decoding without shallow rules time considerably faster improved reordering shallow-n grammar based hierarchical phrase-based translation improved reordering shallow-n grammar based hierarchical phrase-based translation improved reordering shallow-n grammar based hierarchical phrase-based translation 
propose tuning method statistical machine translation based pairwise ranking approach hopkins may presented method uses binary classifier work use linear regression show approach effective using binary classifier converges faster tuning linear regression tuning linear regression tuning linear regression 
describe evaluate several methods estimating confidence correctness predicted dependency parse show empirically confidence associated probability edge selected correctly used detect incorrect edges efficiently evaluate methods parsing text languages sure? confidence prediction dependency tree edges sure? confidence prediction dependency tree edges sure? confidence prediction dependency tree edges 
investigate models unsupervised learning concave functions begin example ibm model word alignment brown et al analyze properties discussing models unsupervised learning seldom concave present concave models dependency grammar induction validate experimentally find concave models effective initializers dependency model klein manning show encode linguistic knowledge improved performance concavity initialization unsupervised dependency parsing concavity initialization unsupervised dependency parsing concavity initialization unsupervised dependency parsing 
paper investigate use temporal information improving extractive summarization historical articles method clusters sentences based timestamps temporal similarity resulting cluster assigned importance score used weight traditional sentence ranking techniques temporal importance weighting offers consistent improvements baseline systems summarization historical articles using temporal event clustering summarization historical articles using temporal event clustering summarization historical articles using temporal event clustering 
present general framework containing graded spectrum expectation maximization em algorithms called unified expectation maximization uem uem parameterized single parameter covers existing algorithms like standard em hard em constrained versions em constraintdriven learning chang et al posterior regularization ganchev et al along range new em algorithms constrained inference step uem present efficient dual projected gradient ascent algorithm generalizes several dual decomposition lagrange relaxation algorithms popularized recently nlp literature ganchev et al koo et al rush collins uem efficient easy implement standard em furthermore experiments pos tagging information extraction show often best performing algorithm uem family new algorithm wasn available earlier exhibiting benefits uem framework unified expectation maximization unified expectation maximization unified expectation maximization 
accuracy many natural language processing tasks improved reranking step involves selecting single output list candidate outputs generated baseline system propose novel family reranking algorithms based learning separate embeddings task input output spaces embedding learned way prediction becomes search done computationally efficiently key quality approach feature engineering done separately input output spaces relationship inputs outputs learned automatically experiments tagging task four languages show significant improvements baseline decoder existing reranking approaches low-dimensional discriminative reranking low-dimensional discriminative reranking low-dimensional discriminative reranking 
propose unsupervised method clustering translations word translations cluster share common semantic sense words assigned clusters based usage distribution large monolingual parallel corpora using algorithm addition describing approach formalize task translation sense clustering describe procedure leverages wordnet evaluation comparing induced clusters reference clusters generated wordnet demonstrate method effectively identifies translation clusters benefits monolingual parallel corpora finally describe method annotating clusters usage examples unsupervised translation sense clustering unsupervised translation sense clustering unsupervised translation sense clustering 
introduce automatic annotation noun phrases parsed sentences tags semantic animacy hierarchy information interest within lexical semantics potential value feature several nlp tasks train discriminative classifier annotated corpus spoken english features capturing noun phrase constituent words internal structure syntactic relations key words sentence first two three feature sets substantial impact performance resulting model able fairly accurately classify new data corpus shows promise binary animacy classification use automatically parsed text automatic animacy classification automatic animacy classification automatic animacy classification 
statistical natural language processing nlp builds models language based statistical features extracted input text investigate deep learning methods unsupervised feature learning nlp tasks recent results indicate features learned using deep learning methods silver bullet always lead improved results work hypothesise result disjoint training protocol results mismatched word representations classifiers also hypothesise modelling dependencies input separately output layers would improve performance suggest methods overcoming limitations form part final thesis work deep unsupervised feature learning natural language processing deep unsupervised feature learning natural language processing deep unsupervised feature learning natural language processing 
demonstrate conversational humanoid robot allows users follow dialogue structures system uses hierarchy reinforcement learning dialogue agents support transitions across order relax strictness hierarchical control therefore support flexible interactions demonstrate system nao robot playing two versions quiz game whilst language input dialogue control autonomous wizarded language output provided robot combining verbal contributions novel features system flexibility given users navigate flexibly interaction framework investigating adaptive flexible dialogues interactive humanoid robot exhibiting flexible sub-dialogues interactive humanoid robot exhibiting flexible sub-dialogues interactive humanoid robot exhibiting flexible sub-dialogues 
parallel data domain interest key resource training statistical machine translation smt system specific purpose since manual translation represent significant investment time money prior assesment amount training data required achieve satisfactory accuracy level useful work show predict learning curve would look like manually translate increasing amounts data consider two scenarios monolingual samples source target languages available additional small amount parallel corpus also available propose methods predicting learning curves scenarios prediction learning curves machine translation prediction learning curves machine translation prediction learning curves machine translation 
paper presents probabilistic framework combines multiple knowledge sources haptic voice recognition hvr multimodal input method designed provide efficient text entry modern mobile devices hvr extends conventional voice input allowing users provide complementary partial lexical information via touch input improve efficiency accuracy voice recognition paper investigates use initial letter words utterance partial lexical information addition acoustic language models used automatic speech recognition systems hvr uses haptic partial lexical models additional knowledge sources reduce recognition search space suppress confusions experimental results show word error rate runtime factor reduced factor two using hvr probabilistic integration partial lexical information noise robust haptic voice recognition probabilistic integration partial lexical information noise robust haptic voice recognition probabilistic integration partial lexical information noise robust haptic voice recognition 
paper demonstrate accurate machine translation possible without concept words treating mt problem transformation character strings achieve result applying phrasal inversion transduction grammar alignment techniques character strings train translation model using mt framework also propose parsing algorithm prior probabilities achieve effective efficient alignment evaluation demonstrate translation achieve results compare systems effectively translating unknown uncommon words several language pairs machine translation without words substring alignment machine translation without words substring alignment machine translation without words substring alignment 
previous parsing models increase decoding complexity use features due decoding paper present approach enriching feature representations dependency parsing models using dependency language model beam search dependency language model built additional autoparsed data processed baseline parser based dependency language model represent set features parsing model finally features efficiently integrated parsing model decoding using beam search approach two advantages firstly utilize rich features defined view large scope additional large raw corpus secondly approach increase decoding complexity evaluate proposed approach english chinese data experimental results show new parser achieves best accuracy chinese data comparable accuracy best known systems english data utilizing dependency language models graph-based dependency parsing models utilizing dependency language models graph-based dependency parsing models utilizing dependency language models graph-based dependency parsing models 
introduce spectral learning algorithm pcfgs petrov et al separability singular value condition prove method provides consistent parameter estimates spectral learning latent-variable pcfgs spectral learning latent-variable pcfgs spectral learning latent-variable pcfgs 
paper propose innovative representations automatic classification verbs according mainstream linguistic theories namely verbnet framenet first syntactic semantic structures capturing essential lexical syntactic properties verbs defined design advanced similarity functions structures semantic tree kernel functions exploiting distributional grammatical information support vector machines extensive empirical analysis verbnet class frame detection shows models capture meaningful syntactic semantic structures allows improving verb classification using distributional similarity syntactic semantic structures verb classification using distributional similarity syntactic semantic structures verb classification using distributional similarity syntactic semantic structures 
previous research conflicting conclusions whether word sense disambiguation wsd systems improve information retrieval ir performance paper propose method estimate sense distributions short queries together senses predicted words documents propose novel approach incorporate word senses language modeling approach ir also exploit integration synonym relations experimental results standard trec collections show using word senses tagged supervised wsd system obtain significant improvements ir system word sense disambiguation improves information retrieval word sense disambiguation improves information retrieval word sense disambiguation improves information retrieval 
paper address issue learning better translation consensus machine translation mt research explore search translation consensus similar rather source sentences spans unlike previous work topic formulate problem structured labeling much smaller graph propose novel structured label propagation task convert translation consensus similar source strings useful features output reranking decoding algorithm experimental results show method significantly improve machine translation performance iwslt nist data compared baseline learning translation consensus structured label propagation learning translation consensus structured label propagation learning translation consensus structured label propagation 
two decades invention ibm translation models widely available giza toolkit remain dominant approach word alignment integral part many statistical translation systems although many models surpassed accuracy none supplanted practice paper propose simple extension ibm models prior encourage sparsity translation model explain implement extension efficiently data also released modification giza demonstrate experiments czech arabic chinese urdu english translation significant improvements ibm model word alignment translation quality bleu smaller alignment models better translations: unsupervised word alignment l0-norm smaller alignment models better translations: unsupervised word alignment l0-norm smaller alignment models better translations: unsupervised word alignment l0-norm 
paper presents novel method suggest long word reorderings smt decoder address language pairs long reordering concentrates patterns use fuzzy rules predict likely reorderings phenomena use reordered lms rank resulting permutations select translation finally encode reorderings modifying selected entries distortion cost matrix basis way expand search space much finer degree simply raised distortion limit proposed techniques tested using smt benchmarks modified distortion matrices phrase-based statistical machine translation modified distortion matrices phrase-based statistical machine translation modified distortion matrices phrase-based statistical machine translation 
optimising one grammatical representation evaluating different one particular challenge parsers ccg parsing find mismatch causes many ccg parses semantically equivalent describe hashing technique eliminates problem improving oracle reranking accuracy also present comprehensive analysis errors made ccg parser providing first breakdown impact implementation decisions supertagging parsing accuracy dependency hashing n-best ccg parsing dependency hashing n-best ccg parsing dependency hashing n-best ccg parsing 
amount labeled sentiment data english much larger languages disproportion arouse interest sentiment classification aims conduct sentiment classification target language chinese using labeled data source language english existing work relies machine translation engines directly adapt labeled data source language target language approach suffers limited coverage vocabulary machine translation results paper propose generative mixture model clmm leverage unlabeled bilingual parallel data fitting parameters maximize likelihood bilingual parallel data proposed model learns previously unseen sentiment words large bilingual parallel data improves vocabulary coverage significantly experiments multiple data sets show clmm consistently effective two settings labeled data target language unavailable labeled data target language also available cross-lingual mixture model sentiment classification cross-lingual mixture model sentiment classification cross-lingual mixture model sentiment classification 
sequential modeling widely used variety important applications including named entity recognition shallow parsing however real time tagging applications arise decoding speed become bottleneck existing sequential tagging algorithms paper propose iterative iterative viterbi algorithms sequential decoding show efficiency proposed algorithms five nlp tagging tasks particular show iterative viterbi decoding several times orders magnitude faster algorithm tagging tasks large number labels algorithm makes tagging applications thousands labels feasible iterative viterbi a* algorithm k-best sequential decoding iterative viterbi a* algorithm k-best sequential decoding iterative viterbi a* algorithm k-best sequential decoding 
bootstrapping classifier small set seed rules viewed propagation labels examples via features shared paper introduces novel variant yarowsky algorithm based view bootstrapping learning method uses graph propagation algorithm well defined objective function experimental results show proposed bootstrapping algorithm achieves state art performance better several different natural language data sets bootstrapping via graph propagation bootstrapping via graph propagation bootstrapping via graph propagation 
previous work using topic model statistical machine translation smt explore topic information word level however smt advanced paradigm phrase paradigm therefore propose topic similarity model exploit topic information synchronous rule level hierarchical translation associate synchronous rule topic distribution select desirable rules according similarity topic distributions given documents show model significantly improves translation performance baseline nist translation experiments model also achieves better performance faster speed previous approaches work word level topic similarity model hierarchical phrase-based translation topic similarity model hierarchical phrase-based translation topic similarity model hierarchical phrase-based translation 
classically training relation extractors relies manually annotated training data expensive obtain mitigate cost nlu researchers considered two newly available sources less expensive potentially lower quality labeled data distant supervision crowd sourcing however study comparing relative impact two sources precision recall answers fill gap empirically study techniques affected scaling two sources use corpus sizes million documents tens thousands labeled examples experiments show increasing corpus size distant supervision statistically significant positive impact quality score contrast human feedback positive statistically significant lower impact precision recall big data versus crowd: looking relationships right places big data versus crowd: looking relationships right places big data versus crowd: looking relationships right places 
unsupervised word representations useful nlp tasks inputs learning algorithms extra word features nlp systems however models built local context one representation per word problematic words often polysemous global context also provide useful information learning word meanings present new neural network architecture learns word embeddings better capture semantics words incorporating local global document context accounts homonymy polysemy learning multiple embeddings per word introduce new dataset human judgments pairs words sentential context evaluate model showing model outperforms competitive baselines neural language models improving word representations via global context multiple word prototypes improving word representations via global context multiple word prototypes improving word representations via global context multiple word prototypes 
many machine translation mt evaluation metrics shown correlate better human judgment bleu principle tuning metrics yield better systems tuning bleu however due issues speed requirements linguistic resources optimization difficulty widely adopted tuning paper presents port new mt evaluation metric combines precision recall ordering metric primarily designed tuning mt systems port require external resources quick compute better correlation human judgment bleu compare mt systems baselines five experimental conditions involving four language pairs port tuning achieves consistently better performance bleu tuning according four automated metrics including bleu human evaluation comparisons outputs source sentences human judges preferred output time vs bleu tuning preferences ties port: precision-order-recall mt evaluation metric tuning port: precision-order-recall mt evaluation metric tuning port: precision-order-recall mt evaluation metric tuning 
statistical machine translation often faced problem combining training data many diverse sources single translation model translate sentences new domain propose novel approach ensemble decoding combines number translation systems dynamically decoding step paper evaluate performance domain adaptation setting translate sentences medical domain experimental results show ensemble decoding outperforms various strong baselines including mixture models current domain adaptation machine translation mixing multiple translation models statistical machine translation mixing multiple translation models statistical machine translation mixing multiple translation models statistical machine translation 
present hierarchical translation model seen compromise hierarchical phrasebased model model combine merits two models help shallow parsing model learns rules consisting words chunks meanwhile introduce syntax cohesion weighed synchronous grammar defined rules model searches best translation derivation yields target translation simultaneously experiments show model significantly outperforms hierarchical phrasebased model model translation tasks hierarchical chunk-to-string translation hierarchical chunk-to-string translation hierarchical chunk-to-string translation 
propose simple generative syntactic language model conditions overlapping windows tree context treelets way language models condition overlapping windows linear context estimate parameters model collecting counts automatically parsed text using standard language model estimation techniques allowing us train model one billion tokens data using single machine matter hours evaluate perplexity range grammaticality tasks find perform well better models generative baselines model even competes discriminative models grammaticality tasks despite training positive data alone also show fluency improvements preliminary machine translation experiment large-scale syntactic language modeling treelets large-scale syntactic language modeling treelets large-scale syntactic language modeling treelets 
propose novel approach improve smt via paraphrase rules automatically extracted bilingual training data without using extra paraphrase resources acquire rules comparing source side parallel corpus translations target side besides word phrase paraphrases acquired paraphrase rules mainly cover structured paraphrases sentence level rules employed enrich smt inputs translation quality improvement experimental results show proposed approach achieves significant improvements points bleu oral domain points news domain improve smt quality automatically extracted paraphrase rules improve smt quality automatically extracted paraphrase rules improve smt quality automatically extracted paraphrase rules 
polarity classification words important applications opinion mining sentiment analysis number sentiment word sense dictionaries manually semi automatically constructed dictionaries substantial inaccuracies besides obvious instances word appears different polarities different dictionaries dictionaries exhibit complex cases cannot detected mere manual inspection introduce concept polarity consistency words senses sentiment dictionaries paper show consistency problem reduce polarity consistency problem satisfiability problem utilize fast sat solver detect inconsistencies sentiment dictionary perform experiments four sentiment dictionaries wordnet polarity consistency checking sentiment dictionaries polarity consistency checking sentiment dictionaries polarity consistency checking sentiment dictionaries 
ideal summarization system produce summaries high content coverage linguistic quality many summarization systems focus content coverage extracting sentences source articles current research focus process sentences read fluently whole current aesop task encourages research evaluating summaries content readability overall responsiveness work adapt machine translation metric measure content coverage apply enhanced discourse coherence model evaluate summary readability combine trained regression model evaluate overall responsiveness results show significantly improved performance aesop submitted metrics combining coherence models machine translation evaluation metrics summarization evaluation combining coherence models machine translation evaluation metrics summarization evaluation combining coherence models machine translation evaluation metrics summarization evaluation 
paper presents model constituent parsing aimed utilizing local structural context decide score grammar rule instance parse tree experiments english chinese treebanks confirm advantage version achieves best scores two languages respectively pushes via combination highperformance parsers higher-order constituent parsing parser combination higher-order constituent parsing parser combination higher-order constituent parsing parser combination 
stanford dependencies widely used natural language processing semanticallyoriented representation commonly generated either converting output constituent parser ii predicting dependencies directly previous comparisons two approaches english suggest starting constituents yields higher accuracies paper methods chinese using accurate dependency parsers previous work comparison performance efficiency across seven popular open source parsers four constituent three dependency shows contrast recent techniques accurate though somewhat slower constituent parsers demonstrate also jackknifing useful technique producing automatic rather gold tags train chinese dependency parsers finally analyze relations produced kinds parsing suggest specific parsers use practice comparison chinese parsers stanford dependencies comparison chinese parsers stanford dependencies comparison chinese parsers stanford dependencies 
paper presents extension chiang hierarchical hpb model called hpb incorporates head information translation rules better capture information well improved reordering two neighboring stage derivation explore larger reordering search space experiments translation four nist mt test sets show model significantly outperforms chiang model average gains points absolute bleu head-driven hierarchical phrase-based translation head-driven hierarchical phrase-based translation head-driven hierarchical phrase-based translation 
although researchers conducted extensive studies relation extraction last decade supervised approaches still limited require large amounts training data achieve high performances build relation extractor without significant annotation effort exploit annotation projection leverages parallel corpora external resources supervision paper proposes novel projection approach demonstrates merits using korean relation extraction system based projected dataset parallel corpus graph-based cross-lingual projection approach weakly supervised relation extraction graph-based cross-lingual projection approach weakly supervised relation extraction graph-based cross-lingual projection approach weakly supervised relation extraction 
paper presents comparative study target dependency structures yielded several linguistic parsers approach measure impact nonisomorphic dependency structures used translation besides using traditional dependency parsers also use dependency structures transformed pcfg trees structures pass generated hpsg parser ccg parser experiments translation show hpsg parser pass achieved best dependency translation accuracies comparative study target dependency structures statistical machine translation comparative study target dependency structures statistical machine translation comparative study target dependency structures statistical machine translation 
propose probabilistic generative model unsupervised semantic role induction integrates local role assignment decisions global role ordering decision unified model role sequence divided intervals based notion primary roles interval generates sequence secondary roles syntactic constituents using local features global role ordering consists sequence primary roles thus making partial ordering unsupervised semantic role induction global role ordering unsupervised semantic role induction global role ordering unsupervised semantic role induction global role ordering 
previous approaches instruction interpretation required either extensive domain adaptation manually annotated corpora paper presents novel approach instruction interpretation leverages large amount unannotated data humans interacting virtual world compare several algorithms automatically segmenting discretizing data utterance reaction pairs training classifier predict reactions given next utterance empirical analysis shows best algorithm achieves accuracy task manual annotation required corpus-based interpretation instructions virtual environments corpus-based interpretation instructions virtual environments corpus-based interpretation instructions virtual environments 
syntactic analysis search queries important variety tasks however lack annotated data makes training query analysis models difficult propose simple efficient procedure tags transferred snippets queries training time unlike previous work final model require additional resources compared approach achieve relative error reduction additionally annotate corpus search queries tags providing resource future work syntactic query analysis using search-logs improve query tagging using search-logs improve query tagging using search-logs improve query tagging 
paper introduce novel task word epoch disambiguation defined problem identifying changes word usage time experiments run using word usage examples collected three major periods time show task feasible significant differences observed occurrences words different periods time word epoch disambiguation: finding words change time word epoch disambiguation: finding words change time word epoch disambiguation: finding words change time 
dominant practice statistical machine translation smt uses chinese word segmentation specification alignment translation rule induction steps building smt system may suffer suboptimal problem word segmentation better alignment necessarily better translation tackle propose framework uses two different segmentation specifications alignment translation respectively use chinese character basic unit alignment convert alignment conventional word alignment translation rule induction experimentally approach outperformed two baselines fully system using word alignment translation fully system terms alignment quality translation performance enhancing statistical machine translation character alignment enhancing statistical machine translation character alignment enhancing statistical machine translation character alignment 
paper propose novel method reducing size translation model hierarchical machine translation systems previous approaches try prune infrequent entries unreliable entries based statistics cause problem reducing translation coverage contrary proposed method try prune ineffective entries based estimation information redundancy encoded phrase pairs hierarchical rules thus preserve search space smt decoders much possible experimental results machine translation tasks show method able reduce almost half size translation model tiny degradation translation performance translation model size reduction hierarchical phrase-based statistical machine translation translation model size reduction hierarchical phrase-based statistical machine translation translation model size reduction hierarchical phrase-based statistical machine translation 
propose novel heuristic algorithm cube pruning running linear time beam size empirically show gain running time standard machine translation system small loss accuracy heuristic cube pruning linear time heuristic cube pruning linear time heuristic cube pruning linear time 
propose several techniques improving statistical machine translation languages scarce resources use translation trained bitexts tuned using bleu augment transliteration word level combine translation model evaluation movie subtitles shows improvement bleu points baseline combining word-level character-level models machine translation closely-related languages combining word-level character-level models machine translation closely-related languages combining word-level character-level models machine translation closely-related languages 
introduce novel method grammatical error correction number small corpora make best use several corpora different characteristics employ several base classifiers trained different corpora research focuses grammatical error correction task article errors series experiments presented show effectiveness proposed approach two different grammatical error tagged corpora meta learning approach grammatical error correction meta learning approach grammatical error correction meta learning approach grammatical error correction 
investigate consistency human assessors involved summarization evaluation understand effect system ranking automatic evaluation techniques using text analysis conference data measure annotator consistency based human scoring summaries responsiveness readability pyramid scoring identify inconsistencies data measure extent inconsistencies affect ranking automatic summarization systems finally examine stability automatic metrics rouge classy respect inconsistent assessments assessing effect inconsistent assessors summarization evaluation assessing effect inconsistent assessors summarization evaluation assessing effect inconsistent assessors summarization evaluation 
paper presents comparative study spelling errors corrected type vs remain uncorrected first generate naturally occurring online error correction data logging users keystrokes automatically deriving postcorrection strings perform analysis data errors remain final text well across languages analysis shows clear distinction types errors generated remain uncorrected well across languages spelling errors generated corrected? study corrected uncorrected spelling errors using keystroke logs spelling errors generated corrected? study corrected uncorrected spelling errors using keystroke logs spelling errors generated corrected? study corrected uncorrected spelling errors using keystroke logs 
examine frequently disregarded subtleties tokenization penn treebank style present new preprocessing toolkit reproduces treebank tokenization unmatched accuracy also maintains exact pointers original text allows flexible configuration diverse use cases genreor idiosyncrasies tokenization: returning long solved problem ?a survey, contrastive experiment, recommendations, toolkit ? tokenization: returning long solved problem ?a survey, contrastive experiment, recommendations, toolkit ? tokenization: returning long solved problem ?a survey, contrastive experiment, recommendations, toolkit ? 
present uwn large multilingual lexical knowledge base describes meanings relationships words languages paper explains link prediction information integration taxonomy induction methods used build uwn based wordnet extend millions named entities wikipedia additionally introduce extensions cover lexical relationships knowledge language data online interface provides human access data software api enables applications look million words names uwn: large multilingual lexical knowledge base uwn: large multilingual lexical knowledge base uwn: large multilingual lexical knowledge base 
paper investigate supervised machine learning framework identifying english phrasal verbs given context concentrate define confusing phrasal verbs sense commonly used ones whose occurrence may correspond either true phrasal verb alignment simple verb preposition construct benchmark dataset sentences bnc annotated via internet crowdsourcing platform dataset split two groups idiomatic group consists tend used true phrasal verb compositional group tends used either way build discriminative classifier easily available lexical syntactic features test datasets classifier overall achieves accuracy error deduction compared corpus majority baseline however even interesting discover classifier learns compositional examples idiomatic ones sorting confusing english phrasal verbs sorting confusing english phrasal verbs sorting confusing english phrasal verbs 
joint conference lexical computational semantics sem year hosts shared task semantic related topics first edition held shared task dedicated resolving scope focus negation paper presents specifications datasets evaluation criteria task overview participating systems provided results summarized *sem 2012 shared task: resolving scope focus negation *sem 2012 shared task: resolving scope focus negation *sem 2012 shared task: resolving scope focus negation 
semeval shared task based recently introduced spatial annotation scheme called spatial role labeling spatial role labeling task concerns extraction main components spatial semantics natural language trajectors landmarks spatial indicators addition major components links spatial relationships including region direction distance targeted annotated dataset contains sentences describe images clef iapr image benchmark one participant system two runs participant runs compared system kordjamshidi et al provided task organizers semeval-2012 task 3: spatial role labeling semeval-2012 task 3: spatial role labeling semeval-2012 task 3: spatial role labeling 
paper presents shared task chinese semantic dependency parsing goal task identify dependency structure chinese sentences semantic view firstly introduce motivation providing chinese semantic dependency parsing task describe task detail including data preparation data format task evaluation ten thousand sentences labeled participants train evaluate systems last briefly describe submitted systems analyze results semeval-2012 task 5: chinese semantic dependency parsing semeval-2012 task 5: chinese semantic dependency parsing semeval-2012 task 5: chinese semantic dependency parsing 
choice plausible alternatives copa task presents series questions wherein question provides premise two viable cause effect scenarios correct answer cause effect plausible paper describes copacetic system developed university texas dallas utd task approach task casting classification problem using features derived bigram timeml temporal links events polarities harvard general inquirer causal syntactic dependency structures within gigaword corpus additionally show although components improves score evaluation difference accuracy using features using bigram information alone statistically significant problem surfer caught wave statement although almost tautological human understanding requires considerable depth semantic reasoning surfer mean catch wave concepts related want ascertain given surfer caught wave whether likely next event wave carried shore paddled board ocean type causal temporal reasoning requires breadth often called commonsense understanding question find effect premise poured water sleeping friend alternative friend awoke alternative friend snored question find cause premise man closed umbrella alternative got car alternative approached building figure example type question one targeting effect another targeting cause seventh task evaluates precisely type cogitation copa choice plausible alternatives presents sets questions presented premise two alternatives provided simple english sentences goal question choose plausible cause effect entailed premise dataset provided equal distribution cause effect targetting questions additionally question labeled describe whether answer cause effect indicated utdhlt: copacetic system choosing plausible alternatives utdhlt: copacetic system choosing plausible alternatives utdhlt: copacetic system choosing plausible alternatives 
paper describes new method crosslingual textual entailment clte detection based machine translation mt use translations different mt systems available online source crosslingual knowledge work describe evaluate different features derived translations used support vector machine classifier detect cltes presented system semeval task obtaining accuracy english spanish test set second best performing approach contest ualacant: using online machine translation cross-lingual textual entailment ualacant: using online machine translation cross-lingual textual entailment ualacant: using online machine translation cross-lingual textual entailment 
goal semantic dependency parsing build dependency structure label semantic relation head modifier attain goal concentrate obtaining better dependency structure predict better semantic relations propose method combine results three dependency parsers unfortunately made mistake generate final output results lower score term labeled attachment score las reported organizers giving golden testing set fix bug rerun evaluation script time obtain score consistent results developing set report detailed experimental results correct program comparison standard research ict:a system combination chinese semantic dependency parsing ict:a system combination chinese semantic dependency parsing ict:a system combination chinese semantic dependency parsing 
paper presents work hong kong polytechnic university polyucomp team participated semantic textual similarity task polyucomp system combines semantic vectors skip bigrams determine sentence similarity semantic vector used compute similarities sentence pairs using lexical database wordnet wikipedia corpus use skip bigram introduce order words measuring sentence similarity polyucomp: combining semantic vectors skip bigrams semantic textual similarity polyucomp: combining semantic vectors skip bigrams semantic textual similarity polyucomp: combining semantic vectors skip bigrams semantic textual similarity 
paper describes participation irit team semeval task semantic textual similarity method used consists based comparison method combined conceptual similarity measure uses wordnet calculate similarity pair concepts irit: textual similarity combining conceptual similarity n-gram comparison method irit: textual similarity combining conceptual similarity n-gram comparison method irit: textual similarity combining conceptual similarity n-gram comparison method 
estimate semantic similarity two sentences using regression models features hit rates lexical matches sentences lexical semantic similarity words sentence length lexical semantic similarity computed via counts corpus harvested web using modified mutual information metric results obtained semantic similarity computation word level however fusion information sentence level provides moderate improvement task semeval despite simple features used regression models provide good performance especially shorter sentences reaching correlation semeval test set deeppurple: estimating sentence semantic similarity using n-gram regression models web snippets deeppurple: estimating sentence semantic similarity using n-gram regression models web snippets deeppurple: estimating sentence semantic similarity using n-gram regression models web snippets 
paper aims come system examines degree semantic equivalence two sentences core paper attempt grade similarity two sentences finding maximal weighted bipartite match tokens two sentences tokens include single words multiwords case named entitites adjectivally numerically modified words two token similarity measures used task wordnet based similarity statistical word similarity measure overcomes shortcomings wordnet based similarity part three systems created task explore simple bag words tokenization scheme careful tokenization scheme captures named entities times dates monetary entities etc finally try capture context around tokens using grammatical dependencies sranjans : semantic textual similarity using maximal weighted bipartite graph matching sranjans : semantic textual similarity using maximal weighted bipartite graph matching sranjans : semantic textual similarity using maximal weighted bipartite graph matching 
paper describe system submitted semantic textual similarity sts task semeval implemented two approaches calculate degree similarity two sentences first approach combines semantic relatedness measure whole sentence semantic similarity scores obtained words falling syntactic roles sentences fed scores features machine learning models obtain single score giving degree similarity sentences linear regression bagging models used purpose used explicit semantic analysis esa semantic relatedness measure knowledgebased semantic similarity words modified wordnet based lin measure used second approach uses bipartite based method wordnet based lin measure without modification paper shows significant improvement calculating semantic similarity sentences fusion similarity measure relatedness measure corpus based measure taken alone deri&upm: pushing corpus based relatedness similarity: shared task system description deri&upm: pushing corpus based relatedness similarity: shared task system description deri&upm: pushing corpus based relatedness similarity: shared task system description 
present penn system semeval task computing degree semantic equivalence two sentences explore contributions different vector models computing sentence word similarity collobert weston embeddings well two novel approaches namely eigenwords selectors embeddings provide different measures distributional similarity words contexts used regression combine different similarity measures found provides partially independent predictive signal baseline models penn: using word similarities better estimate sentence similarity penn: using word similarities better estimate sentence similarity penn: using word similarities better estimate sentence similarity 
proceedings th conference european chapter association computational linguistics pages avignon france april association computational linguistics pluto automated solutions patent translation john tinsley alexandru ceausu jian zhang centre next generation localisation school computing dublin city university ireland jtinsley aceausu jzhang computing dcu ie pluto: automated solutions patent translation pluto: automated solutions patent translation pluto: automated solutions patent translation 
present automatic approach combines translation systems produce syntactic trees output nodes generation tree targetside scfg tree aligned form basis computing structural similarity structural similarity computation aligns subtrees based alignment subtrees substituted create accurate translations two different techniques implemented compute structural similarity leaves distance report translation quality machine translation mt system techniques implemented approach shows significant improvement baseline mt systems limited training data structural improvement mt systems trained europarl tree-based hybrid machine translation tree-based hybrid machine translation tree-based hybrid machine translation 
describe hybrid machine translation mt system extended machine learning component controlling phrase selection approach based mt rbmt system creates template translations based generation parse tree rbmt system standard word alignment computation identify potential translation snippets one translation engines could substituted translation templates substitution process controlled binary classifier trained feature vectors different mt engines using set manually annotated training data able observe improvements terms bleu scores baseline version hybrid system machine learning algorithms improve phrase selection hybrid machine translation? machine learning algorithms improve phrase selection hybrid machine translation? machine learning algorithms improve phrase selection hybrid machine translation? 
paper present linguisticallyaugmented statistical machine translation model bulgarian english combines statistical machine translation smt system backbone deep linguistic features factors motivation take advantages robustness smt system linguistic knowledge morphological analysis grammar system combination approach preliminary evaluation shown promising results terms bleu scores manual analysis also confirms high quality translation system delivers linguistically-augmented bulgarian-to-english statistical machine translation model linguistically-augmented bulgarian-to-english statistical machine translation model linguistically-augmented bulgarian-to-english statistical machine translation model 
article shows automatic disambiguation discourse connectives improve statistical machine translation smt english french connectives firstly disambiguated terms discourse relation signal segments several classifiers trained using syntactic semantic features reach performance scores thirteen ambiguous english connectives labeled connectives used smt systems either modifying phrase table training labeled corpora best modified smt systems improve translation connectives without degrading bleu scores smt system using labels improves bleu scores points using sense-labeled discourse connectives statistical machine translation using sense-labeled discourse connectives statistical machine translation using sense-labeled discourse connectives statistical machine translation 
paper presents iterative algorithm bilingual lexicon extraction comparable corpora based model generated level sentences present results experimentation corpora multiple degrees comparability derived fire dataset evaluation results nouns shows method outperforms standard based approaches co-occurrence graph based iterative bilingual lexicon extraction comparable corpora co-occurrence graph based iterative bilingual lexicon extraction comparable corpora co-occurrence graph based iterative bilingual lexicon extraction comparable corpora 
numerous sentiment analysis applications make usage sentiment lexicon paper present experiments hybrid sentiment lexicon acquisition approach thus suitable languages lacking general dictionarybased resources approach hybrid process combines semisupervised algorithms supervised models evaluate performance three tasks capture different aspects sentiment lexicon polarity ranking task polarity regression task sentiment classification task extensive evaluation shows results comparable sentiment lexicon sentiwordnet polarity ranking task sentiment classification task results also comparable sentiwordnet restricted monosentimous senses carry sentiment words satisfactory given absence explicit semantic relations words corpus experiments hybrid corpus-based sentiment lexicon acquisition experiments hybrid corpus-based sentiment lexicon acquisition experiments hybrid corpus-based sentiment lexicon acquisition 
paper describes several novel hybrid semantic similarity measures study various combinations baseline measures based wordnet web corpus corpora dictionaries encyclopedia hybrid measures rely combination methods measure selection techniques evaluated task predicting semantic similarity scores task predicting semantic relation two terms results show hybrid measures outperform single measures wide margin achieving correlation map study hybrid similarity measures semantic relation extraction study hybrid similarity measures semantic relation extraction study hybrid similarity measures semantic relation extraction 
dependency parsing made many advancements recent years particular english dependency parsers achieve comparable accuracy scores different types errors paper examines creating new dependency structure ensemble learning using hybrid outputs various parsers combine tree outputs weighted edge graph using weighting mechanisms weighted edge graph input ensemble system hybrid different parsing techniques constituent parsers transitionbased dependency parsers graphbased parser graph take maximum spanning tree examine new dependency structure terms accuracy errors individual values results indicate using greater number varied parsers improve accuracy results combined ensemble system using parsers based different parsing techniques achieves accuracy score beating single parsers wall street journal section test set additionally ensemble system reduces average relative error selected pos tags hybrid combination constituency dependency trees ensemble dependency parser hybrid combination constituency dependency trees ensemble dependency parser hybrid combination constituency dependency trees ensemble dependency parser 
prepositions hard translate meaning often vague choice correct preposition often arbitrary time making correct choice often critical coherence output text context statistical machine translation difficulty enhanced due possible long distance preposition head modifies opposed local nature standard language models work use monolingual language resources determine set prepositions likely occur verb use information statistical machine translation system show incorporating linguistic knowledge distribution prepositions significantly improves translation quality incorporating linguistic knowledge statistical machine translation: translating prepositions incorporating linguistic knowledge statistical machine translation: translating prepositions incorporating linguistic knowledge statistical machine translation: translating prepositions 
recognizing speech act types twitter much theoretical interest practical use previous research adequately address deficiency training data learning task work set assuming small seed training set experiment two learning schemes transductive svm label propagation leverage knowledge unlabeled data efficacy learning established extensive experiments also show transductive svm suitable label propagation task empirical findings detailed evidences contribute scalable speech act recognition twitter towards scalable speech act recognition twitter: tackling insufficient training data towards scalable speech act recognition twitter: tackling insufficient training data towards scalable speech act recognition twitter: tackling insufficient training data 
classifying blog posts topics useful applications search marketing however topic classification time consuming error prone especially open domain blogosphere relies supervised methods requiring considerable training effort use whole corpus vocabulary features demanding considerable memory process show effective alternative whereby distant supervision used obtain training data use wikipedia articles labelled freebase domains address memory requirements using named entities features test classifier sample blog posts report accuracy labelling binary classification topic classification blog posts using distant supervision topic classification blog posts using distant supervision topic classification blog posts using distant supervision 
surface realisation shared task first run two input representations developed first time several independently developed surface realisers produced realisations shared inputs however input representations several shortcomings aiming address time since paper reports work date improving input representations plans next edition sr task also briefly summarise related developments nlg shared tasks outline different ideas may usefully brought together future surface realisation task: recent developments future plans surface realisation task: recent developments future plans surface realisation task: recent developments future plans 
inlg proceedings th international natural language generation conference pages utica may association computational linguistics kbgen text generation knowledge bases new shared task eva banik claire gardent donia scott nikhil dinesh fennie liang ebanik co uk computational linguistics ltd london uk claire gardent loria fr cnrs loria nancy france scott sussex ac uk school informatics university sussex brighton uk dinesh ai sri com sri international menlo park ca fennie liang cs man ac uk school computer science university manchester uk kbgen ?text generation knowledge bases new shared task kbgen ?text generation knowledge bases new shared task kbgen ?text generation knowledge bases new shared task 
robust system understands route instructions able process instructions generated naturally humans also desirable would ability handle repairs modifications existing instructions end collected corpus spoken instructions modified instructions produced subjects provided origin destination found instructions could classified four categories depending intent imperative feedback meta comment asked different set subjects follow instructions determine usefulness comprehensibility individual instructions finally constructed semantic grammar evaluated coverage determine whether instructiongiving forms predictable tested grammar three corpora collected others determined largely case work suggests predictable may exist tasks index terms robot navigation spoken instructions structure generality spoken route instructions structure generality spoken route instructions structure generality spoken route instructions 
work study effectiveness speaker adaptation dialogue act recognition multiparty meetings first analyze idiosyncracy dialogue verbal acts qualitatively studying differences conflicts among speakers quantitively comparing models based observations propose new approach dialogue act recognition based reweighted domain adaptation effectively balance influence speaker specific speakers data experiments realworld meeting dataset show even annotated dialogue acts performances dialogue act recognition significantly improved compared several baseline algorithms knowledge work first tackle promising research direction speaker adaptation dialogue act recogntion dialogue act recognition using reweighted speaker adaptation dialogue act recognition using reweighted speaker adaptation dialogue act recognition using reweighted speaker adaptation 
probabilistic grammars pcfgs popular cognitive model syntax jurafsky formulated sensitive human working memory constraints application transform schuler one transform guarantees single expansion push single reduction pop syntactic parse primary finding paper property parsing exploited obtain dramatic reduction number random variables probabilistic sequence model parser yields simpler structure closely resembles existing simple recurrent network models sentence comprehension connectionist-inspired incremental pcfg parsing connectionist-inspired incremental pcfg parsing connectionist-inspired incremental pcfg parsing 
system consists simple induction algorithm bisk hockenmaier induces combinatory categorial grammar ccg lexicon based small number linguistic principles verbs may roots sentences take nouns arguments induction linguistic structure combinatory categorial grammars induction linguistic structure combinatory categorial grammars induction linguistic structure combinatory categorial grammars 
date attempts made develop new methods validate existing ones automatic evaluation discourse coherence noisy domain learner texts present first systematic analysis several methods assessing coherence framework automated assessment aa learner responses examine predictive power different coherence models measuring effect performance combined aa system achieves competitive results use discourse coherence features also strong indicators learner level attainment additionally identify new techniques outperform previously developed ones improve best published result aa dataset english learner examination scripts modeling coherence esol learner texts modeling coherence esol learner texts modeling coherence esol learner texts 
paper describes submission national university singapore nus hoo shared task system uses pipeline linear classifiers correct determiner preposition errors system achieves highest correction score official test set among participating teams based edits revision nus hoo 2012 shared task nus hoo 2012 shared task nus hoo 2012 shared task 
paper describes nara institute science technology naist error correction system helping hoo shared task system targets preposition determiner errors spelling correction step result shows spelling correction improves detection correction recognition fscores preposition errors regard preposition error correction improved using training set correction preposition errors determiner error correction improvement constituent parser trained concatenation treebank modified treebank articles appearing first word np removed system ranked third preposition fourth determiner error corrections naist hoo 2012 shared task naist hoo 2012 shared task naist hoo 2012 shared task 
